{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "satisfactory-crown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 42, 'trainer': {'gpus': 0, 'num_nodes': 1, 'max_epochs': 8, 'max_steps': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': 0, 'amp_level': 'O0', 'precision': 32, 'checkpoint_callback': False, 'logger': False, 'log_every_n_steps': 1, 'val_check_interval': 1.0, 'reload_dataloaders_every_epoch': True, 'resume_from_checkpoint': None}, 'exp_manager': {'exp_dir': '/home/nxingyu/project/', 'name': 'Punctuation_with_Domain_discriminator', 'create_tensorboard_logger': True, 'create_checkpoint_callback': True, 'restore_path': '/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-08_11-57-58/', 'override_config_path': '/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-08_11-57-58/hparams.yaml'}, 'base_path': '/home/nxingyu/data', 'tmp_path': '/home/nxingyu/data/tmp', 'model': {'nemo_path': None, 'transformer_path': 'google/electra-small-discriminator', 'unfrozen': 0, 'maximum_unfrozen': 1, 'unfreeze_step': 1, 'punct_label_ids': ['', '!', ',', '-', '.', ':', ';', '?', '—', '…'], 'punct_class_weights': False, 'dataset': {'data_dir': '/home/nxingyu/data', 'labelled': ['${base_path}/ted_talks_processed'], 'unlabelled': ['${base_path}/open_subtitles_processed'], 'max_seq_length': 128, 'pad_label': '', 'ignore_extra_tokens': False, 'ignore_start_end': False, 'use_cache': False, 'num_workers': 4, 'pin_memory': True, 'drop_last': False, 'num_labels': 10, 'num_domains': 2, 'test_unlabelled': True, 'train_ds': {'shuffle': True, 'num_samples': -1, 'batch_size': 4}, 'validation_ds': {'shuffle': True, 'num_samples': -1, 'batch_size': 4}}, 'tokenizer': {'tokenizer_name': '${model.language_model.pretrained_model_name}', 'vocab_file': None, 'tokenizer_model': None, 'special_tokens': None}, 'language_model': {'pretrained_model_name': '${model.transformer_path}', 'lm_checkpoint': None, 'config_file': None, 'config': None}, 'punct_head': {'punct_num_fc_layers': 1, 'fc_dropout': 0.1, 'activation': 'relu', 'log_softmax': False, 'use_transformer_init': True, 'loss': 'dice'}, 'domain_head': {'domain_num_fc_layers': 1, 'fc_dropout': 0.1, 'activation': 'relu', 'log_softmax': False, 'use_transformer_init': True, 'loss': 'cel', 'gamma': 0, 'pooling': 'mean_max', 'idx_conditioned_on': 0}, 'dice_loss': {'epsilon': 0.01, 'alpha': 3, 'macro_average': True}, 'focal_loss': {'gamma': 1}, 'optim': {'name': 'adamw', 'lr': 0.001, 'weight_decay': 0.0, 'sched': {'name': 'WarmupAnnealing', 'warmup_steps': None, 'warmup_ratio': 0.1, 'last_epoch': -1, 'monitor': 'val_loss', 'reduce_on_plateau': False}}}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hydra\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from data import PunctuationDataModule, PunctuationInferenceDataset\n",
    "import os\n",
    "from models import PunctuationDomainModel\n",
    "\n",
    "# from nemo.core.config import hydra_runner\n",
    "# from nemo.utils import logging\n",
    "from nemo.utils.exp_manager import exp_manager\n",
    "from time import time\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "import atexit\n",
    "from copy import deepcopy\n",
    "import snoop\n",
    "snoop.install()\n",
    "\n",
    "from hydra.experimental import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize()\n",
    "cfg=compose(\n",
    "    config_name=\"test_config.yaml\", \n",
    ")\n",
    "cfg.model.punct_label_ids=OmegaConf.create(sorted(cfg.model.punct_label_ids))\n",
    "labels_to_ids = {_[1]:_[0] for _ in enumerate(cfg.model.punct_label_ids)}\n",
    "ids_to_labels = {_[0]:_[1] for _ in enumerate(cfg.model.punct_label_ids)}\n",
    "cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "recreational-change",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:03:22.19 LOG:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling <data.punctuation_dataset_multi.PunctuationDomainDataset object at 0x7f0560766730>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:03:22.27 .... os.system('bash data/shuffle.sh -i {} -o {} -a {} -s {} -m {} -t {}'.format(self.target_file, self.target_file, ['true','false'][randomize], seed, '100M',self.tmp_path)) = 0\n",
      "09:03:22.32 LOG:\n",
      "09:03:22.59 .... f\"1st {n} encoder layers of transformer frozen\" = '1st 11 encoder layers of transformer frozen'\n"
     ]
    }
   ],
   "source": [
    "model = PunctuationDomainModel.load_from_checkpoint(checkpoint_path=\"/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-08_11-57-58/checkpoints/Punctuation_with_Domain_discriminator-last.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sporting-people",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "[NeMo W 2021-02-09 09:03:22 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
      "      warnings.warn(*args, **kwargs)\n",
      "    \n"
     ]
    },
    {
     "ename": "ModuleAttributeError",
     "evalue": "'PunctuationDomainModel' object has no attribute 'add_punctuation_capitalization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c069ed18000d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'how are you'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m ]\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0minference_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_punctuation_capitalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m    779\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'PunctuationDomainModel' object has no attribute 'add_punctuation_capitalization'"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(**cfg.trainer)\n",
    "queries = [\n",
    "    'we bought four shirts one pen and a mug from the nvidia gear store in santa clara',\n",
    "    'what can i do for you today',\n",
    "    'how are you',\n",
    "]\n",
    "inference_results = model.add_punctuation(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-level",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "political-monster",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PunctuationInferenceDataset' object has no attribute 'degree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5dcdb2b71e00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPunctuationInferenceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'google/electra-small-discriminator'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_to_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/project/experiment/data/punctuation_dataset_multi.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tokenizer, queries, max_seq_length, punct_label_ids, degree)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpunct_label_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;34m\"\"\" Initializes BertPunctuationInferDataset. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_examples_with_degree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunct_label_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_to_len_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'texts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabelled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PunctuationInferenceDataset' object has no attribute 'degree'"
     ]
    }
   ],
   "source": [
    "PunctuationInferenceDataset('google/electra-small-discriminator',queries,128,labels_to_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
