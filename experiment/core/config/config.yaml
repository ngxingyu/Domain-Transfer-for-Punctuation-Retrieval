base_path: /home/nxingyu2/data

trainer:
    gpus: 1 # the number of gpus, 0 for CPU
    num_nodes: 1
    max_epochs: 3
    max_steps: null # precedence over max_epochs
    accumulate_grad_batches: 1 # accumulates grads every k batches
    gradient_clip_val: 0.0
    amp_level: O0 # O1/O2 for mixed precision
    precision: 16 # Should be set to 16 for O1 and O2, default is 16 as PT ignores it when am_level is O0
    accelerator: ddp
    checkpoint_callback: false  # Provided by exp_manager
    logger: true #false  # Provided by exp_manager
    log_every_n_steps: 1  # Interval of logging.
    val_check_interval: 1.0  # Set to 0.25 to check 4 times per epoch, or an int for number of iterations
    resume_from_checkpoint: null

exp_manager:
    exp_dir: null  # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
    name: Punctuation_with_Domain_discriminator  # The name of your model
    create_tensorboard_logger: true  # Whether you want exp_manger to create a tb logger
    create_checkpoint_callback: true 

model:
    transformer_path: ${base_path}/electra-base-discriminator # filename to save the model and associated artifacts to .nemo file
    punct_label_ids:
        - ""
        - "!"
        - ","
        - "-"
        - "."
        - ":"
        - ";"
        - "?"
        - "—"
        - "…"

    dataset:
        data_dir: ${base_path} # /path/to/training/data
        labelled:
            - ${base_path}/ted_talks_processed
        unlabelled:
            - ${base_path}/open_subtitles_processed
            # parameters for dataset preprocessing
        max_seq_length: 128
        pad_label: ''
        ignore_extra_tokens: false
        ignore_start_end: false
        use_cache: true
        # shared among dataloaders
        num_workers:  2
        pin_memory: false
        drop_last: false

    

    train_ds:
        shuffle: true
        num_samples: -1
        batch_size: 64

    validation_ds:
        # if evaluation data is not in the model.dataset.data_dir as the training data or multiple datasets are used for
        # evaluationis needed, specify ds_item, otherwise by default data_dir is used
        ds_item: null # expected format: [PATH_TO_DEV1,PATH_TO_DEV2] (Note no space between the paths and square brackets)
        shuffle: false
        num_samples: -1
        batch_size: 64

    tokenizer:
        tokenizer_name: ${model.language_model.pretrained_model_name} # or sentencepiece
        vocab_file: null # path to vocab file
        tokenizer_model: null # only used if tokenizer is sentencepiece
        special_tokens: null

    language_model:
        pretrained_model_name: ${model.transformer_path} # bert-base-uncased
        lm_checkpoint: null
        config_file: null # json file, precedence over config
        config: null
        unfrozen_layers: 0

    punct_head:
        punct_num_fc_layers: 1
        fc_dropout: 0.1
        activation: 'relu'
        use_transformer_init: True
        loss: 'cel'

    domain_head:
        domain_num_fc_layers: 1
        fc_dropout: 0.1
        activation: 'relu'
        log_softmax: true
        use_transformer_init: true
        loss: 'cel'
        lbd: 1 # coefficient of gradient reversal
    
    dice_loss:
        alpha: 0.8
        gamma: 2

    optim:
        name: adam
        lr: 1e-4
        weight_decay: 0.00

    sched:
        name: WarmupAnnealing
        # Scheduler params
        warmup_steps: null
        warmup_ratio: 0.1
        last_epoch: -1

        # pytorch lightning args
        monitor: val_loss
        reduce_on_plateau: false
hydra:
    run:
        dir: .
    job_logging:
        formatters:
            simple:
                format: '[%(levelname)s] - %(message)s'
        handlers:
          console:
            class: logging.StreamHandler
            formatter: simple
            stream: ext://sys.stdout
          file:
            class: logging.FileHandler
            level: INFO
            formatter: simple
            filename: info.log
            encoding: utf8
            mode: w
        root:
          handlers: [console, file]
