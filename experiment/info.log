[INFO] - GPU available: True, used: True
[INFO] - TPU available: None, using: 0 TPU cores
[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[INFO] - Using native 16bit precision.
[INFO] - shuffling train set
[INFO] - Optimizer config = AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.02
    weight_decay: 0.0
)
[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7f467661b6d0>" 
will be used during training (effective maximum steps = 3750) - 
Parameters : 
(warmup_steps: null
warmup_ratio: 0.1
min_lr: 1.0e-08
last_epoch: -1
max_steps: 3750
)
[INFO] - 
  | Name                       | Type                 | Params
--------------------------------------------------------------------
0 | transformer                | ElectraModel         | 108 M 
1 | punct_classifier           | TokenClassifier      | 6.9 K 
2 | domain_classifier          | SequenceClassifier   | 4.7 M 
3 | punctuation_loss           | LinearChainCRF       | 99    
4 | domain_loss                | CrossEntropyLoss     | 0     
5 | agg_loss                   | AggregatorLoss       | 0     
6 | punct_class_report         | ClassificationReport | 0     
7 | chunked_punct_class_report | ClassificationReport | 0     
8 | domain_class_report        | ClassificationReport | 0     
--------------------------------------------------------------------
18.9 M    Trainable params
94.7 M    Non-trainable params
113 M     Total params
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          72.95      38.21      50.15      57792
! (label_id: 1)                                          0.11       1.28       0.21        312
# (label_id: 2)                                         11.34      26.52      15.89      11236
, (label_id: 3)                                          1.87       0.26       0.46       4572
- (label_id: 4)                                          0.46       7.51       0.86        346
. (label_id: 5)                                         17.53       4.09       6.63       8946
: (label_id: 6)                                          0.00       0.00       0.00          2
? (label_id: 7)                                          0.00       0.00       0.00       1582
… (label_id: 8)                                          0.35       2.60       0.61        616
-------------------
micro avg                                               29.84      29.84      29.84      85404
macro avg                                               11.62       8.94       8.31      85404
weighted avg                                            52.79      29.84      36.75      85404

-------------------
                       !           #           ,           -           .           :           ?           …
    22082.00        50.00      3852.00      1200.00       118.00      2504.00         0.00       354.00       112.00
     2528.00         4.00       444.00       144.00         8.00       306.00         0.00       116.00        30.00
    16040.00       166.00      2980.00      2036.00       112.00      3906.00         2.00       698.00       332.00
      516.00         0.00        92.00        12.00         0.00        22.00         0.00         0.00         0.00
     3568.00        22.00      1608.00       152.00        26.00       234.00         0.00        50.00        16.00
     1380.00        16.00        86.00       136.00        14.00       366.00         0.00        78.00        12.00
     7732.00        50.00      1106.00       802.00        36.00      1464.00         0.00       270.00        94.00
      638.00         0.00        54.00         4.00         2.00         0.00         0.00         0.00         4.00
     3308.00         4.00      1014.00        86.00        30.00       144.00         0.00        16.00        16.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                        100.00     100.00     100.00        684
-------------------
micro avg                                              100.00     100.00     100.00        684
macro avg                                              100.00     100.00     100.00        684
weighted avg                                           100.00     100.00     100.00        684

-------------------
           0
      684.00
-------------------

[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          97.34      92.50      94.86   32706272
! (label_id: 1)                                         19.06      47.94      27.27     593839
# (label_id: 2)                                         91.67      95.00      93.30    6536760
, (label_id: 3)                                         48.09      47.29      47.69    2690401
- (label_id: 4)                                         46.12      44.96      45.53     260726
. (label_id: 5)                                         64.75      66.27      65.50    4897272
: (label_id: 6)                                         41.45      56.67      47.88      14055
? (label_id: 7)                                         68.00      47.52      55.95    1307202
… (label_id: 8)                                          9.42      28.71      14.19     396834
-------------------
micro avg                                               85.27      85.27      85.27   49403360
macro avg                                               53.99      58.54      54.69   49403360
weighted avg                                            87.97      85.27      86.41   49403360

-------------------
                       !           #           ,           -           .           :           ?           …
 30254648.00     15160.00    314617.00    182162.00     30256.00    153734.00       864.00     55738.00     74527.00
   136137.00    284703.00      1649.00    313008.00     16991.00    592909.00       616.00    106949.00     40959.00
   542520.00       296.00   6209611.00      6706.00      7163.00      5250.00        16.00       728.00      1392.00
   534901.00     67722.00      2049.00   1272323.00     14151.00    583890.00      1097.00    104145.00     65575.00
   115275.00      1697.00      1032.00      6042.00    117219.00      8938.00        40.00      1673.00      2233.00
   534368.00    188730.00      4128.00    545198.00     28653.00   3245473.00      2545.00    377232.00     85956.00
     5005.00        48.00       496.00      2648.00      1600.00      1344.00      7965.00        32.00        80.00
    94649.00     20039.00       456.00     62950.00      3709.00     98264.00        80.00    621234.00     12197.00
   488844.00     15444.00      2722.00    299364.00     40984.00    207470.00       832.00     39471.00    113915.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                        100.00     100.00     100.00     394112
-------------------
micro avg                                              100.00     100.00     100.00     394112
macro avg                                              100.00     100.00     100.00     394112
weighted avg                                           100.00     100.00     100.00     394112

-------------------
           0
   394112.00
-------------------

[INFO] - Epoch 0, step 8124: val_loss was not in top 3
[INFO] - Internal process exited
