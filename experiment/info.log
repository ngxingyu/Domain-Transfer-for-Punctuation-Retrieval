[INFO] - Global seed set to 42
[INFO] - GPU available: True, used: True
[INFO] - TPU available: None, using: 0 TPU cores
[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
[INFO] - Using native 16bit precision.
[INFO] - shuffling train set
[INFO] - Global seed set to 42
[INFO] - initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
[INFO] - Optimizer config = AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 2
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 3
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 4
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 5
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 6
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 7
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 8
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 9
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 10
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 11
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 12
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 13
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 14
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 15
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 16
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 17
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 18
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 19
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 20
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 21
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 22
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 23
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 24
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 25
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 26
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 27
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 28
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 29
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 30
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 31
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 32
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 33
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 34
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 35
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 36
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 37
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 38
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 39
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 40
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 41
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 42
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 43
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 44
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 45
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 46
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 47
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 48
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 49
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 50
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 51
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 52
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 53
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 54
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 55
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 56
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 57
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 58
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 59
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 60
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 61
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 62
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 63
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 64
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 65
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 66
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 67
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 68
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 69
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 70
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 71
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 72
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 73
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 74
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 75
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 76
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 77
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 78
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 79
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 80
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 81
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 82
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 83
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 84
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 85
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 86
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 87
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 88
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 89
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 90
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 91
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 92
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 93
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 94
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 95
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 96
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 97
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 98
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 99
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 100
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 101
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 102
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 103
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 104
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 105
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 106
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 107
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 108
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 109
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 110
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 111
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 112
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 113
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 114
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 115
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 116
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 117
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 118
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 119
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 120
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 121
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 122
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 123
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 124
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 125
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 126
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 127
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 128
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 129
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 130
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 131
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 132
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 133
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 134
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 135
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 136
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 137
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 138
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 139
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 140
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 141
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 142
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 143
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 144
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 145
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 146
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 147
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 148
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 149
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 150
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 151
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 152
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 153
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 154
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 155
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 156
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 157
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 158
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 159
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 160
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 161
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 162
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 163
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 164
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 165
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 166
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 167
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 168
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 169
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 170
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 171
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 172
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 173
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 174
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 175
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 176
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 177
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 178
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 179
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 180
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 181
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 182
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 183
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 184
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 185
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 186
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 187
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 188
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 189
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 190
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 191
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 192
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0
)
[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7fba6978f520>" 
will be used during training (effective maximum steps = 3000) - 
Parameters : 
(warmup_steps: null
warmup_ratio: 0.1
min_lr: 1.0e-08
last_epoch: -1
max_steps: 3000
)
[INFO] - 
  | Name                       | Type                 | Params
--------------------------------------------------------------------
0 | transformer                | ElectraModel         | 108 M 
1 | punct_classifier           | TokenClassifier      | 601 K 
2 | domain_classifier          | SequenceClassifier   | 593 K 
3 | punctuation_loss           | FocalDiceLoss        | 0     
4 | domain_loss                | FocalDiceLoss        | 0     
5 | agg_loss                   | AggregatorLoss       | 0     
6 | punct_class_report         | ClassificationReport | 0     
7 | chunked_punct_class_report | ClassificationReport | 0     
8 | domain_class_report        | ClassificationReport | 0     
--------------------------------------------------------------------
43.7 M    Trainable params
66.4 M    Non-trainable params
110 M     Total params
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          56.19       1.84       3.56      47634
! (label_id: 1)                                          0.69      41.88       1.36        308
, (label_id: 2)                                          9.43       5.06       6.59       5139
- (label_id: 3)                                          0.34      19.27       0.68        384
. (label_id: 4)                                          3.06       0.34       0.61       4156
: (label_id: 5)                                          0.24      13.64       0.48         22
? (label_id: 6)                                          1.81       5.43       2.71        663
… (label_id: 7)                                          0.93      29.75       1.80        326
-------------------
micro avg                                                2.54       2.54       2.54      58632
macro avg                                                2.36      16.48       2.03      58632
weighted avg                                            46.73       2.54       3.57      58632

-------------------
                       !           ,           -           .           :           ?           …
      876.00        11.00       381.00        16.00       201.00         0.00        39.00        35.00
    15260.00       129.00      1324.00       103.00      1513.00         5.00       253.00        90.00
     2209.00         9.00       260.00         3.00       202.00         1.00        49.00        23.00
    18823.00        63.00      1103.00        74.00      1152.00        11.00       182.00        65.00
      417.00         0.00        23.00         0.00        14.00         0.00         4.00         0.00
      928.00        12.00        95.00         6.00       166.00         3.00        25.00         5.00
     1443.00        27.00       206.00        14.00       252.00         0.00        36.00        11.00
     7678.00        57.00      1747.00       168.00       656.00         2.00        75.00        97.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                         32.79     100.00      49.38        180
1 (label_id: 1)                                          0.00       0.00       0.00        189
2 (label_id: 2)                                          0.00       0.00       0.00        180
-------------------
micro avg                                               32.79      32.79      32.79        549
macro avg                                               10.93      33.33      16.46        549
weighted avg                                            10.75      32.79      16.19        549

-------------------
           0           1           2
      180.00       189.00       180.00
        0.00         0.00         0.00
        0.00         0.00         0.00
-------------------

[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          99.13      91.66      95.25   11437247
! (label_id: 1)                                         13.01      72.53      22.06      81158
, (label_id: 2)                                         52.68      68.00      59.37    1228179
- (label_id: 3)                                         59.03      89.82      71.24     106983
. (label_id: 4)                                         66.22      48.86      56.23    1097538
: (label_id: 5)                                          0.00       0.00       0.00       6888
? (label_id: 6)                                         43.60      78.07      55.95     188625
… (label_id: 7)                                         16.85      47.24      24.84     123634
-------------------
micro avg                                               85.60      85.60      85.60   14270252
macro avg                                               35.91      57.79      41.38   14270252
weighted avg                                            90.31      85.60      87.39   14270252

-------------------
                       !           ,           -           .           :           ?           …
 10483169.00      1352.00     56202.00      3453.00     21556.00       541.00      3229.00      6139.00
    63225.00     58860.00     92665.00      1609.00    203451.00       396.00     19208.00     13055.00
   622464.00      2136.00    835119.00      3543.00     95884.00      2695.00      4638.00     18738.00
    59321.00       270.00      3131.00     96095.00      3228.00       389.00       121.00       225.00
   110830.00     12429.00    115248.00      1359.00    536215.00      2641.00     10700.00     20362.00
        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
    79629.00      6030.00     42040.00       548.00     55345.00       214.00    147265.00      6709.00
    18609.00        81.00     83774.00       376.00    181859.00        12.00      3464.00     58406.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                         93.17      90.36      91.74      44403
1 (label_id: 1)                                         94.52      94.62      94.57      46969
2 (label_id: 2)                                         94.72      97.63      96.15      41910
-------------------
micro avg                                               94.15      94.15      94.15     133282
macro avg                                               94.14      94.20      94.15     133282
weighted avg                                            94.13      94.15      94.13     133282

-------------------
           0           1           2
    40121.00      2234.00       706.00
     2290.00     44444.00       288.00
     1992.00       291.00     40916.00
-------------------

[INFO] - Epoch 0, global step 749: val_loss reached 0.51531 (best 0.51531), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-28_11-56-37/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.52-epoch=0.ckpt" as top 3
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          99.26      92.23      95.61   11437247
! (label_id: 1)                                         10.81      83.78      19.15      81158
, (label_id: 2)                                         57.70      65.62      61.40    1228179
- (label_id: 3)                                         56.97      90.71      69.98     106983
. (label_id: 4)                                         64.33      46.92      54.26    1097538
: (label_id: 5)                                         13.53      15.62      14.50       6888
? (label_id: 6)                                         48.86      77.24      59.86     188625
… (label_id: 7)                                         18.40      50.57      26.98     123634
-------------------
micro avg                                               85.80      85.80      85.80   14270252
macro avg                                               38.66      61.49      43.73   14270252
weighted avg                                            90.76      85.80      87.76   14270252

-------------------
                       !           ,           -           .           :           ?           …
 10548597.00      1030.00     51847.00      2917.00     14619.00       400.00      3066.00      5165.00
   100030.00     67992.00    119999.00      1581.00    298296.00       565.00     24303.00     16278.00
   502157.00      1011.00    805901.00      2379.00     67555.00      1651.00      3128.00     13037.00
    64474.00       397.00      4337.00     97049.00      3386.00        40.00       275.00       402.00
   121012.00      5304.00    127188.00      1083.00    514946.00      2806.00      7750.00     20385.00
     4079.00        22.00      2042.00       177.00       475.00      1076.00        40.00        44.00
    58165.00      4442.00     36435.00       471.00     47011.00       189.00    145702.00      5807.00
    38733.00       960.00     80430.00      1326.00    151250.00       161.00      4361.00     62516.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                         95.20      88.07      91.50      44403
1 (label_id: 1)                                         89.58      97.76      93.49      46969
2 (label_id: 2)                                         98.08      95.82      96.94      41910
-------------------
micro avg                                               93.92      93.92      93.92     133282
macro avg                                               94.29      93.89      93.98     133282
weighted avg                                            94.13      93.92      93.91     133282

-------------------
           0           1           2
    39105.00       926.00      1045.00
     4636.00     45919.00       705.00
      662.00       124.00     40160.00
-------------------

[INFO] - Epoch 1, global step 1499: val_loss reached 0.50999 (best 0.50999), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-28_11-56-37/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.51-epoch=1.ckpt" as top 3
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          99.17      93.46      96.23   11437247
! (label_id: 1)                                         15.09      73.51      25.03      81158
, (label_id: 2)                                         60.22      69.38      64.48    1228179
- (label_id: 3)                                         63.80      90.16      74.72     106983
. (label_id: 4)                                         68.96      53.33      60.14    1097538
: (label_id: 5)                                         23.94      15.36      18.71       6888
? (label_id: 6)                                         51.12      78.19      61.82     188625
… (label_id: 7)                                         17.61      55.31      26.72     123634
-------------------
micro avg                                               87.59      87.59      87.59   14270252
macro avg                                               42.96      62.18      47.38   14270252
weighted avg                                            91.37      87.59      89.06   14270252

-------------------
                       !           ,           -           .           :           ?           …
 10689083.00      1397.00     57866.00      3760.00     16828.00       474.00      3524.00      5834.00
    43408.00     59658.00     75001.00       989.00    188721.00       261.00     16757.00     10664.00
   451237.00      2059.00    852057.00      2441.00     87183.00      2333.00      4132.00     13377.00
    48441.00       297.00      2707.00     96460.00      2902.00        25.00       215.00       149.00
   103778.00     10994.00    114070.00      1225.00    585301.00      2416.00     11273.00     19739.00
     2018.00        20.00       716.00       205.00       351.00      1058.00        14.00        37.00
    49650.00      5137.00     34379.00       421.00     45823.00       153.00    147478.00      5446.00
    49632.00      1596.00     91383.00      1482.00    170429.00       168.00      5232.00     68388.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                         91.92      95.59      93.72      44403
1 (label_id: 1)                                         96.34      92.83      94.55      46969
2 (label_id: 2)                                         97.28      97.14      97.21      41910
-------------------
micro avg                                               95.11      95.11      95.11     133282
macro avg                                               95.18      95.19      95.16     133282
weighted avg                                            95.17      95.11      95.11     133282

-------------------
           0           1           2
    42446.00      2923.00       807.00
     1264.00     43602.00       391.00
      693.00       444.00     40712.00
-------------------

[INFO] - Epoch 2, global step 2249: val_loss reached 0.50528 (best 0.50528), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-28_11-56-37/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.51-epoch=2.ckpt" as top 3
[INFO] - Saving latest checkpoint...
[INFO] - GPU available: True, used: True
[INFO] - TPU available: None, using: 0 TPU cores
[INFO] - Using environment variable NODE_RANK for node rank (0).
[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          99.14      93.25      96.10   11618608
! (label_id: 1)                                         12.78      70.25      21.62      51473
, (label_id: 2)                                         59.42      70.49      64.48    1298275
- (label_id: 3)                                         57.68      84.74      68.64     119315
. (label_id: 4)                                         68.99      56.73      62.26    1077612
: (label_id: 5)                                         46.94      59.65      52.53      16023
? (label_id: 6)                                         51.24      76.82      61.47     161230
… (label_id: 7)                                         17.09      55.91      26.18     117925
-------------------
micro avg                                               87.80      87.80      87.80   14460461
macro avg                                               44.88      67.80      51.03   14460461
weighted avg                                            91.42      87.80      89.25   14460461

-------------------
                       !           ,           -           .           :           ?           …
 10833943.00       660.00     62814.00      3799.00     16422.00       405.00      2912.00      7129.00
    28607.00     36160.00     58262.00      1541.00    139256.00       211.00     11416.00      7576.00
   497656.00      2218.00    915113.00      4447.00     97476.00      2479.00      4654.00     15999.00
    62955.00       357.00      3760.00    101104.00      6383.00        52.00       231.00       430.00
   105690.00      8049.00    126806.00      1913.00    611319.00      3047.00     13369.00     15955.00
     3151.00         8.00      4775.00      2384.00       446.00      9557.00        20.00        20.00
    40519.00      3113.00     28987.00       696.00     39559.00       114.00    123857.00      4881.00
    46087.00       908.00     97758.00      3431.00    166751.00       158.00      4771.00     65935.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                         80.24      95.12      87.05      44989
1 (label_id: 1)                                         94.53      75.81      84.14      46590
2 (label_id: 2)                                         94.97      96.89      95.92      43484
-------------------
micro avg                                               89.03      89.03      89.03     135063
macro avg                                               89.91      89.27      89.04     135063
weighted avg                                            89.91      89.03      88.90     135063

-------------------
           0           1           2
    42795.00      9738.00       803.00
     1495.00     35319.00       549.00
      699.00      1533.00     42132.00
-------------------

[INFO] - saving to /home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-28_11-56-37/test-tedopeswi-4.txt
[INFO] - Internal process exited
