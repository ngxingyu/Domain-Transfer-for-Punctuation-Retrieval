[INFO] - Global seed set to 42
[INFO] - GPU available: True, used: True
[INFO] - TPU available: None, using: 0 TPU cores
[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[INFO] - Using native 16bit precision.
[INFO] - shuffling train set
[INFO] - Global seed set to 42
[INFO] - initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
[INFO] - Optimizer config = AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0
)
[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7fbc5559e1c0>" 
will be used during training (effective maximum steps = 1000) - 
Parameters : 
(warmup_steps: null
warmup_ratio: 0.1
min_lr: 1.0e-08
last_epoch: -1
max_steps: 1000
)
[INFO] - 
  | Name                       | Type                 | Params
--------------------------------------------------------------------
0 | transformer                | ElectraModel         | 108 M 
1 | punct_classifier           | TokenClassifier      | 7.7 K 
2 | domain_classifier          | SequenceClassifier   | 2.3 K 
3 | punctuation_loss           | FocalDiceLoss        | 0     
4 | domain_loss                | FocalDiceLoss        | 0     
5 | agg_loss                   | AggregatorLoss       | 0     
6 | punct_class_report         | ClassificationReport | 0     
7 | chunked_punct_class_report | ClassificationReport | 0     
8 | domain_class_report        | ClassificationReport | 0     
--------------------------------------------------------------------
10.0 K    Trainable params
108 M     Non-trainable params
108 M     Total params
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          76.95      10.30      18.16      20104
# (label_id: 1)                                          5.26       0.07       0.13       2968
, (label_id: 2)                                         15.97      86.50      26.97       4622
. (label_id: 3)                                          5.54       2.04       2.98       2062
? (label_id: 4)                                          1.00       8.54       1.79        164
-------------------
micro avg                                               20.47      20.47      20.47      29920
macro avg                                               20.95      21.49      10.01      29920
weighted avg                                            55.08      20.47      16.60      29920

-------------------
                       #           ,           .           ?
     2070.00       342.00       186.00        92.00         0.00
       32.00         2.00         2.00         2.00         0.00
    16794.00      2340.00      3998.00      1750.00       148.00
      410.00       104.00       200.00        42.00         2.00
      798.00       180.00       236.00       176.00        14.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                        100.00      97.78      98.88        270
1 (label_id: 1)                                          0.00       0.00       0.00          0
-------------------
micro avg                                               97.78      97.78      97.78        270
macro avg                                               50.00      48.89      49.44        270
weighted avg                                           100.00      97.78      98.88        270

-------------------
           0           1
      264.00         0.00
        6.00         0.00
-------------------

[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          94.59      89.64      92.05     392771
# (label_id: 1)                                         90.18      95.08      92.57      60610
, (label_id: 2)                                         68.34      68.38      68.36      95560
. (label_id: 3)                                         51.68      66.88      58.31      44918
? (label_id: 4)                                         21.03      45.61      28.79       3407
-------------------
micro avg                                               84.83      84.83      84.83     597266
macro avg                                               65.16      73.12      68.01     597266
weighted avg                                            86.30      84.83      85.41     597266

-------------------
                       #           ,           .           ?
   352081.00      2273.00     13852.00      3740.00       276.00
     6209.00     57630.00        54.00         6.00         3.00
    20961.00       156.00     65346.00      8659.00       502.00
    12016.00       449.00     14549.00     30043.00      1072.00
     1504.00       102.00      1759.00      2470.00      1554.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                        100.00       3.44       6.66       5490
1 (label_id: 1)                                          0.00       0.00       0.00          0
-------------------
micro avg                                                3.44       3.44       3.44       5490
macro avg                                               50.00       1.72       3.33       5490
weighted avg                                           100.00       3.44       6.66       5490

-------------------
           0           1
      189.00         0.00
     5301.00         0.00
-------------------

[INFO] - Epoch 0, global step 124: val_loss reached 0.87423 (best 0.87423), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-18_07-37-05/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.87-epoch=0.ckpt" as top 3
