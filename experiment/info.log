[INFO] - Global seed set to 42
[INFO] - GPU available: True, used: True
[INFO] - TPU available: None, using: 0 TPU cores
[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[INFO] - Using native 16bit precision.
[INFO] - shuffling train set
[INFO] - Global seed set to 42
[INFO] - initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
[INFO] - Optimizer config = AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 2
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 3
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 4
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 5
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 6
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 7
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 8
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 9
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 10
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 11
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 12
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 13
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 14
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 15
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.4359738368000025e-06
    weight_decay: 0.0

Parameter Group 16
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 17
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 18
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 19
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 20
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 21
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 22
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 23
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 24
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 25
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 26
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 27
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 28
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 29
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 30
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 31
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.294967296000003e-06
    weight_decay: 0.0

Parameter Group 32
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 33
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 34
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 35
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 36
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 37
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 38
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 39
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 40
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 41
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 42
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 43
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 44
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 45
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 46
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 47
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.368709120000003e-06
    weight_decay: 0.0

Parameter Group 48
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 49
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 50
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 51
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 52
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 53
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 54
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 55
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 56
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 57
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 58
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 59
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 60
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 61
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 62
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 63
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.7108864000000044e-06
    weight_decay: 0.0

Parameter Group 64
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 65
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 66
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 67
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 68
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 69
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 70
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 71
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 72
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 73
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 74
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 75
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 76
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 77
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 78
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 79
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.388608000000003e-06
    weight_decay: 0.0

Parameter Group 80
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 81
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 82
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 83
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 84
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 85
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 86
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 87
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 88
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 89
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 90
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 91
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 92
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 93
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 94
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 95
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0485760000000004e-05
    weight_decay: 0.0

Parameter Group 96
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 97
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 98
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 99
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 100
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 101
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 102
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 103
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 104
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 105
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 106
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 107
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 108
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 109
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 110
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 111
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3107200000000004e-05
    weight_decay: 0.0

Parameter Group 112
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 113
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 114
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 115
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 116
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 117
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 118
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 119
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 120
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 121
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 122
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 123
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 124
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 125
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 126
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 127
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.6384000000000004e-05
    weight_decay: 0.0

Parameter Group 128
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 129
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 130
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 131
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 132
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 133
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 134
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 135
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 136
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 137
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 138
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 139
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 140
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 141
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 142
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 143
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.0480000000000007e-05
    weight_decay: 0.0

Parameter Group 144
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 145
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 146
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 147
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 148
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 149
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 150
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 151
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 152
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 153
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 154
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 155
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 156
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 157
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 158
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 159
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

Parameter Group 160
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 161
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 162
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 163
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 164
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 165
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 166
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 167
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 168
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 169
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 170
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 171
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 172
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 173
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 174
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 175
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.2000000000000005e-05
    weight_decay: 0.0

Parameter Group 176
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 177
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 178
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 179
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 180
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 181
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 182
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 183
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 184
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 185
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 186
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 187
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 188
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 189
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 190
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 191
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0

Parameter Group 192
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4e-05
    weight_decay: 0.0
)
[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7fd7ae987d30>" 
will be used during training (effective maximum steps = 3000) - 
Parameters : 
(warmup_steps: null
warmup_ratio: 0.1
min_lr: 1.0e-08
last_epoch: -1
max_steps: 3000
)
[INFO] - 
  | Name                       | Type                 | Params
--------------------------------------------------------------------
0 | transformer                | ElectraModel         | 108 M 
1 | punct_classifier           | TokenClassifier      | 593 K 
2 | domain_classifier          | SequenceClassifier   | 592 K 
3 | punctuation_loss           | CrossEntropyLoss     | 0     
4 | domain_loss                | FocalDiceLoss        | 0     
5 | agg_loss                   | AggregatorLoss       | 0     
6 | punct_class_report         | ClassificationReport | 0     
7 | chunked_punct_class_report | ClassificationReport | 0     
8 | domain_class_report        | ClassificationReport | 0     
--------------------------------------------------------------------
43.7 M    Trainable params
66.4 M    Non-trainable params
110 M     Total params
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          95.12       3.09       5.98      15764
, (label_id: 1)                                          8.13      67.54      14.51       1066
. (label_id: 2)                                          3.67      30.35       6.55        906
? (label_id: 3)                                          0.21       3.03       0.40         66
-------------------
micro avg                                                8.34       8.34       8.34      17802
macro avg                                                4.00      33.64       7.15      17802
weighted avg                                            84.90       8.34       6.50      17802

-------------------
                       ,           .           ?
      487.00        12.00         9.00         4.00
     7503.00       720.00       585.00        49.00
     6905.00       299.00       275.00        11.00
      869.00        35.00        37.00         2.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                        100.00     100.00     100.00        182
-------------------
micro avg                                              100.00     100.00     100.00        182
macro avg                                              100.00     100.00     100.00        182
weighted avg                                           100.00     100.00     100.00        182

-------------------
           0
      182.00
-------------------

[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          99.66      92.73      96.07     654476
, (label_id: 1)                                         49.75      87.12      63.33      49744
. (label_id: 2)                                         78.25      83.23      80.66      39700
? (label_id: 3)                                         32.53      88.31      47.54       3258
-------------------
micro avg                                               91.84      91.84      91.84     747178
macro avg                                               53.51      86.22      63.85     747178
weighted avg                                            94.91      91.84      92.86     747178

-------------------
                       ,           .           ?
   606916.00      1797.00       271.00        14.00
    38475.00     43335.00      5145.00       151.00
     5300.00      3669.00     33044.00       216.00
     3785.00       943.00      1240.00      2877.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                        100.00     100.00     100.00       7386
-------------------
micro avg                                              100.00     100.00     100.00       7386
macro avg                                              100.00     100.00     100.00       7386
weighted avg                                           100.00     100.00     100.00       7386

-------------------
           0
     7386.00
-------------------

[INFO] - Epoch 0, global step 749: val_loss reached 0.86593 (best 0.86593), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-29_12-14-21/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.87-epoch=0.ckpt" as top 3
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          99.64      93.80      96.63     654476
, (label_id: 1)                                         54.67      84.56      66.41      49744
. (label_id: 2)                                         75.50      87.00      80.84      39700
? (label_id: 3)                                         35.07      90.64      50.57       3258
-------------------
micro avg                                               92.81      92.81      92.81     747178
macro avg                                               55.08      87.40      65.94     747178
weighted avg                                            95.09      92.81      93.58     747178

-------------------
                       ,           .           ?
   613876.00      1938.00       234.00        17.00
    31102.00     42065.00      3706.00        72.00
     6349.00      4643.00     34539.00       216.00
     3149.00      1098.00      1221.00      2953.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                        100.00     100.00     100.00       7386
-------------------
micro avg                                              100.00     100.00     100.00       7386
macro avg                                              100.00     100.00     100.00       7386
weighted avg                                           100.00     100.00     100.00       7386

-------------------
           0
     7386.00
-------------------

[INFO] - Epoch 1, global step 1499: val_loss reached 0.85402 (best 0.85402), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-29_12-14-21/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.85-epoch=1.ckpt" as top 3
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          99.67      93.71      96.60     654476
, (label_id: 1)                                         53.90      85.14      66.01      49744
. (label_id: 2)                                         77.38      86.73      81.79      39700
? (label_id: 3)                                         33.86      91.38      49.41       3258
-------------------
micro avg                                               92.76      92.76      92.76     747178
macro avg                                               55.05      87.75      65.74     747178
weighted avg                                            95.15      92.76      93.57     747178

-------------------
                       ,           .           ?
   613299.00      1785.00       223.00        11.00
    32591.00     42350.00      3557.00        74.00
     5520.00      4350.00     34430.00       196.00
     3066.00      1259.00      1490.00      2977.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                        100.00     100.00     100.00       7386
-------------------
micro avg                                              100.00     100.00     100.00       7386
macro avg                                              100.00     100.00     100.00       7386
weighted avg                                           100.00     100.00     100.00       7386

-------------------
           0
     7386.00
-------------------

[INFO] - Epoch 2, global step 2249: val_loss reached 0.85171 (best 0.85171), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-29_12-14-21/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.85-epoch=2.ckpt" as top 3
[INFO] - Saving latest checkpoint...
[INFO] - GPU available: True, used: True
[INFO] - TPU available: None, using: 0 TPU cores
[INFO] - Using environment variable NODE_RANK for node rank (0).
[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          99.60      93.76      96.59     821812
, (label_id: 1)                                         55.86      84.02      67.11      68424
. (label_id: 2)                                         77.23      85.70      81.24      54837
? (label_id: 3)                                         35.37      92.14      51.12       4812
-------------------
micro avg                                               92.58      92.58      92.58     949885
macro avg                                               56.15      87.29      66.49     949885
weighted avg                                            94.84      92.58      93.35     949885

-------------------
                       ,           .           ?
   770516.00      2691.00       357.00        17.00
    39975.00     57491.00      5349.00       102.00
     7225.00      6375.00     46993.00       259.00
     4096.00      1867.00      2138.00      4434.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                        100.00     100.00     100.00       9193
-------------------
micro avg                                              100.00     100.00     100.00       9193
macro avg                                              100.00     100.00     100.00       9193
weighted avg                                           100.00     100.00     100.00       9193

-------------------
           0
     9193.00
-------------------

[INFO] - saving to /home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-29_12-14-21/test-ted-4.txt
[INFO] - Internal process exited
