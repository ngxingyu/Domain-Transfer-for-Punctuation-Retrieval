[INFO] - Global seed set to 42
[INFO] - GPU available: True, used: True
[INFO] - TPU available: None, using: 0 TPU cores
[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[INFO] - Using native 16bit precision.
[INFO] - shuffling train set
[INFO] - Global seed set to 42
[INFO] - initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
[INFO] - Optimizer config = AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0008589934592000006
=======
    lr: 3.4359738368000025e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0008589934592000006
=======
    lr: 3.4359738368000025e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 2
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0008589934592000006
=======
    lr: 3.4359738368000025e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 3
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0008589934592000006
=======
    lr: 3.4359738368000025e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 4
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0008589934592000006
=======
    lr: 3.4359738368000025e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 5
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0008589934592000006
=======
    lr: 3.4359738368000025e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 6
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0008589934592000006
=======
    lr: 3.4359738368000025e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 7
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0008589934592000006
=======
    lr: 3.4359738368000025e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 8
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0008589934592000006
=======
    lr: 3.4359738368000025e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 9
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0008589934592000006
=======
    lr: 3.4359738368000025e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 10
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0008589934592000006
=======
    lr: 3.4359738368000025e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 11
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0008589934592000006
=======
    lr: 3.4359738368000025e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 12
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0008589934592000006
=======
    lr: 3.4359738368000025e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 13
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0008589934592000006
=======
    lr: 3.4359738368000025e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 14
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0008589934592000006
=======
    lr: 3.4359738368000025e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 15
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0008589934592000006
=======
    lr: 3.4359738368000025e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 16
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0010737418240000006
=======
    lr: 4.294967296000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 17
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0010737418240000006
=======
    lr: 4.294967296000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 18
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0010737418240000006
=======
    lr: 4.294967296000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 19
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0010737418240000006
=======
    lr: 4.294967296000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 20
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0010737418240000006
=======
    lr: 4.294967296000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 21
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0010737418240000006
=======
    lr: 4.294967296000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 22
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0010737418240000006
=======
    lr: 4.294967296000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 23
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0010737418240000006
=======
    lr: 4.294967296000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 24
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0010737418240000006
=======
    lr: 4.294967296000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 25
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0010737418240000006
=======
    lr: 4.294967296000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 26
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0010737418240000006
=======
    lr: 4.294967296000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 27
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0010737418240000006
=======
    lr: 4.294967296000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 28
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0010737418240000006
=======
    lr: 4.294967296000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 29
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0010737418240000006
=======
    lr: 4.294967296000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 30
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0010737418240000006
=======
    lr: 4.294967296000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 31
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0010737418240000006
=======
    lr: 4.294967296000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 32
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0013421772800000006
=======
    lr: 5.368709120000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 33
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0013421772800000006
=======
    lr: 5.368709120000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 34
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0013421772800000006
=======
    lr: 5.368709120000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 35
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0013421772800000006
=======
    lr: 5.368709120000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 36
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0013421772800000006
=======
    lr: 5.368709120000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 37
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0013421772800000006
=======
    lr: 5.368709120000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 38
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0013421772800000006
=======
    lr: 5.368709120000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 39
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0013421772800000006
=======
    lr: 5.368709120000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 40
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0013421772800000006
=======
    lr: 5.368709120000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 41
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0013421772800000006
=======
    lr: 5.368709120000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 42
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0013421772800000006
=======
    lr: 5.368709120000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 43
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0013421772800000006
=======
    lr: 5.368709120000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 44
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0013421772800000006
=======
    lr: 5.368709120000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 45
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0013421772800000006
=======
    lr: 5.368709120000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 46
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0013421772800000006
=======
    lr: 5.368709120000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 47
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0013421772800000006
=======
    lr: 5.368709120000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 48
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.001677721600000001
=======
    lr: 6.7108864000000044e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 49
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.001677721600000001
=======
    lr: 6.7108864000000044e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 50
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.001677721600000001
=======
    lr: 6.7108864000000044e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 51
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.001677721600000001
=======
    lr: 6.7108864000000044e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 52
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.001677721600000001
=======
    lr: 6.7108864000000044e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 53
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.001677721600000001
=======
    lr: 6.7108864000000044e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 54
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.001677721600000001
=======
    lr: 6.7108864000000044e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 55
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.001677721600000001
=======
    lr: 6.7108864000000044e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 56
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.001677721600000001
=======
    lr: 6.7108864000000044e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 57
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.001677721600000001
=======
    lr: 6.7108864000000044e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 58
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.001677721600000001
=======
    lr: 6.7108864000000044e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 59
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.001677721600000001
=======
    lr: 6.7108864000000044e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 60
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.001677721600000001
=======
    lr: 6.7108864000000044e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 61
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.001677721600000001
=======
    lr: 6.7108864000000044e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 62
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.001677721600000001
=======
    lr: 6.7108864000000044e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 63
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.001677721600000001
=======
    lr: 6.7108864000000044e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 64
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002097152000000001
=======
    lr: 8.388608000000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 65
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002097152000000001
=======
    lr: 8.388608000000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 66
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002097152000000001
=======
    lr: 8.388608000000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 67
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002097152000000001
=======
    lr: 8.388608000000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 68
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002097152000000001
=======
    lr: 8.388608000000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 69
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002097152000000001
=======
    lr: 8.388608000000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 70
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002097152000000001
=======
    lr: 8.388608000000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 71
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002097152000000001
=======
    lr: 8.388608000000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 72
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002097152000000001
=======
    lr: 8.388608000000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 73
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002097152000000001
=======
    lr: 8.388608000000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 74
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002097152000000001
=======
    lr: 8.388608000000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 75
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002097152000000001
=======
    lr: 8.388608000000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 76
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002097152000000001
=======
    lr: 8.388608000000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 77
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002097152000000001
=======
    lr: 8.388608000000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 78
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002097152000000001
=======
    lr: 8.388608000000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 79
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002097152000000001
=======
    lr: 8.388608000000003e-06
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 80
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002621440000000001
=======
    lr: 1.0485760000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 81
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002621440000000001
=======
    lr: 1.0485760000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 82
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002621440000000001
=======
    lr: 1.0485760000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 83
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002621440000000001
=======
    lr: 1.0485760000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 84
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002621440000000001
=======
    lr: 1.0485760000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 85
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002621440000000001
=======
    lr: 1.0485760000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 86
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002621440000000001
=======
    lr: 1.0485760000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 87
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002621440000000001
=======
    lr: 1.0485760000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 88
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002621440000000001
=======
    lr: 1.0485760000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 89
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002621440000000001
=======
    lr: 1.0485760000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 90
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002621440000000001
=======
    lr: 1.0485760000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 91
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002621440000000001
=======
    lr: 1.0485760000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 92
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002621440000000001
=======
    lr: 1.0485760000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 93
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002621440000000001
=======
    lr: 1.0485760000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 94
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002621440000000001
=======
    lr: 1.0485760000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 95
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.002621440000000001
=======
    lr: 1.0485760000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 96
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0032768000000000007
=======
    lr: 1.3107200000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 97
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0032768000000000007
=======
    lr: 1.3107200000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 98
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0032768000000000007
=======
    lr: 1.3107200000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 99
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0032768000000000007
=======
    lr: 1.3107200000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 100
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0032768000000000007
=======
    lr: 1.3107200000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 101
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0032768000000000007
=======
    lr: 1.3107200000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 102
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0032768000000000007
=======
    lr: 1.3107200000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 103
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0032768000000000007
=======
    lr: 1.3107200000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 104
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0032768000000000007
=======
    lr: 1.3107200000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 105
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0032768000000000007
=======
    lr: 1.3107200000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 106
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0032768000000000007
=======
    lr: 1.3107200000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 107
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0032768000000000007
=======
    lr: 1.3107200000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 108
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0032768000000000007
=======
    lr: 1.3107200000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 109
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0032768000000000007
=======
    lr: 1.3107200000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 110
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0032768000000000007
=======
    lr: 1.3107200000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 111
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0032768000000000007
=======
    lr: 1.3107200000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 112
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.004096000000000001
=======
    lr: 1.6384000000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 113
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.004096000000000001
=======
    lr: 1.6384000000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 114
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.004096000000000001
=======
    lr: 1.6384000000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 115
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.004096000000000001
=======
    lr: 1.6384000000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 116
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.004096000000000001
=======
    lr: 1.6384000000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 117
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.004096000000000001
=======
    lr: 1.6384000000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 118
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.004096000000000001
=======
    lr: 1.6384000000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 119
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.004096000000000001
=======
    lr: 1.6384000000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 120
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.004096000000000001
=======
    lr: 1.6384000000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 121
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.004096000000000001
=======
    lr: 1.6384000000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 122
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.004096000000000001
=======
    lr: 1.6384000000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 123
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.004096000000000001
=======
    lr: 1.6384000000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 124
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.004096000000000001
=======
    lr: 1.6384000000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 125
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.004096000000000001
=======
    lr: 1.6384000000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 126
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.004096000000000001
=======
    lr: 1.6384000000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 127
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.004096000000000001
=======
    lr: 1.6384000000000004e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 128
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.005120000000000001
=======
    lr: 2.0480000000000007e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 129
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.005120000000000001
=======
    lr: 2.0480000000000007e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 130
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.005120000000000001
=======
    lr: 2.0480000000000007e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 131
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.005120000000000001
=======
    lr: 2.0480000000000007e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 132
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.005120000000000001
=======
    lr: 2.0480000000000007e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 133
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.005120000000000001
=======
    lr: 2.0480000000000007e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 134
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.005120000000000001
=======
    lr: 2.0480000000000007e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 135
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.005120000000000001
=======
    lr: 2.0480000000000007e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 136
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.005120000000000001
=======
    lr: 2.0480000000000007e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 137
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.005120000000000001
=======
    lr: 2.0480000000000007e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 138
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.005120000000000001
=======
    lr: 2.0480000000000007e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 139
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.005120000000000001
=======
    lr: 2.0480000000000007e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 140
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.005120000000000001
=======
    lr: 2.0480000000000007e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 141
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.005120000000000001
=======
    lr: 2.0480000000000007e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 142
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.005120000000000001
=======
    lr: 2.0480000000000007e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 143
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.005120000000000001
=======
    lr: 2.0480000000000007e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 144
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.006400000000000001
=======
    lr: 2.5600000000000006e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 145
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.006400000000000001
=======
    lr: 2.5600000000000006e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 146
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.006400000000000001
=======
    lr: 2.5600000000000006e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 147
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.006400000000000001
=======
    lr: 2.5600000000000006e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 148
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.006400000000000001
=======
    lr: 2.5600000000000006e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 149
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.006400000000000001
=======
    lr: 2.5600000000000006e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 150
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.006400000000000001
=======
    lr: 2.5600000000000006e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 151
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.006400000000000001
=======
    lr: 2.5600000000000006e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 152
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.006400000000000001
    weight_decay: 0.0

Parameter Group 153
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.006400000000000001
    weight_decay: 0.0

Parameter Group 154
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.006400000000000001
    weight_decay: 0.0

Parameter Group 155
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.006400000000000001
    weight_decay: 0.0

Parameter Group 156
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.006400000000000001
    weight_decay: 0.0

Parameter Group 157
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.006400000000000001
    weight_decay: 0.0

Parameter Group 158
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.006400000000000001
    weight_decay: 0.0

Parameter Group 159
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.006400000000000001
    weight_decay: 0.0

Parameter Group 160
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.008
    weight_decay: 0.0

Parameter Group 161
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.008
    weight_decay: 0.0

Parameter Group 162
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.008
    weight_decay: 0.0

Parameter Group 163
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.008
    weight_decay: 0.0

Parameter Group 164
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.008
    weight_decay: 0.0

Parameter Group 165
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.008
    weight_decay: 0.0

Parameter Group 166
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.008
    weight_decay: 0.0

Parameter Group 167
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.008
    weight_decay: 0.0

Parameter Group 168
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.008
    weight_decay: 0.0

Parameter Group 169
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.008
    weight_decay: 0.0

Parameter Group 170
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.008
    weight_decay: 0.0

Parameter Group 171
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.008
    weight_decay: 0.0

Parameter Group 172
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.008
    weight_decay: 0.0

Parameter Group 173
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.008
    weight_decay: 0.0

Parameter Group 174
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.008
    weight_decay: 0.0

Parameter Group 175
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.008
    weight_decay: 0.0

Parameter Group 176
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 177
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 178
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 179
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 180
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 181
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 182
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 183
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 184
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 185
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 186
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 187
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 188
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 189
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 190
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 191
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0

Parameter Group 192
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0.0
)
[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7fc452820c70>" 
will be used during training (effective maximum steps = 4290) - 
Parameters : 
(warmup_steps: null
warmup_ratio: 0.1
min_lr: 1.0e-08
last_epoch: -1
max_steps: 4290
)
[INFO] - 
  | Name                       | Type                 | Params
--------------------------------------------------------------------
0 | transformer                | ElectraModel         | 108 M 
1 | punct_classifier           | TokenClassifier      | 593 K 
2 | domain_classifier          | SequenceClassifier   | 2.3 K 
3 | punctuation_loss           | FocalDiceLoss        | 0     
4 | domain_loss                | FocalDiceLoss        | 0     
5 | agg_loss                   | AggregatorLoss       | 0     
6 | punct_class_report         | ClassificationReport | 0     
7 | chunked_punct_class_report | ClassificationReport | 0     
8 | domain_class_report        | ClassificationReport | 0     
--------------------------------------------------------------------
7.7 M     Trainable params
101 M     Non-trainable params
109 M     Total params
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          75.71      23.87      36.30      21035
, (label_id: 1)                                          9.41      23.12      13.38       3304
. (label_id: 2)                                          4.85      18.54       7.69       1672
? (label_id: 3)                                          0.24      12.37       0.47         97
-------------------
micro avg                                               23.40      23.40      23.40      26108
macro avg                                               22.55      19.48      14.46      26108
weighted avg                                            62.50      23.40      31.44      26108

-------------------
                       ,           .           ?
     5022.00      1033.00       548.00        30.00
     6863.00       764.00       461.00        31.00
     5523.00       532.00       310.00        24.00
     3627.00       975.00       353.00        12.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                         42.75      86.76      57.28         68
1 (label_id: 1)                                         43.75       8.14      13.73         86
-------------------
micro avg                                               42.86      42.86      42.86        154
macro avg                                               43.25      47.45      35.50        154
weighted avg                                            43.31      42.86      32.96        154

-------------------
           0           1
       59.00        79.00
        9.00         7.00
-------------------

[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          93.64      91.54      92.58    1087786
, (label_id: 1)                                         51.87      49.67      50.75     176757
. (label_id: 2)                                         38.67      53.44      44.87      99259
? (label_id: 3)                                          7.17       0.58       1.07       6601
-------------------
micro avg                                               82.95      82.95      82.95    1370403
macro avg                                               47.84      48.81      47.32    1370403
weighted avg                                            83.86      82.95      83.29    1370403

-------------------
                       ,           .           ?
   995800.00     53754.00     12637.00      1234.00
    46455.00     87801.00     33525.00      1490.00
    45121.00     35171.00     53046.00      3839.00
      410.00        31.00        51.00        38.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                         66.05      98.66      79.13       3735
1 (label_id: 1)                                         97.87      54.85      70.30       4195
-------------------
micro avg                                               75.49      75.49      75.49       7930
macro avg                                               81.96      76.76      74.72       7930
weighted avg                                            82.89      75.49      74.46       7930

-------------------
           0           1
     3685.00      1894.00
       50.00      2301.00
-------------------

[INFO] - Epoch 0, global step 428: val_loss reached 0.32806 (best 0.32806), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-23_16-22-27/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.33-epoch=0.ckpt" as top 3
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          91.09      84.60      87.72    1087786
, (label_id: 1)                                         35.73      48.82      41.26     176757
. (label_id: 2)                                         31.97      38.21      34.81      99259
? (label_id: 3)                                          0.00       0.00       0.00       6601
-------------------
micro avg                                               76.21      76.21      76.21    1370403
macro avg                                               39.70      42.90      40.95    1370403
weighted avg                                            79.23      76.21      77.47    1370403

-------------------
                       ,           .           ?
   920220.00     64343.00     23731.00      1973.00
   115488.00     86289.00     37605.00      2127.00
    52076.00     26125.00     37923.00      2501.00
        2.00         0.00         0.00         0.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                         54.88      98.05      70.37       3735
1 (label_id: 1)                                         94.19      28.22      43.43       4195
-------------------
micro avg                                               61.11      61.11      61.11       7930
macro avg                                               74.54      63.13      56.90       7930
weighted avg                                            75.68      61.11      56.12       7930

-------------------
           0           1
     3662.00      3011.00
       73.00      1184.00
-------------------

[INFO] - Epoch 1, global step 857: val_loss reached 0.35899 (best 0.32806), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-23_16-22-27/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.36-epoch=1.ckpt" as top 3
[ERROR] - punctuation_loss nan
[ERROR] - domain_loss nan
[INFO] - Saving latest checkpoint...
[INFO] - Epoch 2, global step 1091: val_loss reached 0.35899 (best 0.32806), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-23_16-22-27/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.36-epoch=2.ckpt" as top 3
[INFO] - Internal process exited
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          96.75      91.64      94.13    1103277
, (label_id: 1)                                         59.27      60.65      59.96     179106
. (label_id: 2)                                         51.94      69.40      59.41     100450
? (label_id: 3)                                         12.79      51.89      20.52       6668
-------------------
micro avg                                               85.85      85.85      85.85    1389501
macro avg                                               55.19      68.40      58.50    1389501
weighted avg                                            88.28      85.85      86.86    1389501

-------------------
                       ,           .           ?
  1011042.00     25614.00      7727.00       571.00
    64043.00    108634.00     10016.00       580.00
    24268.00     38181.00     69714.00      2057.00
     3924.00      6677.00     12993.00      3460.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                         94.72      99.61      97.10       6748
1 (label_id: 1)                                         99.62      94.76      97.13       7159
-------------------
micro avg                                               97.12      97.12      97.12      13907
macro avg                                               97.17      97.19      97.12      13907
weighted avg                                            97.24      97.12      97.12      13907

-------------------
           0           1
     6722.00       375.00
       26.00      6784.00
-------------------

[INFO] - Epoch 3, global step 3431: val_loss reached 0.35946 (best 0.35946), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-23_15-41-10/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.36-epoch=3.ckpt" as top 3
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          97.25      90.43      93.71    1103277
, (label_id: 1)                                         56.36      64.92      60.34     179106
. (label_id: 2)                                         52.70      69.81      60.06     100450
? (label_id: 3)                                         14.92      54.26      23.41       6668
-------------------
micro avg                                               85.47      85.47      85.47    1389501
macro avg                                               55.31      69.85      59.38    1389501
weighted avg                                            88.36      85.47      86.64    1389501

-------------------
                       ,           .           ?
   997642.00     21607.00      6164.00       459.00
    77480.00    116275.00     11989.00       570.00
    24367.00     36555.00     70126.00      2021.00
     3788.00      4669.00     12171.00      3618.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                         94.40      99.70      96.98       6748
1 (label_id: 1)                                         99.71      94.43      96.99       7159
-------------------
micro avg                                               96.99      96.99      96.99      13907
macro avg                                               97.05      97.07      96.99      13907
weighted avg                                            97.13      96.99      96.99      13907

-------------------
           0           1
     6728.00       399.00
       20.00      6760.00
-------------------

[INFO] - Epoch 4, global step 4289: val_loss reached 0.35394 (best 0.35394), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-23_15-41-10/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.35-epoch=4.ckpt" as top 3
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          97.46      90.07      93.62    1103277
, (label_id: 1)                                         54.84      69.41      61.27     179106
. (label_id: 2)                                         56.70      70.60      62.89     100450
? (label_id: 3)                                         18.98      51.53      27.74       6668
-------------------
micro avg                                               85.82      85.82      85.82    1389501
macro avg                                               56.99      70.40      61.38    1389501
weighted avg                                            88.64      85.82      86.91    1389501

-------------------
                       ,           .           ?
   993745.00     20629.00      4972.00       289.00
    85787.00    124309.00     15885.00       709.00
    20852.00     31066.00     70917.00      2234.00
     2893.00      3102.00      8676.00      3436.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                         94.02      99.76      96.81       6748
1 (label_id: 1)                                         99.76      94.02      96.81       7159
-------------------
micro avg                                               96.81      96.81      96.81      13907
macro avg                                               96.89      96.89      96.81      13907
weighted avg                                            96.98      96.81      96.81      13907

-------------------
           0           1
     6732.00       428.00
       16.00      6731.00
-------------------

[INFO] - Epoch 5, global step 5147: val_loss reached 0.35421 (best 0.35394), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-23_15-41-10/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.35-epoch=5.ckpt" as top 3
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          97.28      91.27      94.18    1103277
, (label_id: 1)                                         57.66      66.26      61.66     179106
. (label_id: 2)                                         55.75      71.07      62.49     100450
? (label_id: 3)                                         17.09      52.59      25.80       6668
-------------------
micro avg                                               86.40      86.40      86.40    1389501
macro avg                                               56.95      70.30      61.03    1389501
weighted avg                                            88.78      86.40      87.37    1389501

-------------------
                       ,           .           ?
  1006923.00     22564.00      5282.00       351.00
    73109.00    118680.00     13354.00       677.00
    20416.00     34107.00     71388.00      2133.00
     2829.00      3755.00     10426.00      3507.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                         95.02      99.75      97.33       6748
1 (label_id: 1)                                         99.75      95.07      97.35       7159
-------------------
micro avg                                               97.34      97.34      97.34      13907
macro avg                                               97.38      97.41      97.34      13907
weighted avg                                            97.45      97.34      97.34      13907

-------------------
           0           1
     6731.00       353.00
       17.00      6806.00
-------------------

[INFO] - Epoch 6, global step 6005: val_loss reached 0.35320 (best 0.35320), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-23_15-41-10/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.35-epoch=6.ckpt" as top 3
[INFO] - Saving latest checkpoint...
[INFO] - Global seed set to 42
[INFO] - Optimizer config = AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000005e-05
    weight_decay: 0.0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000005e-05
    weight_decay: 0.0

Parameter Group 2
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000005e-05
    weight_decay: 0.0

Parameter Group 3
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000005e-05
    weight_decay: 0.0

Parameter Group 4
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000005e-05
    weight_decay: 0.0

Parameter Group 5
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000005e-05
    weight_decay: 0.0

Parameter Group 6
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000005e-05
    weight_decay: 0.0

Parameter Group 7
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000005e-05
    weight_decay: 0.0

Parameter Group 8
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000005e-05
    weight_decay: 0.0

Parameter Group 9
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000005e-05
    weight_decay: 0.0

Parameter Group 10
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000005e-05
    weight_decay: 0.0

Parameter Group 11
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000005e-05
    weight_decay: 0.0

Parameter Group 12
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000005e-05
    weight_decay: 0.0

Parameter Group 13
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000005e-05
    weight_decay: 0.0

Parameter Group 14
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000005e-05
    weight_decay: 0.0

Parameter Group 15
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000005e-05
    weight_decay: 0.0

Parameter Group 16
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00010737418240000006
    weight_decay: 0.0

Parameter Group 17
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00010737418240000006
    weight_decay: 0.0

Parameter Group 18
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00010737418240000006
    weight_decay: 0.0

Parameter Group 19
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00010737418240000006
    weight_decay: 0.0

Parameter Group 20
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00010737418240000006
    weight_decay: 0.0

Parameter Group 21
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00010737418240000006
    weight_decay: 0.0

Parameter Group 22
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00010737418240000006
    weight_decay: 0.0

Parameter Group 23
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00010737418240000006
    weight_decay: 0.0

Parameter Group 24
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00010737418240000006
    weight_decay: 0.0

Parameter Group 25
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00010737418240000006
    weight_decay: 0.0

Parameter Group 26
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00010737418240000006
    weight_decay: 0.0

Parameter Group 27
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00010737418240000006
    weight_decay: 0.0

Parameter Group 28
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00010737418240000006
    weight_decay: 0.0

Parameter Group 29
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00010737418240000006
    weight_decay: 0.0

Parameter Group 30
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00010737418240000006
    weight_decay: 0.0

Parameter Group 31
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00010737418240000006
    weight_decay: 0.0

Parameter Group 32
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00013421772800000008
    weight_decay: 0.0

Parameter Group 33
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00013421772800000008
    weight_decay: 0.0

Parameter Group 34
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00013421772800000008
    weight_decay: 0.0

Parameter Group 35
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00013421772800000008
    weight_decay: 0.0

Parameter Group 36
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00013421772800000008
    weight_decay: 0.0

Parameter Group 37
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00013421772800000008
    weight_decay: 0.0

Parameter Group 38
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00013421772800000008
    weight_decay: 0.0

Parameter Group 39
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00013421772800000008
    weight_decay: 0.0

Parameter Group 40
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00013421772800000008
    weight_decay: 0.0

Parameter Group 41
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00013421772800000008
    weight_decay: 0.0

Parameter Group 42
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00013421772800000008
    weight_decay: 0.0

Parameter Group 43
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00013421772800000008
    weight_decay: 0.0

Parameter Group 44
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00013421772800000008
    weight_decay: 0.0

Parameter Group 45
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00013421772800000008
    weight_decay: 0.0

Parameter Group 46
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00013421772800000008
    weight_decay: 0.0

Parameter Group 47
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00013421772800000008
    weight_decay: 0.0

Parameter Group 48
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001677721600000001
    weight_decay: 0.0

Parameter Group 49
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001677721600000001
    weight_decay: 0.0

Parameter Group 50
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001677721600000001
    weight_decay: 0.0

Parameter Group 51
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001677721600000001
    weight_decay: 0.0

Parameter Group 52
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001677721600000001
    weight_decay: 0.0

Parameter Group 53
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001677721600000001
    weight_decay: 0.0

Parameter Group 54
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001677721600000001
    weight_decay: 0.0

Parameter Group 55
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001677721600000001
    weight_decay: 0.0

Parameter Group 56
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001677721600000001
    weight_decay: 0.0

Parameter Group 57
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001677721600000001
    weight_decay: 0.0

Parameter Group 58
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001677721600000001
    weight_decay: 0.0

Parameter Group 59
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001677721600000001
    weight_decay: 0.0

Parameter Group 60
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001677721600000001
    weight_decay: 0.0

Parameter Group 61
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001677721600000001
    weight_decay: 0.0

Parameter Group 62
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001677721600000001
    weight_decay: 0.0

Parameter Group 63
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001677721600000001
    weight_decay: 0.0

Parameter Group 64
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002097152000000001
    weight_decay: 0.0

Parameter Group 65
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002097152000000001
    weight_decay: 0.0

Parameter Group 66
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002097152000000001
    weight_decay: 0.0

Parameter Group 67
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002097152000000001
    weight_decay: 0.0

Parameter Group 68
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002097152000000001
    weight_decay: 0.0

Parameter Group 69
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002097152000000001
    weight_decay: 0.0

Parameter Group 70
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002097152000000001
    weight_decay: 0.0

Parameter Group 71
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002097152000000001
    weight_decay: 0.0

Parameter Group 72
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002097152000000001
    weight_decay: 0.0

Parameter Group 73
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002097152000000001
    weight_decay: 0.0

Parameter Group 74
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002097152000000001
    weight_decay: 0.0

Parameter Group 75
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002097152000000001
    weight_decay: 0.0

Parameter Group 76
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002097152000000001
    weight_decay: 0.0

Parameter Group 77
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002097152000000001
    weight_decay: 0.0

Parameter Group 78
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002097152000000001
    weight_decay: 0.0

Parameter Group 79
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002097152000000001
    weight_decay: 0.0

Parameter Group 80
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002621440000000001
    weight_decay: 0.0

Parameter Group 81
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002621440000000001
    weight_decay: 0.0

Parameter Group 82
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002621440000000001
    weight_decay: 0.0

Parameter Group 83
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002621440000000001
    weight_decay: 0.0

Parameter Group 84
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002621440000000001
    weight_decay: 0.0

Parameter Group 85
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002621440000000001
    weight_decay: 0.0

Parameter Group 86
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002621440000000001
    weight_decay: 0.0

Parameter Group 87
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002621440000000001
    weight_decay: 0.0

Parameter Group 88
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002621440000000001
    weight_decay: 0.0

Parameter Group 89
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002621440000000001
    weight_decay: 0.0

Parameter Group 90
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002621440000000001
    weight_decay: 0.0

Parameter Group 91
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002621440000000001
    weight_decay: 0.0

Parameter Group 92
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002621440000000001
    weight_decay: 0.0

Parameter Group 93
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002621440000000001
    weight_decay: 0.0

Parameter Group 94
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002621440000000001
    weight_decay: 0.0

Parameter Group 95
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002621440000000001
    weight_decay: 0.0

Parameter Group 96
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003276800000000001
    weight_decay: 0.0

Parameter Group 97
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003276800000000001
    weight_decay: 0.0

Parameter Group 98
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003276800000000001
    weight_decay: 0.0

Parameter Group 99
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003276800000000001
    weight_decay: 0.0

Parameter Group 100
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003276800000000001
    weight_decay: 0.0

Parameter Group 101
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003276800000000001
    weight_decay: 0.0

Parameter Group 102
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003276800000000001
    weight_decay: 0.0

Parameter Group 103
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003276800000000001
    weight_decay: 0.0

Parameter Group 104
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003276800000000001
    weight_decay: 0.0

Parameter Group 105
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003276800000000001
    weight_decay: 0.0

Parameter Group 106
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003276800000000001
    weight_decay: 0.0

Parameter Group 107
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003276800000000001
    weight_decay: 0.0

Parameter Group 108
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003276800000000001
    weight_decay: 0.0

Parameter Group 109
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003276800000000001
    weight_decay: 0.0

Parameter Group 110
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003276800000000001
    weight_decay: 0.0

Parameter Group 111
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003276800000000001
    weight_decay: 0.0

Parameter Group 112
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0004096000000000001
    weight_decay: 0.0

Parameter Group 113
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0004096000000000001
    weight_decay: 0.0

Parameter Group 114
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0004096000000000001
    weight_decay: 0.0

Parameter Group 115
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0004096000000000001
    weight_decay: 0.0

Parameter Group 116
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0004096000000000001
    weight_decay: 0.0

Parameter Group 117
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0004096000000000001
    weight_decay: 0.0

Parameter Group 118
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0004096000000000001
    weight_decay: 0.0

Parameter Group 119
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0004096000000000001
    weight_decay: 0.0

Parameter Group 120
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0004096000000000001
    weight_decay: 0.0

Parameter Group 121
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0004096000000000001
    weight_decay: 0.0

Parameter Group 122
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0004096000000000001
    weight_decay: 0.0

Parameter Group 123
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0004096000000000001
    weight_decay: 0.0

Parameter Group 124
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0004096000000000001
    weight_decay: 0.0

Parameter Group 125
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0004096000000000001
    weight_decay: 0.0

Parameter Group 126
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0004096000000000001
    weight_decay: 0.0

Parameter Group 127
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0004096000000000001
    weight_decay: 0.0

Parameter Group 128
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005120000000000001
    weight_decay: 0.0

Parameter Group 129
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005120000000000001
    weight_decay: 0.0

Parameter Group 130
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005120000000000001
    weight_decay: 0.0

Parameter Group 131
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005120000000000001
    weight_decay: 0.0

Parameter Group 132
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005120000000000001
    weight_decay: 0.0

Parameter Group 133
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005120000000000001
    weight_decay: 0.0

Parameter Group 134
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005120000000000001
    weight_decay: 0.0

Parameter Group 135
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005120000000000001
    weight_decay: 0.0

Parameter Group 136
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005120000000000001
    weight_decay: 0.0

Parameter Group 137
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005120000000000001
    weight_decay: 0.0

Parameter Group 138
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005120000000000001
    weight_decay: 0.0

Parameter Group 139
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005120000000000001
    weight_decay: 0.0

Parameter Group 140
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005120000000000001
    weight_decay: 0.0

Parameter Group 141
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005120000000000001
    weight_decay: 0.0

Parameter Group 142
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005120000000000001
    weight_decay: 0.0

Parameter Group 143
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005120000000000001
    weight_decay: 0.0

Parameter Group 144
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0006400000000000002
    weight_decay: 0.0

Parameter Group 145
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0006400000000000002
    weight_decay: 0.0

Parameter Group 146
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0006400000000000002
    weight_decay: 0.0

Parameter Group 147
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0006400000000000002
    weight_decay: 0.0

Parameter Group 148
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0006400000000000002
    weight_decay: 0.0

Parameter Group 149
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0006400000000000002
    weight_decay: 0.0

Parameter Group 150
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0006400000000000002
    weight_decay: 0.0

Parameter Group 151
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0006400000000000002
    weight_decay: 0.0

Parameter Group 152
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0006400000000000002
    weight_decay: 0.0

Parameter Group 153
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0006400000000000002
    weight_decay: 0.0

Parameter Group 154
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0006400000000000002
    weight_decay: 0.0

Parameter Group 155
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0006400000000000002
    weight_decay: 0.0

Parameter Group 156
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0006400000000000002
    weight_decay: 0.0

Parameter Group 157
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0006400000000000002
    weight_decay: 0.0

Parameter Group 158
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0006400000000000002
    weight_decay: 0.0

Parameter Group 159
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0006400000000000002
    weight_decay: 0.0

Parameter Group 160
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0008
    weight_decay: 0.0

Parameter Group 161
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0008
    weight_decay: 0.0

Parameter Group 162
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0008
    weight_decay: 0.0

Parameter Group 163
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0008
    weight_decay: 0.0

Parameter Group 164
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0008
    weight_decay: 0.0

Parameter Group 165
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0008
    weight_decay: 0.0

Parameter Group 166
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0008
    weight_decay: 0.0

Parameter Group 167
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0008
    weight_decay: 0.0

Parameter Group 168
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0008
    weight_decay: 0.0

Parameter Group 169
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0008
    weight_decay: 0.0

Parameter Group 170
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0008
    weight_decay: 0.0

Parameter Group 171
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0008
    weight_decay: 0.0

Parameter Group 172
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0008
    weight_decay: 0.0

Parameter Group 173
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0008
    weight_decay: 0.0

Parameter Group 174
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0008
    weight_decay: 0.0

Parameter Group 175
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0008
    weight_decay: 0.0

Parameter Group 176
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0

Parameter Group 177
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0

Parameter Group 178
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0

Parameter Group 179
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0

Parameter Group 180
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0

Parameter Group 181
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0

Parameter Group 182
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0

Parameter Group 183
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0

Parameter Group 184
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0

Parameter Group 185
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0

Parameter Group 186
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0

Parameter Group 187
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0

Parameter Group 188
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0

Parameter Group 189
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0

Parameter Group 190
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0

Parameter Group 191
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0

Parameter Group 192
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0
)
[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7f9cdefa8700>" 
will be used during training (effective maximum steps = 6864) - 
Parameters : 
(warmup_steps: null
warmup_ratio: 0.1
min_lr: 1.0e-08
last_epoch: -1
max_steps: 6864
)
[INFO] - 
  | Name                       | Type                 | Params
--------------------------------------------------------------------
0 | transformer                | ElectraModel         | 108 M 
1 | punct_classifier           | TokenClassifier      | 593 K 
2 | domain_classifier          | SequenceClassifier   | 2.3 K 
3 | punctuation_loss           | FocalDiceLoss        | 0     
4 | domain_loss                | FocalDiceLoss        | 0     
5 | agg_loss                   | AggregatorLoss       | 0     
6 | punct_class_report         | ClassificationReport | 0     
7 | chunked_punct_class_report | ClassificationReport | 0     
8 | domain_class_report        | ClassificationReport | 0     
--------------------------------------------------------------------
14.8 M    Trainable params
94.7 M    Non-trainable params
109 M     Total params
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          97.38      90.95      94.06      10930
, (label_id: 1)                                         54.21      65.62      59.37       1620
. (label_id: 2)                                         52.75      66.44      58.81        882
? (label_id: 3)                                         12.17      62.16      20.35         37
-------------------
micro avg                                               86.22      86.22      86.22      13469
macro avg                                               54.13      71.29      58.15      13469
weighted avg                                            89.03      86.22      87.37      13469

-------------------
                       ,           .           ?
     9941.00       211.00        53.00         3.00
      753.00      1063.00       143.00         2.00
      204.00       312.00       586.00         9.00
       32.00        34.00       100.00        23.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                         91.30     100.00      95.45         63
1 (label_id: 1)                                        100.00      91.89      95.77         74
-------------------
micro avg                                               95.62      95.62      95.62        137
macro avg                                               95.65      95.95      95.61        137
weighted avg                                            96.00      95.62      95.63        137

-------------------
           0           1
       63.00         6.00
        0.00        68.00
-------------------

[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          97.27      91.21      94.14    1103277
, (label_id: 1)                                         57.57      66.30      61.62     179106
. (label_id: 2)                                         55.75      70.91      62.42     100450
? (label_id: 3)                                         16.78      52.56      25.44       6668
-------------------
micro avg                                               86.35      86.35      86.35    1389501
macro avg                                               56.84      70.24      60.91    1389501
weighted avg                                            88.76      86.35      87.33    1389501

-------------------
                       ,           .           ?
  1006292.00     22614.00      5316.00       364.00
    73639.00    118742.00     13223.00       666.00
    20355.00     34039.00     71226.00      2133.00
     2991.00      3711.00     10685.00      3505.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                         94.38      99.72      96.97       6748
1 (label_id: 1)                                         99.72      94.40      96.99       7159
-------------------
micro avg                                               96.98      96.98      96.98      13907
macro avg                                               97.05      97.06      96.98      13907
weighted avg                                            97.13      96.98      96.98      13907

-------------------
           0           1
     6729.00       401.00
       19.00      6758.00
-------------------

[INFO] - Epoch 0, global step 6006: val_loss reached 0.35367 (best 0.35320), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-23_15-41-10/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.35-epoch=0.ckpt" as top 3
[INFO] - Global seed set to 42
[INFO] - Optimizer config = AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000006e-06
    weight_decay: 0.0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000006e-06
    weight_decay: 0.0

Parameter Group 2
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000006e-06
    weight_decay: 0.0

Parameter Group 3
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000006e-06
    weight_decay: 0.0

Parameter Group 4
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000006e-06
    weight_decay: 0.0

Parameter Group 5
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000006e-06
    weight_decay: 0.0

Parameter Group 6
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000006e-06
    weight_decay: 0.0

Parameter Group 7
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000006e-06
    weight_decay: 0.0

Parameter Group 8
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000006e-06
    weight_decay: 0.0

Parameter Group 9
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000006e-06
    weight_decay: 0.0

Parameter Group 10
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000006e-06
    weight_decay: 0.0

Parameter Group 11
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000006e-06
    weight_decay: 0.0

Parameter Group 12
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000006e-06
    weight_decay: 0.0

Parameter Group 13
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000006e-06
    weight_decay: 0.0

Parameter Group 14
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000006e-06
    weight_decay: 0.0

Parameter Group 15
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 8.589934592000006e-06
    weight_decay: 0.0

Parameter Group 16
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0737418240000007e-05
    weight_decay: 0.0

Parameter Group 17
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0737418240000007e-05
    weight_decay: 0.0

Parameter Group 18
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0737418240000007e-05
    weight_decay: 0.0

Parameter Group 19
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0737418240000007e-05
    weight_decay: 0.0

Parameter Group 20
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0737418240000007e-05
    weight_decay: 0.0

Parameter Group 21
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0737418240000007e-05
    weight_decay: 0.0

Parameter Group 22
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0737418240000007e-05
    weight_decay: 0.0

Parameter Group 23
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0737418240000007e-05
    weight_decay: 0.0

Parameter Group 24
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0737418240000007e-05
    weight_decay: 0.0

Parameter Group 25
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0737418240000007e-05
    weight_decay: 0.0

Parameter Group 26
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0737418240000007e-05
    weight_decay: 0.0

Parameter Group 27
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0737418240000007e-05
    weight_decay: 0.0

Parameter Group 28
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0737418240000007e-05
    weight_decay: 0.0

Parameter Group 29
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0737418240000007e-05
    weight_decay: 0.0

Parameter Group 30
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0737418240000007e-05
    weight_decay: 0.0

Parameter Group 31
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.0737418240000007e-05
    weight_decay: 0.0

Parameter Group 32
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3421772800000007e-05
    weight_decay: 0.0

Parameter Group 33
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3421772800000007e-05
    weight_decay: 0.0

Parameter Group 34
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3421772800000007e-05
    weight_decay: 0.0

Parameter Group 35
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3421772800000007e-05
    weight_decay: 0.0

Parameter Group 36
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3421772800000007e-05
    weight_decay: 0.0

Parameter Group 37
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3421772800000007e-05
    weight_decay: 0.0

Parameter Group 38
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3421772800000007e-05
    weight_decay: 0.0

Parameter Group 39
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3421772800000007e-05
    weight_decay: 0.0

Parameter Group 40
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3421772800000007e-05
    weight_decay: 0.0

Parameter Group 41
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3421772800000007e-05
    weight_decay: 0.0

Parameter Group 42
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3421772800000007e-05
    weight_decay: 0.0

Parameter Group 43
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3421772800000007e-05
    weight_decay: 0.0

Parameter Group 44
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3421772800000007e-05
    weight_decay: 0.0

Parameter Group 45
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3421772800000007e-05
    weight_decay: 0.0

Parameter Group 46
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3421772800000007e-05
    weight_decay: 0.0

Parameter Group 47
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.3421772800000007e-05
    weight_decay: 0.0

Parameter Group 48
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.677721600000001e-05
    weight_decay: 0.0

Parameter Group 49
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.677721600000001e-05
    weight_decay: 0.0

Parameter Group 50
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.677721600000001e-05
    weight_decay: 0.0

Parameter Group 51
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.677721600000001e-05
    weight_decay: 0.0

Parameter Group 52
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.677721600000001e-05
    weight_decay: 0.0

Parameter Group 53
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.677721600000001e-05
    weight_decay: 0.0

Parameter Group 54
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.677721600000001e-05
    weight_decay: 0.0

Parameter Group 55
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.677721600000001e-05
    weight_decay: 0.0

Parameter Group 56
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.677721600000001e-05
    weight_decay: 0.0

Parameter Group 57
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.677721600000001e-05
    weight_decay: 0.0

Parameter Group 58
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.677721600000001e-05
    weight_decay: 0.0

Parameter Group 59
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.677721600000001e-05
    weight_decay: 0.0

Parameter Group 60
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.677721600000001e-05
    weight_decay: 0.0

Parameter Group 61
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.677721600000001e-05
    weight_decay: 0.0

Parameter Group 62
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.677721600000001e-05
    weight_decay: 0.0

Parameter Group 63
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1.677721600000001e-05
    weight_decay: 0.0

Parameter Group 64
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.097152000000001e-05
    weight_decay: 0.0

Parameter Group 65
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.097152000000001e-05
    weight_decay: 0.0

Parameter Group 66
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.097152000000001e-05
    weight_decay: 0.0

Parameter Group 67
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.097152000000001e-05
    weight_decay: 0.0

Parameter Group 68
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.097152000000001e-05
    weight_decay: 0.0

Parameter Group 69
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.097152000000001e-05
    weight_decay: 0.0

Parameter Group 70
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.097152000000001e-05
    weight_decay: 0.0

Parameter Group 71
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.097152000000001e-05
    weight_decay: 0.0

Parameter Group 72
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.097152000000001e-05
    weight_decay: 0.0

Parameter Group 73
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.097152000000001e-05
    weight_decay: 0.0

Parameter Group 74
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.097152000000001e-05
    weight_decay: 0.0

Parameter Group 75
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.097152000000001e-05
    weight_decay: 0.0

Parameter Group 76
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.097152000000001e-05
    weight_decay: 0.0

Parameter Group 77
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.097152000000001e-05
    weight_decay: 0.0

Parameter Group 78
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.097152000000001e-05
    weight_decay: 0.0

Parameter Group 79
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.097152000000001e-05
    weight_decay: 0.0

Parameter Group 80
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.621440000000001e-05
    weight_decay: 0.0

Parameter Group 81
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.621440000000001e-05
    weight_decay: 0.0

Parameter Group 82
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.621440000000001e-05
    weight_decay: 0.0

Parameter Group 83
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.621440000000001e-05
    weight_decay: 0.0

Parameter Group 84
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.621440000000001e-05
    weight_decay: 0.0

Parameter Group 85
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.621440000000001e-05
    weight_decay: 0.0

Parameter Group 86
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.621440000000001e-05
    weight_decay: 0.0

Parameter Group 87
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.621440000000001e-05
    weight_decay: 0.0

Parameter Group 88
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.621440000000001e-05
    weight_decay: 0.0

Parameter Group 89
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.621440000000001e-05
    weight_decay: 0.0

Parameter Group 90
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.621440000000001e-05
    weight_decay: 0.0

Parameter Group 91
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.621440000000001e-05
    weight_decay: 0.0

Parameter Group 92
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.621440000000001e-05
    weight_decay: 0.0

Parameter Group 93
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.621440000000001e-05
    weight_decay: 0.0

Parameter Group 94
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.621440000000001e-05
    weight_decay: 0.0

Parameter Group 95
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 2.621440000000001e-05
    weight_decay: 0.0

Parameter Group 96
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.276800000000001e-05
    weight_decay: 0.0

Parameter Group 97
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.276800000000001e-05
    weight_decay: 0.0

Parameter Group 98
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.276800000000001e-05
    weight_decay: 0.0

Parameter Group 99
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.276800000000001e-05
    weight_decay: 0.0

Parameter Group 100
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.276800000000001e-05
    weight_decay: 0.0

Parameter Group 101
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.276800000000001e-05
    weight_decay: 0.0

Parameter Group 102
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.276800000000001e-05
    weight_decay: 0.0

Parameter Group 103
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.276800000000001e-05
    weight_decay: 0.0

Parameter Group 104
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.276800000000001e-05
    weight_decay: 0.0

Parameter Group 105
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.276800000000001e-05
    weight_decay: 0.0

Parameter Group 106
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.276800000000001e-05
    weight_decay: 0.0

Parameter Group 107
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.276800000000001e-05
    weight_decay: 0.0

Parameter Group 108
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.276800000000001e-05
    weight_decay: 0.0

Parameter Group 109
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.276800000000001e-05
    weight_decay: 0.0

Parameter Group 110
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.276800000000001e-05
    weight_decay: 0.0

Parameter Group 111
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 3.276800000000001e-05
    weight_decay: 0.0

Parameter Group 112
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.096000000000001e-05
    weight_decay: 0.0

Parameter Group 113
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.096000000000001e-05
    weight_decay: 0.0

Parameter Group 114
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.096000000000001e-05
    weight_decay: 0.0

Parameter Group 115
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.096000000000001e-05
    weight_decay: 0.0

Parameter Group 116
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.096000000000001e-05
    weight_decay: 0.0

Parameter Group 117
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.096000000000001e-05
    weight_decay: 0.0

Parameter Group 118
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.096000000000001e-05
    weight_decay: 0.0

Parameter Group 119
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.096000000000001e-05
    weight_decay: 0.0

Parameter Group 120
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.096000000000001e-05
    weight_decay: 0.0

Parameter Group 121
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.096000000000001e-05
    weight_decay: 0.0

Parameter Group 122
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.096000000000001e-05
    weight_decay: 0.0

Parameter Group 123
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.096000000000001e-05
    weight_decay: 0.0

Parameter Group 124
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.096000000000001e-05
    weight_decay: 0.0

Parameter Group 125
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.096000000000001e-05
    weight_decay: 0.0

Parameter Group 126
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.096000000000001e-05
    weight_decay: 0.0

Parameter Group 127
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 4.096000000000001e-05
    weight_decay: 0.0

Parameter Group 128
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.120000000000001e-05
    weight_decay: 0.0

Parameter Group 129
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.120000000000001e-05
    weight_decay: 0.0

Parameter Group 130
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.120000000000001e-05
    weight_decay: 0.0

Parameter Group 131
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.120000000000001e-05
    weight_decay: 0.0

Parameter Group 132
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.120000000000001e-05
    weight_decay: 0.0

Parameter Group 133
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.120000000000001e-05
    weight_decay: 0.0

Parameter Group 134
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.120000000000001e-05
    weight_decay: 0.0

Parameter Group 135
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.120000000000001e-05
    weight_decay: 0.0

Parameter Group 136
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.120000000000001e-05
    weight_decay: 0.0

Parameter Group 137
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.120000000000001e-05
    weight_decay: 0.0

Parameter Group 138
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.120000000000001e-05
    weight_decay: 0.0

Parameter Group 139
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.120000000000001e-05
    weight_decay: 0.0

Parameter Group 140
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.120000000000001e-05
    weight_decay: 0.0

Parameter Group 141
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.120000000000001e-05
    weight_decay: 0.0

Parameter Group 142
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.120000000000001e-05
    weight_decay: 0.0

Parameter Group 143
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5.120000000000001e-05
    weight_decay: 0.0

Parameter Group 144
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.400000000000001e-05
    weight_decay: 0.0

Parameter Group 145
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.400000000000001e-05
    weight_decay: 0.0

Parameter Group 146
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.400000000000001e-05
    weight_decay: 0.0

Parameter Group 147
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.400000000000001e-05
    weight_decay: 0.0

Parameter Group 148
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.400000000000001e-05
    weight_decay: 0.0

Parameter Group 149
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.400000000000001e-05
    weight_decay: 0.0

Parameter Group 150
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.400000000000001e-05
    weight_decay: 0.0

Parameter Group 151
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.400000000000001e-05
    weight_decay: 0.0

Parameter Group 152
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 6.400000000000001e-05
    weight_decay: 0.0

=======
    lr: 2.5600000000000006e-05
    weight_decay: 0.0

>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
Parameter Group 153
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 6.400000000000001e-05
=======
    lr: 2.5600000000000006e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 154
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 6.400000000000001e-05
=======
    lr: 2.5600000000000006e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 155
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 6.400000000000001e-05
=======
    lr: 2.5600000000000006e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 156
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 6.400000000000001e-05
=======
    lr: 2.5600000000000006e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 157
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 6.400000000000001e-05
=======
    lr: 2.5600000000000006e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 158
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 6.400000000000001e-05
=======
    lr: 2.5600000000000006e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 159
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 6.400000000000001e-05
=======
    lr: 2.5600000000000006e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 160
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 8e-05
=======
    lr: 3.2000000000000005e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 161
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 8e-05
=======
    lr: 3.2000000000000005e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 162
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 8e-05
=======
    lr: 3.2000000000000005e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 163
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 8e-05
=======
    lr: 3.2000000000000005e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 164
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 8e-05
=======
    lr: 3.2000000000000005e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 165
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 8e-05
=======
    lr: 3.2000000000000005e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 166
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 8e-05
=======
    lr: 3.2000000000000005e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 167
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 8e-05
=======
    lr: 3.2000000000000005e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 168
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 8e-05
=======
    lr: 3.2000000000000005e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 169
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 8e-05
=======
    lr: 3.2000000000000005e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 170
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 8e-05
=======
    lr: 3.2000000000000005e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 171
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 8e-05
=======
    lr: 3.2000000000000005e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 172
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 8e-05
=======
    lr: 3.2000000000000005e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 173
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 8e-05
=======
    lr: 3.2000000000000005e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 174
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 8e-05
=======
    lr: 3.2000000000000005e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 175
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 8e-05
=======
    lr: 3.2000000000000005e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 176
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0001
=======
    lr: 4e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 177
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0001
=======
    lr: 4e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 178
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0001
=======
    lr: 4e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 179
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0001
=======
    lr: 4e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 180
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0001
=======
    lr: 4e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 181
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0001
=======
    lr: 4e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 182
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0001
=======
    lr: 4e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 183
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0001
=======
    lr: 4e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 184
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0001
=======
    lr: 4e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 185
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0001
=======
    lr: 4e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 186
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0001
=======
    lr: 4e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 187
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0001
=======
    lr: 4e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 188
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0001
=======
    lr: 4e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 189
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0001
=======
    lr: 4e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 190
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0001
=======
    lr: 4e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 191
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0001
=======
    lr: 4e-05
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
    weight_decay: 0.0

Parameter Group 192
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
<<<<<<< HEAD
    lr: 0.0001
    weight_decay: 0.0
)
[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7f9cabd4df40>" 
will be used during training (effective maximum steps = 6864) - 
=======
    lr: 4e-05
    weight_decay: 0.0
)
[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7fba6978f520>" 
will be used during training (effective maximum steps = 3000) - 
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
Parameters : 
(warmup_steps: null
warmup_ratio: 0.1
min_lr: 1.0e-08
last_epoch: -1
<<<<<<< HEAD
max_steps: 6864
=======
max_steps: 3000
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
)
[INFO] - 
  | Name                       | Type                 | Params
--------------------------------------------------------------------
0 | transformer                | ElectraModel         | 108 M 
<<<<<<< HEAD
1 | punct_classifier           | TokenClassifier      | 593 K 
2 | domain_classifier          | SequenceClassifier   | 2.3 K 
=======
1 | punct_classifier           | TokenClassifier      | 601 K 
2 | domain_classifier          | SequenceClassifier   | 593 K 
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
3 | punctuation_loss           | FocalDiceLoss        | 0     
4 | domain_loss                | FocalDiceLoss        | 0     
5 | agg_loss                   | AggregatorLoss       | 0     
6 | punct_class_report         | ClassificationReport | 0     
7 | chunked_punct_class_report | ClassificationReport | 0     
8 | domain_class_report        | ClassificationReport | 0     
--------------------------------------------------------------------
<<<<<<< HEAD
28.9 M    Trainable params
80.5 M    Non-trainable params
109 M     Total params
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          97.38      90.95      94.06      10930
, (label_id: 1)                                         54.21      65.62      59.37       1620
. (label_id: 2)                                         52.75      66.44      58.81        882
? (label_id: 3)                                         12.17      62.16      20.35         37
-------------------
micro avg                                               86.22      86.22      86.22      13469
macro avg                                               54.13      71.29      58.15      13469
weighted avg                                            89.03      86.22      87.37      13469

-------------------
                       ,           .           ?
     9941.00       211.00        53.00         3.00
      753.00      1063.00       143.00         2.00
      204.00       312.00       586.00         9.00
       32.00        34.00       100.00        23.00
=======
43.7 M    Trainable params
66.4 M    Non-trainable params
110 M     Total params
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          56.19       1.84       3.56      47634
! (label_id: 1)                                          0.69      41.88       1.36        308
, (label_id: 2)                                          9.43       5.06       6.59       5139
- (label_id: 3)                                          0.34      19.27       0.68        384
. (label_id: 4)                                          3.06       0.34       0.61       4156
: (label_id: 5)                                          0.24      13.64       0.48         22
? (label_id: 6)                                          1.81       5.43       2.71        663
… (label_id: 7)                                          0.93      29.75       1.80        326
-------------------
micro avg                                                2.54       2.54       2.54      58632
macro avg                                                2.36      16.48       2.03      58632
weighted avg                                            46.73       2.54       3.57      58632

-------------------
                       !           ,           -           .           :           ?           …
      876.00        11.00       381.00        16.00       201.00         0.00        39.00        35.00
    15260.00       129.00      1324.00       103.00      1513.00         5.00       253.00        90.00
     2209.00         9.00       260.00         3.00       202.00         1.00        49.00        23.00
    18823.00        63.00      1103.00        74.00      1152.00        11.00       182.00        65.00
      417.00         0.00        23.00         0.00        14.00         0.00         4.00         0.00
      928.00        12.00        95.00         6.00       166.00         3.00        25.00         5.00
     1443.00        27.00       206.00        14.00       252.00         0.00        36.00        11.00
     7678.00        57.00      1747.00       168.00       656.00         2.00        75.00        97.00
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
<<<<<<< HEAD
0 (label_id: 0)                                         91.30     100.00      95.45         63
1 (label_id: 1)                                        100.00      91.89      95.77         74
-------------------
micro avg                                               95.62      95.62      95.62        137
macro avg                                               95.65      95.95      95.61        137
weighted avg                                            96.00      95.62      95.63        137

-------------------
           0           1
       63.00         6.00
        0.00        68.00
=======
0 (label_id: 0)                                         32.79     100.00      49.38        180
1 (label_id: 1)                                          0.00       0.00       0.00        189
2 (label_id: 2)                                          0.00       0.00       0.00        180
-------------------
micro avg                                               32.79      32.79      32.79        549
macro avg                                               10.93      33.33      16.46        549
weighted avg                                            10.75      32.79      16.19        549

-------------------
           0           1           2
      180.00       189.00       180.00
        0.00         0.00         0.00
        0.00         0.00         0.00
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
-------------------

[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
<<<<<<< HEAD
 (label_id: 0)                                          97.27      91.21      94.14    1103277
, (label_id: 1)                                         57.57      66.30      61.62     179106
. (label_id: 2)                                         55.75      70.91      62.42     100450
? (label_id: 3)                                         16.78      52.56      25.44       6668
-------------------
micro avg                                               86.35      86.35      86.35    1389501
macro avg                                               56.84      70.24      60.91    1389501
weighted avg                                            88.76      86.35      87.33    1389501

-------------------
                       ,           .           ?
  1006292.00     22614.00      5316.00       364.00
    73639.00    118742.00     13223.00       666.00
    20355.00     34039.00     71226.00      2133.00
     2991.00      3711.00     10685.00      3505.00
=======
 (label_id: 0)                                          99.13      91.66      95.25   11437247
! (label_id: 1)                                         13.01      72.53      22.06      81158
, (label_id: 2)                                         52.68      68.00      59.37    1228179
- (label_id: 3)                                         59.03      89.82      71.24     106983
. (label_id: 4)                                         66.22      48.86      56.23    1097538
: (label_id: 5)                                          0.00       0.00       0.00       6888
? (label_id: 6)                                         43.60      78.07      55.95     188625
… (label_id: 7)                                         16.85      47.24      24.84     123634
-------------------
micro avg                                               85.60      85.60      85.60   14270252
macro avg                                               35.91      57.79      41.38   14270252
weighted avg                                            90.31      85.60      87.39   14270252

-------------------
                       !           ,           -           .           :           ?           …
 10483169.00      1352.00     56202.00      3453.00     21556.00       541.00      3229.00      6139.00
    63225.00     58860.00     92665.00      1609.00    203451.00       396.00     19208.00     13055.00
   622464.00      2136.00    835119.00      3543.00     95884.00      2695.00      4638.00     18738.00
    59321.00       270.00      3131.00     96095.00      3228.00       389.00       121.00       225.00
   110830.00     12429.00    115248.00      1359.00    536215.00      2641.00     10700.00     20362.00
        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
    79629.00      6030.00     42040.00       548.00     55345.00       214.00    147265.00      6709.00
    18609.00        81.00     83774.00       376.00    181859.00        12.00      3464.00     58406.00
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
<<<<<<< HEAD
0 (label_id: 0)                                         94.38      99.72      96.97       6748
1 (label_id: 1)                                         99.72      94.40      96.99       7159
-------------------
micro avg                                               96.98      96.98      96.98      13907
macro avg                                               97.05      97.06      96.98      13907
weighted avg                                            97.13      96.98      96.98      13907

-------------------
           0           1
     6729.00       401.00
       19.00      6758.00
-------------------

[INFO] - GPU available: True, used: True
[INFO] - TPU available: None, using: 0 TPU cores
[INFO] - Using environment variable NODE_RANK for node rank (0).
[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          97.26      91.05      94.05    1348890
, (label_id: 1)                                         57.37      66.55      61.62     220399
. (label_id: 2)                                         55.53      70.43      62.10     124644
? (label_id: 3)                                         18.03      54.52      27.10       8606
-------------------
micro avg                                               86.18      86.18      86.18    1702539
macro avg                                               57.05      70.64      61.22    1702539
weighted avg                                            88.64      86.18      87.17    1702539

-------------------
                       ,           .           ?
  1228124.00     27448.00      6749.00       437.00
    90981.00    146672.00     17125.00       884.00
    25995.00     41723.00     87784.00      2593.00
     3790.00      4556.00     12986.00      4692.00
=======
0 (label_id: 0)                                         93.17      90.36      91.74      44403
1 (label_id: 1)                                         94.52      94.62      94.57      46969
2 (label_id: 2)                                         94.72      97.63      96.15      41910
-------------------
micro avg                                               94.15      94.15      94.15     133282
macro avg                                               94.14      94.20      94.15     133282
weighted avg                                            94.13      94.15      94.13     133282

-------------------
           0           1           2
    40121.00      2234.00       706.00
     2290.00     44444.00       288.00
     1992.00       291.00     40916.00
-------------------

[INFO] - Epoch 0, global step 749: val_loss reached 0.51531 (best 0.51531), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-28_11-56-37/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.52-epoch=0.ckpt" as top 3
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          99.26      92.23      95.61   11437247
! (label_id: 1)                                         10.81      83.78      19.15      81158
, (label_id: 2)                                         57.70      65.62      61.40    1228179
- (label_id: 3)                                         56.97      90.71      69.98     106983
. (label_id: 4)                                         64.33      46.92      54.26    1097538
: (label_id: 5)                                         13.53      15.62      14.50       6888
? (label_id: 6)                                         48.86      77.24      59.86     188625
… (label_id: 7)                                         18.40      50.57      26.98     123634
-------------------
micro avg                                               85.80      85.80      85.80   14270252
macro avg                                               38.66      61.49      43.73   14270252
weighted avg                                            90.76      85.80      87.76   14270252

-------------------
                       !           ,           -           .           :           ?           …
 10548597.00      1030.00     51847.00      2917.00     14619.00       400.00      3066.00      5165.00
   100030.00     67992.00    119999.00      1581.00    298296.00       565.00     24303.00     16278.00
   502157.00      1011.00    805901.00      2379.00     67555.00      1651.00      3128.00     13037.00
    64474.00       397.00      4337.00     97049.00      3386.00        40.00       275.00       402.00
   121012.00      5304.00    127188.00      1083.00    514946.00      2806.00      7750.00     20385.00
     4079.00        22.00      2042.00       177.00       475.00      1076.00        40.00        44.00
    58165.00      4442.00     36435.00       471.00     47011.00       189.00    145702.00      5807.00
    38733.00       960.00     80430.00      1326.00    151250.00       161.00      4361.00     62516.00
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
<<<<<<< HEAD
0 (label_id: 0)                                         95.20      99.81      97.45       8452
1 (label_id: 1)                                         99.80      95.04      97.37       8577
-------------------
micro avg                                               97.41      97.41      97.41      17029
macro avg                                               97.50      97.43      97.41      17029
weighted avg                                            97.52      97.41      97.41      17029

-------------------
           0           1
     8436.00       425.00
       16.00      8152.00
-------------------

[INFO] - saving to /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-23_15-41-10/test-tedswi-6.txt
=======
0 (label_id: 0)                                         95.20      88.07      91.50      44403
1 (label_id: 1)                                         89.58      97.76      93.49      46969
2 (label_id: 2)                                         98.08      95.82      96.94      41910
-------------------
micro avg                                               93.92      93.92      93.92     133282
macro avg                                               94.29      93.89      93.98     133282
weighted avg                                            94.13      93.92      93.91     133282

-------------------
           0           1           2
    39105.00       926.00      1045.00
     4636.00     45919.00       705.00
      662.00       124.00     40160.00
-------------------

[INFO] - Epoch 1, global step 1499: val_loss reached 0.50999 (best 0.50999), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-28_11-56-37/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.51-epoch=1.ckpt" as top 3
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          99.17      93.46      96.23   11437247
! (label_id: 1)                                         15.09      73.51      25.03      81158
, (label_id: 2)                                         60.22      69.38      64.48    1228179
- (label_id: 3)                                         63.80      90.16      74.72     106983
. (label_id: 4)                                         68.96      53.33      60.14    1097538
: (label_id: 5)                                         23.94      15.36      18.71       6888
? (label_id: 6)                                         51.12      78.19      61.82     188625
… (label_id: 7)                                         17.61      55.31      26.72     123634
-------------------
micro avg                                               87.59      87.59      87.59   14270252
macro avg                                               42.96      62.18      47.38   14270252
weighted avg                                            91.37      87.59      89.06   14270252

-------------------
                       !           ,           -           .           :           ?           …
 10689083.00      1397.00     57866.00      3760.00     16828.00       474.00      3524.00      5834.00
    43408.00     59658.00     75001.00       989.00    188721.00       261.00     16757.00     10664.00
   451237.00      2059.00    852057.00      2441.00     87183.00      2333.00      4132.00     13377.00
    48441.00       297.00      2707.00     96460.00      2902.00        25.00       215.00       149.00
   103778.00     10994.00    114070.00      1225.00    585301.00      2416.00     11273.00     19739.00
     2018.00        20.00       716.00       205.00       351.00      1058.00        14.00        37.00
    49650.00      5137.00     34379.00       421.00     45823.00       153.00    147478.00      5446.00
    49632.00      1596.00     91383.00      1482.00    170429.00       168.00      5232.00     68388.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                         91.92      95.59      93.72      44403
1 (label_id: 1)                                         96.34      92.83      94.55      46969
2 (label_id: 2)                                         97.28      97.14      97.21      41910
-------------------
micro avg                                               95.11      95.11      95.11     133282
macro avg                                               95.18      95.19      95.16     133282
weighted avg                                            95.17      95.11      95.11     133282

-------------------
           0           1           2
    42446.00      2923.00       807.00
     1264.00     43602.00       391.00
      693.00       444.00     40712.00
-------------------

[INFO] - Epoch 2, global step 2249: val_loss reached 0.50528 (best 0.50528), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-28_11-56-37/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.51-epoch=2.ckpt" as top 3
[INFO] - Saving latest checkpoint...
[INFO] - GPU available: True, used: True
[INFO] - TPU available: None, using: 0 TPU cores
[INFO] - Using environment variable NODE_RANK for node rank (0).
[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
[INFO] - Punctuation report: 
label                                                precision    recall       f1           support   
 (label_id: 0)                                          99.14      93.25      96.10   11618608
! (label_id: 1)                                         12.78      70.25      21.62      51473
, (label_id: 2)                                         59.42      70.49      64.48    1298275
- (label_id: 3)                                         57.68      84.74      68.64     119315
. (label_id: 4)                                         68.99      56.73      62.26    1077612
: (label_id: 5)                                         46.94      59.65      52.53      16023
? (label_id: 6)                                         51.24      76.82      61.47     161230
… (label_id: 7)                                         17.09      55.91      26.18     117925
-------------------
micro avg                                               87.80      87.80      87.80   14460461
macro avg                                               44.88      67.80      51.03   14460461
weighted avg                                            91.42      87.80      89.25   14460461

-------------------
                       !           ,           -           .           :           ?           …
 10833943.00       660.00     62814.00      3799.00     16422.00       405.00      2912.00      7129.00
    28607.00     36160.00     58262.00      1541.00    139256.00       211.00     11416.00      7576.00
   497656.00      2218.00    915113.00      4447.00     97476.00      2479.00      4654.00     15999.00
    62955.00       357.00      3760.00    101104.00      6383.00        52.00       231.00       430.00
   105690.00      8049.00    126806.00      1913.00    611319.00      3047.00     13369.00     15955.00
     3151.00         8.00      4775.00      2384.00       446.00      9557.00        20.00        20.00
    40519.00      3113.00     28987.00       696.00     39559.00       114.00    123857.00      4881.00
    46087.00       908.00     97758.00      3431.00    166751.00       158.00      4771.00     65935.00
-------------------

[INFO] - Domain report: 
label                                                precision    recall       f1           support   
0 (label_id: 0)                                         80.24      95.12      87.05      44989
1 (label_id: 1)                                         94.53      75.81      84.14      46590
2 (label_id: 2)                                         94.97      96.89      95.92      43484
-------------------
micro avg                                               89.03      89.03      89.03     135063
macro avg                                               89.91      89.27      89.04     135063
weighted avg                                            89.91      89.03      88.90     135063

-------------------
           0           1           2
    42795.00      9738.00       803.00
     1495.00     35319.00       549.00
      699.00      1533.00     42132.00
-------------------

[INFO] - saving to /home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-28_11-56-37/test-tedopeswi-4.txt
>>>>>>> 685fc40118c0a5b1039c9fc2926f4bd42aa03d13
[INFO] - Internal process exited
