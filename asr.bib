@misc{
	dynamiccrf,
	author = {W. Lu and H.T. Ng},
	title = {Better punctuation prediction with dynamic conditional random fields},
	year = {2010},
	abstract = {This paper focuses on the task of inserting punctuation symbols into transcribed conversational speech texts, without relying on prosodic cues. We investigate limitations associated with previous methods, and propose a novel approach based on dynamic conditional random fields. Different from previous work, our proposed approach is designed to jointly perform both sentence boundary and sentence type prediction, and punctuation prediction on speech utterances. We performed evaluations on a transcribed conversational speech domain consisting of both English and Chinese texts. Empirical results show that our method outperforms an approach based on linear-chain conditional random fields and other previous approaches. © 2010 Association for Computational Linguistics.}
}

@article{jointlearningcorrbirnn, title={Joint Learning of Correlated Sequence Labeling Tasks Using Bidirectional Recurrent Neural Networks}, DOI={10.21437/interspeech.2017-1247}, journal={Interspeech 2017}, author={Pahuja, Vardaan and Laha, Anirban and Mirkin, Shachar and Raykar, Vikas and Kotlerman, Lili and Lev, Guy}, year={2017}, month={Jul}} 

@inproceedings{birnnattention,
  title={Bidirectional Recurrent Neural Network with Attention Mechanism for Punctuation Restoration},
  author={Ottokar Tilk and Tanel Alum{\"a}e},
  booktitle={INTERSPEECH},
  year={2016}
}

@article{kim_2019, title={Deep Recurrent Neural Networks with Layer-wise Multi-head Attentions for Punctuation Restoration}, DOI={10.1109/icassp.2019.8682418}, journal={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, author={Kim, Seokhwan}, year={2019}, month={Apr}} 

@article{nguyen_nguyen_nguyen_phuong_nguyen_do_mai_2019, title={Fast and Accurate Capitalization and Punctuation for Automatic Speech Recognition Using Transformer and Chunk Merging}, DOI={10.1109/o-cocosda46868.2019.9041202}, journal={2019 22nd Conference of the Oriental COCOSDA International Committee for the Co-ordination and Standardisation of Speech Databases and Assessment Techniques (O-COCOSDA)}, author={Nguyen, Binh and Nguyen, Vu Bao Hung and Nguyen, Hien and Phuong, Pham Ngoc and Nguyen, The-Loc and Do, Quoc Truong and Mai, Luong Chi}, year={2019}, month={Aug}}

@INPROCEEDINGS{pandababa,  author={K. {Makhija} and T. {Ho} and E. {Chng}},  booktitle={2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)},   title={\href{https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9023200}{Transfer Learning for Punctuation Prediction}},   year={2019},  volume={},  number={},  pages={268-273},  note={Code available at \url{https://github.com/panda-baba/bert\_punct}}, doi={10.1109/APSIPAASC47483.2019.9023200}}

@INPROCEEDINGS{2009,
  author={A. {Gravano} and M. {Jansche} and M. {Bacchiani}},
  booktitle={2009 IEEE International Conference on Acoustics, Speech and Signal Processing}, 
  title={Restoring punctuation and capitalization in transcribed speech}, 
  year={2009},
  volume={},
  number={},
  pages={4741-4744},
  doi={10.1109/ICASSP.2009.4960690}}

@article{adversarial,
  title={Adversarial Transfer Learning for Punctuation Restoration},
  author={Jiangyan Yi and J. Tao and Ye Bai and Z. Tian and Cunhang Fan},
  journal={ArXiv},
  year={2020},
  volume={abs/2004.00248}
}

@misc{bertcrf,
    title={Portuguese Named Entity Recognition using BERT-CRF},
    author={Fábio Souza and Rodrigo Nogueira and Roberto Lotufo},
    year={2019},
    eprint={1909.10649},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{chinesebertbilstm,
  title={Using bidirectional LSTM with BERT for Chinese punctuation prediction},
  author={Fang, Mingfeng and Zhao, Haifeng and Song, Xiao and Wang, Xin and Huang, Shilei},
  booktitle={2019 IEEE International Conference on Signal, Information and Data Processing (ICSIDP)},
  pages={1--5},
  year={2019},
  organization={IEEE}
}

@inproceedings{glove,
    title = "{G}lo{V}e: Global Vectors for Word Representation",
    author = "Pennington, Jeffrey  and
      Socher, Richard  and
      Manning, Christopher",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D14-1162",
    doi = "10.3115/v1/D14-1162",
    pages = "1532--1543",
}

@article{floater,
  title={Learning to Encode Position for Transformer with Continuous Dynamical Model},
  author={Liu, Xuanqing and Yu, Hsiang-Fu and Dhillon, Inderjit and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:2003.09229},
  year={2020},
  note={Code available at \url{https://github.com/xuanqing94/FLOATER}}
}

@article{positionembedding,
  title={What Do Position Embeddings Learn? An Empirical Study of Pre-Trained Language Model Positional Encoding},
  author={Wang, Yu-An and Chen, Yun-Nung},
  journal={arXiv preprint arXiv:2010.04903},
  year={2020}
}

@inproceedings{mecrf,
    title = "Capturing Long-range Contextual Dependencies with Memory-enhanced Conditional Random Fields",
    author = "Liu, Fei  and
      Baldwin, Timothy  and
      Cohn, Trevor",
    booktitle = "Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = nov,
    year = "2017",
    address = "Taipei, Taiwan",
    publisher = "Asian Federation of Natural Language Processing",
    url = "https://www.aclweb.org/anthology/I17-1056",
    pages = "555--565",
    abstract = "Despite successful applications across a broad range of NLP tasks, conditional random fields ({``}CRFs{''}), in particular the linear-chain variant, are only able to model local features. While this has important benefits in terms of inference tractability, it limits the ability of the model to capture long-range dependencies between items. Attempts to extend CRFs to capture long-range dependencies have largely come at the cost of computational complexity and approximate inference. In this work, we propose an extension to CRFs by integrating external memory, taking inspiration from memory networks, thereby allowing CRFs to incorporate information far beyond neighbouring steps. Experiments across two tasks show substantial improvements over strong CRF and LSTM baselines.",
}

@inproceedings{lstmbase,
  title={LSTM for punctuation restoration in speech transcripts},
  author={Tilk, Ottokar and Alum{\"a}e, Tanel},
  booktitle={Sixteenth annual conference of the international speech communication association},
  year={2015}
}

@inproceedings{memnet,   
  title={Memnet: A persistent memory network for image restoration},
  author={Tai, Ying and Yang, Jian and Liu, Xiaoming and Xu, Chunyan},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4539--4547},
  year={2017}
}

@article{adaptivenerunbalanceddata,
  title={Adaptive Name Entity Recognition under Highly Unbalanced Data},
  author={Nguyen, Thong and Nguyen, Duy and Rao, Pramod},
  journal={arXiv preprint arXiv:2003.10296},
  year={2020}
}

@inproceedings{attentionisallyouneed,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@inproceedings{efficientbertrobust,
    title = "Efficient Automatic Punctuation Restoration Using Bidirectional Transformers with Robust Inference",
    author = "Courtland, Maury  and
      Faulkner, Adam  and
      McElvain, Gayle",
    booktitle = "Proceedings of the 17th International Conference on Spoken Language Translation",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.iwslt-1.33",
    doi = "10.18653/v1/2020.iwslt-1.33",
    pages = "272--279",
    abstract = "Though people rarely speak in complete sentences, punctuation confers many benefits to the readers of transcribed speech. Unfortunately, most ASR systems do not produce punctuated output. To address this, we propose a solution for automatic punctuation that is both cost efficient and easy to train. Our solution benefits from the recent trend in fine-tuning transformer-based language models. We also modify the typical framing of this task by predicting punctuation for sequences rather than individual tokens, which makes for more efficient training and inference. Finally, we find that aggregating predictions across multiple context windows improves accuracy even further. Our best model achieves a new state of the art on benchmark data (TED Talks) with a combined F1 of 83.9, representing a 48.7{\%} relative improvement (15.3 absolute) over the previous state of the art.",
}

@INPROCEEDINGS{translation,  author={F. {Wang} and W. {Chen} and Z. {Yang} and B. {Xu}},  booktitle={2018 24th International Conference on Pattern Recognition (ICPR)},   title={Self-Attention Based Network for Punctuation Restoration},   year={2018},  volume={},  number={},  pages={2803-2808},  doi={10.1109/ICPR.2018.8545470}}

@misc{speechtranslationrobust,
      title={Improving the Robustness of Speech Translation}, 
      author={Xiang Li and Haiyang Xue and Wei Chen and Yang Liu and Yang Feng and Qun Liu},
      year={2018},
      eprint={1811.00728},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{noisy,
    title = "Punctuation Restoration using Transformer Models for High-and Low-Resource Languages",
    author = "Alam, Tanvirul  and
      Khan, Akib  and
      Alam, Firoj",
    booktitle = "Proceedings of the Sixth Workshop on Noisy User-generated Text (W-NUT 2020)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.wnut-1.18",
    doi = "10.18653/v1/2020.wnut-1.18",
    pages = "132--142",
    abstract = "Punctuation restoration is a common post-processing problem for Automatic Speech Recognition (ASR) systems. It is important to improve the readability of the transcribed text for the human reader and facilitate NLP tasks. Current state-of-art address this problem using different deep learning models. Recently, transformer models have proven their success in downstream NLP tasks, and these models have been explored very little for the punctuation restoration problem. In this work, we explore different transformer based models and propose an augmentation strategy for this task, focusing on high-resource (English) and low-resource (Bangla) languages. For English, we obtain comparable state-of-the-art results, while for Bangla, it is the first reported work, which can serve as a strong baseline for future work. We have made our developed Bangla dataset publicly available for the research community.",
}

@misc{medicalasr,
      title={Robust Prediction of Punctuation and Truecasing for Medical ASR}, 
      author={Monica Sunkara and Srikanth Ronanki and Kalpit Dixit and Sravan Bodapati and Katrin Kirchhoff},
      year={2020},
      eprint={2007.02025},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{multimodalsemi,
      title={Multimodal Semi-supervised Learning Framework for Punctuation Prediction in Conversational Speech}, 
      author={Monica Sunkara and Srikanth Ronanki and Dhanush Bekal and Sravan Bodapati and Katrin Kirchhoff},
      year={2020},
      eprint={2008.00702},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@misc{li2020dice,
      title={Dice Loss for Data-imbalanced NLP Tasks}, 
      author={Xiaoya Li and Xiaofei Sun and Yuxian Meng and Junjun Liang and Fei Wu and Jiwei Li},
      year={2020},
      eprint={1911.02855},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}