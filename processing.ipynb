{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_test=pd.read_csv(\"/home/nxingyu/data/open_subtitles_processed.test.csv\")\n",
    "open_dev=pd.read_csv(\"/home/nxingyu/data/open_subtitles_processed.dev.csv\")\n",
    "open_train=pd.read_csv(\"/home/nxingyu/data/open_subtitles_processed.train.csv\")\n",
    "def punct_proportion(df):\n",
    "    l=[]\n",
    "    for c in \".?!,;:-—\":\n",
    "        l.append(sum(df.transcript.str.count(\"\\\\\"+c)))\n",
    "    [print(i[0],i[1],i[1]/sum(l)) for i in zip(list(\".?!,;:-—\"),l)]\n",
    "for split in open_train, open_dev, open_test:\n",
    "# for split in ted_train,ted_dev,ted_test:\n",
    "    punct_proportion(split)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1320    THOSE LOVE PANGS RIVALS THERE'S A FEMALE HIDIN...\n",
       "Name: transcript, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_test.transcript[open_test.transcript.apply(lambda x:len(x.split()))==17]#.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset csv (/home/nxingyu/.cache/huggingface/datasets/csv/default-f6b55550f42cdbb1/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2)\n",
      "Using custom data configuration default\n",
      "Reusing dataset csv (/home/nxingyu/.cache/huggingface/datasets/csv/default-55c9b22019308537/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ted=load_dataset('csv',data_files={'train':'/home/nxingyu/data/ted_talks_processed.train.csv',\n",
    "                                         'dev':'/home/nxingyu/data/ted_talks_processed.dev.csv',\n",
    "                                         'test':'/home/nxingyu/data/ted_talks_processed.test.csv'})\n",
    "subtitles=load_dataset('csv',data_files={'train':'/home/nxingyu/data/open_subtitles_processed.train.csv',\n",
    "                                         'dev':'/home/nxingyu/data/open_subtitles_processed.dev.csv',\n",
    "                                         'test':'/home/nxingyu/data/open_subtitles_processed.test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk_id</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1561</td>\n",
       "      <td>Some years ago, I set out to try to understand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1526</td>\n",
       "      <td>I thought if I skipped it might help my nerves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1215</td>\n",
       "      <td>Today I'd like to show you the future of the w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633</td>\n",
       "      <td>These are grim economic times, fellow TEDsters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1655</td>\n",
       "      <td>Let me tell you a story. It's my first year as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>1644</td>\n",
       "      <td>Hello. My name is Jarrett Krosoczka, and I wri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>1692</td>\n",
       "      <td>I have a friend in Portugal whose grandfather ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>1910</td>\n",
       "      <td>Some of my most wonderful memories of childhoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>1324</td>\n",
       "      <td>Nearly everyone in the world is part of some c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>62263</td>\n",
       "      <td>Picture yourself driving down the road tomorro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3189 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      talk_id                                         transcript\n",
       "0        1561  Some years ago, I set out to try to understand...\n",
       "1        1526  I thought if I skipped it might help my nerves...\n",
       "2        1215  Today I'd like to show you the future of the w...\n",
       "3         633  These are grim economic times, fellow TEDsters...\n",
       "4        1655  Let me tell you a story. It's my first year as...\n",
       "...       ...                                                ...\n",
       "3184     1644  Hello. My name is Jarrett Krosoczka, and I wri...\n",
       "3185     1692  I have a friend in Portugal whose grandfather ...\n",
       "3186     1910  Some of my most wonderful memories of childhoo...\n",
       "3187     1324  Nearly everyone in the world is part of some c...\n",
       "3188    62263  Picture yourself driving down the road tomorro...\n",
       "\n",
       "[3189 rows x 2 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_train.sort_values('talk_id').sample(frac=1,random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'!': 1, ',': 2, '-': 3, '.': 4, ':': 5, ';': 6, '?': 7, '—': 8, '…': 9},\n",
       " {1: '!', 2: ',', 3: '-', 4: '.', 5: ':', 6: ';', 7: '?', 8: '—', 9: '…'})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
    "tags=sorted(list('.?!,;:-—…'))\n",
    "tag2id = {tag: id+1 for id, tag in enumerate(tags)}\n",
    "id2tag = {id: tag for tag, id in tag2id.items()}\n",
    "tag2id,id2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import numpy as np\n",
    "def text2masks(text,n):\n",
    "    '''Converts single paragraph of text into a list of words and corresponding punctuation based on the degree requested.'''\n",
    "    refilter=\"(?<=[.?!,;:\\-—… ])(?=[^.?!,;:\\-—… ])|$\" if n==0 else \"[.?!,;:\\-—…]{1,%d}(?= *[^.?!,;:\\-—…]+|$)|(?<=[^.?!,;:\\-—…]) +(?=[^.?!,;:\\-—…])\"%(n)\n",
    "    punct=re.findall(refilter,text)\n",
    "    word=re.split(refilter,text)\n",
    "    wordlist=[]\n",
    "    punctlist=[]\n",
    "    for i in zip(word,punct+['']):\n",
    "        w,p=i[0].strip(),i[1].strip()\n",
    "        if w!='':\n",
    "            wordlist.append(re.sub(r'[.?!,;:\\-—… ]','',w))\n",
    "            punctlist.append(0 if not w[-1] in '.?!,;:-—…' else tag2id[w[-1]])\n",
    "        if p!='':\n",
    "            wordlist.append(p)\n",
    "            punctlist.append(0)\n",
    "    return(wordlist,punctlist)\n",
    "def chunk_examples_with_degree(n):\n",
    "    def chunk_examples(examples):\n",
    "        output={}\n",
    "        output['texts']=[]\n",
    "        output['tags']=[]\n",
    "        for sentence in examples['transcript']:\n",
    "            text,tag=text2masks(sentence,n)    \n",
    "            for i in range(len(text)//8):\n",
    "                output['texts'].append(text[i*8:min((i+2)*8,len(text))])\n",
    "                output['tags'].append(tag[i*8:min((i+2)*8,len(text))])\n",
    "        return output\n",
    "    return chunk_examples\n",
    "\n",
    "def encode_tags(encodings, labels):\n",
    "    encoded_labels = []\n",
    "    for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
    "        # create an empty array of -100\n",
    "        doc_enc_labels = np.ones(len(doc_offset),dtype=int) * -100\n",
    "        arr_offset = np.array(doc_offset)\n",
    "\n",
    "        # set labels whose first offset position is 0 and the second is not 0\n",
    "        doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
    "        encoded_labels.append(doc_enc_labels.tolist())\n",
    "\n",
    "    return encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa96f21d6eeb4c8a925c2a339626b483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=64.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ({input_ids: (60,), token_type_ids: (60,), attention_mask: (60,)}, (60,)), types: ({input_ids: tf.int32, token_type_ids: tf.int32, attention_mask: tf.int32}, tf.int32)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "chunked_ted=ted['train'].map(chunk_examples_with_degree(0), batched=True, batch_size=50,remove_columns=ted['train'].column_names)\n",
    "encodings=tokenizer(chunked_ted['texts'], is_split_into_words=True, return_offsets_mapping=True, return_overflowing_tokens=True, padding=True, truncation=True)\n",
    "labels=encode_tags(encodings, chunked_ted['tags'])\n",
    "encodings.pop(\"offset_mapping\")\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(encodings),\n",
    "    labels\n",
    "))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1448, 2247, 4427, 1107, 1381, 5227, 2021, 15474, 8449, 1105, 8703, 170, 1299, 1150, 102], [101, 2021, 15474, 8449, 1105, 8703, 170, 1299, 1150, 1691, 10108, 102, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]], 'offset_mapping': [[(0, 0), (0, 3), (0, 6), (0, 9), (0, 2), (0, 4), (0, 2), (0, 6), (0, 8), (0, 10), (0, 3), (0, 8), (0, 1), (0, 3), (0, 3), (0, 0)], [(0, 0), (0, 6), (0, 8), (0, 10), (0, 3), (0, 8), (0, 1), (0, 3), (0, 3), (0, 8), (0, 10), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)]], 'overflow_to_sample_mapping': [0, 0]}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(chunked_ted['texts'][0], is_split_into_words=True, return_offsets_mapping=True, return_overflowing_tokens=True, padding=True, truncation=True, stride=8, max_length=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "encodings.pop(\"offset_mapping\")\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(encodings),\n",
    "    labels\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': <tf.Tensor: shape=(25,), dtype=int32, numpy=\n",
      "array([  101,  1448,  2247,  4427,  1107,  1381,  5227,  2021, 15474,\n",
      "        8449,  1105,  8703,   170,  1299,  1150,  1691,   102,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(25,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(25,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0], dtype=int32)>}, <tf.Tensor: shape=(25,), dtype=int32, numpy=\n",
      "array([-100,    0,    0,    0,    0,    2,    0,    0,    2,    0,    0,\n",
      "          0,    0,    0,    0,    0, -100, -100, -100, -100, -100, -100,\n",
      "       -100, -100, -100], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for data in dataset.take(1):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import TFBertForSequenceClassification\n",
    "# model = TFBertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=len(unique_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 20062, 117, 1166, 122, 1553, 126, 3775, 1234, 2541, 4223, 4139, 119, 1130, 2593, 117, 1234, 1132, 2257, 1106, 10556, 1147, 1583, 117, 2128, 1166, 1405, 1550, 8940, 119, 4288, 117, 1443, 170, 4095, 117, 1132, 1103, 1211, 7386, 1105, 8018, 5256, 795, 1133, 1136, 1198, 1121, 1103, 5119, 2952, 18552, 117, 1133, 1121, 1103, 1510, 8362, 20080, 27443, 3154, 1115, 8755, 1138, 1113, 1147, 2073, 119, 1109, 5758, 1104, 1594, 1817, 1482, 1120, 170, 1842, 1344, 3187, 1111, 1103, 1718, 1104, 6438, 1105, 18560, 2645, 119, 4288, 117, 1112, 1195, 1169, 1178, 5403, 117, 1209, 1631, 4472, 117, 4963, 1105, 1120, 3187, 119, 1252, 1175, 1110, 1363, 2371, 119, 1109, 3068, 1104, 1920, 1115, 1482, 3531, 1107, 1147, 2073, 1169, 1138, 170, 1167, 2418, 2629, 1113, 1147, 1218, 118, 1217, 1190, 1121, 1103, 4315, 5758, 1104, 1594, 1115, 1152, 1138, 1151, 5490, 1106, 119, 1573, 2140, 117, 1482, 1169, 1129, 4921, 1118, 3258, 117, 5343, 6486, 1158, 1219, 1105, 1170, 4139, 119, 1130, 1349, 117, 146, 1108, 170, 1148, 118, 1214, 7735, 2377, 1107, 1103, 1239, 1104, 4280, 1323, 1104, 24797, 4052, 119, 2409, 1242, 1104, 1128, 1303, 117, 146, 2542, 1103, 5532, 1107, 7303, 8362, 10787, 1107, 1524, 1104, 1143, 1113, 1103, 1794, 119, 1422, 1266, 1110, 2034, 1121, 7303, 117, 1105, 1304, 1346, 1113, 117, 146, 1575, 1317, 1266, 1484, 1107, 1541, 16358, 14791, 16877, 3242, 119, 146, 112, 173, 3465, 1105, 146, 112, 173, 8422, 1114, 1139, 1266, 1105, 2824, 1103, 1794, 119, 1284, 112, 1396, 1155, 1562, 1343, 4429, 131, 10095, 9769, 2275, 117, 10676, 117, 5915, 1105, 1234, 7406, 1105, 1919, 119, 1135, 1108, 1579, 1103, 1234, 7406, 1105, 1919, 1115, 1541, 1400, 1143, 1103, 1211, 117, 2108, 1343, 10444, 118, 1702, 1482, 119, 146, 1108, 170, 1534, 1106, 1160, 1685, 117, 3417, 1107, 27110, 8588, 1482, 119, 1220, 1127, 1421, 1105, 1565, 1173, 117, 1120, 1126, 1425, 1187, 1152, 3417, 1455, 7424, 1105, 7424, 1104, 3243, 117, 1105, 2637, 1842, 117, 13870, 6615, 119, 1573, 117, 146, 1310, 1106, 4608, 1184, 1122, 1547, 1129, 1176, 1106, 6486, 1139, 1482, 1107, 170, 1594, 4834, 1105, 170, 15820, 3227, 119, 5718, 1139, 1482, 1849, 136, 5718, 1139, 1797, 112, 188, 3999, 117, 2816, 1257, 3857, 1147, 18978, 136, 5718, 1139, 1488, 112, 188, 1541, 8000, 1105, 1920, 26743, 2731, 1561, 22984, 1105, 9512, 136, 1731, 1156, 146, 16743, 136, 5718, 146, 1849, 136, 1249, 16979, 1116, 1105, 6486, 26657, 117, 1195, 1221, 1115, 1981, 1158, 2153, 1114, 4196, 1107, 12605, 1111, 1147, 1482, 1169, 1138, 170, 3321, 2629, 1113, 1147, 1218, 118, 1217, 117, 1105, 1195, 1840, 1142, 6486, 2013, 119, 1109, 2304, 146, 1125, 1108, 117, 1180, 6486, 2013, 2648, 1129, 5616, 1111, 2073, 1229, 1152, 1127, 1253, 1107, 1594, 10490, 1137, 15820, 7869, 136, 7426, 1195, 2519, 1172, 1114, 5566, 1137, 2013, 1115, 1156, 1494, 1172, 1194, 1292, 11998, 136, 1573, 146, 4685, 1139, 7735, 16014, 117, 2986, 4858, 11917, 2312, 117, 1114, 1103, 1911, 1104, 1606, 1139, 3397, 4196, 1106, 1294, 1199, 1849, 1107, 1103, 1842, 1362, 119, 146, 1445, 112, 189, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 9), (9, 10), (11, 15), (16, 17), (18, 23), (24, 25), (26, 33), (34, 40), (41, 51), (52, 57), (58, 66), (66, 67), (68, 70), (71, 79), (79, 80), (81, 87), (88, 91), (92, 98), (99, 101), (102, 106), (107, 112), (113, 120), (120, 121), (122, 129), (130, 134), (135, 137), (138, 145), (146, 154), (154, 155), (156, 164), (164, 165), (166, 173), (174, 175), (176, 181), (181, 182), (183, 186), (187, 190), (191, 195), (196, 204), (205, 208), (209, 219), (220, 227), (228, 229), (230, 233), (234, 237), (238, 242), (243, 247), (248, 251), (252, 259), (260, 268), (269, 276), (276, 277), (278, 281), (282, 286), (287, 290), (291, 296), (297, 299), (299, 301), (301, 305), (306, 313), (314, 318), (319, 323), (324, 328), (329, 331), (332, 337), (338, 346), (346, 347), (348, 351), (352, 363), (364, 366), (367, 370), (371, 376), (377, 385), (386, 388), (389, 390), (391, 395), (396, 400), (401, 405), (406, 409), (410, 413), (414, 425), (426, 428), (429, 438), (439, 442), (443, 453), (454, 462), (462, 463), (464, 472), (472, 473), (474, 476), (477, 479), (480, 483), (484, 488), (489, 496), (496, 497), (498, 502), (503, 507), (508, 515), (515, 516), (517, 527), (528, 531), (532, 534), (535, 539), (539, 540), (541, 544), (545, 550), (551, 553), (554, 558), (559, 563), (563, 564), (565, 568), (569, 576), (577, 579), (580, 584), (585, 589), (590, 598), (599, 606), (607, 609), (610, 615), (616, 624), (625, 628), (629, 633), (634, 635), (636, 640), (641, 652), (653, 659), (660, 662), (663, 668), (669, 673), (673, 674), (674, 679), (680, 684), (685, 689), (690, 693), (694, 700), (701, 712), (713, 715), (716, 719), (720, 724), (725, 729), (730, 734), (735, 739), (740, 747), (748, 750), (750, 751), (752, 754), (755, 763), (763, 764), (765, 773), (774, 777), (778, 780), (781, 790), (791, 793), (794, 798), (798, 799), (800, 806), (807, 813), (813, 816), (817, 823), (824, 827), (828, 833), (834, 842), (842, 843), (844, 846), (847, 851), (851, 852), (853, 854), (855, 858), (859, 860), (861, 866), (866, 867), (867, 871), (872, 875), (876, 883), (884, 886), (887, 890), (891, 901), (902, 904), (905, 915), (916, 922), (923, 925), (926, 939), (940, 948), (948, 949), (950, 954), (955, 959), (960, 962), (963, 966), (967, 971), (971, 972), (973, 974), (975, 982), (983, 986), (987, 993), (994, 996), (997, 1002), (1003, 1005), (1005, 1009), (1010, 1012), (1013, 1018), (1019, 1021), (1022, 1024), (1025, 1027), (1028, 1031), (1032, 1034), (1034, 1035), (1036, 1038), (1039, 1045), (1046, 1048), (1049, 1059), (1060, 1064), (1065, 1070), (1070, 1071), (1072, 1075), (1076, 1080), (1081, 1086), (1087, 1089), (1089, 1090), (1091, 1092), (1093, 1097), (1098, 1105), (1106, 1112), (1113, 1120), (1121, 1123), (1124, 1130), (1131, 1133), (1133, 1136), (1136, 1141), (1142, 1146), (1146, 1147), (1148, 1149), (1149, 1150), (1150, 1151), (1152, 1155), (1156, 1159), (1160, 1161), (1161, 1162), (1162, 1163), (1164, 1170), (1171, 1175), (1176, 1178), (1179, 1185), (1186, 1189), (1190, 1195), (1196, 1199), (1200, 1202), (1202, 1203), (1204, 1206), (1206, 1207), (1207, 1209), (1210, 1213), (1214, 1218), (1219, 1224), (1225, 1231), (1231, 1232), (1233, 1238), (1239, 1249), (1250, 1259), (1259, 1260), (1261, 1266), (1266, 1267), (1268, 1279), (1280, 1283), (1284, 1290), (1291, 1300), (1301, 1304), (1305, 1312), (1312, 1313), (1314, 1316), (1317, 1320), (1321, 1327), (1328, 1331), (1332, 1338), (1339, 1348), (1349, 1352), (1353, 1360), (1361, 1365), (1366, 1372), (1373, 1376), (1377, 1379), (1380, 1383), (1384, 1388), (1388, 1389), (1390, 1400), (1401, 1406), (1407, 1416), (1416, 1417), (1417, 1424), (1425, 1433), (1433, 1434), (1435, 1436), (1437, 1440), (1441, 1442), (1443, 1449), (1450, 1452), (1453, 1456), (1457, 1462), (1462, 1463), (1464, 1473), (1474, 1476), (1476, 1480), (1480, 1485), (1486, 1494), (1494, 1495), (1496, 1500), (1501, 1505), (1506, 1510), (1511, 1514), (1515, 1518), (1519, 1523), (1523, 1524), (1525, 1527), (1528, 1530), (1531, 1534), (1535, 1540), (1541, 1545), (1546, 1555), (1556, 1561), (1562, 1566), (1567, 1570), (1571, 1575), (1576, 1578), (1579, 1588), (1588, 1589), (1590, 1593), (1594, 1602), (1603, 1607), (1607, 1608), (1609, 1619), (1620, 1627), (1627, 1628), (1629, 1631), (1631, 1632), (1633, 1634), (1635, 1640), (1641, 1643), (1644, 1650), (1651, 1655), (1656, 1658), (1659, 1664), (1665, 1667), (1668, 1672), (1673, 1675), (1676, 1682), (1683, 1685), (1686, 1694), (1695, 1697), (1698, 1699), (1700, 1703), (1704, 1708), (1709, 1712), (1713, 1714), (1715, 1722), (1723, 1727), (1727, 1728), (1729, 1734), (1735, 1737), (1738, 1746), (1747, 1753), (1753, 1754), (1755, 1760), (1761, 1763), (1764, 1772), (1772, 1773), (1773, 1774), (1775, 1781), (1781, 1782), (1783, 1788), (1789, 1793), (1794, 1798), (1799, 1804), (1805, 1810), (1810, 1811), (1812, 1817), (1818, 1820), (1821, 1824), (1824, 1825), (1825, 1826), (1827, 1833), (1834, 1841), (1842, 1845), (1846, 1850), (1850, 1854), (1855, 1861), (1862, 1868), (1869, 1876), (1877, 1880), (1881, 1890), (1890, 1891), (1892, 1895), (1896, 1901), (1902, 1903), (1904, 1908), (1908, 1909), (1910, 1915), (1916, 1917), (1918, 1924), (1924, 1925), (1926, 1928), (1929, 1941), (1941, 1942), (1943, 1946), (1947, 1953), (1954, 1962), (1962, 1963), (1964, 1966), (1967, 1971), (1972, 1976), (1977, 1980), (1980, 1983), (1984, 1991), (1992, 1996), (1997, 2003), (2004, 2006), (2007, 2013), (2014, 2017), (2018, 2023), (2024, 2032), (2033, 2036), (2037, 2041), (2042, 2043), (2044, 2048), (2049, 2055), (2056, 2058), (2059, 2064), (2065, 2069), (2069, 2070), (2070, 2075), (2075, 2076), (2077, 2080), (2081, 2083), (2084, 2088), (2089, 2093), (2094, 2100), (2101, 2109), (2109, 2110), (2111, 2114), (2115, 2123), (2124, 2125), (2126, 2129), (2130, 2133), (2133, 2134), (2135, 2140), (2141, 2147), (2148, 2156), (2157, 2165), (2166, 2168), (2169, 2175), (2176, 2179), (2180, 2188), (2189, 2194), (2195, 2199), (2200, 2204), (2205, 2210), (2211, 2213), (2214, 2217), (2218, 2223), (2224, 2226), (2227, 2234), (2235, 2240), (2240, 2241), (2242, 2247), (2248, 2250), (2251, 2256), (2257, 2261), (2262, 2266), (2267, 2273), (2274, 2276), (2277, 2285), (2286, 2290), (2291, 2296), (2297, 2301), (2302, 2306), (2307, 2314), (2315, 2320), (2321, 2330), (2330, 2331), (2332, 2334), (2335, 2336), (2337, 2347), (2348, 2350), (2351, 2354), (2355, 2365), (2365, 2366), (2367, 2376), (2377, 2383), (2384, 2387), (2387, 2389), (2389, 2390), (2391, 2395), (2396, 2399), (2400, 2404), (2405, 2407), (2408, 2413), (2414, 2416), (2417, 2425), (2426, 2432), (2433, 2435), (2436, 2440), (2441, 2445), (2446, 2452), (2453, 2455), (2456, 2459), (2460, 2464), (2465, 2470), (2470, 2471), (2472, 2473), (2474, 2478), (2478, 2479), (2479, 2480), (0, 0)]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(ted['train'][0]['transcript'], return_offsets_mapping=True, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_pretraining_data.py\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import random\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "import tensorflow as tf\n",
    "\n",
    "flags = tf.compat.v1.flags\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow.python.platform.flags' from '/home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/tensorflow/python/platform/flags.py'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TrainingInstance(object):\n",
    "    def __init__(self, tokens, segment_ids, masked_lm_positions, masked_lm_labels, is_random_next):\n",
    "        self.tokens = tokens\n",
    "        self.segment_ids = segment_ids\n",
    "        self.is_random_next = is_random_next\n",
    "        self.masked_lm_positions = masked_lm_positions\n",
    "        self.masked_lm_labels = masked_lm_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
