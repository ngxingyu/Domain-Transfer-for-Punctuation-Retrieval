commit hash: 8db08c4e955012a3024cd494bae21b779bd190d1
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/cmd-args.log b/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/cmd-args.log
deleted file mode 100644
index 11a5d8e..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/cmd-args.log
+++ /dev/null
@@ -1 +0,0 @@
-main.py
\ No newline at end of file
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/events.out.tfevents.1614559517.Titan.22068.0 b/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/events.out.tfevents.1614559517.Titan.22068.0
deleted file mode 100644
index 6d13b0d..0000000
Binary files a/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/events.out.tfevents.1614559517.Titan.22068.0 and /dev/null differ
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/git-info.log b/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/git-info.log
deleted file mode 100644
index b875b0e..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/git-info.log
+++ /dev/null
@@ -1,564 +0,0 @@
-commit hash: e5b025ebdf9e1bc559ccfd307d06d4cb9cfd677a
-diff --git a/NLP.yml b/NLP.yml
-index bc9aa5d..4ae7fd2 100644
---- a/NLP.yml
-+++ b/NLP.yml
-@@ -5,161 +5,237 @@ channels:
-   - defaults
- dependencies:
-   - _libgcc_mutex=0.1=main
-+  - _pytorch_select=0.2=gpu_0
-+  - _tflow_select=2.3.0=mkl
-+  - absl-py=0.11.0=py38h578d9bd_0
-+  - aiohttp=3.7.3=py38h25fe258_0
-+  - argon2-cffi=20.1.0=py38h7b6447c_1
-   - astroid=2.4.2=py38_0
--  - backcall=0.2.0=py_0
-+  - astunparse=1.6.3=py_0
-+  - async-timeout=3.0.1=py_1000
-+  - async_generator=1.10=pyhd3eb1b0_0
-+  - attrs=20.3.0=pyhd3eb1b0_0
-+  - autopep8=1.5.4=py_0
-+  - backcall=0.2.0=pyhd3eb1b0_0
-   - blas=1.0=mkl
-+  - bleach=3.2.3=pyhd3eb1b0_0
-+  - blinker=1.4=py_1
-+  - brotlipy=0.7.0=py38h8df0ef7_1001
-+  - c-ares=1.17.1=h36c2ea0_0
-   - ca-certificates=2021.1.19=h06a4308_0
-+  - cachetools=4.2.1=pyhd8ed1ab_0
-   - certifi=2020.12.5=py38h06a4308_0
-+  - cffi=1.14.4=py38h261ae71_0
-+  - chardet=3.0.4=py38h924ce5b_1008
-+  - click=7.1.2=pyh9f0ad1d_0
-   - code-server=3.8.0=ha770c72_0
--  - cuda91=1.0=h4c16780_0
--  - cudatoolkit=10.2.89=hfd86e86_1
--  - decorator=4.4.2=py_0
--  - icu=68.1=h58526e2_0
-+  - cryptography=3.3.1=py38h3c74f83_0
-+  - cudatoolkit=10.1.243=h6bb024c_0
-+  - cudnn=7.6.5=cuda10.1_0
-+  - dbus=1.13.18=hb2f20db_0
-+  - decorator=4.4.2=pyhd3eb1b0_0
-+  - defusedxml=0.6.0=py_0
-+  - entrypoints=0.3=py38_0
-+  - expat=2.2.10=he6710b0_2
-+  - fontconfig=2.13.0=h9420a91_0
-+  - freetype=2.10.4=h5ab3b9f_0
-+  - fsspec=0.8.5=pyhd8ed1ab_0
-+  - future=0.18.2=py38h578d9bd_3
-+  - gast=0.3.3=py_0
-+  - glib=2.66.1=h92f7085_0
-+  - google-auth=1.24.0=pyhd3deb0d_0
-+  - google-pasta=0.2.0=py_0
-+  - gst-plugins-base=1.14.0=h8213a91_2
-+  - gstreamer=1.14.0=h28cd5cc_2
-+  - hdf5=1.10.6=hb1b8bf9_0
-+  - icu=58.2=he6710b0_3
-+  - idna=2.10=pyh9f0ad1d_0
-+  - importlib-metadata=2.0.0=py_1
-+  - importlib_metadata=2.0.0=1
-   - intel-openmp=2020.2=254
--  - ipython=7.19.0=py38hb070fc8_0
-+  - ipykernel=5.3.4=py38h5ca1d4c_0
-+  - ipython=7.19.0=py38hb070fc8_1
-   - ipython_genutils=0.2.0=pyhd3eb1b0_1
--  - jedi=0.18.0=py38h06a4308_1
-+  - ipywidgets=7.6.3=pyhd3eb1b0_1
-+  - jedi=0.17.0=py38_0
-+  - jinja2=2.11.2=pyhd3eb1b0_0
-+  - jpeg=9b=h024ee3a_2
-+  - jsonschema=3.2.0=py_2
-+  - jupyter=1.0.0=py38_7
-+  - jupyter_client=6.1.7=py_0
-+  - jupyter_console=6.2.0=py_0
-+  - jupyter_core=4.7.0=py38h06a4308_0
-+  - jupyterlab_pygments=0.1.2=py_0
-+  - jupyterlab_widgets=1.0.0=pyhd3eb1b0_1
-+  - keras-preprocessing=1.1.0=py_1
-   - lazy-object-proxy=1.4.3=py38h27cfd23_2
-   - ld_impl_linux-64=2.33.1=h53a641e_7
-   - libedit=3.1.20191231=h14c3975_1
-   - libffi=3.3=he6710b0_2
-   - libgcc-ng=9.1.0=hdf63c60_0
-+  - libgfortran-ng=7.3.0=hdf63c60_0
-+  - libpng=1.6.37=hbc83047_0
-+  - libprotobuf=3.13.0.1=h8b12597_0
-+  - libsodium=1.0.18=h7b6447c_0
-   - libstdcxx-ng=9.1.0=hdf63c60_0
--  - libuv=1.40.0=hd18ef5c_0
-+  - libuuid=1.0.3=h1bed415_2
-+  - libuv=1.40.0=h7b6447c_0
-+  - libxcb=1.14=h7b6447c_0
-+  - libxml2=2.9.10=hb55368b_3
-+  - markdown=3.3.3=pyh9f0ad1d_0
-+  - markupsafe=1.1.1=py38h7b6447c_0
-   - mccabe=0.6.1=py38_1
-+  - mistune=0.8.4=py38h7b6447c_1000
-   - mkl=2020.2=256
-   - mkl-service=2.3.0=py38he904b0f_0
-   - mkl_fft=1.2.0=py38h23d657b_0
-   - mkl_random=1.1.1=py38h0573a6f_0
-+  - multidict=5.1.0=py38h27cfd23_2
-+  - nbclient=0.5.1=py_0
-+  - nbconvert=6.0.7=py38_0
-+  - nbformat=5.1.2=pyhd3eb1b0_1
-   - ncurses=6.2=he6710b0_1
--  - nodejs=12.19.0=hfa01f41_2
-+  - nest-asyncio=1.4.3=pyhd3eb1b0_0
-+  - ninja=1.10.2=py38hff7bd54_0
-+  - nodejs=12.4.0=he1b5a44_0
-+  - notebook=6.2.0=py38h06a4308_0
-   - numpy=1.19.2=py38h54aff64_0
-   - numpy-base=1.19.2=py38hfa32c7d_0
-   - openssl=1.1.1i=h27cfd23_0
--  - pandas=1.2.1=py38ha9443f7_0
-+  - opt_einsum=3.1.0=py_0
-+  - packaging=20.9=pyhd3eb1b0_0
-+  - pandoc=2.11=hb0f4dca_0
-+  - pandocfilters=1.4.3=py38h06a4308_1
-   - parso=0.8.1=pyhd3eb1b0_0
-+  - pcre=8.44=he6710b0_0
-   - pexpect=4.8.0=pyhd3eb1b0_3
-   - pickleshare=0.7.5=pyhd3eb1b0_1003
-   - pip=20.3.3=py38h06a4308_0
-+  - prometheus_client=0.9.0=pyhd3eb1b0_0
-   - prompt-toolkit=3.0.8=py_0
-+  - prompt_toolkit=3.0.8=0
-   - ptyprocess=0.7.0=pyhd3eb1b0_2
-+  - pyasn1=0.4.8=py_0
-+  - pycodestyle=2.6.0=py_0
-+  - pycparser=2.20=py_2
-   - pygments=2.7.4=pyhd3eb1b0_0
-+  - pyjwt=2.0.1=pyhd8ed1ab_0
-   - pylint=2.6.0=py38_0
-+  - pyopenssl=20.0.1=pyhd8ed1ab_0
-+  - pyparsing=2.4.7=pyhd3eb1b0_0
-+  - pyqt=5.9.2=py38h05f1152_4
-+  - pyrsistent=0.17.3=py38h7b6447c_0
-+  - pysocks=1.7.1=py38h578d9bd_3
-   - python=3.8.5=h7579374_1
--  - python-dateutil=2.8.1=py_0
-+  - python-dateutil=2.8.1=pyhd3eb1b0_0
-   - python_abi=3.8=1_cp38
--  - pytz=2020.5=pyhd3eb1b0_0
--  - readline=8.0=h7b6447c_0
-+  - pytorch=1.7.1=py3.8_cuda10.1.243_cudnn7.6.3_0
-+  - pyzmq=20.0.0=py38h2531618_1
-+  - qt=5.9.7=h5867ecd_1
-+  - qtconsole=4.7.7=py_0
-+  - qtpy=1.9.0=py_0
-+  - readline=8.1=h27cfd23_0
-+  - requests=2.25.1=pyhd3deb0d_0
-+  - requests-oauthlib=1.3.0=pyh9f0ad1d_0
-+  - rope=0.18.0=py_0
-+  - rsa=4.7=pyhd3deb0d_0
-+  - send2trash=1.5.0=pyhd3eb1b0_1
-   - setuptools=52.0.0=py38h06a4308_0
-+  - sip=4.19.13=py38he6710b0_0
-   - six=1.15.0=py38h06a4308_0
-   - sqlite=3.33.0=h62c20be_0
-+  - tensorboard=2.3.0=pyh4dce500_0
-+  - tensorboard-plugin-wit=1.8.0=pyh44b312d_0
-+  - tensorflow=2.2.0=mkl_py38h6d3daf0_0
-+  - tensorflow-base=2.2.0=mkl_py38h5059a2d_0
-+  - tensorflow-estimator=2.2.0=pyh208ff02_0
-+  - termcolor=1.1.0=py38_1
-+  - terminado=0.9.2=py38h06a4308_0
-+  - testpath=0.4.4=pyhd3eb1b0_0
-   - tk=8.6.10=hbc83047_0
--  - traitlets=5.0.5=py_0
-+  - toml=0.10.1=py_0
-+  - tornado=6.1=py38h27cfd23_0
-+  - traitlets=5.0.5=pyhd3eb1b0_0
-+  - typing-extensions=3.7.4.3=0
-+  - typing_extensions=3.7.4.3=py_0
-+  - urllib3=1.26.3=pyhd8ed1ab_0
-   - wcwidth=0.2.5=py_0
-+  - webencodings=0.5.1=py38_1
-+  - werkzeug=1.0.1=pyh9f0ad1d_0
-   - wheel=0.36.2=pyhd3eb1b0_0
-+  - widgetsnbextension=3.5.1=py38_0
-+  - wrapt=1.11.2=py38h7b6447c_0
-   - xz=5.2.5=h7b6447c_0
-+  - yaml=0.2.5=h516909a_0
-+  - yarl=1.6.3=py38h25fe258_0
-+  - zeromq=4.3.3=he6710b0_3
-+  - zipp=3.4.0=pyhd3eb1b0_0
-   - zlib=1.2.11=h7b6447c_3
-   - pip:
--    - absl-py==0.11.0
--    - aiohttp==3.7.3
-     - alabaster==0.7.12
-     - antlr4-python3-runtime==4.8
--    - apex==0.1
-     - appdirs==1.4.4
--    - argon2-cffi==20.1.0
-     - asttokens==2.0.4
--    - async-generator==1.10
--    - async-timeout==3.0.1
-     - attrdict==2.0.1
--    - attrs==20.3.0
-     - audioread==2.1.9
-     - babel==2.9.0
-     - black==19.10b0
--    - bleach==3.2.3
--    - boto3==1.16.61
--    - botocore==1.19.61
-+    - boto3==1.16.63
-+    - botocore==1.19.63
-     - braceexpand==0.1.6
--    - cachetools==4.2.1
--    - cffi==1.14.4
--    - chardet==3.0.4
--    - click==7.1.2
-+    - cheap-repr==0.4.4
-     - colorama==0.4.4
-     - configparser==5.0.1
-     - cycler==0.10.0
-     - cython==0.29.21
-     - datasets==1.2.1
--    - defusedxml==0.6.0
-     - dill==0.3.3
-     - distance==0.1.3
-     - docker-pycreds==0.4.0
-     - docopt==0.6.2
-     - docutils==0.16
-     - editdistance==0.5.3
--    - entrypoints==0.3
-     - executing==0.5.4
-     - filelock==3.0.12
-     - frozendict==1.2
--    - fsspec==0.8.5
--    - future==0.18.2
-     - g2p-en==2.1.0
-     - gdown==3.12.2
-     - gitdb==4.0.5
-     - gitpython==3.1.12
--    - google-auth==1.24.0
-     - google-auth-oauthlib==0.4.2
-     - grpcio==1.35.0
-     - h5py==3.1.0
--    - hydra==2.5
--    - hydra-core==1.0.5
-+    - hydra-core==1.1.0.dev3
-     - icecream==2.1.0
--    - idna==2.10
-     - imagesize==1.2.0
-     - importlib-resources==5.1.0
-     - inflect==5.0.2
-     - iniconfig==1.1.1
--    - ipykernel==5.4.3
--    - ipywidgets==7.6.3
-     - isort==4.3.21
--    - jinja2==2.11.2
-     - jmespath==0.10.0
-     - joblib==1.0.0
--    - jsonschema==3.2.0
--    - jupyter==1.0.0
--    - jupyter-client==6.1.11
--    - jupyter-console==6.2.0
--    - jupyter-core==4.7.0
--    - jupyterlab-pygments==0.1.2
--    - jupyterlab-widgets==1.0.0
-+    - kaggle==1.5.10
-     - kaldi-io==0.9.4
-     - kaldi-python-io==1.2.1
-     - kiwisolver==1.3.1
-     - latexcodec==2.0.1
-     - librosa==0.8.0
-     - llvmlite==0.35.0
--    - markdown==3.3.3
--    - markupsafe==1.1.1
-+    - logging==0.4.9.6
-     - marshmallow==3.10.0
--    - matplotlib==3.3.3
-+    - matplotlib==3.3.4
-     - megatron-lm==1.1.5
--    - mistune==0.8.4
-     - msgpack==1.0.2
--    - multidict==5.1.0
-     - multiprocess==0.70.11.1
--    - nbclient==0.5.1
--    - nbconvert==6.0.7
--    - nbformat==5.1.2
-     - nemo-toolkit==1.0.0b2
--    - nest-asyncio==1.4.3
-     - nltk==3.5
--    - notebook==6.2.0
-     - num2words==0.5.10
-     - numba==0.52.0
-     - oauthlib==3.1.0
-     - objectio==0.2.29
--    - omegaconf==2.0.6
--    - onnx==1.8.0
--    - packaging==20.8
--    - pandocfilters==1.4.3
-+    - omegaconf==2.1.0.dev17
-+    - onnx==1.8.1
-+    - pandas==1.2.1
-     - parameterized==0.8.1
-     - pathspec==0.8.1
-     - pathtools==0.1.2
-@@ -169,52 +245,38 @@ dependencies:
-     - pipreqs==0.4.10
-     - pluggy==0.13.1
-     - pooch==1.3.0
--    - portalocker==2.1.0
--    - prometheus-client==0.9.0
-     - promise==2.3
-     - protobuf==3.14.0
-     - psutil==5.8.0
-     - py==1.10.0
-     - pyarrow==3.0.0
--    - pyasn1==0.4.8
-     - pyasn1-modules==0.2.8
-     - pybind11==2.6.2
-     - pybtex==0.24.0
-     - pybtex-docutils==1.0.0
--    - pycparser==2.20
--    - pydub==0.24.1
--    - pyparsing==2.4.7
-     - pypinyin==0.40.0
--    - pyrsistent==0.17.3
--    - pysocks==1.7.1
-     - pystoi==0.3.3
-     - pytest==6.2.2
-     - pytest-runner==5.2
--    - python-levenshtein==0.12.1
--    - pytorch-lightning==1.1.3
--    - pyyaml==5.4.1
--    - pyzmq==21.0.2
--    - qtconsole==5.0.2
--    - qtpy==1.9.0
-+    - python-slugify==4.0.1
-+    - pytorch-lightning==1.1.5
-+    - pytz==2020.5
-+    - pyyaml==5.3.1
-     - rapidfuzz==0.14.2
-     - regex==2020.11.13
--    - requests==2.25.1
--    - requests-oauthlib==1.3.0
-     - resampy==0.2.2
--    - rsa==4.7
-     - ruamel-yaml==0.16.12
-     - ruamel-yaml-clib==0.2.2
-     - s3transfer==0.3.4
--    - sacrebleu==1.5.0
-     - sacremoses==0.0.43
-     - scikit-learn==0.24.1
-     - scipy==1.6.0
--    - send2trash==1.5.0
-     - sentencepiece==0.1.95
-     - sentry-sdk==0.19.5
-     - shortuuid==1.0.1
-     - simplejson==3.17.2
-     - smmap==3.0.5
-+    - snoop==0.2.5
-     - snowballstemmer==2.1.0
-     - soundfile==0.10.3.post1
-     - sox==1.4.1
-@@ -227,35 +289,24 @@ dependencies:
-     - sphinxcontrib-qthelp==1.0.3
-     - sphinxcontrib-serializinghtml==1.1.4
-     - subprocess32==3.5.4
--    - tensorboard==2.4.1
--    - tensorboard-plugin-wit==1.8.0
--    - terminado==0.9.2
--    - testpath==0.4.4
-+    - tensorboardx==2.1
-+    - text-unidecode==1.3
-     - threadpoolctl==2.1.0
-     - tokenizers==0.9.4
--    - toml==0.10.2
-     - torch==1.7.1
-     - torch-stft==0.1.4
--    - torchtext==0.8.1
-+    - torchtools==0.2.5
-     - torchvision==0.8.2
--    - tornado==6.1
-     - tqdm==4.49.0
-     - transformers==4.2.2
-     - typed-ast==1.4.2
-     - typer==0.3.2
--    - typing-extensions==3.7.4.3
-     - unidecode==1.1.2
--    - urllib3==1.26.3
-     - wandb==0.10.15
-     - watchdog==0.10.4
-     - webdataset==0.1.40
--    - webencodings==0.5.1
--    - werkzeug==1.0.1
-     - wget==3.2
--    - widgetsnbextension==3.5.1
--    - wrapt==1.12.1
-     - xxhash==2.0.0
-     - yarg==0.1.9
--    - yarl==1.6.3
-     - youtokentome==1.0.6
- prefix: /home/nxingyu/miniconda3/envs/NLP
-diff --git a/experiment/config.yaml b/experiment/config.yaml
-index 3e8fef7..809477a 100644
---- a/experiment/config.yaml
-+++ b/experiment/config.yaml
-@@ -32,12 +32,12 @@ trainer:
-     # resume_from_checkpoint: null
- 
- exp_manager:
--    exp_dir: /home/nxingyu2/project/ # /root/project # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
-+    exp_dir: /home/${env:USER}/project/ # /root/project # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
-     name: Punctuation_with_Domain_discriminator  # The name of your model
-     create_tensorboard_logger: true  # Whether you want exp_manger to create a tb logger
-     create_checkpoint_callback: true 
--base_path: /home/nxingyu2/data # /root/data # 
--tmp_path: /home/nxingyu2/data/tmp # /tmp # 
-+base_path: /home/${env:USER}/data # /root/data # 
-+tmp_path: /home/${env:USER}/data/tmp # /tmp # 
- log_dir: null
- 
- model:
-@@ -74,7 +74,7 @@ model:
-     punct_class_weights: false #false
-     
-     dataset:
--        data_dir: /home/nxingyu2/data # /root/data # 
-+        data_dir: /home/${env:USER}/data # /root/data # 
-         labelled:
-             # - ${base_path}/ted2010 #
-             - ${base_path}/ted_talks_processed #
-diff --git a/experiment/core/losses/focal_loss.py b/experiment/core/losses/focal_loss.py
-index 96f1391..2352908 100644
---- a/experiment/core/losses/focal_loss.py
-+++ b/experiment/core/losses/focal_loss.py
-@@ -18,8 +18,8 @@ class FocalLoss(torch.nn.NLLLoss):
-         self.gamma = gamma
- 
-     def forward(self, logits: Tensor, labels: Tensor, loss_mask=None) -> Tensor:
--        logits_flatten = torch.flatten(logits, start_dim=0, end_dim=-2)
--        labels_flatten = torch.flatten(labels, start_dim=0, end_dim=-1)
-+        logits_flatten = torch.flatten(logits, start_dim=0, end_dim=1) #try change from -2 to 1
-+        labels_flatten = torch.flatten(labels, start_dim=0, end_dim=1) #try change from -1 to 1
-         self.num_classes=logits_flatten.shape[-1]
-         
-         if loss_mask is not None:
-diff --git a/experiment/data/punctuation_dataset_multi.py b/experiment/data/punctuation_dataset_multi.py
-index f5a0778..d34b33a 100644
---- a/experiment/data/punctuation_dataset_multi.py
-+++ b/experiment/data/punctuation_dataset_multi.py
-@@ -91,7 +91,7 @@ class PunctuationDomainDataset(IterableDataset):
-         batch = next(self.dataset)[1]
- 
-         l=batch.str.split().map(len).values
--        n=8
-+        n=16
-         a=np.maximum((l-self.max_seq_length*n).clip(min=0),(l*np.random.random(l.__len__())).astype(int))
-         b=np.minimum(l,a+self.max_seq_length*n)
-         batch=pd.DataFrame({'t':batch,'a':a,'b':b}).apply(lambda row: ' '.join(row.t.split()[row.a:row.b]),axis=1)
-diff --git a/experiment/info.log b/experiment/info.log
-index 5fc3200..4195503 100644
---- a/experiment/info.log
-+++ b/experiment/info.log
-@@ -1,84 +1,5 @@
-+[INFO] - Global seed set to 42
- [INFO] - GPU available: True, used: True
- [INFO] - TPU available: None, using: 0 TPU cores
--[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
-+[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]
- [INFO] - Using native 16bit precision.
--[INFO] - shuffling train set
--[INFO] - initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.001
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7f1f8ee04790>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 3.1 K 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--8.3 M     Trainable params
--101 M     Non-trainable params
--110 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          88.38      37.36      52.51      32611
--! (label_id: 1)                                          0.00       0.00       0.00         10
--# (label_id: 2)                                          1.95      16.57       3.49       1358
--, (label_id: 3)                                          1.59       0.40       0.64        997
--- (label_id: 4)                                          0.24       4.90       0.46        102
--. (label_id: 5)                                          4.48       4.72       4.60        932
--: (label_id: 6)                                          0.04      11.76       0.09         17
--? (label_id: 7)                                          0.00       0.00       0.00         71
--… (label_id: 8)                                          0.00       0.00       0.00          6
---------------------
--micro avg                                               34.52      34.52      34.52      36104
--macro avg                                               10.74       8.41       6.87      36104
--weighted avg                                            80.06      34.52      47.70      36104
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    12182.00         5.00       661.00       447.00        46.00       411.00         8.00        22.00         2.00
--     1145.00         0.00        52.00        48.00        10.00        65.00         1.00         6.00         0.00
--    10705.00         1.00       225.00       312.00        17.00       256.00         6.00        27.00         3.00
--      225.00         0.00        21.00         4.00         0.00         2.00         0.00         0.00         0.00
--     1914.00         0.00       114.00        15.00         5.00         4.00         0.00         1.00         0.00
--      874.00         0.00        20.00        37.00         3.00        44.00         0.00         3.00         1.00
--     4235.00         4.00       128.00       113.00        11.00       135.00         2.00        12.00         0.00
--      193.00         0.00         6.00         1.00         0.00         0.00         0.00         0.00         0.00
--     1138.00         0.00       131.00        20.00        10.00        15.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                         50.65     100.00      67.24        156
--1 (label_id: 1)                                        100.00       2.56       5.00        156
---------------------
--micro avg                                               51.28      51.28      51.28        312
--macro avg                                               75.32      51.28      36.12        312
--weighted avg                                            75.32      51.28      36.12        312
--
---------------------
--           0           1
--      156.00       152.00
--        0.00         4.00
---------------------
--
--[INFO] - Internal process exited
-diff --git a/experiment/models/punctuation_domain_model.py b/experiment/models/punctuation_domain_model.py
-index 93bcf19..91b6665 100644
---- a/experiment/models/punctuation_domain_model.py
-+++ b/experiment/models/punctuation_domain_model.py
-@@ -114,9 +114,9 @@ class PunctuationDomainModel(pl.LightningModule, Serialization, FileIO):
-             self.hparams.model.domain_head.loss = 'cel'
-         # self.hparams.model.domain_head.loss
-         if self.hparams.model.punct_head.loss == 'focal':
--            self.domain_loss = FocalLoss(logits_ndim=2)
-+            self.domain_loss = FocalLoss(weight=list(self.hparams.model.domain_head.weight))
-         else:
--            self.domain_loss = CrossEntropyLoss(logits_ndim=2)
-+            self.domain_loss = CrossEntropyLoss(logits_ndim=2, weight=list(self.hparams.model.domain_head.weight))
- 
-         self.agg_loss = AggregatorLoss(num_inputs=2)
- 
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/hparams.yaml b/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/hparams.yaml
deleted file mode 100644
index 7ef87d2..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/hparams.yaml
+++ /dev/null
@@ -1,135 +0,0 @@
-seed: 42
-trainer:
-  gpus: 1
-  num_nodes: 1
-  max_epochs: 8
-  max_steps: null
-  accumulate_grad_batches: 4
-  gradient_clip_val: 0
-  amp_level: O1
-  precision: 16
-  accelerator: ddp
-  checkpoint_callback: false
-  logger: false
-  log_every_n_steps: 1
-  val_check_interval: 1.0
-  resume_from_checkpoint: null
-exp_manager:
-  exp_dir: /home/nxingyu/project/
-  name: Punctuation_with_Domain_discriminator
-  create_tensorboard_logger: true
-  create_checkpoint_callback: true
-base_path: /home/nxingyu/data
-tmp_path: /home/nxingyu/data/tmp
-log_dir: /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14
-model:
-  nemo_path: null
-  transformer_path: google/electra-base-discriminator
-  unfrozen: 1
-  maximum_unfrozen: 3
-  unfreeze_step: 1
-  punct_label_ids:
-  - ''
-  - ','
-  - .
-  - '?'
-  - '-'
-  - '!'
-  - ':'
-  - …
-  label_map:
-    —: ','
-    ;: .
-  no_space_label: '#'
-  test_chunk_percent: 0.5
-  punct_class_weights: false
-  dataset:
-    data_dir: /home/nxingyu/data
-    labelled:
-    - /home/nxingyu/data/ted_talks_processed
-    unlabelled:
-    - /home/nxingyu/data/switchboardutt_processed
-    max_seq_length: 128
-    pad_label: ''
-    ignore_extra_tokens: false
-    ignore_start_end: false
-    use_cache: false
-    num_workers: 8
-    pin_memory: false
-    drop_last: true
-    num_labels: 9
-    num_domains: 2
-    test_unlabelled: true
-    attach_label_to_end: null
-    pad_start: 0
-    train_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 16
-      manual_len: 20000
-    validation_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 16
-  tokenizer:
-    tokenizer_name: google/electra-base-discriminator
-    vocab_file: null
-    tokenizer_model: null
-    special_tokens: null
-  language_model:
-    pretrained_model_name: google/electra-base-discriminator
-    lm_checkpoint: null
-    config_file: null
-    config: null
-  punct_head:
-    punct_num_fc_layers: 3
-    fc_dropout: 0.1
-    activation: gelu
-    log_softmax: false
-    use_transformer_init: true
-    loss: dice
-    bilstm: false
-  domain_head:
-    predict_labelled: true
-    domain_num_fc_layers: 1
-    fc_dropout: 0.1
-    activation: relu
-    log_softmax: false
-    use_transformer_init: true
-    loss: cel
-    gamma: 0.1
-    pooling: mean_max
-    idx_conditioned_on: 0
-    weight:
-    - 0.8
-    - 0.2
-  dice_loss:
-    epsilon: 0.01
-    alpha: 2
-    macro_average: true
-  focal_loss:
-    gamma: 2
-  frozen_lr:
-  - 0.001
-  - 0.0001
-  - 0.0001
-  - 1.0e-05
-  - 1.0e-07
-  - 1.0e-08
-  gamma:
-  - 0.5
-  - 0.4
-  - 0.0001
-  - 1.0e-05
-  optim:
-    name: adamw
-    lr: 0.01
-    weight_decay: 0.0
-    sched:
-      name: CosineAnnealing
-      warmup_steps: null
-      warmup_ratio: 0.1
-      min_lr: 1.0e-08
-      last_epoch: -1
-      monitor: val_loss
-      reduce_on_plateau: false
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/lightning_logs.txt b/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/lightning_logs.txt
deleted file mode 100644
index 11e39a9..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/lightning_logs.txt
+++ /dev/null
@@ -1,86 +0,0 @@
-Global seed set to 42
-GPU available: True, used: True
-TPU available: None, using: 0 TPU cores
-LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]
-Using native 16bit precision.
-Global seed set to 42
-initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 1.2 M 
-2 | domain_classifier          | SequenceClassifier   | 3.1 K 
-3 | punctuation_loss           | FocalDiceLoss        | 0     
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-8.3 M     Trainable params
-101 M     Non-trainable params
-110 M     Total params
-Epoch 0, global step 49: val_loss reached 0.87379 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.87-epoch=0.ckpt" as top 3
-Epoch 1, global step 99: val_loss reached 3.50919 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/checkpoints/Punctuation_with_Domain_discriminator---val_loss=3.51-epoch=1.ckpt" as top 3
-Epoch 2, global step 149: val_loss reached 1.63914 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/checkpoints/Punctuation_with_Domain_discriminator---val_loss=1.64-epoch=2.ckpt" as top 3
-Epoch 3, global step 199: val_loss reached 2.39718 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/checkpoints/Punctuation_with_Domain_discriminator---val_loss=2.40-epoch=3.ckpt" as top 3
-Epoch 4, step 249: val_loss was not in top 3
-Epoch 5, global step 299: val_loss reached 1.92603 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/checkpoints/Punctuation_with_Domain_discriminator---val_loss=1.93-epoch=5.ckpt" as top 3
-Epoch 6, global step 349: val_loss reached 1.73141 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/checkpoints/Punctuation_with_Domain_discriminator---val_loss=1.73-epoch=6.ckpt" as top 3
-Epoch 7, global step 399: val_loss reached 1.69383 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/checkpoints/Punctuation_with_Domain_discriminator---val_loss=1.69-epoch=7.ckpt" as top 3
-Saving latest checkpoint...
-Global seed set to 42
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 1.2 M 
-2 | domain_classifier          | SequenceClassifier   | 3.1 K 
-3 | punctuation_loss           | FocalDiceLoss        | 0     
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-15.4 M    Trainable params
-94.7 M    Non-trainable params
-110 M     Total params
-Epoch 0, global step 449: val_loss reached 1.69119 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/checkpoints/Punctuation_with_Domain_discriminator---val_loss=1.69-epoch=0.ckpt" as top 3
-Epoch 1, global step 499: val_loss reached 1.69074 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/checkpoints/Punctuation_with_Domain_discriminator---val_loss=1.69-epoch=1.ckpt" as top 3
-Epoch 2, global step 549: val_loss reached 1.68174 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/checkpoints/Punctuation_with_Domain_discriminator---val_loss=1.68-epoch=2.ckpt" as top 3
-Epoch 3, step 599: val_loss was not in top 3
-Epoch 4, step 649: val_loss was not in top 3
-Epoch 5, step 699: val_loss was not in top 3
-Epoch 6, step 749: val_loss was not in top 3
-Epoch 7, step 799: val_loss was not in top 3
-Global seed set to 42
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 1.2 M 
-2 | domain_classifier          | SequenceClassifier   | 3.1 K 
-3 | punctuation_loss           | FocalDiceLoss        | 0     
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-22.5 M    Trainable params
-87.6 M    Non-trainable params
-110 M     Total params
-Epoch 0, step 849: val_loss was not in top 3
-Epoch 1, step 899: val_loss was not in top 3
-Epoch 2, step 949: val_loss was not in top 3
-Epoch 3, step 999: val_loss was not in top 3
-Epoch 4, step 1049: val_loss was not in top 3
-Epoch 5, step 1099: val_loss was not in top 3
-Epoch 6, step 1149: val_loss was not in top 3
-Epoch 7, step 1199: val_loss was not in top 3
-GPU available: True, used: True
-TPU available: None, using: 0 TPU cores
-Using environment variable NODE_RANK for node rank (0).
-LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/nemo_error_log.txt b/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/nemo_error_log.txt
deleted file mode 100644
index 853bd0d..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/nemo_error_log.txt
+++ /dev/null
@@ -1,34 +0,0 @@
-[NeMo W 2021-03-01 08:44:13 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:44:14 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
-[NeMo W 2021-03-01 08:44:26 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:44:26 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:44:29 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:44:29 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:44:29 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:45:17 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
-      warnings.warn(*args, **kwargs)
-    
-[NeMo W 2021-03-01 08:46:25 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
-      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
-    
-[NeMo W 2021-03-01 08:50:19 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f4a8bbfd6a0> was reported to be 199 (when accessing len(dataloader)), but 200 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-03-01 08:50:53 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f4a8bbfd070> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-03-01 11:00:22 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f4a8bb4fa00> was reported to be 7 (when accessing len(dataloader)), but 8 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/nemo_log_globalrank-0_localrank-0.txt b/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/nemo_log_globalrank-0_localrank-0.txt
deleted file mode 100644
index 9a0e38b..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/nemo_log_globalrank-0_localrank-0.txt
+++ /dev/null
@@ -1,36 +0,0 @@
-[NeMo W 2021-03-01 08:44:13 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo I 2021-03-01 08:44:14 exp_manager:183] Experiments will be logged at /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14
-[NeMo I 2021-03-01 08:44:14 exp_manager:519] TensorboardLogger has been set up
-[NeMo W 2021-03-01 08:44:14 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
-[NeMo W 2021-03-01 08:44:26 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:44:26 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:44:29 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:44:29 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:44:29 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:45:17 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
-      warnings.warn(*args, **kwargs)
-    
-[NeMo W 2021-03-01 08:46:25 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
-      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
-    
-[NeMo W 2021-03-01 08:50:19 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f4a8bbfd6a0> was reported to be 199 (when accessing len(dataloader)), but 200 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-03-01 08:50:53 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f4a8bbfd070> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-03-01 11:00:22 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f4a8bb4fa00> was reported to be 7 (when accessing len(dataloader)), but 8 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/test.txt b/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/test.txt
deleted file mode 100644
index 41f5aa8..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_08-44-14/test.txt
+++ /dev/null
@@ -1,87 +0,0 @@
-Punct report
-
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          65.05      99.95      78.81      44639
-! (label_id: 1)                                          0.00       0.00       0.00          0
-# (label_id: 2)                                         94.44       1.75       3.44       6783
-, (label_id: 3)                                         53.85       0.47       0.94      10325
-- (label_id: 4)                                          0.00       0.00       0.00        966
-. (label_id: 5)                                          0.00       0.00       0.00       4669
-: (label_id: 6)                                          0.00       0.00       0.00          0
-? (label_id: 7)                                          0.00       0.00       0.00        210
-… (label_id: 8)                                          0.00       0.00       0.00       1225
--------------------
-micro avg                                               65.08      65.08      65.08      68817
-macro avg                                               23.70      11.35       9.24      68817
-weighted avg                                            59.58      65.08      51.60      68817
-
--------------------
-                       !           #           ,           -           .           :           ?           …
-    44618.00         0.00      6664.00     10276.00       966.00      4641.00         0.00       210.00      1218.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        7.00         0.00       119.00         0.00         0.00         0.00         0.00         0.00         0.00
-       14.00         0.00         0.00        49.00         0.00        28.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         7.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--------------------
-
-Chunked Punct report
-
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          64.45      99.91      78.35      22155
-! (label_id: 1)                                          0.00       0.00       0.00          0
-# (label_id: 2)                                         83.33       1.04       2.06       3360
-, (label_id: 3)                                         20.00       0.13       0.26       5390
-- (label_id: 4)                                          0.00       0.00       0.00        504
-. (label_id: 5)                                          0.00       0.00       0.00       2317
-: (label_id: 6)                                          0.00       0.00       0.00          0
-? (label_id: 7)                                          0.00       0.00       0.00         98
-… (label_id: 8)                                          0.00       0.00       0.00        602
--------------------
-micro avg                                               64.42      64.42      64.42      34426
-macro avg                                               18.64      11.23       8.96      34426
-weighted avg                                            52.74      64.42      50.67      34426
-
--------------------
-                       !           #           ,           -           .           :           ?           …
-    22134.00         0.00      3325.00      5383.00       504.00      2303.00         0.00        98.00       595.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        7.00         0.00        35.00         0.00         0.00         0.00         0.00         0.00         0.00
-       14.00         0.00         0.00         7.00         0.00        14.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         7.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--------------------
-
-Domain report
-
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00      18.39      31.07        609
--------------------
-micro avg                                               18.39      18.39      18.39        609
-macro avg                                               50.00       9.20      15.53        609
-weighted avg                                           100.00      18.39      31.07        609
-
--------------------
-           0           1
-        0.00       497.00
-        0.00       112.00
--------------------
-
-
-test_loss: 2.82830548286438
-punct_precision: 23.704227447509766
-punct_f1: 9.24375057220459
-punct_recall: 11.353547096252441
-chunked_punct_precision: 18.64278221130371
-chunked_punct_f1: 8.96336555480957
-chunked_punct_recall: 11.23075008392334
-domain_precision: 50.0
-domain_f1: 15.533980369567871
-domain_recall: 9.195402145385742
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/cmd-args.log b/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/cmd-args.log
deleted file mode 100644
index 11a5d8e..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/cmd-args.log
+++ /dev/null
@@ -1 +0,0 @@
-main.py
\ No newline at end of file
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/events.out.tfevents.1614560175.Titan.8250.0 b/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/events.out.tfevents.1614560175.Titan.8250.0
deleted file mode 100644
index adebd98..0000000
Binary files a/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/events.out.tfevents.1614560175.Titan.8250.0 and /dev/null differ
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/git-info.log b/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/git-info.log
deleted file mode 100644
index 4c1fb96..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/git-info.log
+++ /dev/null
@@ -1,512 +0,0 @@
-commit hash: c3e0c8d06d6c49891d066054f713b1fe9405d41f
-diff --git a/NLP.yml b/NLP.yml
-index bc9aa5d..4ae7fd2 100644
---- a/NLP.yml
-+++ b/NLP.yml
-@@ -5,161 +5,237 @@ channels:
-   - defaults
- dependencies:
-   - _libgcc_mutex=0.1=main
-+  - _pytorch_select=0.2=gpu_0
-+  - _tflow_select=2.3.0=mkl
-+  - absl-py=0.11.0=py38h578d9bd_0
-+  - aiohttp=3.7.3=py38h25fe258_0
-+  - argon2-cffi=20.1.0=py38h7b6447c_1
-   - astroid=2.4.2=py38_0
--  - backcall=0.2.0=py_0
-+  - astunparse=1.6.3=py_0
-+  - async-timeout=3.0.1=py_1000
-+  - async_generator=1.10=pyhd3eb1b0_0
-+  - attrs=20.3.0=pyhd3eb1b0_0
-+  - autopep8=1.5.4=py_0
-+  - backcall=0.2.0=pyhd3eb1b0_0
-   - blas=1.0=mkl
-+  - bleach=3.2.3=pyhd3eb1b0_0
-+  - blinker=1.4=py_1
-+  - brotlipy=0.7.0=py38h8df0ef7_1001
-+  - c-ares=1.17.1=h36c2ea0_0
-   - ca-certificates=2021.1.19=h06a4308_0
-+  - cachetools=4.2.1=pyhd8ed1ab_0
-   - certifi=2020.12.5=py38h06a4308_0
-+  - cffi=1.14.4=py38h261ae71_0
-+  - chardet=3.0.4=py38h924ce5b_1008
-+  - click=7.1.2=pyh9f0ad1d_0
-   - code-server=3.8.0=ha770c72_0
--  - cuda91=1.0=h4c16780_0
--  - cudatoolkit=10.2.89=hfd86e86_1
--  - decorator=4.4.2=py_0
--  - icu=68.1=h58526e2_0
-+  - cryptography=3.3.1=py38h3c74f83_0
-+  - cudatoolkit=10.1.243=h6bb024c_0
-+  - cudnn=7.6.5=cuda10.1_0
-+  - dbus=1.13.18=hb2f20db_0
-+  - decorator=4.4.2=pyhd3eb1b0_0
-+  - defusedxml=0.6.0=py_0
-+  - entrypoints=0.3=py38_0
-+  - expat=2.2.10=he6710b0_2
-+  - fontconfig=2.13.0=h9420a91_0
-+  - freetype=2.10.4=h5ab3b9f_0
-+  - fsspec=0.8.5=pyhd8ed1ab_0
-+  - future=0.18.2=py38h578d9bd_3
-+  - gast=0.3.3=py_0
-+  - glib=2.66.1=h92f7085_0
-+  - google-auth=1.24.0=pyhd3deb0d_0
-+  - google-pasta=0.2.0=py_0
-+  - gst-plugins-base=1.14.0=h8213a91_2
-+  - gstreamer=1.14.0=h28cd5cc_2
-+  - hdf5=1.10.6=hb1b8bf9_0
-+  - icu=58.2=he6710b0_3
-+  - idna=2.10=pyh9f0ad1d_0
-+  - importlib-metadata=2.0.0=py_1
-+  - importlib_metadata=2.0.0=1
-   - intel-openmp=2020.2=254
--  - ipython=7.19.0=py38hb070fc8_0
-+  - ipykernel=5.3.4=py38h5ca1d4c_0
-+  - ipython=7.19.0=py38hb070fc8_1
-   - ipython_genutils=0.2.0=pyhd3eb1b0_1
--  - jedi=0.18.0=py38h06a4308_1
-+  - ipywidgets=7.6.3=pyhd3eb1b0_1
-+  - jedi=0.17.0=py38_0
-+  - jinja2=2.11.2=pyhd3eb1b0_0
-+  - jpeg=9b=h024ee3a_2
-+  - jsonschema=3.2.0=py_2
-+  - jupyter=1.0.0=py38_7
-+  - jupyter_client=6.1.7=py_0
-+  - jupyter_console=6.2.0=py_0
-+  - jupyter_core=4.7.0=py38h06a4308_0
-+  - jupyterlab_pygments=0.1.2=py_0
-+  - jupyterlab_widgets=1.0.0=pyhd3eb1b0_1
-+  - keras-preprocessing=1.1.0=py_1
-   - lazy-object-proxy=1.4.3=py38h27cfd23_2
-   - ld_impl_linux-64=2.33.1=h53a641e_7
-   - libedit=3.1.20191231=h14c3975_1
-   - libffi=3.3=he6710b0_2
-   - libgcc-ng=9.1.0=hdf63c60_0
-+  - libgfortran-ng=7.3.0=hdf63c60_0
-+  - libpng=1.6.37=hbc83047_0
-+  - libprotobuf=3.13.0.1=h8b12597_0
-+  - libsodium=1.0.18=h7b6447c_0
-   - libstdcxx-ng=9.1.0=hdf63c60_0
--  - libuv=1.40.0=hd18ef5c_0
-+  - libuuid=1.0.3=h1bed415_2
-+  - libuv=1.40.0=h7b6447c_0
-+  - libxcb=1.14=h7b6447c_0
-+  - libxml2=2.9.10=hb55368b_3
-+  - markdown=3.3.3=pyh9f0ad1d_0
-+  - markupsafe=1.1.1=py38h7b6447c_0
-   - mccabe=0.6.1=py38_1
-+  - mistune=0.8.4=py38h7b6447c_1000
-   - mkl=2020.2=256
-   - mkl-service=2.3.0=py38he904b0f_0
-   - mkl_fft=1.2.0=py38h23d657b_0
-   - mkl_random=1.1.1=py38h0573a6f_0
-+  - multidict=5.1.0=py38h27cfd23_2
-+  - nbclient=0.5.1=py_0
-+  - nbconvert=6.0.7=py38_0
-+  - nbformat=5.1.2=pyhd3eb1b0_1
-   - ncurses=6.2=he6710b0_1
--  - nodejs=12.19.0=hfa01f41_2
-+  - nest-asyncio=1.4.3=pyhd3eb1b0_0
-+  - ninja=1.10.2=py38hff7bd54_0
-+  - nodejs=12.4.0=he1b5a44_0
-+  - notebook=6.2.0=py38h06a4308_0
-   - numpy=1.19.2=py38h54aff64_0
-   - numpy-base=1.19.2=py38hfa32c7d_0
-   - openssl=1.1.1i=h27cfd23_0
--  - pandas=1.2.1=py38ha9443f7_0
-+  - opt_einsum=3.1.0=py_0
-+  - packaging=20.9=pyhd3eb1b0_0
-+  - pandoc=2.11=hb0f4dca_0
-+  - pandocfilters=1.4.3=py38h06a4308_1
-   - parso=0.8.1=pyhd3eb1b0_0
-+  - pcre=8.44=he6710b0_0
-   - pexpect=4.8.0=pyhd3eb1b0_3
-   - pickleshare=0.7.5=pyhd3eb1b0_1003
-   - pip=20.3.3=py38h06a4308_0
-+  - prometheus_client=0.9.0=pyhd3eb1b0_0
-   - prompt-toolkit=3.0.8=py_0
-+  - prompt_toolkit=3.0.8=0
-   - ptyprocess=0.7.0=pyhd3eb1b0_2
-+  - pyasn1=0.4.8=py_0
-+  - pycodestyle=2.6.0=py_0
-+  - pycparser=2.20=py_2
-   - pygments=2.7.4=pyhd3eb1b0_0
-+  - pyjwt=2.0.1=pyhd8ed1ab_0
-   - pylint=2.6.0=py38_0
-+  - pyopenssl=20.0.1=pyhd8ed1ab_0
-+  - pyparsing=2.4.7=pyhd3eb1b0_0
-+  - pyqt=5.9.2=py38h05f1152_4
-+  - pyrsistent=0.17.3=py38h7b6447c_0
-+  - pysocks=1.7.1=py38h578d9bd_3
-   - python=3.8.5=h7579374_1
--  - python-dateutil=2.8.1=py_0
-+  - python-dateutil=2.8.1=pyhd3eb1b0_0
-   - python_abi=3.8=1_cp38
--  - pytz=2020.5=pyhd3eb1b0_0
--  - readline=8.0=h7b6447c_0
-+  - pytorch=1.7.1=py3.8_cuda10.1.243_cudnn7.6.3_0
-+  - pyzmq=20.0.0=py38h2531618_1
-+  - qt=5.9.7=h5867ecd_1
-+  - qtconsole=4.7.7=py_0
-+  - qtpy=1.9.0=py_0
-+  - readline=8.1=h27cfd23_0
-+  - requests=2.25.1=pyhd3deb0d_0
-+  - requests-oauthlib=1.3.0=pyh9f0ad1d_0
-+  - rope=0.18.0=py_0
-+  - rsa=4.7=pyhd3deb0d_0
-+  - send2trash=1.5.0=pyhd3eb1b0_1
-   - setuptools=52.0.0=py38h06a4308_0
-+  - sip=4.19.13=py38he6710b0_0
-   - six=1.15.0=py38h06a4308_0
-   - sqlite=3.33.0=h62c20be_0
-+  - tensorboard=2.3.0=pyh4dce500_0
-+  - tensorboard-plugin-wit=1.8.0=pyh44b312d_0
-+  - tensorflow=2.2.0=mkl_py38h6d3daf0_0
-+  - tensorflow-base=2.2.0=mkl_py38h5059a2d_0
-+  - tensorflow-estimator=2.2.0=pyh208ff02_0
-+  - termcolor=1.1.0=py38_1
-+  - terminado=0.9.2=py38h06a4308_0
-+  - testpath=0.4.4=pyhd3eb1b0_0
-   - tk=8.6.10=hbc83047_0
--  - traitlets=5.0.5=py_0
-+  - toml=0.10.1=py_0
-+  - tornado=6.1=py38h27cfd23_0
-+  - traitlets=5.0.5=pyhd3eb1b0_0
-+  - typing-extensions=3.7.4.3=0
-+  - typing_extensions=3.7.4.3=py_0
-+  - urllib3=1.26.3=pyhd8ed1ab_0
-   - wcwidth=0.2.5=py_0
-+  - webencodings=0.5.1=py38_1
-+  - werkzeug=1.0.1=pyh9f0ad1d_0
-   - wheel=0.36.2=pyhd3eb1b0_0
-+  - widgetsnbextension=3.5.1=py38_0
-+  - wrapt=1.11.2=py38h7b6447c_0
-   - xz=5.2.5=h7b6447c_0
-+  - yaml=0.2.5=h516909a_0
-+  - yarl=1.6.3=py38h25fe258_0
-+  - zeromq=4.3.3=he6710b0_3
-+  - zipp=3.4.0=pyhd3eb1b0_0
-   - zlib=1.2.11=h7b6447c_3
-   - pip:
--    - absl-py==0.11.0
--    - aiohttp==3.7.3
-     - alabaster==0.7.12
-     - antlr4-python3-runtime==4.8
--    - apex==0.1
-     - appdirs==1.4.4
--    - argon2-cffi==20.1.0
-     - asttokens==2.0.4
--    - async-generator==1.10
--    - async-timeout==3.0.1
-     - attrdict==2.0.1
--    - attrs==20.3.0
-     - audioread==2.1.9
-     - babel==2.9.0
-     - black==19.10b0
--    - bleach==3.2.3
--    - boto3==1.16.61
--    - botocore==1.19.61
-+    - boto3==1.16.63
-+    - botocore==1.19.63
-     - braceexpand==0.1.6
--    - cachetools==4.2.1
--    - cffi==1.14.4
--    - chardet==3.0.4
--    - click==7.1.2
-+    - cheap-repr==0.4.4
-     - colorama==0.4.4
-     - configparser==5.0.1
-     - cycler==0.10.0
-     - cython==0.29.21
-     - datasets==1.2.1
--    - defusedxml==0.6.0
-     - dill==0.3.3
-     - distance==0.1.3
-     - docker-pycreds==0.4.0
-     - docopt==0.6.2
-     - docutils==0.16
-     - editdistance==0.5.3
--    - entrypoints==0.3
-     - executing==0.5.4
-     - filelock==3.0.12
-     - frozendict==1.2
--    - fsspec==0.8.5
--    - future==0.18.2
-     - g2p-en==2.1.0
-     - gdown==3.12.2
-     - gitdb==4.0.5
-     - gitpython==3.1.12
--    - google-auth==1.24.0
-     - google-auth-oauthlib==0.4.2
-     - grpcio==1.35.0
-     - h5py==3.1.0
--    - hydra==2.5
--    - hydra-core==1.0.5
-+    - hydra-core==1.1.0.dev3
-     - icecream==2.1.0
--    - idna==2.10
-     - imagesize==1.2.0
-     - importlib-resources==5.1.0
-     - inflect==5.0.2
-     - iniconfig==1.1.1
--    - ipykernel==5.4.3
--    - ipywidgets==7.6.3
-     - isort==4.3.21
--    - jinja2==2.11.2
-     - jmespath==0.10.0
-     - joblib==1.0.0
--    - jsonschema==3.2.0
--    - jupyter==1.0.0
--    - jupyter-client==6.1.11
--    - jupyter-console==6.2.0
--    - jupyter-core==4.7.0
--    - jupyterlab-pygments==0.1.2
--    - jupyterlab-widgets==1.0.0
-+    - kaggle==1.5.10
-     - kaldi-io==0.9.4
-     - kaldi-python-io==1.2.1
-     - kiwisolver==1.3.1
-     - latexcodec==2.0.1
-     - librosa==0.8.0
-     - llvmlite==0.35.0
--    - markdown==3.3.3
--    - markupsafe==1.1.1
-+    - logging==0.4.9.6
-     - marshmallow==3.10.0
--    - matplotlib==3.3.3
-+    - matplotlib==3.3.4
-     - megatron-lm==1.1.5
--    - mistune==0.8.4
-     - msgpack==1.0.2
--    - multidict==5.1.0
-     - multiprocess==0.70.11.1
--    - nbclient==0.5.1
--    - nbconvert==6.0.7
--    - nbformat==5.1.2
-     - nemo-toolkit==1.0.0b2
--    - nest-asyncio==1.4.3
-     - nltk==3.5
--    - notebook==6.2.0
-     - num2words==0.5.10
-     - numba==0.52.0
-     - oauthlib==3.1.0
-     - objectio==0.2.29
--    - omegaconf==2.0.6
--    - onnx==1.8.0
--    - packaging==20.8
--    - pandocfilters==1.4.3
-+    - omegaconf==2.1.0.dev17
-+    - onnx==1.8.1
-+    - pandas==1.2.1
-     - parameterized==0.8.1
-     - pathspec==0.8.1
-     - pathtools==0.1.2
-@@ -169,52 +245,38 @@ dependencies:
-     - pipreqs==0.4.10
-     - pluggy==0.13.1
-     - pooch==1.3.0
--    - portalocker==2.1.0
--    - prometheus-client==0.9.0
-     - promise==2.3
-     - protobuf==3.14.0
-     - psutil==5.8.0
-     - py==1.10.0
-     - pyarrow==3.0.0
--    - pyasn1==0.4.8
-     - pyasn1-modules==0.2.8
-     - pybind11==2.6.2
-     - pybtex==0.24.0
-     - pybtex-docutils==1.0.0
--    - pycparser==2.20
--    - pydub==0.24.1
--    - pyparsing==2.4.7
-     - pypinyin==0.40.0
--    - pyrsistent==0.17.3
--    - pysocks==1.7.1
-     - pystoi==0.3.3
-     - pytest==6.2.2
-     - pytest-runner==5.2
--    - python-levenshtein==0.12.1
--    - pytorch-lightning==1.1.3
--    - pyyaml==5.4.1
--    - pyzmq==21.0.2
--    - qtconsole==5.0.2
--    - qtpy==1.9.0
-+    - python-slugify==4.0.1
-+    - pytorch-lightning==1.1.5
-+    - pytz==2020.5
-+    - pyyaml==5.3.1
-     - rapidfuzz==0.14.2
-     - regex==2020.11.13
--    - requests==2.25.1
--    - requests-oauthlib==1.3.0
-     - resampy==0.2.2
--    - rsa==4.7
-     - ruamel-yaml==0.16.12
-     - ruamel-yaml-clib==0.2.2
-     - s3transfer==0.3.4
--    - sacrebleu==1.5.0
-     - sacremoses==0.0.43
-     - scikit-learn==0.24.1
-     - scipy==1.6.0
--    - send2trash==1.5.0
-     - sentencepiece==0.1.95
-     - sentry-sdk==0.19.5
-     - shortuuid==1.0.1
-     - simplejson==3.17.2
-     - smmap==3.0.5
-+    - snoop==0.2.5
-     - snowballstemmer==2.1.0
-     - soundfile==0.10.3.post1
-     - sox==1.4.1
-@@ -227,35 +289,24 @@ dependencies:
-     - sphinxcontrib-qthelp==1.0.3
-     - sphinxcontrib-serializinghtml==1.1.4
-     - subprocess32==3.5.4
--    - tensorboard==2.4.1
--    - tensorboard-plugin-wit==1.8.0
--    - terminado==0.9.2
--    - testpath==0.4.4
-+    - tensorboardx==2.1
-+    - text-unidecode==1.3
-     - threadpoolctl==2.1.0
-     - tokenizers==0.9.4
--    - toml==0.10.2
-     - torch==1.7.1
-     - torch-stft==0.1.4
--    - torchtext==0.8.1
-+    - torchtools==0.2.5
-     - torchvision==0.8.2
--    - tornado==6.1
-     - tqdm==4.49.0
-     - transformers==4.2.2
-     - typed-ast==1.4.2
-     - typer==0.3.2
--    - typing-extensions==3.7.4.3
-     - unidecode==1.1.2
--    - urllib3==1.26.3
-     - wandb==0.10.15
-     - watchdog==0.10.4
-     - webdataset==0.1.40
--    - webencodings==0.5.1
--    - werkzeug==1.0.1
-     - wget==3.2
--    - widgetsnbextension==3.5.1
--    - wrapt==1.12.1
-     - xxhash==2.0.0
-     - yarg==0.1.9
--    - yarl==1.6.3
-     - youtokentome==1.0.6
- prefix: /home/nxingyu/miniconda3/envs/NLP
-diff --git a/experiment/config.yaml b/experiment/config.yaml
-index 809477a..56d2f37 100644
---- a/experiment/config.yaml
-+++ b/experiment/config.yaml
-@@ -142,13 +142,13 @@ model:
-         activation: 'relu'
-         log_softmax: false
-         use_transformer_init: true
--        loss: 'cel'
-+        loss: 'focal'
-         gamma: 0.1 #0.1 # coefficient of gradient reversal
-         pooling: 'mean_max' # 'mean' mean_max
-         idx_conditioned_on: 0
-         weight:
--            - 0.8
--            - 0.2
-+            - 0.6
-+            - 0.4
- 
- 
-     dice_loss:
-diff --git a/experiment/info.log b/experiment/info.log
-index 5fc3200..a4bbbb5 100644
---- a/experiment/info.log
-+++ b/experiment/info.log
-@@ -1,84 +1,5 @@
-+[INFO] - Global seed set to 42
- [INFO] - GPU available: True, used: True
- [INFO] - TPU available: None, using: 0 TPU cores
--[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
-+[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
- [INFO] - Using native 16bit precision.
--[INFO] - shuffling train set
--[INFO] - initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.001
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7f1f8ee04790>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 3.1 K 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--8.3 M     Trainable params
--101 M     Non-trainable params
--110 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          88.38      37.36      52.51      32611
--! (label_id: 1)                                          0.00       0.00       0.00         10
--# (label_id: 2)                                          1.95      16.57       3.49       1358
--, (label_id: 3)                                          1.59       0.40       0.64        997
--- (label_id: 4)                                          0.24       4.90       0.46        102
--. (label_id: 5)                                          4.48       4.72       4.60        932
--: (label_id: 6)                                          0.04      11.76       0.09         17
--? (label_id: 7)                                          0.00       0.00       0.00         71
--… (label_id: 8)                                          0.00       0.00       0.00          6
---------------------
--micro avg                                               34.52      34.52      34.52      36104
--macro avg                                               10.74       8.41       6.87      36104
--weighted avg                                            80.06      34.52      47.70      36104
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    12182.00         5.00       661.00       447.00        46.00       411.00         8.00        22.00         2.00
--     1145.00         0.00        52.00        48.00        10.00        65.00         1.00         6.00         0.00
--    10705.00         1.00       225.00       312.00        17.00       256.00         6.00        27.00         3.00
--      225.00         0.00        21.00         4.00         0.00         2.00         0.00         0.00         0.00
--     1914.00         0.00       114.00        15.00         5.00         4.00         0.00         1.00         0.00
--      874.00         0.00        20.00        37.00         3.00        44.00         0.00         3.00         1.00
--     4235.00         4.00       128.00       113.00        11.00       135.00         2.00        12.00         0.00
--      193.00         0.00         6.00         1.00         0.00         0.00         0.00         0.00         0.00
--     1138.00         0.00       131.00        20.00        10.00        15.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                         50.65     100.00      67.24        156
--1 (label_id: 1)                                        100.00       2.56       5.00        156
---------------------
--micro avg                                               51.28      51.28      51.28        312
--macro avg                                               75.32      51.28      36.12        312
--weighted avg                                            75.32      51.28      36.12        312
--
---------------------
--           0           1
--      156.00       152.00
--        0.00         4.00
---------------------
--
--[INFO] - Internal process exited
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/hparams.yaml b/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/hparams.yaml
deleted file mode 100644
index 5241c00..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/hparams.yaml
+++ /dev/null
@@ -1,135 +0,0 @@
-seed: 42
-trainer:
-  gpus: 1
-  num_nodes: 1
-  max_epochs: 8
-  max_steps: null
-  accumulate_grad_batches: 4
-  gradient_clip_val: 0
-  amp_level: O1
-  precision: 16
-  accelerator: ddp
-  checkpoint_callback: false
-  logger: false
-  log_every_n_steps: 1
-  val_check_interval: 1.0
-  resume_from_checkpoint: null
-exp_manager:
-  exp_dir: /home/nxingyu/project/
-  name: Punctuation_with_Domain_discriminator
-  create_tensorboard_logger: true
-  create_checkpoint_callback: true
-base_path: /home/nxingyu/data
-tmp_path: /home/nxingyu/data/tmp
-log_dir: /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57
-model:
-  nemo_path: null
-  transformer_path: google/electra-base-discriminator
-  unfrozen: 1
-  maximum_unfrozen: 3
-  unfreeze_step: 1
-  punct_label_ids:
-  - ''
-  - ','
-  - .
-  - '?'
-  - '-'
-  - '!'
-  - ':'
-  - …
-  label_map:
-    —: ','
-    ;: .
-  no_space_label: '#'
-  test_chunk_percent: 0.5
-  punct_class_weights: false
-  dataset:
-    data_dir: /home/nxingyu/data
-    labelled:
-    - /home/nxingyu/data/ted_talks_processed
-    unlabelled:
-    - /home/nxingyu/data/switchboardutt_processed
-    max_seq_length: 128
-    pad_label: ''
-    ignore_extra_tokens: false
-    ignore_start_end: false
-    use_cache: false
-    num_workers: 8
-    pin_memory: false
-    drop_last: true
-    num_labels: 9
-    num_domains: 2
-    test_unlabelled: true
-    attach_label_to_end: null
-    pad_start: 0
-    train_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 16
-      manual_len: 20000
-    validation_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 16
-  tokenizer:
-    tokenizer_name: google/electra-base-discriminator
-    vocab_file: null
-    tokenizer_model: null
-    special_tokens: null
-  language_model:
-    pretrained_model_name: google/electra-base-discriminator
-    lm_checkpoint: null
-    config_file: null
-    config: null
-  punct_head:
-    punct_num_fc_layers: 3
-    fc_dropout: 0.1
-    activation: gelu
-    log_softmax: false
-    use_transformer_init: true
-    loss: dice
-    bilstm: false
-  domain_head:
-    predict_labelled: true
-    domain_num_fc_layers: 1
-    fc_dropout: 0.1
-    activation: relu
-    log_softmax: false
-    use_transformer_init: true
-    loss: focal
-    gamma: 0.1
-    pooling: mean_max
-    idx_conditioned_on: 0
-    weight:
-    - 0.6
-    - 0.4
-  dice_loss:
-    epsilon: 0.01
-    alpha: 2
-    macro_average: true
-  focal_loss:
-    gamma: 2
-  frozen_lr:
-  - 0.001
-  - 0.0001
-  - 0.0001
-  - 1.0e-05
-  - 1.0e-07
-  - 1.0e-08
-  gamma:
-  - 0.5
-  - 0.4
-  - 0.0001
-  - 1.0e-05
-  optim:
-    name: adamw
-    lr: 0.01
-    weight_decay: 0.0
-    sched:
-      name: CosineAnnealing
-      warmup_steps: null
-      warmup_ratio: 0.1
-      min_lr: 1.0e-08
-      last_epoch: -1
-      monitor: val_loss
-      reduce_on_plateau: false
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/lightning_logs.txt b/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/lightning_logs.txt
deleted file mode 100644
index 0b41320..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/lightning_logs.txt
+++ /dev/null
@@ -1,86 +0,0 @@
-Global seed set to 42
-GPU available: True, used: True
-TPU available: None, using: 0 TPU cores
-LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
-Using native 16bit precision.
-Global seed set to 42
-initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 1.2 M 
-2 | domain_classifier          | SequenceClassifier   | 3.1 K 
-3 | punctuation_loss           | FocalDiceLoss        | 0     
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-8.3 M     Trainable params
-101 M     Non-trainable params
-110 M     Total params
-Epoch 0, global step 49: val_loss reached 0.87379 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.87-epoch=0.ckpt" as top 3
-Epoch 1, global step 99: val_loss reached 3.50919 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/checkpoints/Punctuation_with_Domain_discriminator---val_loss=3.51-epoch=1.ckpt" as top 3
-Epoch 2, global step 149: val_loss reached 1.63914 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/checkpoints/Punctuation_with_Domain_discriminator---val_loss=1.64-epoch=2.ckpt" as top 3
-Epoch 3, global step 199: val_loss reached 2.39718 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/checkpoints/Punctuation_with_Domain_discriminator---val_loss=2.40-epoch=3.ckpt" as top 3
-Epoch 4, step 249: val_loss was not in top 3
-Epoch 5, global step 299: val_loss reached 1.92603 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/checkpoints/Punctuation_with_Domain_discriminator---val_loss=1.93-epoch=5.ckpt" as top 3
-Epoch 6, global step 349: val_loss reached 1.73141 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/checkpoints/Punctuation_with_Domain_discriminator---val_loss=1.73-epoch=6.ckpt" as top 3
-Epoch 7, global step 399: val_loss reached 1.69383 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/checkpoints/Punctuation_with_Domain_discriminator---val_loss=1.69-epoch=7.ckpt" as top 3
-Saving latest checkpoint...
-Global seed set to 42
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 1.2 M 
-2 | domain_classifier          | SequenceClassifier   | 3.1 K 
-3 | punctuation_loss           | FocalDiceLoss        | 0     
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-15.4 M    Trainable params
-94.7 M    Non-trainable params
-110 M     Total params
-Epoch 0, global step 449: val_loss reached 1.69119 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/checkpoints/Punctuation_with_Domain_discriminator---val_loss=1.69-epoch=0.ckpt" as top 3
-Epoch 1, global step 499: val_loss reached 1.69074 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/checkpoints/Punctuation_with_Domain_discriminator---val_loss=1.69-epoch=1.ckpt" as top 3
-Epoch 2, global step 549: val_loss reached 1.68174 (best 0.87379), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/checkpoints/Punctuation_with_Domain_discriminator---val_loss=1.68-epoch=2.ckpt" as top 3
-Epoch 3, step 599: val_loss was not in top 3
-Epoch 4, step 649: val_loss was not in top 3
-Epoch 5, step 699: val_loss was not in top 3
-Epoch 6, step 749: val_loss was not in top 3
-Epoch 7, step 799: val_loss was not in top 3
-Global seed set to 42
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 1.2 M 
-2 | domain_classifier          | SequenceClassifier   | 3.1 K 
-3 | punctuation_loss           | FocalDiceLoss        | 0     
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-22.5 M    Trainable params
-87.6 M    Non-trainable params
-110 M     Total params
-Epoch 0, step 849: val_loss was not in top 3
-Epoch 1, step 899: val_loss was not in top 3
-Epoch 2, step 949: val_loss was not in top 3
-Epoch 3, step 999: val_loss was not in top 3
-Epoch 4, step 1049: val_loss was not in top 3
-Epoch 5, step 1099: val_loss was not in top 3
-Epoch 6, step 1149: val_loss was not in top 3
-Epoch 7, step 1199: val_loss was not in top 3
-GPU available: True, used: True
-TPU available: None, using: 0 TPU cores
-Using environment variable NODE_RANK for node rank (0).
-LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/nemo_error_log.txt b/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/nemo_error_log.txt
deleted file mode 100644
index 02e0d70..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/nemo_error_log.txt
+++ /dev/null
@@ -1,31 +0,0 @@
-[NeMo W 2021-03-01 08:55:57 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
-[NeMo W 2021-03-01 08:56:10 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:56:10 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:56:14 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:56:14 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:56:14 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:56:16 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
-      warnings.warn(*args, **kwargs)
-    
-[NeMo W 2021-03-01 08:57:31 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
-      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
-    
-[NeMo W 2021-03-01 09:01:33 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f6b4f4cd5b0> was reported to be 199 (when accessing len(dataloader)), but 200 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-03-01 09:02:11 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f6b4f4cd850> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-03-01 11:20:55 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f6b4f544af0> was reported to be 7 (when accessing len(dataloader)), but 8 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/nemo_log_globalrank-0_localrank-0.txt b/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/nemo_log_globalrank-0_localrank-0.txt
deleted file mode 100644
index ed21d3a..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/nemo_log_globalrank-0_localrank-0.txt
+++ /dev/null
@@ -1,33 +0,0 @@
-[NeMo I 2021-03-01 08:55:57 exp_manager:183] Experiments will be logged at /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57
-[NeMo I 2021-03-01 08:55:57 exp_manager:519] TensorboardLogger has been set up
-[NeMo W 2021-03-01 08:55:57 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
-[NeMo W 2021-03-01 08:56:10 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:56:10 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:56:14 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:56:14 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:56:14 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 08:56:16 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
-      warnings.warn(*args, **kwargs)
-    
-[NeMo W 2021-03-01 08:57:31 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
-      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
-    
-[NeMo W 2021-03-01 09:01:33 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f6b4f4cd5b0> was reported to be 199 (when accessing len(dataloader)), but 200 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-03-01 09:02:11 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f6b4f4cd850> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-03-01 11:20:55 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f6b4f544af0> was reported to be 7 (when accessing len(dataloader)), but 8 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/test.txt b/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/test.txt
deleted file mode 100644
index 41f5aa8..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_08-55-57/test.txt
+++ /dev/null
@@ -1,87 +0,0 @@
-Punct report
-
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          65.05      99.95      78.81      44639
-! (label_id: 1)                                          0.00       0.00       0.00          0
-# (label_id: 2)                                         94.44       1.75       3.44       6783
-, (label_id: 3)                                         53.85       0.47       0.94      10325
-- (label_id: 4)                                          0.00       0.00       0.00        966
-. (label_id: 5)                                          0.00       0.00       0.00       4669
-: (label_id: 6)                                          0.00       0.00       0.00          0
-? (label_id: 7)                                          0.00       0.00       0.00        210
-… (label_id: 8)                                          0.00       0.00       0.00       1225
--------------------
-micro avg                                               65.08      65.08      65.08      68817
-macro avg                                               23.70      11.35       9.24      68817
-weighted avg                                            59.58      65.08      51.60      68817
-
--------------------
-                       !           #           ,           -           .           :           ?           …
-    44618.00         0.00      6664.00     10276.00       966.00      4641.00         0.00       210.00      1218.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        7.00         0.00       119.00         0.00         0.00         0.00         0.00         0.00         0.00
-       14.00         0.00         0.00        49.00         0.00        28.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         7.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--------------------
-
-Chunked Punct report
-
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          64.45      99.91      78.35      22155
-! (label_id: 1)                                          0.00       0.00       0.00          0
-# (label_id: 2)                                         83.33       1.04       2.06       3360
-, (label_id: 3)                                         20.00       0.13       0.26       5390
-- (label_id: 4)                                          0.00       0.00       0.00        504
-. (label_id: 5)                                          0.00       0.00       0.00       2317
-: (label_id: 6)                                          0.00       0.00       0.00          0
-? (label_id: 7)                                          0.00       0.00       0.00         98
-… (label_id: 8)                                          0.00       0.00       0.00        602
--------------------
-micro avg                                               64.42      64.42      64.42      34426
-macro avg                                               18.64      11.23       8.96      34426
-weighted avg                                            52.74      64.42      50.67      34426
-
--------------------
-                       !           #           ,           -           .           :           ?           …
-    22134.00         0.00      3325.00      5383.00       504.00      2303.00         0.00        98.00       595.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        7.00         0.00        35.00         0.00         0.00         0.00         0.00         0.00         0.00
-       14.00         0.00         0.00         7.00         0.00        14.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         7.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--------------------
-
-Domain report
-
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00      18.39      31.07        609
--------------------
-micro avg                                               18.39      18.39      18.39        609
-macro avg                                               50.00       9.20      15.53        609
-weighted avg                                           100.00      18.39      31.07        609
-
--------------------
-           0           1
-        0.00       497.00
-        0.00       112.00
--------------------
-
-
-test_loss: 2.82830548286438
-punct_precision: 23.704227447509766
-punct_f1: 9.24375057220459
-punct_recall: 11.353547096252441
-chunked_punct_precision: 18.64278221130371
-chunked_punct_f1: 8.96336555480957
-chunked_punct_recall: 11.23075008392334
-domain_precision: 50.0
-domain_f1: 15.533980369567871
-domain_recall: 9.195402145385742
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_11-16-07/hparams.yaml b/Punctuation_with_Domain_discriminator/2021-03-01_11-16-07/hparams.yaml
deleted file mode 100644
index 21e7edc..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_11-16-07/hparams.yaml
+++ /dev/null
@@ -1,137 +0,0 @@
-seed: 42
-trainer:
-  gpus: 1
-  num_nodes: 1
-  max_epochs: 8
-  max_steps: null
-  accumulate_grad_batches: 4
-  gradient_clip_val: 0
-  amp_level: O1
-  precision: 16
-  accelerator: ddp
-  checkpoint_callback: false
-  logger: false
-  log_every_n_steps: 1
-  val_check_interval: 1.0
-  resume_from_checkpoint: null
-exp_manager:
-  exp_dir: /home/nxingyu/project/
-  name: Punctuation_with_Domain_discriminator
-  create_tensorboard_logger: true
-  create_checkpoint_callback: true
-base_path: /home/nxingyu/data
-tmp_path: /home/nxingyu/data/tmp
-log_dir: /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_11-16-07
-model:
-  nemo_path: null
-  transformer_path: google/electra-base-discriminator
-  unfrozen: 0
-  maximum_unfrozen: 3
-  unfreeze_step: 1
-  punct_label_ids:
-  - ''
-  - ','
-  - .
-  - '?'
-  - '-'
-  - '!'
-  - ':'
-  - …
-  label_map:
-    —: ','
-    ;: .
-  no_space_label: '#'
-  test_chunk_percent: 0.5
-  punct_class_weights: false
-  dataset:
-    data_dir: /home/nxingyu/data
-    labelled:
-    - /home/nxingyu/data/ted_talks_processed
-    unlabelled:
-    - /home/nxingyu/data/switchboardutt_processed
-    max_seq_length: 128
-    pad_label: ''
-    ignore_extra_tokens: false
-    ignore_start_end: false
-    use_cache: false
-    num_workers: 8
-    pin_memory: false
-    drop_last: true
-    num_labels: 9
-    num_domains: 2
-    test_unlabelled: true
-    attach_label_to_end: null
-    pad_start: 0
-    train_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 16
-      manual_len: 20000
-    validation_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 16
-  tokenizer:
-    tokenizer_name: google/electra-base-discriminator
-    vocab_file: null
-    tokenizer_model: null
-    special_tokens: null
-  language_model:
-    pretrained_model_name: google/electra-base-discriminator
-    lm_checkpoint: null
-    config_file: null
-    config: null
-  punct_head:
-    punct_num_fc_layers: 3
-    fc_dropout: 0.1
-    activation: gelu
-    log_softmax: false
-    use_transformer_init: true
-    loss: dice
-    bilstm: false
-  domain_head:
-    predict_labelled: true
-    domain_num_fc_layers: 2
-    fc_dropout: 0.1
-    activation: relu
-    log_softmax: false
-    use_transformer_init: true
-    loss: focal
-    gamma: 1
-    pooling: mean_max
-    idx_conditioned_on: 0
-    weight:
-    - 0.8
-    - 0.2
-  dice_loss:
-    epsilon: 0.01
-    alpha: 2
-    macro_average: true
-  focal_loss:
-    gamma: 2
-  frozen_lr:
-  - 0.01
-  - 0.001
-  - 0.0001
-  - 0.0001
-  - 1.0e-05
-  - 1.0e-07
-  - 1.0e-08
-  gamma:
-  - 1
-  - 1
-  - 1
-  - 1
-  - 1
-  optim:
-    name: adamw
-    lr: 0.01
-    weight_decay: 0.0
-    sched:
-      name: CosineAnnealing
-      warmup_steps: null
-      warmup_ratio: 0.1
-      min_lr: 1.0e-08
-      last_epoch: -1
-      monitor: val_loss
-      reduce_on_plateau: false
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_11-16-07/test.txt b/Punctuation_with_Domain_discriminator/2021-03-01_11-16-07/test.txt
deleted file mode 100644
index 24921df..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_11-16-07/test.txt
+++ /dev/null
@@ -1,87 +0,0 @@
-Punct report
-
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          65.33      99.69      78.93      44639
-! (label_id: 1)                                          0.00       0.00       0.00          0
-# (label_id: 2)                                        100.00       2.79       5.42       6783
-, (label_id: 3)                                         53.85       1.42       2.77      10325
-- (label_id: 4)                                         20.00       0.72       1.40        966
-. (label_id: 5)                                         60.71       2.55       4.89       4669
-: (label_id: 6)                                          0.00       0.00       0.00          0
-? (label_id: 7)                                        100.00       3.33       6.45        210
-… (label_id: 8)                                          0.00       0.00       0.00       1225
--------------------
-micro avg                                               65.34      65.34      65.34      68817
-macro avg                                               44.43      12.28      11.10      68817
-weighted avg                                            65.02      65.34      52.52      68817
-
--------------------
-                       !           #           ,           -           .           :           ?           …
-    44499.00         0.00      6594.00     10122.00       959.00      4515.00         0.00       196.00      1225.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00       189.00         0.00         0.00         0.00         0.00         0.00         0.00
-       98.00         0.00         0.00       147.00         0.00        28.00         0.00         0.00         0.00
-       28.00         0.00         0.00         0.00         7.00         0.00         0.00         0.00         0.00
-       14.00         0.00         0.00        56.00         0.00       119.00         0.00         7.00         0.00
-        0.00         0.00         0.00         0.00         0.00         7.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         7.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--------------------
-
-Chunked Punct report
-
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          64.79      99.78      78.57      22155
-! (label_id: 1)                                          0.00       0.00       0.00          0
-# (label_id: 2)                                        100.00       2.50       4.88       3360
-, (label_id: 3)                                         61.11       1.43       2.79       5390
-- (label_id: 4)                                          0.00       0.00       0.00        504
-. (label_id: 5)                                         46.15       1.81       3.49       2317
-: (label_id: 6)                                          0.00       0.00       0.00          0
-? (label_id: 7)                                          0.00       0.00       0.00         98
-… (label_id: 8)                                          0.00       0.00       0.00        602
--------------------
-micro avg                                               64.80      64.80      64.80      34426
-macro avg                                               30.23      11.72       9.97      34426
-weighted avg                                            64.13      64.80      51.71      34426
-
--------------------
-                       !           #           ,           -           .           :           ?           …
-    22106.00         0.00      3276.00      5278.00       504.00      2254.00         0.00        98.00       602.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00        84.00         0.00         0.00         0.00         0.00         0.00         0.00
-       35.00         0.00         0.00        77.00         0.00        14.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-       14.00         0.00         0.00        35.00         0.00        42.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         7.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--------------------
-
-Domain report
-
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00        609
--------------------
-micro avg                                              100.00     100.00     100.00        609
-macro avg                                               50.00      50.00      50.00        609
-weighted avg                                           100.00     100.00     100.00        609
-
--------------------
-           0           1
-        0.00         0.00
-        0.00       609.00
--------------------
-
-
-test_loss: 0.7714332938194275
-punct_precision: 44.432716369628906
-punct_f1: 11.096967697143555
-punct_recall: 12.278130531311035
-chunked_punct_precision: 30.2286376953125
-chunked_punct_f1: 9.969476699829102
-chunked_punct_recall: 11.724454879760742
-domain_precision: 50.0
-domain_f1: 50.0
-domain_recall: 50.0
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/cmd-args.log b/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/cmd-args.log
deleted file mode 100644
index 11a5d8e..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/cmd-args.log
+++ /dev/null
@@ -1 +0,0 @@
-main.py
\ No newline at end of file
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/events.out.tfevents.1614569248.Titan.18606.0 b/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/events.out.tfevents.1614569248.Titan.18606.0
deleted file mode 100644
index 29cf3d8..0000000
Binary files a/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/events.out.tfevents.1614569248.Titan.18606.0 and /dev/null differ
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/git-info.log b/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/git-info.log
deleted file mode 100644
index 55749f7..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/git-info.log
+++ /dev/null
@@ -1,548 +0,0 @@
-commit hash: 4e54dd0a2d81c506d2afdaf9987d22dada2f16ad
-diff --git a/NLP.yml b/NLP.yml
-index bc9aa5d..4ae7fd2 100644
---- a/NLP.yml
-+++ b/NLP.yml
-@@ -5,161 +5,237 @@ channels:
-   - defaults
- dependencies:
-   - _libgcc_mutex=0.1=main
-+  - _pytorch_select=0.2=gpu_0
-+  - _tflow_select=2.3.0=mkl
-+  - absl-py=0.11.0=py38h578d9bd_0
-+  - aiohttp=3.7.3=py38h25fe258_0
-+  - argon2-cffi=20.1.0=py38h7b6447c_1
-   - astroid=2.4.2=py38_0
--  - backcall=0.2.0=py_0
-+  - astunparse=1.6.3=py_0
-+  - async-timeout=3.0.1=py_1000
-+  - async_generator=1.10=pyhd3eb1b0_0
-+  - attrs=20.3.0=pyhd3eb1b0_0
-+  - autopep8=1.5.4=py_0
-+  - backcall=0.2.0=pyhd3eb1b0_0
-   - blas=1.0=mkl
-+  - bleach=3.2.3=pyhd3eb1b0_0
-+  - blinker=1.4=py_1
-+  - brotlipy=0.7.0=py38h8df0ef7_1001
-+  - c-ares=1.17.1=h36c2ea0_0
-   - ca-certificates=2021.1.19=h06a4308_0
-+  - cachetools=4.2.1=pyhd8ed1ab_0
-   - certifi=2020.12.5=py38h06a4308_0
-+  - cffi=1.14.4=py38h261ae71_0
-+  - chardet=3.0.4=py38h924ce5b_1008
-+  - click=7.1.2=pyh9f0ad1d_0
-   - code-server=3.8.0=ha770c72_0
--  - cuda91=1.0=h4c16780_0
--  - cudatoolkit=10.2.89=hfd86e86_1
--  - decorator=4.4.2=py_0
--  - icu=68.1=h58526e2_0
-+  - cryptography=3.3.1=py38h3c74f83_0
-+  - cudatoolkit=10.1.243=h6bb024c_0
-+  - cudnn=7.6.5=cuda10.1_0
-+  - dbus=1.13.18=hb2f20db_0
-+  - decorator=4.4.2=pyhd3eb1b0_0
-+  - defusedxml=0.6.0=py_0
-+  - entrypoints=0.3=py38_0
-+  - expat=2.2.10=he6710b0_2
-+  - fontconfig=2.13.0=h9420a91_0
-+  - freetype=2.10.4=h5ab3b9f_0
-+  - fsspec=0.8.5=pyhd8ed1ab_0
-+  - future=0.18.2=py38h578d9bd_3
-+  - gast=0.3.3=py_0
-+  - glib=2.66.1=h92f7085_0
-+  - google-auth=1.24.0=pyhd3deb0d_0
-+  - google-pasta=0.2.0=py_0
-+  - gst-plugins-base=1.14.0=h8213a91_2
-+  - gstreamer=1.14.0=h28cd5cc_2
-+  - hdf5=1.10.6=hb1b8bf9_0
-+  - icu=58.2=he6710b0_3
-+  - idna=2.10=pyh9f0ad1d_0
-+  - importlib-metadata=2.0.0=py_1
-+  - importlib_metadata=2.0.0=1
-   - intel-openmp=2020.2=254
--  - ipython=7.19.0=py38hb070fc8_0
-+  - ipykernel=5.3.4=py38h5ca1d4c_0
-+  - ipython=7.19.0=py38hb070fc8_1
-   - ipython_genutils=0.2.0=pyhd3eb1b0_1
--  - jedi=0.18.0=py38h06a4308_1
-+  - ipywidgets=7.6.3=pyhd3eb1b0_1
-+  - jedi=0.17.0=py38_0
-+  - jinja2=2.11.2=pyhd3eb1b0_0
-+  - jpeg=9b=h024ee3a_2
-+  - jsonschema=3.2.0=py_2
-+  - jupyter=1.0.0=py38_7
-+  - jupyter_client=6.1.7=py_0
-+  - jupyter_console=6.2.0=py_0
-+  - jupyter_core=4.7.0=py38h06a4308_0
-+  - jupyterlab_pygments=0.1.2=py_0
-+  - jupyterlab_widgets=1.0.0=pyhd3eb1b0_1
-+  - keras-preprocessing=1.1.0=py_1
-   - lazy-object-proxy=1.4.3=py38h27cfd23_2
-   - ld_impl_linux-64=2.33.1=h53a641e_7
-   - libedit=3.1.20191231=h14c3975_1
-   - libffi=3.3=he6710b0_2
-   - libgcc-ng=9.1.0=hdf63c60_0
-+  - libgfortran-ng=7.3.0=hdf63c60_0
-+  - libpng=1.6.37=hbc83047_0
-+  - libprotobuf=3.13.0.1=h8b12597_0
-+  - libsodium=1.0.18=h7b6447c_0
-   - libstdcxx-ng=9.1.0=hdf63c60_0
--  - libuv=1.40.0=hd18ef5c_0
-+  - libuuid=1.0.3=h1bed415_2
-+  - libuv=1.40.0=h7b6447c_0
-+  - libxcb=1.14=h7b6447c_0
-+  - libxml2=2.9.10=hb55368b_3
-+  - markdown=3.3.3=pyh9f0ad1d_0
-+  - markupsafe=1.1.1=py38h7b6447c_0
-   - mccabe=0.6.1=py38_1
-+  - mistune=0.8.4=py38h7b6447c_1000
-   - mkl=2020.2=256
-   - mkl-service=2.3.0=py38he904b0f_0
-   - mkl_fft=1.2.0=py38h23d657b_0
-   - mkl_random=1.1.1=py38h0573a6f_0
-+  - multidict=5.1.0=py38h27cfd23_2
-+  - nbclient=0.5.1=py_0
-+  - nbconvert=6.0.7=py38_0
-+  - nbformat=5.1.2=pyhd3eb1b0_1
-   - ncurses=6.2=he6710b0_1
--  - nodejs=12.19.0=hfa01f41_2
-+  - nest-asyncio=1.4.3=pyhd3eb1b0_0
-+  - ninja=1.10.2=py38hff7bd54_0
-+  - nodejs=12.4.0=he1b5a44_0
-+  - notebook=6.2.0=py38h06a4308_0
-   - numpy=1.19.2=py38h54aff64_0
-   - numpy-base=1.19.2=py38hfa32c7d_0
-   - openssl=1.1.1i=h27cfd23_0
--  - pandas=1.2.1=py38ha9443f7_0
-+  - opt_einsum=3.1.0=py_0
-+  - packaging=20.9=pyhd3eb1b0_0
-+  - pandoc=2.11=hb0f4dca_0
-+  - pandocfilters=1.4.3=py38h06a4308_1
-   - parso=0.8.1=pyhd3eb1b0_0
-+  - pcre=8.44=he6710b0_0
-   - pexpect=4.8.0=pyhd3eb1b0_3
-   - pickleshare=0.7.5=pyhd3eb1b0_1003
-   - pip=20.3.3=py38h06a4308_0
-+  - prometheus_client=0.9.0=pyhd3eb1b0_0
-   - prompt-toolkit=3.0.8=py_0
-+  - prompt_toolkit=3.0.8=0
-   - ptyprocess=0.7.0=pyhd3eb1b0_2
-+  - pyasn1=0.4.8=py_0
-+  - pycodestyle=2.6.0=py_0
-+  - pycparser=2.20=py_2
-   - pygments=2.7.4=pyhd3eb1b0_0
-+  - pyjwt=2.0.1=pyhd8ed1ab_0
-   - pylint=2.6.0=py38_0
-+  - pyopenssl=20.0.1=pyhd8ed1ab_0
-+  - pyparsing=2.4.7=pyhd3eb1b0_0
-+  - pyqt=5.9.2=py38h05f1152_4
-+  - pyrsistent=0.17.3=py38h7b6447c_0
-+  - pysocks=1.7.1=py38h578d9bd_3
-   - python=3.8.5=h7579374_1
--  - python-dateutil=2.8.1=py_0
-+  - python-dateutil=2.8.1=pyhd3eb1b0_0
-   - python_abi=3.8=1_cp38
--  - pytz=2020.5=pyhd3eb1b0_0
--  - readline=8.0=h7b6447c_0
-+  - pytorch=1.7.1=py3.8_cuda10.1.243_cudnn7.6.3_0
-+  - pyzmq=20.0.0=py38h2531618_1
-+  - qt=5.9.7=h5867ecd_1
-+  - qtconsole=4.7.7=py_0
-+  - qtpy=1.9.0=py_0
-+  - readline=8.1=h27cfd23_0
-+  - requests=2.25.1=pyhd3deb0d_0
-+  - requests-oauthlib=1.3.0=pyh9f0ad1d_0
-+  - rope=0.18.0=py_0
-+  - rsa=4.7=pyhd3deb0d_0
-+  - send2trash=1.5.0=pyhd3eb1b0_1
-   - setuptools=52.0.0=py38h06a4308_0
-+  - sip=4.19.13=py38he6710b0_0
-   - six=1.15.0=py38h06a4308_0
-   - sqlite=3.33.0=h62c20be_0
-+  - tensorboard=2.3.0=pyh4dce500_0
-+  - tensorboard-plugin-wit=1.8.0=pyh44b312d_0
-+  - tensorflow=2.2.0=mkl_py38h6d3daf0_0
-+  - tensorflow-base=2.2.0=mkl_py38h5059a2d_0
-+  - tensorflow-estimator=2.2.0=pyh208ff02_0
-+  - termcolor=1.1.0=py38_1
-+  - terminado=0.9.2=py38h06a4308_0
-+  - testpath=0.4.4=pyhd3eb1b0_0
-   - tk=8.6.10=hbc83047_0
--  - traitlets=5.0.5=py_0
-+  - toml=0.10.1=py_0
-+  - tornado=6.1=py38h27cfd23_0
-+  - traitlets=5.0.5=pyhd3eb1b0_0
-+  - typing-extensions=3.7.4.3=0
-+  - typing_extensions=3.7.4.3=py_0
-+  - urllib3=1.26.3=pyhd8ed1ab_0
-   - wcwidth=0.2.5=py_0
-+  - webencodings=0.5.1=py38_1
-+  - werkzeug=1.0.1=pyh9f0ad1d_0
-   - wheel=0.36.2=pyhd3eb1b0_0
-+  - widgetsnbextension=3.5.1=py38_0
-+  - wrapt=1.11.2=py38h7b6447c_0
-   - xz=5.2.5=h7b6447c_0
-+  - yaml=0.2.5=h516909a_0
-+  - yarl=1.6.3=py38h25fe258_0
-+  - zeromq=4.3.3=he6710b0_3
-+  - zipp=3.4.0=pyhd3eb1b0_0
-   - zlib=1.2.11=h7b6447c_3
-   - pip:
--    - absl-py==0.11.0
--    - aiohttp==3.7.3
-     - alabaster==0.7.12
-     - antlr4-python3-runtime==4.8
--    - apex==0.1
-     - appdirs==1.4.4
--    - argon2-cffi==20.1.0
-     - asttokens==2.0.4
--    - async-generator==1.10
--    - async-timeout==3.0.1
-     - attrdict==2.0.1
--    - attrs==20.3.0
-     - audioread==2.1.9
-     - babel==2.9.0
-     - black==19.10b0
--    - bleach==3.2.3
--    - boto3==1.16.61
--    - botocore==1.19.61
-+    - boto3==1.16.63
-+    - botocore==1.19.63
-     - braceexpand==0.1.6
--    - cachetools==4.2.1
--    - cffi==1.14.4
--    - chardet==3.0.4
--    - click==7.1.2
-+    - cheap-repr==0.4.4
-     - colorama==0.4.4
-     - configparser==5.0.1
-     - cycler==0.10.0
-     - cython==0.29.21
-     - datasets==1.2.1
--    - defusedxml==0.6.0
-     - dill==0.3.3
-     - distance==0.1.3
-     - docker-pycreds==0.4.0
-     - docopt==0.6.2
-     - docutils==0.16
-     - editdistance==0.5.3
--    - entrypoints==0.3
-     - executing==0.5.4
-     - filelock==3.0.12
-     - frozendict==1.2
--    - fsspec==0.8.5
--    - future==0.18.2
-     - g2p-en==2.1.0
-     - gdown==3.12.2
-     - gitdb==4.0.5
-     - gitpython==3.1.12
--    - google-auth==1.24.0
-     - google-auth-oauthlib==0.4.2
-     - grpcio==1.35.0
-     - h5py==3.1.0
--    - hydra==2.5
--    - hydra-core==1.0.5
-+    - hydra-core==1.1.0.dev3
-     - icecream==2.1.0
--    - idna==2.10
-     - imagesize==1.2.0
-     - importlib-resources==5.1.0
-     - inflect==5.0.2
-     - iniconfig==1.1.1
--    - ipykernel==5.4.3
--    - ipywidgets==7.6.3
-     - isort==4.3.21
--    - jinja2==2.11.2
-     - jmespath==0.10.0
-     - joblib==1.0.0
--    - jsonschema==3.2.0
--    - jupyter==1.0.0
--    - jupyter-client==6.1.11
--    - jupyter-console==6.2.0
--    - jupyter-core==4.7.0
--    - jupyterlab-pygments==0.1.2
--    - jupyterlab-widgets==1.0.0
-+    - kaggle==1.5.10
-     - kaldi-io==0.9.4
-     - kaldi-python-io==1.2.1
-     - kiwisolver==1.3.1
-     - latexcodec==2.0.1
-     - librosa==0.8.0
-     - llvmlite==0.35.0
--    - markdown==3.3.3
--    - markupsafe==1.1.1
-+    - logging==0.4.9.6
-     - marshmallow==3.10.0
--    - matplotlib==3.3.3
-+    - matplotlib==3.3.4
-     - megatron-lm==1.1.5
--    - mistune==0.8.4
-     - msgpack==1.0.2
--    - multidict==5.1.0
-     - multiprocess==0.70.11.1
--    - nbclient==0.5.1
--    - nbconvert==6.0.7
--    - nbformat==5.1.2
-     - nemo-toolkit==1.0.0b2
--    - nest-asyncio==1.4.3
-     - nltk==3.5
--    - notebook==6.2.0
-     - num2words==0.5.10
-     - numba==0.52.0
-     - oauthlib==3.1.0
-     - objectio==0.2.29
--    - omegaconf==2.0.6
--    - onnx==1.8.0
--    - packaging==20.8
--    - pandocfilters==1.4.3
-+    - omegaconf==2.1.0.dev17
-+    - onnx==1.8.1
-+    - pandas==1.2.1
-     - parameterized==0.8.1
-     - pathspec==0.8.1
-     - pathtools==0.1.2
-@@ -169,52 +245,38 @@ dependencies:
-     - pipreqs==0.4.10
-     - pluggy==0.13.1
-     - pooch==1.3.0
--    - portalocker==2.1.0
--    - prometheus-client==0.9.0
-     - promise==2.3
-     - protobuf==3.14.0
-     - psutil==5.8.0
-     - py==1.10.0
-     - pyarrow==3.0.0
--    - pyasn1==0.4.8
-     - pyasn1-modules==0.2.8
-     - pybind11==2.6.2
-     - pybtex==0.24.0
-     - pybtex-docutils==1.0.0
--    - pycparser==2.20
--    - pydub==0.24.1
--    - pyparsing==2.4.7
-     - pypinyin==0.40.0
--    - pyrsistent==0.17.3
--    - pysocks==1.7.1
-     - pystoi==0.3.3
-     - pytest==6.2.2
-     - pytest-runner==5.2
--    - python-levenshtein==0.12.1
--    - pytorch-lightning==1.1.3
--    - pyyaml==5.4.1
--    - pyzmq==21.0.2
--    - qtconsole==5.0.2
--    - qtpy==1.9.0
-+    - python-slugify==4.0.1
-+    - pytorch-lightning==1.1.5
-+    - pytz==2020.5
-+    - pyyaml==5.3.1
-     - rapidfuzz==0.14.2
-     - regex==2020.11.13
--    - requests==2.25.1
--    - requests-oauthlib==1.3.0
-     - resampy==0.2.2
--    - rsa==4.7
-     - ruamel-yaml==0.16.12
-     - ruamel-yaml-clib==0.2.2
-     - s3transfer==0.3.4
--    - sacrebleu==1.5.0
-     - sacremoses==0.0.43
-     - scikit-learn==0.24.1
-     - scipy==1.6.0
--    - send2trash==1.5.0
-     - sentencepiece==0.1.95
-     - sentry-sdk==0.19.5
-     - shortuuid==1.0.1
-     - simplejson==3.17.2
-     - smmap==3.0.5
-+    - snoop==0.2.5
-     - snowballstemmer==2.1.0
-     - soundfile==0.10.3.post1
-     - sox==1.4.1
-@@ -227,35 +289,24 @@ dependencies:
-     - sphinxcontrib-qthelp==1.0.3
-     - sphinxcontrib-serializinghtml==1.1.4
-     - subprocess32==3.5.4
--    - tensorboard==2.4.1
--    - tensorboard-plugin-wit==1.8.0
--    - terminado==0.9.2
--    - testpath==0.4.4
-+    - tensorboardx==2.1
-+    - text-unidecode==1.3
-     - threadpoolctl==2.1.0
-     - tokenizers==0.9.4
--    - toml==0.10.2
-     - torch==1.7.1
-     - torch-stft==0.1.4
--    - torchtext==0.8.1
-+    - torchtools==0.2.5
-     - torchvision==0.8.2
--    - tornado==6.1
-     - tqdm==4.49.0
-     - transformers==4.2.2
-     - typed-ast==1.4.2
-     - typer==0.3.2
--    - typing-extensions==3.7.4.3
-     - unidecode==1.1.2
--    - urllib3==1.26.3
-     - wandb==0.10.15
-     - watchdog==0.10.4
-     - webdataset==0.1.40
--    - webencodings==0.5.1
--    - werkzeug==1.0.1
-     - wget==3.2
--    - widgetsnbextension==3.5.1
--    - wrapt==1.12.1
-     - xxhash==2.0.0
-     - yarg==0.1.9
--    - yarl==1.6.3
-     - youtokentome==1.0.6
- prefix: /home/nxingyu/miniconda3/envs/NLP
-diff --git a/experiment/config.yaml b/experiment/config.yaml
-index b886b5a..6c3c223 100644
---- a/experiment/config.yaml
-+++ b/experiment/config.yaml
-@@ -43,7 +43,7 @@ log_dir: null
- model:
-     nemo_path: null
-     transformer_path: google/electra-base-discriminator # roberta-base #google/electra-base-discriminator # distilbert-base-uncased # filename to save the model and associated artifacts to .nemo file
--    unfrozen: 1
-+    unfrozen: 0
-     maximum_unfrozen: 3
-     unfreeze_step: 1
-     punct_label_ids:
-@@ -127,28 +127,28 @@ model:
-         # unfrozen_layers: 1
-     
-     punct_head:
--        punct_num_fc_layers: 3
-+        punct_num_fc_layers: 0
-         fc_dropout: 0.1
-         activation: 'gelu'
-         log_softmax: false
-         use_transformer_init: true
--        loss: 'dice'
-+        loss: 'crf'
-         bilstm: false
- 
-     domain_head:
-         predict_labelled: true # if false: treats every domain separately, if true: splits into labelled and unlabelled
--        domain_num_fc_layers: 1
-+        domain_num_fc_layers: 2
-         fc_dropout: 0.1
-         activation: 'relu'
-         log_softmax: false
-         use_transformer_init: true
-         loss: 'focal'
-         gamma: 1 #0.1 # coefficient of gradient reversal
--        pooling: 'mean_max' # 'mean' mean_max
-+        pooling: 'token' # 'mean' # 'mean_max' # 'token'
-         idx_conditioned_on: 0
-         weight:
--            - 0.6
--            - 0.4
-+            - 0.8
-+            - 0.2
- 
- 
-     dice_loss:
-@@ -160,7 +160,7 @@ model:
-         gamma: 2
- 
-     frozen_lr:
--        # - 1e-2
-+        - 1e-2
-         - 1e-3
-         - 1e-4
-         - 1e-4
-diff --git a/experiment/info.log b/experiment/info.log
-index 5fc3200..a4bbbb5 100644
---- a/experiment/info.log
-+++ b/experiment/info.log
-@@ -1,84 +1,5 @@
-+[INFO] - Global seed set to 42
- [INFO] - GPU available: True, used: True
- [INFO] - TPU available: None, using: 0 TPU cores
--[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
-+[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
- [INFO] - Using native 16bit precision.
--[INFO] - shuffling train set
--[INFO] - initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.001
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7f1f8ee04790>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 3.1 K 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--8.3 M     Trainable params
--101 M     Non-trainable params
--110 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          88.38      37.36      52.51      32611
--! (label_id: 1)                                          0.00       0.00       0.00         10
--# (label_id: 2)                                          1.95      16.57       3.49       1358
--, (label_id: 3)                                          1.59       0.40       0.64        997
--- (label_id: 4)                                          0.24       4.90       0.46        102
--. (label_id: 5)                                          4.48       4.72       4.60        932
--: (label_id: 6)                                          0.04      11.76       0.09         17
--? (label_id: 7)                                          0.00       0.00       0.00         71
--… (label_id: 8)                                          0.00       0.00       0.00          6
---------------------
--micro avg                                               34.52      34.52      34.52      36104
--macro avg                                               10.74       8.41       6.87      36104
--weighted avg                                            80.06      34.52      47.70      36104
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    12182.00         5.00       661.00       447.00        46.00       411.00         8.00        22.00         2.00
--     1145.00         0.00        52.00        48.00        10.00        65.00         1.00         6.00         0.00
--    10705.00         1.00       225.00       312.00        17.00       256.00         6.00        27.00         3.00
--      225.00         0.00        21.00         4.00         0.00         2.00         0.00         0.00         0.00
--     1914.00         0.00       114.00        15.00         5.00         4.00         0.00         1.00         0.00
--      874.00         0.00        20.00        37.00         3.00        44.00         0.00         3.00         1.00
--     4235.00         4.00       128.00       113.00        11.00       135.00         2.00        12.00         0.00
--      193.00         0.00         6.00         1.00         0.00         0.00         0.00         0.00         0.00
--     1138.00         0.00       131.00        20.00        10.00        15.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                         50.65     100.00      67.24        156
--1 (label_id: 1)                                        100.00       2.56       5.00        156
---------------------
--micro avg                                               51.28      51.28      51.28        312
--macro avg                                               75.32      51.28      36.12        312
--weighted avg                                            75.32      51.28      36.12        312
--
---------------------
--           0           1
--      156.00       152.00
--        0.00         4.00
---------------------
--
--[INFO] - Internal process exited
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/hparams.yaml b/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/hparams.yaml
deleted file mode 100644
index 9f3780c..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/hparams.yaml
+++ /dev/null
@@ -1,137 +0,0 @@
-seed: 42
-trainer:
-  gpus: 1
-  num_nodes: 1
-  max_epochs: 8
-  max_steps: null
-  accumulate_grad_batches: 4
-  gradient_clip_val: 0
-  amp_level: O1
-  precision: 16
-  accelerator: ddp
-  checkpoint_callback: false
-  logger: false
-  log_every_n_steps: 1
-  val_check_interval: 1.0
-  resume_from_checkpoint: null
-exp_manager:
-  exp_dir: /home/nxingyu/project/
-  name: Punctuation_with_Domain_discriminator
-  create_tensorboard_logger: true
-  create_checkpoint_callback: true
-base_path: /home/nxingyu/data
-tmp_path: /home/nxingyu/data/tmp
-log_dir: /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11
-model:
-  nemo_path: null
-  transformer_path: google/electra-base-discriminator
-  unfrozen: 0
-  maximum_unfrozen: 3
-  unfreeze_step: 1
-  punct_label_ids:
-  - ''
-  - ','
-  - .
-  - '?'
-  - '-'
-  - '!'
-  - ':'
-  - …
-  label_map:
-    —: ','
-    ;: .
-  no_space_label: '#'
-  test_chunk_percent: 0.5
-  punct_class_weights: false
-  dataset:
-    data_dir: /home/nxingyu/data
-    labelled:
-    - /home/nxingyu/data/ted_talks_processed
-    unlabelled:
-    - /home/nxingyu/data/switchboardutt_processed
-    max_seq_length: 128
-    pad_label: ''
-    ignore_extra_tokens: false
-    ignore_start_end: false
-    use_cache: false
-    num_workers: 8
-    pin_memory: false
-    drop_last: true
-    num_labels: 9
-    num_domains: 2
-    test_unlabelled: true
-    attach_label_to_end: null
-    pad_start: 0
-    train_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 16
-      manual_len: 20000
-    validation_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 16
-  tokenizer:
-    tokenizer_name: google/electra-base-discriminator
-    vocab_file: null
-    tokenizer_model: null
-    special_tokens: null
-  language_model:
-    pretrained_model_name: google/electra-base-discriminator
-    lm_checkpoint: null
-    config_file: null
-    config: null
-  punct_head:
-    punct_num_fc_layers: 0
-    fc_dropout: 0.1
-    activation: gelu
-    log_softmax: false
-    use_transformer_init: true
-    loss: crf
-    bilstm: false
-  domain_head:
-    predict_labelled: true
-    domain_num_fc_layers: 2
-    fc_dropout: 0.1
-    activation: relu
-    log_softmax: false
-    use_transformer_init: true
-    loss: focal
-    gamma: 1
-    pooling: token
-    idx_conditioned_on: 0
-    weight:
-    - 0.8
-    - 0.2
-  dice_loss:
-    epsilon: 0.01
-    alpha: 2
-    macro_average: true
-  focal_loss:
-    gamma: 2
-  frozen_lr:
-  - 0.01
-  - 0.001
-  - 0.0001
-  - 0.0001
-  - 1.0e-05
-  - 1.0e-07
-  - 1.0e-08
-  gamma:
-  - 1
-  - 1
-  - 1
-  - 1
-  - 1
-  optim:
-    name: adamw
-    lr: 0.01
-    weight_decay: 0.0
-    sched:
-      name: CosineAnnealing
-      warmup_steps: null
-      warmup_ratio: 0.1
-      min_lr: 1.0e-08
-      last_epoch: -1
-      monitor: val_loss
-      reduce_on_plateau: false
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/lightning_logs.txt b/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/lightning_logs.txt
deleted file mode 100644
index 098b4e0..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/lightning_logs.txt
+++ /dev/null
@@ -1,88 +0,0 @@
-Global seed set to 42
-GPU available: True, used: True
-TPU available: None, using: 0 TPU cores
-LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
-Using native 16bit precision.
-Global seed set to 42
-initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 6.9 K 
-2 | domain_classifier          | SequenceClassifier   | 592 K 
-3 | punctuation_loss           | LinearChainCRF       | 99    
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-599 K     Trainable params
-108 M     Non-trainable params
-109 M     Total params
-Epoch 0, global step 49: val_loss reached 25.80794 (best 25.80794), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.81-epoch=0.ckpt" as top 3
-Epoch 1, global step 99: val_loss reached 19.15409 (best 19.15409), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/checkpoints/Punctuation_with_Domain_discriminator---val_loss=19.15-epoch=1.ckpt" as top 3
-Epoch 2, global step 149: val_loss reached 18.03560 (best 18.03560), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/checkpoints/Punctuation_with_Domain_discriminator---val_loss=18.04-epoch=2.ckpt" as top 3
-Epoch 3, global step 199: val_loss reached 17.00113 (best 17.00113), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/checkpoints/Punctuation_with_Domain_discriminator---val_loss=17.00-epoch=3.ckpt" as top 3
-Epoch 4, global step 249: val_loss reached 16.89523 (best 16.89523), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/checkpoints/Punctuation_with_Domain_discriminator---val_loss=16.90-epoch=4.ckpt" as top 3
-Epoch 5, global step 299: val_loss reached 16.74832 (best 16.74832), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/checkpoints/Punctuation_with_Domain_discriminator---val_loss=16.75-epoch=5.ckpt" as top 3
-Epoch 6, global step 349: val_loss reached 16.37021 (best 16.37021), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/checkpoints/Punctuation_with_Domain_discriminator---val_loss=16.37-epoch=6.ckpt" as top 3
-Epoch 7, global step 399: val_loss reached 16.45627 (best 16.37021), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/checkpoints/Punctuation_with_Domain_discriminator---val_loss=16.46-epoch=7.ckpt" as top 3
-Saving latest checkpoint...
-Global seed set to 42
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 6.9 K 
-2 | domain_classifier          | SequenceClassifier   | 592 K 
-3 | punctuation_loss           | LinearChainCRF       | 99    
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-7.7 M     Trainable params
-101 M     Non-trainable params
-109 M     Total params
-Epoch 0, global step 449: val_loss reached 16.54933 (best 16.37021), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/checkpoints/Punctuation_with_Domain_discriminator---val_loss=16.55-epoch=0.ckpt" as top 3
-Global seed set to 42
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 6.9 K 
-2 | domain_classifier          | SequenceClassifier   | 592 K 
-3 | punctuation_loss           | LinearChainCRF       | 99    
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-14.8 M    Trainable params
-94.7 M    Non-trainable params
-109 M     Total params
-Global seed set to 42
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 6.9 K 
-2 | domain_classifier          | SequenceClassifier   | 592 K 
-3 | punctuation_loss           | LinearChainCRF       | 99    
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-21.9 M    Trainable params
-87.6 M    Non-trainable params
-109 M     Total params
-GPU available: True, used: True
-TPU available: None, using: 0 TPU cores
-Using environment variable NODE_RANK for node rank (0).
-LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/nemo_error_log.txt b/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/nemo_error_log.txt
deleted file mode 100644
index 08ad201..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/nemo_error_log.txt
+++ /dev/null
@@ -1,34 +0,0 @@
-[NeMo W 2021-03-01 11:27:11 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
-[NeMo W 2021-03-01 11:27:23 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 11:27:23 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 11:27:27 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 11:27:27 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 11:27:27 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 11:27:28 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
-      warnings.warn(*args, **kwargs)
-    
-[NeMo W 2021-03-01 11:28:47 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
-      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
-    
-[NeMo W 2021-03-01 11:32:50 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f33c78abe20> was reported to be 199 (when accessing len(dataloader)), but 200 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-03-01 11:33:28 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f33c78abf70> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-03-01 12:27:53 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
-      warnings.warn(*args, **kwargs)
-    
-[NeMo W 2021-03-01 12:28:31 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f33c7918d00> was reported to be 7 (when accessing len(dataloader)), but 8 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/nemo_log_globalrank-0_localrank-0.txt b/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/nemo_log_globalrank-0_localrank-0.txt
deleted file mode 100644
index 13ce373..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/nemo_log_globalrank-0_localrank-0.txt
+++ /dev/null
@@ -1,36 +0,0 @@
-[NeMo I 2021-03-01 11:27:11 exp_manager:183] Experiments will be logged at /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11
-[NeMo I 2021-03-01 11:27:11 exp_manager:519] TensorboardLogger has been set up
-[NeMo W 2021-03-01 11:27:11 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
-[NeMo W 2021-03-01 11:27:23 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 11:27:23 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 11:27:27 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 11:27:27 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 11:27:27 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 11:27:28 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
-      warnings.warn(*args, **kwargs)
-    
-[NeMo W 2021-03-01 11:28:47 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
-      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
-    
-[NeMo W 2021-03-01 11:32:50 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f33c78abe20> was reported to be 199 (when accessing len(dataloader)), but 200 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-03-01 11:33:28 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f33c78abf70> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-03-01 12:27:53 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
-      warnings.warn(*args, **kwargs)
-    
-[NeMo W 2021-03-01 12:28:31 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f33c7918d00> was reported to be 7 (when accessing len(dataloader)), but 8 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/test.txt b/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/test.txt
deleted file mode 100644
index ff4ac9d..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_11-27-11/test.txt
+++ /dev/null
@@ -1,87 +0,0 @@
-Punct report
-
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          65.31      99.95      79.00      44639
-! (label_id: 1)                                          0.00       0.00       0.00          0
-# (label_id: 2)                                        100.00       4.44       8.50       6783
-, (label_id: 3)                                         83.33       0.34       0.68      10325
-- (label_id: 4)                                         66.67       1.45       2.84        966
-. (label_id: 5)                                         75.00       2.25       4.37       4669
-: (label_id: 6)                                          0.00       0.00       0.00          0
-? (label_id: 7)                                          0.00       0.00       0.00        210
-… (label_id: 8)                                          0.00       0.00       0.00       1225
--------------------
-micro avg                                               65.50      65.50      65.50      68817
-macro avg                                               43.37      12.05      10.60      68817
-weighted avg                                            70.75      65.50      52.52      68817
-
--------------------
-                       !           #           ,           -           .           :           ?           …
-    44618.00         0.00      6482.00     10269.00       952.00      4564.00         0.00       203.00      1225.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00       301.00         0.00         0.00         0.00         0.00         0.00         0.00
-        7.00         0.00         0.00        35.00         0.00         0.00         0.00         0.00         0.00
-        7.00         0.00         0.00         0.00        14.00         0.00         0.00         0.00         0.00
-        7.00         0.00         0.00        21.00         0.00       105.00         0.00         7.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--------------------
-
-Chunked Punct report
-
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          64.67      99.94      78.53      22155
-! (label_id: 1)                                          0.00       0.00       0.00          0
-# (label_id: 2)                                        100.00       3.33       6.45       3360
-, (label_id: 3)                                         75.00       0.39       0.78       5390
-- (label_id: 4)                                          0.00       0.00       0.00        504
-. (label_id: 5)                                         57.14       1.21       2.37       2317
-: (label_id: 6)                                          0.00       0.00       0.00          0
-? (label_id: 7)                                          0.00       0.00       0.00         98
-… (label_id: 8)                                          0.00       0.00       0.00        602
--------------------
-micro avg                                               64.78      64.78      64.78      34426
-macro avg                                               32.98      11.65       9.79      34426
-weighted avg                                            66.97      64.78      51.45      34426
-
--------------------
-                       !           #           ,           -           .           :           ?           …
-    22141.00         0.00      3248.00      5355.00       504.00      2289.00         0.00        98.00       602.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00       112.00         0.00         0.00         0.00         0.00         0.00         0.00
-        7.00         0.00         0.00        21.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        7.00         0.00         0.00        14.00         0.00        28.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--------------------
-
-Domain report
-
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00        609
--------------------
-micro avg                                              100.00     100.00     100.00        609
-macro avg                                               50.00      50.00      50.00        609
-weighted avg                                           100.00     100.00     100.00        609
-
--------------------
-           0           1
-        0.00         0.00
-        0.00       609.00
--------------------
-
-
-test_loss: 186.19358825683594
-punct_precision: 43.36823272705078
-punct_f1: 10.597822189331055
-punct_recall: 12.047517776489258
-chunked_punct_precision: 32.979183197021484
-chunked_punct_f1: 9.790999412536621
-chunked_punct_recall: 11.652023315429688
-domain_precision: 50.0
-domain_f1: 50.0
-domain_recall: 50.0
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/cmd-args.log b/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/cmd-args.log
deleted file mode 100644
index 11a5d8e..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/cmd-args.log
+++ /dev/null
@@ -1 +0,0 @@
-main.py
\ No newline at end of file
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/events.out.tfevents.1614576419.Titan.5868.0 b/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/events.out.tfevents.1614576419.Titan.5868.0
deleted file mode 100644
index 712dd9a..0000000
Binary files a/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/events.out.tfevents.1614576419.Titan.5868.0 and /dev/null differ
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/git-info.log b/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/git-info.log
deleted file mode 100644
index 3765344..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/git-info.log
+++ /dev/null
@@ -1,587 +0,0 @@
-commit hash: 4e54dd0a2d81c506d2afdaf9987d22dada2f16ad
-diff --git a/NLP.yml b/NLP.yml
-index bc9aa5d..4ae7fd2 100644
---- a/NLP.yml
-+++ b/NLP.yml
-@@ -5,161 +5,237 @@ channels:
-   - defaults
- dependencies:
-   - _libgcc_mutex=0.1=main
-+  - _pytorch_select=0.2=gpu_0
-+  - _tflow_select=2.3.0=mkl
-+  - absl-py=0.11.0=py38h578d9bd_0
-+  - aiohttp=3.7.3=py38h25fe258_0
-+  - argon2-cffi=20.1.0=py38h7b6447c_1
-   - astroid=2.4.2=py38_0
--  - backcall=0.2.0=py_0
-+  - astunparse=1.6.3=py_0
-+  - async-timeout=3.0.1=py_1000
-+  - async_generator=1.10=pyhd3eb1b0_0
-+  - attrs=20.3.0=pyhd3eb1b0_0
-+  - autopep8=1.5.4=py_0
-+  - backcall=0.2.0=pyhd3eb1b0_0
-   - blas=1.0=mkl
-+  - bleach=3.2.3=pyhd3eb1b0_0
-+  - blinker=1.4=py_1
-+  - brotlipy=0.7.0=py38h8df0ef7_1001
-+  - c-ares=1.17.1=h36c2ea0_0
-   - ca-certificates=2021.1.19=h06a4308_0
-+  - cachetools=4.2.1=pyhd8ed1ab_0
-   - certifi=2020.12.5=py38h06a4308_0
-+  - cffi=1.14.4=py38h261ae71_0
-+  - chardet=3.0.4=py38h924ce5b_1008
-+  - click=7.1.2=pyh9f0ad1d_0
-   - code-server=3.8.0=ha770c72_0
--  - cuda91=1.0=h4c16780_0
--  - cudatoolkit=10.2.89=hfd86e86_1
--  - decorator=4.4.2=py_0
--  - icu=68.1=h58526e2_0
-+  - cryptography=3.3.1=py38h3c74f83_0
-+  - cudatoolkit=10.1.243=h6bb024c_0
-+  - cudnn=7.6.5=cuda10.1_0
-+  - dbus=1.13.18=hb2f20db_0
-+  - decorator=4.4.2=pyhd3eb1b0_0
-+  - defusedxml=0.6.0=py_0
-+  - entrypoints=0.3=py38_0
-+  - expat=2.2.10=he6710b0_2
-+  - fontconfig=2.13.0=h9420a91_0
-+  - freetype=2.10.4=h5ab3b9f_0
-+  - fsspec=0.8.5=pyhd8ed1ab_0
-+  - future=0.18.2=py38h578d9bd_3
-+  - gast=0.3.3=py_0
-+  - glib=2.66.1=h92f7085_0
-+  - google-auth=1.24.0=pyhd3deb0d_0
-+  - google-pasta=0.2.0=py_0
-+  - gst-plugins-base=1.14.0=h8213a91_2
-+  - gstreamer=1.14.0=h28cd5cc_2
-+  - hdf5=1.10.6=hb1b8bf9_0
-+  - icu=58.2=he6710b0_3
-+  - idna=2.10=pyh9f0ad1d_0
-+  - importlib-metadata=2.0.0=py_1
-+  - importlib_metadata=2.0.0=1
-   - intel-openmp=2020.2=254
--  - ipython=7.19.0=py38hb070fc8_0
-+  - ipykernel=5.3.4=py38h5ca1d4c_0
-+  - ipython=7.19.0=py38hb070fc8_1
-   - ipython_genutils=0.2.0=pyhd3eb1b0_1
--  - jedi=0.18.0=py38h06a4308_1
-+  - ipywidgets=7.6.3=pyhd3eb1b0_1
-+  - jedi=0.17.0=py38_0
-+  - jinja2=2.11.2=pyhd3eb1b0_0
-+  - jpeg=9b=h024ee3a_2
-+  - jsonschema=3.2.0=py_2
-+  - jupyter=1.0.0=py38_7
-+  - jupyter_client=6.1.7=py_0
-+  - jupyter_console=6.2.0=py_0
-+  - jupyter_core=4.7.0=py38h06a4308_0
-+  - jupyterlab_pygments=0.1.2=py_0
-+  - jupyterlab_widgets=1.0.0=pyhd3eb1b0_1
-+  - keras-preprocessing=1.1.0=py_1
-   - lazy-object-proxy=1.4.3=py38h27cfd23_2
-   - ld_impl_linux-64=2.33.1=h53a641e_7
-   - libedit=3.1.20191231=h14c3975_1
-   - libffi=3.3=he6710b0_2
-   - libgcc-ng=9.1.0=hdf63c60_0
-+  - libgfortran-ng=7.3.0=hdf63c60_0
-+  - libpng=1.6.37=hbc83047_0
-+  - libprotobuf=3.13.0.1=h8b12597_0
-+  - libsodium=1.0.18=h7b6447c_0
-   - libstdcxx-ng=9.1.0=hdf63c60_0
--  - libuv=1.40.0=hd18ef5c_0
-+  - libuuid=1.0.3=h1bed415_2
-+  - libuv=1.40.0=h7b6447c_0
-+  - libxcb=1.14=h7b6447c_0
-+  - libxml2=2.9.10=hb55368b_3
-+  - markdown=3.3.3=pyh9f0ad1d_0
-+  - markupsafe=1.1.1=py38h7b6447c_0
-   - mccabe=0.6.1=py38_1
-+  - mistune=0.8.4=py38h7b6447c_1000
-   - mkl=2020.2=256
-   - mkl-service=2.3.0=py38he904b0f_0
-   - mkl_fft=1.2.0=py38h23d657b_0
-   - mkl_random=1.1.1=py38h0573a6f_0
-+  - multidict=5.1.0=py38h27cfd23_2
-+  - nbclient=0.5.1=py_0
-+  - nbconvert=6.0.7=py38_0
-+  - nbformat=5.1.2=pyhd3eb1b0_1
-   - ncurses=6.2=he6710b0_1
--  - nodejs=12.19.0=hfa01f41_2
-+  - nest-asyncio=1.4.3=pyhd3eb1b0_0
-+  - ninja=1.10.2=py38hff7bd54_0
-+  - nodejs=12.4.0=he1b5a44_0
-+  - notebook=6.2.0=py38h06a4308_0
-   - numpy=1.19.2=py38h54aff64_0
-   - numpy-base=1.19.2=py38hfa32c7d_0
-   - openssl=1.1.1i=h27cfd23_0
--  - pandas=1.2.1=py38ha9443f7_0
-+  - opt_einsum=3.1.0=py_0
-+  - packaging=20.9=pyhd3eb1b0_0
-+  - pandoc=2.11=hb0f4dca_0
-+  - pandocfilters=1.4.3=py38h06a4308_1
-   - parso=0.8.1=pyhd3eb1b0_0
-+  - pcre=8.44=he6710b0_0
-   - pexpect=4.8.0=pyhd3eb1b0_3
-   - pickleshare=0.7.5=pyhd3eb1b0_1003
-   - pip=20.3.3=py38h06a4308_0
-+  - prometheus_client=0.9.0=pyhd3eb1b0_0
-   - prompt-toolkit=3.0.8=py_0
-+  - prompt_toolkit=3.0.8=0
-   - ptyprocess=0.7.0=pyhd3eb1b0_2
-+  - pyasn1=0.4.8=py_0
-+  - pycodestyle=2.6.0=py_0
-+  - pycparser=2.20=py_2
-   - pygments=2.7.4=pyhd3eb1b0_0
-+  - pyjwt=2.0.1=pyhd8ed1ab_0
-   - pylint=2.6.0=py38_0
-+  - pyopenssl=20.0.1=pyhd8ed1ab_0
-+  - pyparsing=2.4.7=pyhd3eb1b0_0
-+  - pyqt=5.9.2=py38h05f1152_4
-+  - pyrsistent=0.17.3=py38h7b6447c_0
-+  - pysocks=1.7.1=py38h578d9bd_3
-   - python=3.8.5=h7579374_1
--  - python-dateutil=2.8.1=py_0
-+  - python-dateutil=2.8.1=pyhd3eb1b0_0
-   - python_abi=3.8=1_cp38
--  - pytz=2020.5=pyhd3eb1b0_0
--  - readline=8.0=h7b6447c_0
-+  - pytorch=1.7.1=py3.8_cuda10.1.243_cudnn7.6.3_0
-+  - pyzmq=20.0.0=py38h2531618_1
-+  - qt=5.9.7=h5867ecd_1
-+  - qtconsole=4.7.7=py_0
-+  - qtpy=1.9.0=py_0
-+  - readline=8.1=h27cfd23_0
-+  - requests=2.25.1=pyhd3deb0d_0
-+  - requests-oauthlib=1.3.0=pyh9f0ad1d_0
-+  - rope=0.18.0=py_0
-+  - rsa=4.7=pyhd3deb0d_0
-+  - send2trash=1.5.0=pyhd3eb1b0_1
-   - setuptools=52.0.0=py38h06a4308_0
-+  - sip=4.19.13=py38he6710b0_0
-   - six=1.15.0=py38h06a4308_0
-   - sqlite=3.33.0=h62c20be_0
-+  - tensorboard=2.3.0=pyh4dce500_0
-+  - tensorboard-plugin-wit=1.8.0=pyh44b312d_0
-+  - tensorflow=2.2.0=mkl_py38h6d3daf0_0
-+  - tensorflow-base=2.2.0=mkl_py38h5059a2d_0
-+  - tensorflow-estimator=2.2.0=pyh208ff02_0
-+  - termcolor=1.1.0=py38_1
-+  - terminado=0.9.2=py38h06a4308_0
-+  - testpath=0.4.4=pyhd3eb1b0_0
-   - tk=8.6.10=hbc83047_0
--  - traitlets=5.0.5=py_0
-+  - toml=0.10.1=py_0
-+  - tornado=6.1=py38h27cfd23_0
-+  - traitlets=5.0.5=pyhd3eb1b0_0
-+  - typing-extensions=3.7.4.3=0
-+  - typing_extensions=3.7.4.3=py_0
-+  - urllib3=1.26.3=pyhd8ed1ab_0
-   - wcwidth=0.2.5=py_0
-+  - webencodings=0.5.1=py38_1
-+  - werkzeug=1.0.1=pyh9f0ad1d_0
-   - wheel=0.36.2=pyhd3eb1b0_0
-+  - widgetsnbextension=3.5.1=py38_0
-+  - wrapt=1.11.2=py38h7b6447c_0
-   - xz=5.2.5=h7b6447c_0
-+  - yaml=0.2.5=h516909a_0
-+  - yarl=1.6.3=py38h25fe258_0
-+  - zeromq=4.3.3=he6710b0_3
-+  - zipp=3.4.0=pyhd3eb1b0_0
-   - zlib=1.2.11=h7b6447c_3
-   - pip:
--    - absl-py==0.11.0
--    - aiohttp==3.7.3
-     - alabaster==0.7.12
-     - antlr4-python3-runtime==4.8
--    - apex==0.1
-     - appdirs==1.4.4
--    - argon2-cffi==20.1.0
-     - asttokens==2.0.4
--    - async-generator==1.10
--    - async-timeout==3.0.1
-     - attrdict==2.0.1
--    - attrs==20.3.0
-     - audioread==2.1.9
-     - babel==2.9.0
-     - black==19.10b0
--    - bleach==3.2.3
--    - boto3==1.16.61
--    - botocore==1.19.61
-+    - boto3==1.16.63
-+    - botocore==1.19.63
-     - braceexpand==0.1.6
--    - cachetools==4.2.1
--    - cffi==1.14.4
--    - chardet==3.0.4
--    - click==7.1.2
-+    - cheap-repr==0.4.4
-     - colorama==0.4.4
-     - configparser==5.0.1
-     - cycler==0.10.0
-     - cython==0.29.21
-     - datasets==1.2.1
--    - defusedxml==0.6.0
-     - dill==0.3.3
-     - distance==0.1.3
-     - docker-pycreds==0.4.0
-     - docopt==0.6.2
-     - docutils==0.16
-     - editdistance==0.5.3
--    - entrypoints==0.3
-     - executing==0.5.4
-     - filelock==3.0.12
-     - frozendict==1.2
--    - fsspec==0.8.5
--    - future==0.18.2
-     - g2p-en==2.1.0
-     - gdown==3.12.2
-     - gitdb==4.0.5
-     - gitpython==3.1.12
--    - google-auth==1.24.0
-     - google-auth-oauthlib==0.4.2
-     - grpcio==1.35.0
-     - h5py==3.1.0
--    - hydra==2.5
--    - hydra-core==1.0.5
-+    - hydra-core==1.1.0.dev3
-     - icecream==2.1.0
--    - idna==2.10
-     - imagesize==1.2.0
-     - importlib-resources==5.1.0
-     - inflect==5.0.2
-     - iniconfig==1.1.1
--    - ipykernel==5.4.3
--    - ipywidgets==7.6.3
-     - isort==4.3.21
--    - jinja2==2.11.2
-     - jmespath==0.10.0
-     - joblib==1.0.0
--    - jsonschema==3.2.0
--    - jupyter==1.0.0
--    - jupyter-client==6.1.11
--    - jupyter-console==6.2.0
--    - jupyter-core==4.7.0
--    - jupyterlab-pygments==0.1.2
--    - jupyterlab-widgets==1.0.0
-+    - kaggle==1.5.10
-     - kaldi-io==0.9.4
-     - kaldi-python-io==1.2.1
-     - kiwisolver==1.3.1
-     - latexcodec==2.0.1
-     - librosa==0.8.0
-     - llvmlite==0.35.0
--    - markdown==3.3.3
--    - markupsafe==1.1.1
-+    - logging==0.4.9.6
-     - marshmallow==3.10.0
--    - matplotlib==3.3.3
-+    - matplotlib==3.3.4
-     - megatron-lm==1.1.5
--    - mistune==0.8.4
-     - msgpack==1.0.2
--    - multidict==5.1.0
-     - multiprocess==0.70.11.1
--    - nbclient==0.5.1
--    - nbconvert==6.0.7
--    - nbformat==5.1.2
-     - nemo-toolkit==1.0.0b2
--    - nest-asyncio==1.4.3
-     - nltk==3.5
--    - notebook==6.2.0
-     - num2words==0.5.10
-     - numba==0.52.0
-     - oauthlib==3.1.0
-     - objectio==0.2.29
--    - omegaconf==2.0.6
--    - onnx==1.8.0
--    - packaging==20.8
--    - pandocfilters==1.4.3
-+    - omegaconf==2.1.0.dev17
-+    - onnx==1.8.1
-+    - pandas==1.2.1
-     - parameterized==0.8.1
-     - pathspec==0.8.1
-     - pathtools==0.1.2
-@@ -169,52 +245,38 @@ dependencies:
-     - pipreqs==0.4.10
-     - pluggy==0.13.1
-     - pooch==1.3.0
--    - portalocker==2.1.0
--    - prometheus-client==0.9.0
-     - promise==2.3
-     - protobuf==3.14.0
-     - psutil==5.8.0
-     - py==1.10.0
-     - pyarrow==3.0.0
--    - pyasn1==0.4.8
-     - pyasn1-modules==0.2.8
-     - pybind11==2.6.2
-     - pybtex==0.24.0
-     - pybtex-docutils==1.0.0
--    - pycparser==2.20
--    - pydub==0.24.1
--    - pyparsing==2.4.7
-     - pypinyin==0.40.0
--    - pyrsistent==0.17.3
--    - pysocks==1.7.1
-     - pystoi==0.3.3
-     - pytest==6.2.2
-     - pytest-runner==5.2
--    - python-levenshtein==0.12.1
--    - pytorch-lightning==1.1.3
--    - pyyaml==5.4.1
--    - pyzmq==21.0.2
--    - qtconsole==5.0.2
--    - qtpy==1.9.0
-+    - python-slugify==4.0.1
-+    - pytorch-lightning==1.1.5
-+    - pytz==2020.5
-+    - pyyaml==5.3.1
-     - rapidfuzz==0.14.2
-     - regex==2020.11.13
--    - requests==2.25.1
--    - requests-oauthlib==1.3.0
-     - resampy==0.2.2
--    - rsa==4.7
-     - ruamel-yaml==0.16.12
-     - ruamel-yaml-clib==0.2.2
-     - s3transfer==0.3.4
--    - sacrebleu==1.5.0
-     - sacremoses==0.0.43
-     - scikit-learn==0.24.1
-     - scipy==1.6.0
--    - send2trash==1.5.0
-     - sentencepiece==0.1.95
-     - sentry-sdk==0.19.5
-     - shortuuid==1.0.1
-     - simplejson==3.17.2
-     - smmap==3.0.5
-+    - snoop==0.2.5
-     - snowballstemmer==2.1.0
-     - soundfile==0.10.3.post1
-     - sox==1.4.1
-@@ -227,35 +289,24 @@ dependencies:
-     - sphinxcontrib-qthelp==1.0.3
-     - sphinxcontrib-serializinghtml==1.1.4
-     - subprocess32==3.5.4
--    - tensorboard==2.4.1
--    - tensorboard-plugin-wit==1.8.0
--    - terminado==0.9.2
--    - testpath==0.4.4
-+    - tensorboardx==2.1
-+    - text-unidecode==1.3
-     - threadpoolctl==2.1.0
-     - tokenizers==0.9.4
--    - toml==0.10.2
-     - torch==1.7.1
-     - torch-stft==0.1.4
--    - torchtext==0.8.1
-+    - torchtools==0.2.5
-     - torchvision==0.8.2
--    - tornado==6.1
-     - tqdm==4.49.0
-     - transformers==4.2.2
-     - typed-ast==1.4.2
-     - typer==0.3.2
--    - typing-extensions==3.7.4.3
-     - unidecode==1.1.2
--    - urllib3==1.26.3
-     - wandb==0.10.15
-     - watchdog==0.10.4
-     - webdataset==0.1.40
--    - webencodings==0.5.1
--    - werkzeug==1.0.1
-     - wget==3.2
--    - widgetsnbextension==3.5.1
--    - wrapt==1.12.1
-     - xxhash==2.0.0
-     - yarg==0.1.9
--    - yarl==1.6.3
-     - youtokentome==1.0.6
- prefix: /home/nxingyu/miniconda3/envs/NLP
-diff --git a/experiment/config.yaml b/experiment/config.yaml
-index b886b5a..ed040ef 100644
---- a/experiment/config.yaml
-+++ b/experiment/config.yaml
-@@ -43,9 +43,10 @@ log_dir: null
- model:
-     nemo_path: null
-     transformer_path: google/electra-base-discriminator # roberta-base #google/electra-base-discriminator # distilbert-base-uncased # filename to save the model and associated artifacts to .nemo file
--    unfrozen: 1
-+    unfrozen: 0
-     maximum_unfrozen: 3
-     unfreeze_step: 1
-+    test_every_layer: true
-     punct_label_ids:
-         - ""
-         - ","
-@@ -127,12 +128,12 @@ model:
-         # unfrozen_layers: 1
-     
-     punct_head:
--        punct_num_fc_layers: 3
-+        punct_num_fc_layers: 0
-         fc_dropout: 0.1
-         activation: 'gelu'
-         log_softmax: false
-         use_transformer_init: true
--        loss: 'dice'
-+        loss: 'crf'
-         bilstm: false
- 
-     domain_head:
-@@ -144,11 +145,11 @@ model:
-         use_transformer_init: true
-         loss: 'focal'
-         gamma: 1 #0.1 # coefficient of gradient reversal
--        pooling: 'mean_max' # 'mean' mean_max
-+        pooling: 'token' # 'mean' # 'mean_max' # 'token'
-         idx_conditioned_on: 0
-         weight:
--            - 0.6
--            - 0.4
-+            - 0.5
-+            - 0.5
- 
- 
-     dice_loss:
-@@ -160,7 +161,7 @@ model:
-         gamma: 2
- 
-     frozen_lr:
--        # - 1e-2
-+        - 1e-2
-         - 1e-3
-         - 1e-4
-         - 1e-4
-diff --git a/experiment/info.log b/experiment/info.log
-index 5fc3200..a4bbbb5 100644
---- a/experiment/info.log
-+++ b/experiment/info.log
-@@ -1,84 +1,5 @@
-+[INFO] - Global seed set to 42
- [INFO] - GPU available: True, used: True
- [INFO] - TPU available: None, using: 0 TPU cores
--[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
-+[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
- [INFO] - Using native 16bit precision.
--[INFO] - shuffling train set
--[INFO] - initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.001
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7f1f8ee04790>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 3.1 K 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--8.3 M     Trainable params
--101 M     Non-trainable params
--110 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          88.38      37.36      52.51      32611
--! (label_id: 1)                                          0.00       0.00       0.00         10
--# (label_id: 2)                                          1.95      16.57       3.49       1358
--, (label_id: 3)                                          1.59       0.40       0.64        997
--- (label_id: 4)                                          0.24       4.90       0.46        102
--. (label_id: 5)                                          4.48       4.72       4.60        932
--: (label_id: 6)                                          0.04      11.76       0.09         17
--? (label_id: 7)                                          0.00       0.00       0.00         71
--… (label_id: 8)                                          0.00       0.00       0.00          6
---------------------
--micro avg                                               34.52      34.52      34.52      36104
--macro avg                                               10.74       8.41       6.87      36104
--weighted avg                                            80.06      34.52      47.70      36104
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    12182.00         5.00       661.00       447.00        46.00       411.00         8.00        22.00         2.00
--     1145.00         0.00        52.00        48.00        10.00        65.00         1.00         6.00         0.00
--    10705.00         1.00       225.00       312.00        17.00       256.00         6.00        27.00         3.00
--      225.00         0.00        21.00         4.00         0.00         2.00         0.00         0.00         0.00
--     1914.00         0.00       114.00        15.00         5.00         4.00         0.00         1.00         0.00
--      874.00         0.00        20.00        37.00         3.00        44.00         0.00         3.00         1.00
--     4235.00         4.00       128.00       113.00        11.00       135.00         2.00        12.00         0.00
--      193.00         0.00         6.00         1.00         0.00         0.00         0.00         0.00         0.00
--     1138.00         0.00       131.00        20.00        10.00        15.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                         50.65     100.00      67.24        156
--1 (label_id: 1)                                        100.00       2.56       5.00        156
---------------------
--micro avg                                               51.28      51.28      51.28        312
--macro avg                                               75.32      51.28      36.12        312
--weighted avg                                            75.32      51.28      36.12        312
--
---------------------
--           0           1
--      156.00       152.00
--        0.00         4.00
---------------------
--
--[INFO] - Internal process exited
-diff --git a/experiment/main.py b/experiment/main.py
-index 4301a3b..781a18b 100644
---- a/experiment/main.py
-+++ b/experiment/main.py
-@@ -72,6 +72,8 @@ def main(cfg: DictConfig)->None:
-         trainer.current_epoch=0
-         trainer.fit(model)
-         try:
-+            test_trainer = pl.Trainer(gpus=gpu)
-+            test_trainer.test(model,ckpt_path=None)
-             model.unfreeze(cfg.model.unfreeze_step)
-         except:
-             pp('training complete.')
-@@ -81,10 +83,11 @@ def main(cfg: DictConfig)->None:
- 
-     
-     
--    gpu = 1 if cfg.trainer.gpus != 0 else 0
-+    # gpu = 1 if cfg.trainer.gpus != 0 else 0
-     # model.dm.setup('test')
--    trainer = pl.Trainer(gpus=gpu)
--    trainer.test(model,ckpt_path=None)
-+    test_trainer = pl.Trainer(gpus=gpu)
-+    test_trainer.test(model,ckpt_path=None)
-+    
- 
- 
- # @hydra.main(config_name="config.yaml")
-diff --git a/experiment/models/punctuation_domain_model.py b/experiment/models/punctuation_domain_model.py
-index 46322ef..b2fc8c2 100644
---- a/experiment/models/punctuation_domain_model.py
-+++ b/experiment/models/punctuation_domain_model.py
-@@ -353,7 +353,7 @@ class PunctuationDomainModel(pl.LightningModule, Serialization, FileIO):
-         domain_precision, domain_recall, domain_f1, domain_report, domain_cm = self.domain_class_report.compute()
-         logging.info(f'Domain report: {domain_report}')
- 
--        path=f"{self.hparams.log_dir}/test.txt" if self.hparams.log_dir!='' else f'{self.hparams.exp_manager.exp_dir}{self.hparams.exp_manager.name}'
-+        path=f"{self.hparams.log_dir}/test{self.frozen}.txt" if self.hparams.log_dir!='' else f'{self.hparams.exp_manager.exp_dir}{self.hparams.exp_manager.name}'
-         logging.info(f'saving to {path}')
-         with open(path,'w') as f:
-             f.write("Punct report\n")
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/hparams.yaml b/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/hparams.yaml
deleted file mode 100644
index 30c2a4b..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/hparams.yaml
+++ /dev/null
@@ -1,138 +0,0 @@
-seed: 42
-trainer:
-  gpus: 1
-  num_nodes: 1
-  max_epochs: 8
-  max_steps: null
-  accumulate_grad_batches: 4
-  gradient_clip_val: 0
-  amp_level: O1
-  precision: 16
-  accelerator: ddp
-  checkpoint_callback: false
-  logger: false
-  log_every_n_steps: 1
-  val_check_interval: 1.0
-  resume_from_checkpoint: null
-exp_manager:
-  exp_dir: /home/nxingyu/project/
-  name: Punctuation_with_Domain_discriminator
-  create_tensorboard_logger: true
-  create_checkpoint_callback: true
-base_path: /home/nxingyu/data
-tmp_path: /home/nxingyu/data/tmp
-log_dir: /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42
-model:
-  nemo_path: null
-  transformer_path: google/electra-base-discriminator
-  unfrozen: 0
-  maximum_unfrozen: 3
-  unfreeze_step: 1
-  test_every_layer: true
-  punct_label_ids:
-  - ''
-  - ','
-  - .
-  - '?'
-  - '-'
-  - '!'
-  - ':'
-  - …
-  label_map:
-    —: ','
-    ;: .
-  no_space_label: '#'
-  test_chunk_percent: 0.5
-  punct_class_weights: false
-  dataset:
-    data_dir: /home/nxingyu/data
-    labelled:
-    - /home/nxingyu/data/ted_talks_processed
-    unlabelled:
-    - /home/nxingyu/data/switchboardutt_processed
-    max_seq_length: 128
-    pad_label: ''
-    ignore_extra_tokens: false
-    ignore_start_end: false
-    use_cache: false
-    num_workers: 8
-    pin_memory: false
-    drop_last: true
-    num_labels: 9
-    num_domains: 2
-    test_unlabelled: true
-    attach_label_to_end: null
-    pad_start: 0
-    train_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 16
-      manual_len: 20000
-    validation_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 16
-  tokenizer:
-    tokenizer_name: google/electra-base-discriminator
-    vocab_file: null
-    tokenizer_model: null
-    special_tokens: null
-  language_model:
-    pretrained_model_name: google/electra-base-discriminator
-    lm_checkpoint: null
-    config_file: null
-    config: null
-  punct_head:
-    punct_num_fc_layers: 0
-    fc_dropout: 0.1
-    activation: gelu
-    log_softmax: false
-    use_transformer_init: true
-    loss: crf
-    bilstm: false
-  domain_head:
-    predict_labelled: true
-    domain_num_fc_layers: 1
-    fc_dropout: 0.1
-    activation: relu
-    log_softmax: false
-    use_transformer_init: true
-    loss: focal
-    gamma: 1
-    pooling: token
-    idx_conditioned_on: 0
-    weight:
-    - 0.5
-    - 0.5
-  dice_loss:
-    epsilon: 0.01
-    alpha: 2
-    macro_average: true
-  focal_loss:
-    gamma: 2
-  frozen_lr:
-  - 0.01
-  - 0.001
-  - 0.0001
-  - 0.0001
-  - 1.0e-05
-  - 1.0e-07
-  - 1.0e-08
-  gamma:
-  - 1
-  - 1
-  - 1
-  - 1
-  - 1
-  optim:
-    name: adamw
-    lr: 0.01
-    weight_decay: 0.0
-    sched:
-      name: CosineAnnealing
-      warmup_steps: null
-      warmup_ratio: 0.1
-      min_lr: 1.0e-08
-      last_epoch: -1
-      monitor: val_loss
-      reduce_on_plateau: false
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/lightning_logs.txt b/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/lightning_logs.txt
deleted file mode 100644
index 317f675..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/lightning_logs.txt
+++ /dev/null
@@ -1,32 +0,0 @@
-Global seed set to 42
-GPU available: True, used: True
-TPU available: None, using: 0 TPU cores
-LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
-Using native 16bit precision.
-Global seed set to 42
-initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 6.9 K 
-2 | domain_classifier          | SequenceClassifier   | 1.5 K 
-3 | punctuation_loss           | LinearChainCRF       | 99    
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-8.6 K     Trainable params
-108 M     Non-trainable params
-108 M     Total params
-Epoch 0, global step 49: val_loss reached 25.54310 (best 25.54310), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.54-epoch=0.ckpt" as top 3
-Epoch 1, global step 99: val_loss reached 19.05042 (best 19.05042), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/checkpoints/Punctuation_with_Domain_discriminator---val_loss=19.05-epoch=1.ckpt" as top 3
-Epoch 2, global step 149: val_loss reached 17.98836 (best 17.98836), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/checkpoints/Punctuation_with_Domain_discriminator---val_loss=17.99-epoch=2.ckpt" as top 3
-Epoch 3, global step 199: val_loss reached 16.97523 (best 16.97523), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/checkpoints/Punctuation_with_Domain_discriminator---val_loss=16.98-epoch=3.ckpt" as top 3
-Epoch 4, global step 249: val_loss reached 16.87460 (best 16.87460), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/checkpoints/Punctuation_with_Domain_discriminator---val_loss=16.87-epoch=4.ckpt" as top 3
-Epoch 5, global step 299: val_loss reached 16.73402 (best 16.73402), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/checkpoints/Punctuation_with_Domain_discriminator---val_loss=16.73-epoch=5.ckpt" as top 3
-Epoch 6, global step 349: val_loss reached 16.35887 (best 16.35887), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/checkpoints/Punctuation_with_Domain_discriminator---val_loss=16.36-epoch=6.ckpt" as top 3
-Epoch 7, global step 399: val_loss reached 16.44133 (best 16.35887), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/checkpoints/Punctuation_with_Domain_discriminator---val_loss=16.44-epoch=7.ckpt" as top 3
-Saving latest checkpoint...
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/nemo_error_log.txt b/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/nemo_error_log.txt
deleted file mode 100644
index e3ae62c..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/nemo_error_log.txt
+++ /dev/null
@@ -1,31 +0,0 @@
-[NeMo W 2021-03-01 13:26:41 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 13:26:42 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
-[NeMo W 2021-03-01 13:26:53 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 13:26:53 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 13:26:57 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 13:26:57 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 13:26:57 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 13:26:59 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
-      warnings.warn(*args, **kwargs)
-    
-[NeMo W 2021-03-01 13:28:13 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
-      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
-    
-[NeMo W 2021-03-01 13:32:14 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7fbc172a8490> was reported to be 199 (when accessing len(dataloader)), but 200 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-03-01 13:32:53 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7fbc172a80d0> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/nemo_log_globalrank-0_localrank-0.txt b/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/nemo_log_globalrank-0_localrank-0.txt
deleted file mode 100644
index 8d010e1..0000000
--- a/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42/nemo_log_globalrank-0_localrank-0.txt
+++ /dev/null
@@ -1,33 +0,0 @@
-[NeMo W 2021-03-01 13:26:41 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo I 2021-03-01 13:26:42 exp_manager:183] Experiments will be logged at /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_13-26-42
-[NeMo I 2021-03-01 13:26:42 exp_manager:519] TensorboardLogger has been set up
-[NeMo W 2021-03-01 13:26:42 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
-[NeMo W 2021-03-01 13:26:53 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 13:26:53 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 13:26:57 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 13:26:57 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 13:26:57 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-03-01 13:26:59 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
-      warnings.warn(*args, **kwargs)
-    
-[NeMo W 2021-03-01 13:28:13 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
-      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
-    
-[NeMo W 2021-03-01 13:32:14 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7fbc172a8490> was reported to be 199 (when accessing len(dataloader)), but 200 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-03-01 13:32:53 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7fbc172a80d0> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/events.out.tfevents.1614589075.Titan.32294.0 b/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/events.out.tfevents.1614589075.Titan.32294.0
index 516a0fd..57a387b 100644
Binary files a/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/events.out.tfevents.1614589075.Titan.32294.0 and b/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/events.out.tfevents.1614589075.Titan.32294.0 differ
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/lightning_logs.txt b/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/lightning_logs.txt
index baf56de..11a73e3 100644
--- a/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/lightning_logs.txt
+++ b/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/lightning_logs.txt
@@ -21,3 +21,91 @@ initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
 1.2 M     Trainable params
 108 M     Non-trainable params
 110 M     Total params
+Epoch 0, global step 49: val_loss reached 0.71401 (best 0.71401), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.71-epoch=0.ckpt" as top 3
+Epoch 1, global step 99: val_loss reached 0.70701 (best 0.70701), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.71-epoch=1.ckpt" as top 3
+Epoch 2, global step 149: val_loss reached 0.70238 (best 0.70238), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.70-epoch=2.ckpt" as top 3
+Epoch 3, global step 199: val_loss reached 0.70132 (best 0.70132), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.70-epoch=3.ckpt" as top 3
+Epoch 4, global step 249: val_loss reached 0.69949 (best 0.69949), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.70-epoch=4.ckpt" as top 3
+Epoch 5, global step 299: val_loss reached 0.69761 (best 0.69761), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.70-epoch=5.ckpt" as top 3
+Epoch 6, global step 349: val_loss reached 0.69845 (best 0.69761), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.70-epoch=6.ckpt" as top 3
+Epoch 7, global step 399: val_loss reached 0.69638 (best 0.69638), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.70-epoch=7.ckpt" as top 3
+Saving latest checkpoint...
+Global seed set to 42
+
+  | Name                       | Type                 | Params
+--------------------------------------------------------------------
+0 | transformer                | ElectraModel         | 108 M 
+1 | punct_classifier           | TokenClassifier      | 1.2 M 
+2 | domain_classifier          | SequenceClassifier   | 1.5 K 
+3 | punctuation_loss           | FocalDiceLoss        | 0     
+4 | domain_loss                | CrossEntropyLoss     | 0     
+5 | agg_loss                   | AggregatorLoss       | 0     
+6 | punct_class_report         | ClassificationReport | 0     
+7 | chunked_punct_class_report | ClassificationReport | 0     
+8 | domain_class_report        | ClassificationReport | 0     
+--------------------------------------------------------------------
+8.3 M     Trainable params
+101 M     Non-trainable params
+110 M     Total params
+Epoch 0, step 449: val_loss was not in top 3
+Epoch 1, global step 499: val_loss reached 0.69757 (best 0.69638), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.70-epoch=1.ckpt" as top 3
+Epoch 2, global step 549: val_loss reached 0.69678 (best 0.69638), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.70-epoch=2.ckpt" as top 3
+Epoch 3, step 599: val_loss was not in top 3
+Epoch 4, global step 649: val_loss reached 0.69747 (best 0.69638), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.70-epoch=4.ckpt" as top 3
+Epoch 5, global step 699: val_loss reached 0.69663 (best 0.69638), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.70-epoch=5.ckpt" as top 3
+Epoch 6, step 749: val_loss was not in top 3
+Epoch 7, global step 799: val_loss reached 0.69638 (best 0.69638), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.70-epoch=7-v0.ckpt" as top 3
+Global seed set to 42
+
+  | Name                       | Type                 | Params
+--------------------------------------------------------------------
+0 | transformer                | ElectraModel         | 108 M 
+1 | punct_classifier           | TokenClassifier      | 1.2 M 
+2 | domain_classifier          | SequenceClassifier   | 1.5 K 
+3 | punctuation_loss           | FocalDiceLoss        | 0     
+4 | domain_loss                | CrossEntropyLoss     | 0     
+5 | agg_loss                   | AggregatorLoss       | 0     
+6 | punct_class_report         | ClassificationReport | 0     
+7 | chunked_punct_class_report | ClassificationReport | 0     
+8 | domain_class_report        | ClassificationReport | 0     
+--------------------------------------------------------------------
+15.4 M    Trainable params
+94.7 M    Non-trainable params
+110 M     Total params
+Epoch 0, step 849: val_loss was not in top 3
+Epoch 1, step 899: val_loss was not in top 3
+Epoch 2, step 949: val_loss was not in top 3
+Epoch 3, step 999: val_loss was not in top 3
+Epoch 4, step 1049: val_loss was not in top 3
+Epoch 5, global step 1099: val_loss reached 0.69662 (best 0.69638), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.70-epoch=5.ckpt" as top 3
+Epoch 6, step 1149: val_loss was not in top 3
+Epoch 7, global step 1199: val_loss reached 0.69637 (best 0.69637), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.70-epoch=7-v1.ckpt" as top 3
+Global seed set to 42
+
+  | Name                       | Type                 | Params
+--------------------------------------------------------------------
+0 | transformer                | ElectraModel         | 108 M 
+1 | punct_classifier           | TokenClassifier      | 1.2 M 
+2 | domain_classifier          | SequenceClassifier   | 1.5 K 
+3 | punctuation_loss           | FocalDiceLoss        | 0     
+4 | domain_loss                | CrossEntropyLoss     | 0     
+5 | agg_loss                   | AggregatorLoss       | 0     
+6 | punct_class_report         | ClassificationReport | 0     
+7 | chunked_punct_class_report | ClassificationReport | 0     
+8 | domain_class_report        | ClassificationReport | 0     
+--------------------------------------------------------------------
+22.5 M    Trainable params
+87.6 M    Non-trainable params
+110 M     Total params
+Epoch 0, step 1249: val_loss was not in top 3
+Epoch 1, step 1299: val_loss was not in top 3
+Epoch 2, step 1349: val_loss was not in top 3
+Epoch 3, step 1399: val_loss was not in top 3
+Epoch 4, step 1449: val_loss was not in top 3
+Epoch 5, step 1499: val_loss was not in top 3
+Epoch 6, step 1549: val_loss was not in top 3
+Epoch 7, global step 1599: val_loss reached 0.69636 (best 0.69636), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.70-epoch=7.ckpt" as top 3
+GPU available: True, used: True
+TPU available: None, using: 0 TPU cores
+Using environment variable NODE_RANK for node rank (0).
+LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/nemo_error_log.txt b/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/nemo_error_log.txt
index 016ac71..d365b73 100644
--- a/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/nemo_error_log.txt
+++ b/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/nemo_error_log.txt
@@ -17,3 +17,15 @@
 [NeMo W 2021-03-01 16:57:55 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
       warnings.warn(*args, **kwargs)
     
+[NeMo W 2021-03-01 17:03:12 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7fdc261b7670> was reported to be 199 (when accessing len(dataloader)), but 200 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
+      warnings.warn(warn_msg)
+    
+[NeMo W 2021-03-01 17:03:50 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7fdc26215af0> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
+      warnings.warn(warn_msg)
+    
+[NeMo W 2021-03-01 17:44:26 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
+      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
+    
+[NeMo W 2021-03-01 20:01:34 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7fdc261ed190> was reported to be 7 (when accessing len(dataloader)), but 8 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
+      warnings.warn(warn_msg)
+    
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/nemo_log_globalrank-0_localrank-0.txt b/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/nemo_log_globalrank-0_localrank-0.txt
index 4219aef..b027b81 100644
--- a/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/nemo_log_globalrank-0_localrank-0.txt
+++ b/Punctuation_with_Domain_discriminator/2021-03-01_16-57-18/nemo_log_globalrank-0_localrank-0.txt
@@ -19,3 +19,15 @@
 [NeMo W 2021-03-01 16:57:55 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
       warnings.warn(*args, **kwargs)
     
+[NeMo W 2021-03-01 17:03:12 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7fdc261b7670> was reported to be 199 (when accessing len(dataloader)), but 200 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
+      warnings.warn(warn_msg)
+    
+[NeMo W 2021-03-01 17:03:50 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7fdc26215af0> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
+      warnings.warn(warn_msg)
+    
+[NeMo W 2021-03-01 17:44:26 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
+      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
+    
+[NeMo W 2021-03-01 20:01:34 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7fdc261ed190> was reported to be 7 (when accessing len(dataloader)), but 8 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
+      warnings.warn(warn_msg)
+    
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/events.out.tfevents.1614589092.Titan.456.0 b/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/events.out.tfevents.1614589092.Titan.456.0
index 45f68eb..e3751eb 100644
Binary files a/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/events.out.tfevents.1614589092.Titan.456.0 and b/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/events.out.tfevents.1614589092.Titan.456.0 differ
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/hparams.yaml b/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/hparams.yaml
index 98e6fdc..6a5bf34 100644
--- a/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/hparams.yaml
+++ b/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/hparams.yaml
@@ -26,7 +26,7 @@ model:
   nemo_path: null
   transformer_path: google/electra-base-discriminator
   unfrozen: 0
-  maximum_unfrozen: 3
+  maximum_unfrozen: 2
   unfreeze_step: 1
   test_every_layer: true
   punct_label_ids:
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/lightning_logs.txt b/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/lightning_logs.txt
index 6e18bdd..9b35b89 100644
--- a/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/lightning_logs.txt
+++ b/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/lightning_logs.txt
@@ -23,3 +23,89 @@ initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
 110 M     Total params
 Epoch 0, global step 49: val_loss reached 0.64140 (best 0.64140), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.64-epoch=0.ckpt" as top 3
 Epoch 1, global step 99: val_loss reached 0.63818 (best 0.63818), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.64-epoch=1.ckpt" as top 3
+Epoch 2, global step 149: val_loss reached 0.63514 (best 0.63514), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.64-epoch=2.ckpt" as top 3
+Epoch 3, global step 199: val_loss reached 0.62771 (best 0.62771), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.63-epoch=3.ckpt" as top 3
+Epoch 4, global step 249: val_loss reached 0.61773 (best 0.61773), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.62-epoch=4.ckpt" as top 3
+Epoch 5, global step 299: val_loss reached 0.61402 (best 0.61402), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.61-epoch=5.ckpt" as top 3
+Epoch 6, global step 349: val_loss reached 0.61179 (best 0.61179), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.61-epoch=6.ckpt" as top 3
+Epoch 7, global step 399: val_loss reached 0.61222 (best 0.61179), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.61-epoch=7.ckpt" as top 3
+Saving latest checkpoint...
+Global seed set to 42
+
+  | Name                       | Type                 | Params
+--------------------------------------------------------------------
+0 | transformer                | ElectraModel         | 108 M 
+1 | punct_classifier           | TokenClassifier      | 1.2 M 
+2 | domain_classifier          | SequenceClassifier   | 1.5 K 
+3 | punctuation_loss           | FocalDiceLoss        | 0     
+4 | domain_loss                | CrossEntropyLoss     | 0     
+5 | agg_loss                   | AggregatorLoss       | 0     
+6 | punct_class_report         | ClassificationReport | 0     
+7 | chunked_punct_class_report | ClassificationReport | 0     
+8 | domain_class_report        | ClassificationReport | 0     
+--------------------------------------------------------------------
+8.3 M     Trainable params
+101 M     Non-trainable params
+110 M     Total params
+Epoch 0, global step 449: val_loss reached 0.61222 (best 0.61179), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.61-epoch=0.ckpt" as top 3
+Epoch 1, global step 499: val_loss reached 0.61221 (best 0.61179), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.61-epoch=1.ckpt" as top 3
+Epoch 2, step 549: val_loss was not in top 3
+Epoch 3, global step 599: val_loss reached 0.61221 (best 0.61179), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.61-epoch=3.ckpt" as top 3
+Epoch 4, step 649: val_loss was not in top 3
+Epoch 5, global step 699: val_loss reached 0.61221 (best 0.61179), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.61-epoch=5.ckpt" as top 3
+Epoch 6, step 749: val_loss was not in top 3
+Epoch 7, step 799: val_loss was not in top 3
+Global seed set to 42
+
+  | Name                       | Type                 | Params
+--------------------------------------------------------------------
+0 | transformer                | ElectraModel         | 108 M 
+1 | punct_classifier           | TokenClassifier      | 1.2 M 
+2 | domain_classifier          | SequenceClassifier   | 1.5 K 
+3 | punctuation_loss           | FocalDiceLoss        | 0     
+4 | domain_loss                | CrossEntropyLoss     | 0     
+5 | agg_loss                   | AggregatorLoss       | 0     
+6 | punct_class_report         | ClassificationReport | 0     
+7 | chunked_punct_class_report | ClassificationReport | 0     
+8 | domain_class_report        | ClassificationReport | 0     
+--------------------------------------------------------------------
+15.4 M    Trainable params
+94.7 M    Non-trainable params
+110 M     Total params
+Epoch 0, global step 849: val_loss reached 0.61221 (best 0.61179), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.61-epoch=0.ckpt" as top 3
+Epoch 1, global step 899: val_loss reached 0.61221 (best 0.61179), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.61-epoch=1.ckpt" as top 3
+Epoch 2, step 949: val_loss was not in top 3
+Epoch 3, step 999: val_loss was not in top 3
+Epoch 4, global step 1049: val_loss reached 0.61221 (best 0.61179), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.61-epoch=4.ckpt" as top 3
+Epoch 5, step 1099: val_loss was not in top 3
+Epoch 6, global step 1149: val_loss reached 0.61220 (best 0.61179), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.61-epoch=6-v0.ckpt" as top 3
+Epoch 7, step 1199: val_loss was not in top 3
+Global seed set to 42
+
+  | Name                       | Type                 | Params
+--------------------------------------------------------------------
+0 | transformer                | ElectraModel         | 108 M 
+1 | punct_classifier           | TokenClassifier      | 1.2 M 
+2 | domain_classifier          | SequenceClassifier   | 1.5 K 
+3 | punctuation_loss           | FocalDiceLoss        | 0     
+4 | domain_loss                | CrossEntropyLoss     | 0     
+5 | agg_loss                   | AggregatorLoss       | 0     
+6 | punct_class_report         | ClassificationReport | 0     
+7 | chunked_punct_class_report | ClassificationReport | 0     
+8 | domain_class_report        | ClassificationReport | 0     
+--------------------------------------------------------------------
+22.5 M    Trainable params
+87.6 M    Non-trainable params
+110 M     Total params
+Epoch 0, global step 1249: val_loss reached 0.61220 (best 0.61179), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.61-epoch=0.ckpt" as top 3
+Epoch 1, global step 1299: val_loss reached 0.61220 (best 0.61179), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.61-epoch=1.ckpt" as top 3
+Epoch 2, global step 1349: val_loss reached 0.61220 (best 0.61179), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.61-epoch=2.ckpt" as top 3
+Epoch 3, step 1399: val_loss was not in top 3
+Epoch 4, global step 1449: val_loss reached 0.61220 (best 0.61179), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.61-epoch=4.ckpt" as top 3
+Epoch 5, step 1499: val_loss was not in top 3
+Epoch 6, step 1549: val_loss was not in top 3
+Epoch 7, step 1599: val_loss was not in top 3
+GPU available: True, used: True
+TPU available: None, using: 0 TPU cores
+Using environment variable NODE_RANK for node rank (0).
+LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/nemo_error_log.txt b/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/nemo_error_log.txt
index 2dcda6e..9b50ffb 100644
--- a/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/nemo_error_log.txt
+++ b/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/nemo_error_log.txt
@@ -23,3 +23,9 @@
 [NeMo W 2021-03-01 17:00:12 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f49032de070> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
       warnings.warn(warn_msg)
     
+[NeMo W 2021-03-01 17:15:15 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
+      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
+    
+[NeMo W 2021-03-01 18:15:41 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f4903206070> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
+      warnings.warn(warn_msg)
+    
diff --git a/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/nemo_log_globalrank-0_localrank-0.txt b/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/nemo_log_globalrank-0_localrank-0.txt
index 598010e..fd59023 100644
--- a/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/nemo_log_globalrank-0_localrank-0.txt
+++ b/Punctuation_with_Domain_discriminator/2021-03-01_16-57-32/nemo_log_globalrank-0_localrank-0.txt
@@ -25,3 +25,9 @@
 [NeMo W 2021-03-01 17:00:12 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f49032de070> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
       warnings.warn(warn_msg)
     
+[NeMo W 2021-03-01 17:15:15 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
+      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
+    
+[NeMo W 2021-03-01 18:15:41 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f4903206070> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
+      warnings.warn(warn_msg)
+    
diff --git a/experiment/config.yaml b/experiment/config.yaml
index 7bc9ccd..dbb6e41 100644
--- a/experiment/config.yaml
+++ b/experiment/config.yaml
@@ -72,7 +72,7 @@ model:
         
     no_space_label: '#'
     test_chunk_percent: 0.5
-    punct_class_weight_factor: 0.2
+    punct_class_weight_factor: 0
     punct_class_weights:  #0 if don't weight
     
     dataset:
@@ -129,7 +129,7 @@ model:
         # unfrozen_layers: 1
     
     punct_head:
-        punct_num_fc_layers: 2
+        punct_num_fc_layers: 3
         fc_dropout: 0.1
         activation: 'gelu'
         log_softmax: false
@@ -155,7 +155,7 @@ model:
 
     dice_loss:
         epsilon: 0.01
-        alpha: 8
+        alpha: 5
         macro_average: true
 
     focal_loss: 
diff --git a/experiment/info.log b/experiment/info.log
index 648698d..a4bbbb5 100644
--- a/experiment/info.log
+++ b/experiment/info.log
@@ -3,1533 +3,3 @@
 [INFO] - TPU available: None, using: 0 TPU cores
 [INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
 [INFO] - Using native 16bit precision.
-[INFO] - shuffling train set
-[INFO] - Global seed set to 42
-[INFO] - initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
-[INFO] - Optimizer config = AdamW (
-Parameter Group 0
-    amsgrad: False
-    betas: (0.9, 0.999)
-    eps: 1e-08
-    lr: 0.01
-    weight_decay: 0.0
-)
-[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7f6d33474d60>" 
-will be used during training (effective maximum steps = 104) - 
-Parameters : 
-(warmup_steps: null
-warmup_ratio: 0.1
-min_lr: 1.0e-08
-last_epoch: -1
-max_steps: 104
-)
-[INFO] - 
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 1.2 M 
-2 | domain_classifier          | SequenceClassifier   | 1.5 K 
-3 | punctuation_loss           | FocalDiceLoss        | 0     
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-1.2 M     Trainable params
-108 M     Non-trainable params
-110 M     Total params
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          60.00       0.72       1.43      16566
-# (label_id: 1)                                          0.00       0.00       0.00       1458
-, (label_id: 2)                                          5.91      86.94      11.07       1210
-. (label_id: 3)                                          0.00       0.00       0.00       1008
-? (label_id: 4)                                          0.53      14.63       1.02         82
--------------------
-micro avg                                                5.83       5.83       5.83      20324
-macro avg                                               13.29      20.46       2.70      20324
-weighted avg                                            49.26       5.83       1.83      20324
-
--------------------
-                       #           ,           .           ?
-      120.00        34.00        16.00        28.00         2.00
-       16.00         0.00         2.00        12.00         0.00
-    14720.00      1112.00      1052.00       852.00        68.00
-        6.00         0.00         2.00         0.00         0.00
-     1704.00       312.00       138.00       116.00        12.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00      33.33      50.00        174
--------------------
-micro avg                                               33.33      33.33      33.33        174
-macro avg                                               50.00      16.67      25.00        174
-weighted avg                                           100.00      33.33      50.00        174
-
--------------------
-           0           1
-        0.00       116.00
-        0.00        58.00
--------------------
-
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          80.97      99.92      89.45     279905
-# (label_id: 1)                                         98.08      23.85      38.37      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               81.29      81.29      81.29     352541
-macro avg                                               35.81      24.75      25.56     352541
-weighted avg                                            72.33      81.29      74.17     352541
-
--------------------
-                       #           ,           .           ?
-   279673.00     21989.00     24171.00     18071.00      1490.00
-      135.00      6890.00         0.00         0.00         0.00
-       24.00         0.00         0.00         0.00         0.00
-        0.00         1.00         0.00         0.00         0.00
-       73.00         8.00        16.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 0, global step 12: val_loss reached 124.04999 (best 124.04999), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=124.05-epoch=0.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.44      99.41      90.73     279905
-# (label_id: 1)                                         90.89      60.01      72.29      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.85      83.85      83.85     352541
-macro avg                                               34.87      31.88      32.60     352541
-weighted avg                                            73.70      83.85      77.96     352541
-
--------------------
-                       #           ,           .           ?
-   278253.00     11553.00     24110.00     18063.00      1490.00
-     1652.00     17335.00        77.00         8.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 1, global step 25: val_loss reached 108.24886 (best 108.24886), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=108.25-epoch=1.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.23      99.86      90.79     279905
-# (label_id: 1)                                         97.42      56.30      71.36      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.90      83.90      83.90     352541
-macro avg                                               36.13      31.23      32.43     352541
-weighted avg                                            74.06      83.90      77.93     352541
-
--------------------
-                       #           ,           .           ?
-   279519.00     12624.00     24142.00     18071.00      1490.00
-      386.00     16264.00        45.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 2, global step 38: val_loss reached 97.27077 (best 97.27077), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=97.27-epoch=2.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.36      99.92      90.90     279905
-# (label_id: 1)                                         98.25      57.93      72.89      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               84.08      84.08      84.08     352541
-macro avg                                               36.32      31.57      32.76     352541
-weighted avg                                            74.24      84.08      78.14     352541
-
--------------------
-                       #           ,           .           ?
-   279695.00     12152.00     24126.00     18044.00      1490.00
-      210.00     16736.00        61.00        27.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 3, global step 51: val_loss reached 90.53589 (best 90.53589), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=90.54-epoch=3.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.34      99.96      90.89     279905
-# (label_id: 1)                                         98.71      57.47      72.64      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               84.07      84.07      84.07     352541
-macro avg                                               36.41      31.48      32.71     352541
-weighted avg                                            74.26      84.07      78.12     352541
-
--------------------
-                       #           ,           .           ?
-   279784.00     12287.00     24126.00     18036.00      1490.00
-      121.00     16601.00        61.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 4, global step 64: val_loss reached 86.89617 (best 86.89617), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=86.90-epoch=4.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.30      99.94      90.86     279905
-# (label_id: 1)                                         98.41      56.92      72.12      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               84.01      84.01      84.01     352541
-macro avg                                               36.34      31.37      32.60     352541
-weighted avg                                            74.20      84.01      78.05     352541
-
--------------------
-                       #           ,           .           ?
-   279736.00     12445.00     24126.00     18036.00      1490.00
-      169.00     16443.00        61.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 5, global step 77: val_loss reached 85.16472 (best 85.16472), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=85.16-epoch=5.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.39      56.24      71.57      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12641.00     24126.00     18036.00      1490.00
-      170.00     16247.00        61.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 6, global step 90: val_loss reached 84.53021 (best 84.53021), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.53-epoch=6.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.24      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.19      71.53      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.95      83.95      83.95     352541
-macro avg                                               36.32      31.23      32.47     352541
-weighted avg                                            74.15      83.95      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12656.00     24124.00     18036.00      1490.00
-      170.00     16232.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 7, global step 103: val_loss reached 84.43227 (best 84.43227), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.43-epoch=7.ckpt" as top 3
-[INFO] - Saving latest checkpoint...
-[INFO] - Global seed set to 42
-[INFO] - Optimizer config = AdamW (
-Parameter Group 0
-    amsgrad: False
-    betas: (0.9, 0.999)
-    eps: 1e-08
-    lr: 0.001
-    weight_decay: 0.0
-)
-[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7f49f5b88520>" 
-will be used during training (effective maximum steps = 104) - 
-Parameters : 
-(warmup_steps: null
-warmup_ratio: 0.1
-min_lr: 1.0e-08
-last_epoch: -1
-max_steps: 104
-)
-[INFO] - 
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 3.8 K 
-2 | domain_classifier          | SequenceClassifier   | 3.1 K 
-3 | punctuation_loss           | LinearChainCRF       | 35    
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-7.1 M     Trainable params
-101 M     Non-trainable params
-108 M     Total params
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          84.74      99.96      91.72      16566
-# (label_id: 1)                                         98.72      52.95      68.93       1458
-, (label_id: 2)                                          0.00       0.00       0.00       1210
-. (label_id: 3)                                          0.00       0.00       0.00       1008
-? (label_id: 4)                                          0.00       0.00       0.00         82
--------------------
-micro avg                                               85.28      85.28      85.28      20324
-macro avg                                               36.69      30.58      32.13      20324
-weighted avg                                            76.15      85.28      79.71      20324
-
--------------------
-                       #           ,           .           ?
-    16560.00       686.00      1208.00      1006.00        82.00
-        6.00       772.00         2.00         2.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00        174
--------------------
-micro avg                                              100.00     100.00     100.00        174
-macro avg                                               50.00      50.00      50.00        174
-weighted avg                                           100.00     100.00     100.00        174
-
--------------------
-           0           1
-        0.00         0.00
-        0.00       174.00
--------------------
-
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.24      71.57      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12640.00     24124.00     18036.00      1490.00
-      170.00     16248.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 0, global step 116: val_loss reached 84.43176 (best 84.43176), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.43-epoch=0.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.24      71.57      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12640.00     24124.00     18036.00      1490.00
-      170.00     16248.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 1, global step 129: val_loss reached 84.43138 (best 84.43138), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.43-epoch=1.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.24      71.57      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12640.00     24124.00     18036.00      1490.00
-      170.00     16248.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 2, global step 142: val_loss reached 84.43092 (best 84.43092), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.43-epoch=2.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.24      71.57      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12640.00     24124.00     18036.00      1490.00
-      170.00     16248.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 3, global step 155: val_loss reached 84.43053 (best 84.43053), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.43-epoch=3.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.24      71.57      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12640.00     24124.00     18036.00      1490.00
-      170.00     16248.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 4, global step 168: val_loss reached 84.43011 (best 84.43011), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.43-epoch=4.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.24      71.57      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12640.00     24124.00     18036.00      1490.00
-      170.00     16248.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 5, global step 181: val_loss reached 84.42976 (best 84.42976), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.43-epoch=5.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.24      71.57      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12640.00     24124.00     18036.00      1490.00
-      170.00     16248.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 6, global step 194: val_loss reached 84.42931 (best 84.42931), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.43-epoch=6.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.24      71.57      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12640.00     24124.00     18036.00      1490.00
-      170.00     16248.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 7, global step 207: val_loss reached 84.42889 (best 84.42889), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.43-epoch=7.ckpt" as top 3
-[INFO] - Global seed set to 42
-[INFO] - Optimizer config = AdamW (
-Parameter Group 0
-    amsgrad: False
-    betas: (0.9, 0.999)
-    eps: 1e-08
-    lr: 0.0001
-    weight_decay: 0.0
-)
-[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7f49f5bf2d30>" 
-will be used during training (effective maximum steps = 104) - 
-Parameters : 
-(warmup_steps: null
-warmup_ratio: 0.1
-min_lr: 1.0e-08
-last_epoch: -1
-max_steps: 104
-)
-[INFO] - 
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 3.8 K 
-2 | domain_classifier          | SequenceClassifier   | 3.1 K 
-3 | punctuation_loss           | LinearChainCRF       | 35    
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-14.2 M    Trainable params
-94.7 M    Non-trainable params
-108 M     Total params
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          84.74      99.96      91.72      16566
-# (label_id: 1)                                         98.72      52.95      68.93       1458
-, (label_id: 2)                                          0.00       0.00       0.00       1210
-. (label_id: 3)                                          0.00       0.00       0.00       1008
-? (label_id: 4)                                          0.00       0.00       0.00         82
--------------------
-micro avg                                               85.28      85.28      85.28      20324
-macro avg                                               36.69      30.58      32.13      20324
-weighted avg                                            76.15      85.28      79.71      20324
-
--------------------
-                       #           ,           .           ?
-    16560.00       686.00      1208.00      1006.00        82.00
-        6.00       772.00         2.00         2.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00        174
--------------------
-micro avg                                              100.00     100.00     100.00        174
-macro avg                                               50.00      50.00      50.00        174
-weighted avg                                           100.00     100.00     100.00        174
-
--------------------
-           0           1
-        0.00         0.00
-        0.00       174.00
--------------------
-
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.24      71.57      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12640.00     24124.00     18036.00      1490.00
-      170.00     16248.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 0, global step 220: val_loss reached 84.42802 (best 84.42802), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.43-epoch=0.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.24      71.57      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12640.00     24124.00     18036.00      1490.00
-      170.00     16248.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 1, global step 233: val_loss reached 84.42709 (best 84.42709), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.43-epoch=1.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.24      71.57      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12640.00     24124.00     18036.00      1490.00
-      170.00     16248.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 2, global step 246: val_loss reached 84.42627 (best 84.42627), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.43-epoch=2.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.24      71.57      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12640.00     24124.00     18036.00      1490.00
-      170.00     16248.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 3, global step 259: val_loss reached 84.42544 (best 84.42544), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.43-epoch=3.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.24      71.57      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12640.00     24124.00     18036.00      1490.00
-      170.00     16248.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 4, global step 272: val_loss reached 84.42443 (best 84.42443), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.42-epoch=4.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.25      71.58      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12638.00     24124.00     18036.00      1490.00
-      170.00     16250.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 5, global step 285: val_loss reached 84.42360 (best 84.42360), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.42-epoch=5.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.25      71.58      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12638.00     24124.00     18036.00      1490.00
-      170.00     16250.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 6, global step 298: val_loss reached 84.42275 (best 84.42275), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.42-epoch=6.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.25      71.58      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12638.00     24124.00     18036.00      1490.00
-      170.00     16250.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 7, global step 311: val_loss reached 84.42195 (best 84.42195), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.42-epoch=7.ckpt" as top 3
-[INFO] - Global seed set to 42
-[INFO] - Optimizer config = AdamW (
-Parameter Group 0
-    amsgrad: False
-    betas: (0.9, 0.999)
-    eps: 1e-08
-    lr: 0.0001
-    weight_decay: 0.0
-)
-[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7f4a4c64f070>" 
-will be used during training (effective maximum steps = 104) - 
-Parameters : 
-(warmup_steps: null
-warmup_ratio: 0.1
-min_lr: 1.0e-08
-last_epoch: -1
-max_steps: 104
-)
-[INFO] - 
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 3.8 K 
-2 | domain_classifier          | SequenceClassifier   | 3.1 K 
-3 | punctuation_loss           | LinearChainCRF       | 35    
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-21.3 M    Trainable params
-87.6 M    Non-trainable params
-108 M     Total params
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          84.74      99.96      91.72      16566
-# (label_id: 1)                                         98.72      52.95      68.93       1458
-, (label_id: 2)                                          0.00       0.00       0.00       1210
-. (label_id: 3)                                          0.00       0.00       0.00       1008
-? (label_id: 4)                                          0.00       0.00       0.00         82
--------------------
-micro avg                                               85.28      85.28      85.28      20324
-macro avg                                               36.69      30.58      32.13      20324
-weighted avg                                            76.15      85.28      79.71      20324
-
--------------------
-                       #           ,           .           ?
-    16560.00       686.00      1208.00      1006.00        82.00
-        6.00       772.00         2.00         2.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00        174
--------------------
-micro avg                                              100.00     100.00     100.00        174
-macro avg                                               50.00      50.00      50.00        174
-weighted avg                                           100.00     100.00     100.00        174
-
--------------------
-           0           1
-        0.00         0.00
-        0.00       174.00
--------------------
-
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.25      71.58      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12638.00     24124.00     18036.00      1490.00
-      170.00     16250.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 0, global step 324: val_loss reached 84.42070 (best 84.42070), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.42-epoch=0.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.25      71.58      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12638.00     24124.00     18036.00      1490.00
-      170.00     16250.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 1, global step 337: val_loss reached 84.41957 (best 84.41957), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.42-epoch=1.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.25      71.58      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12638.00     24124.00     18036.00      1490.00
-      170.00     16250.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 2, global step 350: val_loss reached 84.41832 (best 84.41832), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.42-epoch=2.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.25      71.58      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12638.00     24124.00     18036.00      1490.00
-      170.00     16250.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 3, global step 363: val_loss reached 84.41717 (best 84.41717), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.42-epoch=3.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.25      71.58      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12638.00     24124.00     18036.00      1490.00
-      170.00     16250.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 4, global step 376: val_loss reached 84.41608 (best 84.41608), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.42-epoch=4.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.25      71.58      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12638.00     24124.00     18036.00      1490.00
-      170.00     16250.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 5, global step 389: val_loss reached 84.41490 (best 84.41490), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.41-epoch=5.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.83     279905
-# (label_id: 1)                                         98.38      56.25      71.58      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.24      32.48     352541
-weighted avg                                            74.16      83.96      77.98     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12638.00     24124.00     18036.00      1490.00
-      170.00     16250.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 6, global step 402: val_loss reached 84.41369 (best 84.41369), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.41-epoch=6.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          83.25      99.94      90.84     279905
-# (label_id: 1)                                         98.38      56.31      71.62      28888
-, (label_id: 2)                                          0.00       0.00       0.00      24187
-. (label_id: 3)                                          0.00       0.00       0.00      18071
-? (label_id: 4)                                          0.00       0.00       0.00       1490
--------------------
-micro avg                                               83.96      83.96      83.96     352541
-macro avg                                               36.33      31.25      32.49     352541
-weighted avg                                            74.16      83.96      77.99     352541
-
--------------------
-                       #           ,           .           ?
-   279735.00     12622.00     24124.00     18036.00      1490.00
-      170.00     16266.00        63.00        35.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       2968
--------------------
-micro avg                                              100.00     100.00     100.00       2968
-macro avg                                               50.00      50.00      50.00       2968
-weighted avg                                           100.00     100.00     100.00       2968
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      2968.00
--------------------
-
-[INFO] - Epoch 7, global step 415: val_loss reached 84.41257 (best 84.41257), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/checkpoints/Punctuation_with_Domain_discriminator---val_loss=84.41-epoch=7.ckpt" as top 3
-[INFO] - GPU available: True, used: True
-[INFO] - TPU available: None, using: 0 TPU cores
-[INFO] - Using environment variable NODE_RANK for node rank (0).
-[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          82.88      99.95      90.62     340743
-# (label_id: 1)                                         98.76      57.86      72.97      35925
-, (label_id: 2)                                          0.00       0.00       0.00      28478
-. (label_id: 3)                                          0.00       0.00       0.00      24981
-? (label_id: 4)                                          0.00       0.00       0.00       1869
--------------------
-micro avg                                               83.65      83.65      83.65     431996
-macro avg                                               36.33      31.56      32.72     431996
-weighted avg                                            73.58      83.65      77.54     431996
-
--------------------
-                       #           ,           .           ?
-   340577.00     15137.00     28437.00     24935.00      1861.00
-      166.00     20788.00        41.00        46.00         8.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Chunked Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          82.71      99.94      90.51     170805
-# (label_id: 1)                                         98.67      58.55      73.49      18619
-, (label_id: 2)                                          0.00       0.00       0.00      14415
-. (label_id: 3)                                          0.00       0.00       0.00      12723
-? (label_id: 4)                                          0.00       0.00       0.00        881
--------------------
-micro avg                                               83.52      83.52      83.52     217443
-macro avg                                               36.28      31.70      32.80     217443
-weighted avg                                            73.42      83.52      77.39     217443
-
--------------------
-                       #           ,           .           ?
-   170708.00      7717.00     14383.00     12705.00       881.00
-       97.00     10902.00        32.00        18.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
-        0.00         0.00         0.00         0.00         0.00
--------------------
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                          0.00       0.00       0.00          0
-1 (label_id: 1)                                        100.00     100.00     100.00       3595
--------------------
-micro avg                                              100.00     100.00     100.00       3595
-macro avg                                               50.00      50.00      50.00       3595
-weighted avg                                           100.00     100.00     100.00       3595
-
--------------------
-           0           1
-        0.00         0.00
-        0.00      3595.00
--------------------
-
-[INFO] - saving to /home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-03-01_21-33-33/test-ted-8.txt
-[INFO] - Internal process exited
diff --git a/experiment/testing.py b/experiment/testing.py
index f10db0f..cd7929e 100644
--- a/experiment/testing.py
+++ b/experiment/testing.py
@@ -22,7 +22,7 @@ import atexit
 from copy import deepcopy
 import snoop
 snoop.install()
-exp='2021-03-02_08-46-23'
+exp='2021-03-02_10-34-43'
 @hydra.main(config_path=f"../Punctuation_with_Domain_discriminator/{exp}/",config_name="hparams.yaml")
 def main(cfg : DictConfig) -> None:
     torch.set_printoptions(sci_mode=False)
@@ -45,8 +45,8 @@ def main(cfg : DictConfig) -> None:
                     max_seq_length=model.dm.max_seq_length,
                     punct_label_ids=model.dm.punct_label_ids,
                     label_map=model.dm.label_map,
-                    labelled=['/home/nxingyu/data/switchboardutt_processed'],
-                    # labelled=['/home/nxingyu2/data/open_subtitles_processed'],
+                    # labelled=['/home/nxingyu/data/switchboardutt_processed'],
+                    labelled=['/home/nxingyu/data/open_subtitles_processed'],
                     # labelled=['/home/nxingyu2/data/ted_talks_processed'], #jointteduttdice32acc4bs16
                     unlabelled=[],
                     tokenizer=model.dm.tokenizer,
