commit hash: ed7303d1e763178a0ec2d13f917d7de6c8553488
diff --git a/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/events.out.tfevents.1612493730.intern-instance.20106.0 b/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/events.out.tfevents.1612493730.intern-instance.20106.0
index af71914..25acd93 100644
Binary files a/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/events.out.tfevents.1612493730.intern-instance.20106.0 and b/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/events.out.tfevents.1612493730.intern-instance.20106.0 differ
diff --git a/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/lightning_logs.txt b/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/lightning_logs.txt
index 95f4866..756258b 100644
--- a/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/lightning_logs.txt
+++ b/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/lightning_logs.txt
@@ -35,3 +35,8 @@ Epoch 1, global step 100: val_loss reached 0.71243 (best 0.71243), saving model
 Epoch 2, global step 200: val_loss reached 0.60420 (best 0.60420), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.60-epoch=2.ckpt" as top 3
 Epoch 3, global step 300: val_loss reached 0.54977 (best 0.54977), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.55-epoch=3.ckpt" as top 3
 Epoch 4, global step 400: val_loss reached 0.58447 (best 0.54977), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.58-epoch=4.ckpt" as top 3
+Epoch 5, global step 500: val_loss reached 0.58260 (best 0.54977), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.58-epoch=5.ckpt" as top 3
+Epoch 6, global step 600: val_loss reached 0.53657 (best 0.53657), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.54-epoch=6.ckpt" as top 3
+Epoch 7, global step 700: val_loss reached 0.56844 (best 0.53657), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.57-epoch=7.ckpt" as top 3
+GPU available: True, used: False
+TPU available: None, using: 0 TPU cores
diff --git a/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/nemo_error_log.txt b/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/nemo_error_log.txt
index 7732b8a..e6499a0 100644
--- a/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/nemo_error_log.txt
+++ b/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/nemo_error_log.txt
@@ -17,3 +17,12 @@
 [NeMo W 2021-02-05 11:08:35 nemo_logging:349] /home/nxingyu2/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset.PunctuationDomainDatasets object at 0x7f1b0f34d5b0> was reported to be 49 (when accessing len(dataloader)), but 50 samples have been fetched. 
       warnings.warn(warn_msg)
     
+[NeMo W 2021-02-05 12:25:44 nemo_logging:349] /home/nxingyu2/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.
+      warnings.warn(*args, **kwargs)
+    
+[NeMo W 2021-02-05 12:25:44 nemo_logging:349] /home/nxingyu2/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
+      warnings.warn(*args, **kwargs)
+    
+[NeMo W 2021-02-05 12:26:20 nemo_logging:349] /home/nxingyu2/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset.PunctuationDomainDatasets object at 0x7f1b0f34d130> was reported to be 50 (when accessing len(dataloader)), but 51 samples have been fetched. 
+      warnings.warn(warn_msg)
+    
diff --git a/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/nemo_log_globalrank-0_localrank-0.txt b/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/nemo_log_globalrank-0_localrank-0.txt
index cb6d529..e5bb9e8 100644
--- a/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/nemo_log_globalrank-0_localrank-0.txt
+++ b/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/nemo_log_globalrank-0_localrank-0.txt
@@ -19,3 +19,12 @@
 [NeMo W 2021-02-05 11:08:35 nemo_logging:349] /home/nxingyu2/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset.PunctuationDomainDatasets object at 0x7f1b0f34d5b0> was reported to be 49 (when accessing len(dataloader)), but 50 samples have been fetched. 
       warnings.warn(warn_msg)
     
+[NeMo W 2021-02-05 12:25:44 nemo_logging:349] /home/nxingyu2/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.
+      warnings.warn(*args, **kwargs)
+    
+[NeMo W 2021-02-05 12:25:44 nemo_logging:349] /home/nxingyu2/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
+      warnings.warn(*args, **kwargs)
+    
+[NeMo W 2021-02-05 12:26:20 nemo_logging:349] /home/nxingyu2/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset.PunctuationDomainDatasets object at 0x7f1b0f34d130> was reported to be 50 (when accessing len(dataloader)), but 51 samples have been fetched. 
+      warnings.warn(warn_msg)
+    
diff --git a/README.md b/README.md
index ca7075a..1f40c55 100644
--- a/README.md
+++ b/README.md
@@ -182,4 +182,100 @@ label                                                precision    recall       f
 Electra small cel weighted ted l 1 unfrozen 0.0031622776 lr adamw accgrad4 bs8
 
 
+### elsmall dice alpha 4 weighted ted-l unfrozen 0.003162277660 lr adamw accgrad4 bbs8
+
+label                 |   precision  |  recall |    f1    |      support
+---|---|---|---|---
+ (label_id: 0)        |      79.50   |   29.94 |   43.50  |    5026
+! (label_id: 1)       |       6.84   |   20.59 |   10.27  |     102
+, (label_id: 2)       |      50.70   |   60.09 |   55.00  |   17571
+- (label_id: 3)       |      64.45   |   82.11 |   72.22  |    1526
+. (label_id: 4)       |      57.40   |   49.43 |   53.12  |   14767
+: (label_id: 5)       |      17.86   |   31.83 |   22.89  |     289
+; (label_id: 6)       |       1.50   |    5.88 |    2.39  |      85
+? (label_id: 7)       |      37.02   |   61.32 |   46.17  |    1228
+— (label_id: 8)       |       6.44   |    7.34 |    6.86  |     763
+… (label_id: 9)       |       0.00   |    0.00 |    0.00  |      80
+-------------------||||
+micro avg             |      51.99   |   51.99 |   51.99  |   41437
+macro avg             |      32.17   |   34.85 |   31.24  |   41437
+weighted avg          |      55.33   |   51.99 |   51.87  |   41437
+
+{'punct_f1': tensor(31.2411),
+ 'punct_precision': tensor(32.1728),
+ 'punct_recall': tensor(34.8539),
+ 'test_loss': tensor(0.6303)}
+
+
+### elsmall dice alpha 1 weighted ted-l unfrozen 0.007943282347 lr adamw accgrad4 bbs7
+
+label                 |   precision  |  recall |    f1    |      support
+---|---|---|---|---
+ (label_id: 0)             |     0.00  |  0.00 |   0.00  |  5026
+! (label_id: 1)            |     0.00  |  0.00 |   0.00  |   102
+, (label_id: 2)            |    42.79  | 47.54 |  45.04  | 17571
+- (label_id: 3)            |    73.63  | 80.87 |  77.08  |  1526
+. (label_id: 4)            |    47.36  | 55.16 |  50.96  | 14767
+: (label_id: 5)            |    10.88  | 27.68 |  15.62  |   289
+; (label_id: 6)            |     0.00  |  0.00 |   0.00  |    85
+? (label_id: 7)            |    43.18  | 60.10 |  50.26  |  1228
+— (label_id: 8)            |     3.03  |  2.36 |   2.65  |   763
+… (label_id: 9)            |     0.00  |  0.00 |   0.00  |    80
+-------------------||||
+micro avg                  |    44.81  | 44.81 |  44.81  | 41437
+macro avg                  |    22.09  | 27.37 |  24.16  | 41437
+weighted avg               |    39.14  | 44.81 |  41.75  | 41437
+
+{'punct_f1': tensor(24.1611),
+ 'punct_precision': tensor(22.0869),
+ 'punct_recall': tensor(27.3705),
+ 'test_loss': tensor(0.4047)}
+
+
+### elsmall crf ted-l unfrozen 0.005011872336272719 lr adamw accgrad4 bbs8
+
+label                  |  precision | recall |   f1   |     support
+---|---|---|---|---
+ (label_id: 0)         |     59.35  |  52.35 |  55.63 |   7314
+! (label_id: 1)        |      0.00  |   0.00 |   0.00 |    154
+, (label_id: 2)        |     44.15  |  82.80 |  57.59 |  28180
+- (label_id: 3)        |      3.91  |   2.02 |   2.66 |   1933
+. (label_id: 4)        |     39.91  |  11.64 |  18.02 |  24624
+: (label_id: 5)        |      0.00  |   0.00 |   0.00 |    522
+; (label_id: 6)        |      0.00  |   0.00 |   0.00 |    485
+? (label_id: 7)        |      0.00  |   0.00 |   0.00 |   2096
+— (label_id: 8)        |      0.00  |   0.00 |   0.00 |   2055
+… (label_id: 9)        |      0.00  |   0.00 |   0.00 |    123
+-------------------||||
+micro avg              |     44.55  |  44.55 |  44.55 |  67486
+macro avg              |     14.73  |  14.88 |  13.39 |  67486
+weighted avg           |     39.54  |  44.55 |  36.73 |  67486
+
+{'punct_f1': 13.390362739562988,
+ 'punct_precision': 14.73101806640625,
+ 'punct_recall': 14.881169319152832,
+ 'test_loss': 11.328206062316895}
+
+### elsmall dice alpha 3 no weight ted-l unfrozen 0.005011872336272719 lr adamw accgrad4 bbs8
+label                |  precision | recall |   f1   |    support
+---|---|---|---|---
+ (label_id: 0)       |  62.32   | 99.78 |  76.72  |   7314
+! (label_id: 1)      |   0.00   |  0.00 |   0.00  |    154
+, (label_id: 2)      |  49.81   |  4.72 |   8.62  |  28180
+- (label_id: 3)      |   5.91   | 28.35 |   9.78  |   1933
+. (label_id: 4)      |  41.80   | 52.40 |  46.50  |  24624
+: (label_id: 5)      |   0.94   |  4.02 |   1.53  |    522
+; (label_id: 6)      |   0.00   |  0.00 |   0.00  |    485
+? (label_id: 7)      |   4.92   | 24.86 |   8.22  |   2096
+— (label_id: 8)      |   0.00   |  0.00 |   0.00  |   2055
+… (label_id: 9)      |   0.00   |  0.00 |   0.00  |    123
+-------------------||||
+micro avg            |  33.52   | 33.52 |  33.52  |  67486
+macro avg            |  16.57   | 21.41 |  15.14  |  67486
+weighted avg         |  43.14   | 33.52 |  29.43  |  67486
+
+'punct_f1': 15.136445999145508,
+ 'punct_precision': 16.57059097290039,
+ 'punct_recall': 21.41229820251465,
+ 'test_loss': 0.6608337163925171}
 
diff --git a/experiment/config.yaml b/experiment/config.yaml
index 7417f08..4e38aa0 100644
--- a/experiment/config.yaml
+++ b/experiment/config.yaml
@@ -41,7 +41,7 @@ tmp_path: /home/nxingyu2/data/tmp # /tmp #
 model:
     nemo_path: null
     transformer_path: google/electra-small-discriminator # distilbert-base-uncased #  filename to save the model and associated artifacts to .nemo file
-    initial_unfrozen: 1
+    initial_unfrozen: 0
     punct_label_ids:
         - ""
         - "!"
@@ -108,7 +108,7 @@ model:
         activation: 'relu'
         log_softmax: false
         use_transformer_init: true
-        loss: 'dice'
+        loss: 'crf'
 
     domain_head:
         domain_num_fc_layers: 1
@@ -121,7 +121,7 @@ model:
     
     dice_loss:
         epsilon: 0.01
-        alpha: 4
+        alpha: 1
         macro_average: true
 
     focal_loss: 
diff --git a/experiment/info.log b/experiment/info.log
index ccfd4ae..5024c4f 100644
--- a/experiment/info.log
+++ b/experiment/info.log
@@ -1,220 +1,2 @@
 [INFO] - GPU available: True, used: False
 [INFO] - TPU available: None, using: 0 TPU cores
-[INFO] - shuffling train set
-[INFO] - Optimizer config = AdamW (
-Parameter Group 0
-    amsgrad: False
-    betas: (0.9, 0.999)
-    eps: 1e-08
-    lr: 0.001
-    weight_decay: 0.0
-)
-[INFO] - Scheduler "<core.optim.lr_scheduler.WarmupAnnealing object at 0x7f1b0f3334c0>" 
-will be used during training (effective maximum steps = 60) - 
-Parameters : 
-(warmup_steps: null
-warmup_ratio: 0.1
-last_epoch: -1
-max_steps: 60
-)
-[INFO] - 
-  | Name                | Type                 | Params
--------------------------------------------------------------
-0 | transformer         | ElectraModel         | 13.5 M
-1 | punct_classifier    | TokenClassifier      | 2.6 K 
-2 | domain_classifier   | SequenceClassifier   | 257   
-3 | punctuation_loss    | FocalDiceLoss        | 0     
-4 | domain_loss         | CrossEntropyLoss     | 0     
-5 | agg_loss            | AggregatorLoss       | 0     
-6 | punct_class_report  | ClassificationReport | 0     
-7 | domain_class_report | ClassificationReport | 0     
--------------------------------------------------------------
-825 K     Trainable params
-12.7 M    Non-trainable params
-13.5 M    Total params
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          17.26      96.74      29.30        184
-! (label_id: 1)                                          0.00       0.00       0.00          4
-, (label_id: 2)                                         58.62       2.86       5.46        594
-- (label_id: 3)                                          7.14       8.47       7.75         59
-. (label_id: 4)                                         48.80      15.46      23.48        524
-: (label_id: 5)                                          1.12       5.56       1.87         18
-; (label_id: 6)                                          0.00       0.00       0.00         13
-? (label_id: 7)                                         14.89       7.37       9.86         95
-— (label_id: 8)                                          0.00       0.00       0.00         12
-… (label_id: 9)                                          0.00       0.00       0.00          0
--------------------
-micro avg                                               19.23      19.23      19.23       1503
-macro avg                                               16.43      15.16       8.64       1503
-weighted avg                                            43.53      19.23      14.88       1503
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                        100.00     100.00     100.00         92
--------------------
-micro avg                                              100.00     100.00     100.00         92
-macro avg                                              100.00     100.00     100.00         92
-weighted avg                                           100.00     100.00     100.00         92
-
-[INFO] - Restored states from the checkpoint file at /home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/lr_find_temp_model.ckpt
-[INFO] - Optimizer config = AdamW (
-Parameter Group 0
-    amsgrad: False
-    betas: (0.9, 0.999)
-    eps: 1e-08
-    lr: 0.003162277660168378
-    weight_decay: 0.0
-)
-[INFO] - Scheduler "<core.optim.lr_scheduler.WarmupAnnealing object at 0x7f1b00306f10>" 
-will be used during training (effective maximum steps = 800) - 
-Parameters : 
-(warmup_steps: null
-warmup_ratio: 0.1
-last_epoch: -1
-max_steps: 800
-)
-[INFO] - 
-  | Name                | Type                 | Params
--------------------------------------------------------------
-0 | transformer         | ElectraModel         | 13.5 M
-1 | punct_classifier    | TokenClassifier      | 2.6 K 
-2 | domain_classifier   | SequenceClassifier   | 257   
-3 | punctuation_loss    | FocalDiceLoss        | 0     
-4 | domain_loss         | CrossEntropyLoss     | 0     
-5 | agg_loss            | AggregatorLoss       | 0     
-6 | punct_class_report  | ClassificationReport | 0     
-7 | domain_class_report | ClassificationReport | 0     
--------------------------------------------------------------
-825 K     Trainable params
-12.7 M    Non-trainable params
-13.5 M    Total params
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          17.82      95.16      30.03        124
-! (label_id: 1)                                          0.00       0.00       0.00          3
-, (label_id: 2)                                         70.59       3.01       5.77        399
-- (label_id: 3)                                          2.56       3.23       2.86         31
-. (label_id: 4)                                         48.76      17.40      25.65        339
-: (label_id: 5)                                          1.79       9.09       2.99         11
-; (label_id: 6)                                          0.00       0.00       0.00          1
-? (label_id: 7)                                         15.62       7.58      10.20         66
-— (label_id: 8)                                          0.00       0.00       0.00         11
-… (label_id: 9)                                          0.00       0.00       0.00          0
--------------------
-micro avg                                               19.90      19.90      19.90        985
-macro avg                                               17.46      15.05       8.61        985
-weighted avg                                            48.77      19.90      15.75        985
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                        100.00     100.00     100.00         62
--------------------
-micro avg                                              100.00     100.00     100.00         62
-macro avg                                              100.00     100.00     100.00         62
-weighted avg                                           100.00     100.00     100.00         62
-
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                         100.00       0.05       0.09       4284
-! (label_id: 1)                                          0.00       0.00       0.00        151
-, (label_id: 2)                                         44.08      77.25      56.13      14795
-- (label_id: 3)                                         65.97      71.00      68.39       1286
-. (label_id: 4)                                         55.76       5.49       9.99      12169
-: (label_id: 5)                                         16.64      34.86      22.53        350
-; (label_id: 6)                                          3.61       8.48       5.06        165
-? (label_id: 7)                                         18.27      69.05      28.90       1021
-— (label_id: 8)                                          2.51       7.36       3.74        421
-… (label_id: 9)                                          0.00       0.00       0.00         85
--------------------
-micro avg                                               39.98      39.98      39.98      34727
-macro avg                                               30.68      27.35      19.48      34727
-weighted avg                                            53.85      39.98      31.11      34727
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                        100.00     100.00     100.00       2142
--------------------
-micro avg                                              100.00     100.00     100.00       2142
-macro avg                                              100.00     100.00     100.00       2142
-weighted avg                                           100.00     100.00     100.00       2142
-
-[INFO] - Epoch 1, global step 100: val_loss reached 0.71243 (best 0.71243), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.71-epoch=1.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                           0.00       0.00       0.00       4044
-! (label_id: 1)                                          0.00       0.00       0.00        145
-, (label_id: 2)                                         43.32      43.32      43.32      13833
-- (label_id: 3)                                         59.53      75.81      66.69       1174
-. (label_id: 4)                                         51.13      53.22      52.15      11588
-: (label_id: 5)                                         32.11      24.69      27.92        320
-; (label_id: 6)                                          3.27      10.76       5.01        158
-? (label_id: 7)                                         22.43      67.01      33.61       1067
-— (label_id: 8)                                          3.45      11.46       5.30        445
-… (label_id: 9)                                          0.00       0.00       0.00         74
--------------------
-micro avg                                               42.35      42.35      42.35      32848
-macro avg                                               21.52      28.63      23.40      32848
-weighted avg                                            39.51      42.35      40.48      32848
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                        100.00     100.00     100.00       2022
--------------------
-micro avg                                              100.00     100.00     100.00       2022
-macro avg                                              100.00     100.00     100.00       2022
-weighted avg                                           100.00     100.00     100.00       2022
-
-[INFO] - Epoch 2, global step 200: val_loss reached 0.60420 (best 0.60420), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.60-epoch=2.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          84.44       0.89       1.75       4292
-! (label_id: 1)                                          7.41       9.02       8.14        133
-, (label_id: 2)                                         43.74      44.01      43.88      14694
-- (label_id: 3)                                         52.78      80.86      63.87       1327
-. (label_id: 4)                                         52.94      50.45      51.66      12213
-: (label_id: 5)                                         18.73      39.23      25.36        339
-; (label_id: 6)                                          3.05      21.52       5.35        158
-? (label_id: 7)                                         27.21      55.73      36.57       1055
-— (label_id: 8)                                          3.02      13.20       4.92        485
-… (label_id: 9)                                          0.00       0.00       0.00         68
--------------------
-micro avg                                               41.91      41.91      41.91      34764
-macro avg                                               29.33      31.49      24.15      34764
-weighted avg                                            50.62      41.91      40.83      34764
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                        100.00     100.00     100.00       2146
--------------------
-micro avg                                              100.00     100.00     100.00       2146
-macro avg                                              100.00     100.00     100.00       2146
-weighted avg                                           100.00     100.00     100.00       2146
-
-[INFO] - Epoch 3, global step 300: val_loss reached 0.54977 (best 0.54977), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.55-epoch=3.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          53.66       2.71       5.15       4066
-! (label_id: 1)                                         10.99       6.90       8.47        145
-, (label_id: 2)                                         43.36      35.48      39.02      14051
-- (label_id: 3)                                         63.28      71.71      67.23       1276
-. (label_id: 4)                                         50.84      73.36      60.06      11507
-: (label_id: 5)                                         23.79      39.88      29.80        321
-; (label_id: 6)                                          3.17       2.67       2.90        150
-? (label_id: 7)                                         44.77      47.00      45.86        983
-— (label_id: 8)                                          2.80      10.36       4.41        386
-… (label_id: 9)                                          0.00       0.00       0.00         83
--------------------
-micro avg                                               45.79      45.79      45.79      32968
-macro avg                                               29.67      29.01      26.29      32968
-weighted avg                                            46.95      45.79      42.59      32968
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                        100.00     100.00     100.00       2033
--------------------
-micro avg                                              100.00     100.00     100.00       2033
-macro avg                                              100.00     100.00     100.00       2033
-weighted avg                                           100.00     100.00     100.00       2033
-
-[INFO] - Epoch 4, global step 400: val_loss reached 0.58447 (best 0.54977), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-05_10-48-12/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.58-epoch=4.ckpt" as top 3
