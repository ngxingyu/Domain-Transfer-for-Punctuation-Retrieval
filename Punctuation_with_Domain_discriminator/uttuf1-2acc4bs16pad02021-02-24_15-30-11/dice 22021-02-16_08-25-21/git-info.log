commit hash: c523cbaa0b6d3efca5ac9fbc9e89b8678b7e7788
diff --git a/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/events.out.tfevents.1613379232.Titan.2419.0 b/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/events.out.tfevents.1613379232.Titan.2419.0
index 55e3ccc..b34b9c9 100644
Binary files a/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/events.out.tfevents.1613379232.Titan.2419.0 and b/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/events.out.tfevents.1613379232.Titan.2419.0 differ
diff --git a/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/lightning_logs.txt b/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/lightning_logs.txt
index 46e1e6e..b210e33 100644
--- a/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/lightning_logs.txt
+++ b/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/lightning_logs.txt
@@ -21,3 +21,9 @@ initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
 7.1 M     Trainable params
 108 M     Non-trainable params
 115 M     Total params
+Epoch 0, global step 656: val_loss reached 146.20628 (best 146.20628), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=146.21-epoch=0.ckpt" as top 3
+Epoch 1, global step 1313: val_loss reached 25.70970 (best 25.70970), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.71-epoch=1.ckpt" as top 3
+Epoch 2, global step 1970: val_loss reached 7.76796 (best 7.76796), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=7.77-epoch=2.ckpt" as top 3
+Epoch 3, global step 2627: val_loss reached 1.31258 (best 1.31258), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=1.31-epoch=3.ckpt" as top 3
+Epoch 4, global step 3284: val_loss reached 2.27040 (best 1.31258), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=2.27-epoch=4.ckpt" as top 3
+Epoch 5, global step 3941: val_loss reached 7.67466 (best 1.31258), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/checkpoints/Punctuation_with_Domain_discriminator---val_loss=7.67-epoch=5.ckpt" as top 3
diff --git a/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/nemo_error_log.txt b/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/nemo_error_log.txt
index 8512f6f..0dab82a 100644
--- a/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/nemo_error_log.txt
+++ b/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/nemo_error_log.txt
@@ -2,3 +2,9 @@
 [NeMo W 2021-02-15 16:53:52 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
       warnings.warn(*args, **kwargs)
     
+[NeMo W 2021-02-15 19:19:00 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f5700031460> was reported to be 2627 (when accessing len(dataloader)), but 2628 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
+      warnings.warn(warn_msg)
+    
+[NeMo W 2021-02-15 19:29:14 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f5700085d30> was reported to be 328 (when accessing len(dataloader)), but 329 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
+      warnings.warn(warn_msg)
+    
diff --git a/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/nemo_log_globalrank-0_localrank-0.txt b/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/nemo_log_globalrank-0_localrank-0.txt
index ffe9ee9..b4814f4 100644
--- a/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/nemo_log_globalrank-0_localrank-0.txt
+++ b/Punctuation_with_Domain_discriminator/2021-02-15_16-53-18/nemo_log_globalrank-0_localrank-0.txt
@@ -4,3 +4,9 @@
 [NeMo W 2021-02-15 16:53:52 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
       warnings.warn(*args, **kwargs)
     
+[NeMo W 2021-02-15 19:19:00 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f5700031460> was reported to be 2627 (when accessing len(dataloader)), but 2628 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
+      warnings.warn(warn_msg)
+    
+[NeMo W 2021-02-15 19:29:14 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f5700085d30> was reported to be 328 (when accessing len(dataloader)), but 329 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
+      warnings.warn(warn_msg)
+    
diff --git a/experiment/config.yaml b/experiment/config.yaml
index 9762568..fa6efd5 100644
--- a/experiment/config.yaml
+++ b/experiment/config.yaml
@@ -2,7 +2,7 @@ seed: 42
 trainer:
     gpus: 1 # the number of gpus, 0 for CPU
     num_nodes: 1
-    max_epochs: 8
+    max_epochs: 4
     max_steps: null # precedence over max_epochs
     accumulate_grad_batches: 4 # accumulates grads every k batches
     gradient_clip_val: 0
@@ -63,11 +63,11 @@ model:
     dataset:
         data_dir: /home/nxingyu/data # /root/data # 
         labelled:
-            # - ${base_path}/ted_talks_processed #
-            - ${base_path}/open_subtitles_processed #  
-        unlabelled:
             - ${base_path}/ted_talks_processed #
             # - ${base_path}/open_subtitles_processed #  
+        unlabelled:
+            # - ${base_path}/ted_talks_processed #
+            # - ${base_path}/open_subtitles_processed #  
             # parameters for dataset preprocessing
         max_seq_length: 128
         pad_label: ''
@@ -75,11 +75,11 @@ model:
         ignore_start_end: false
         use_cache: false
         # shared among dataloaders
-        num_workers:  12
+        num_workers:  4
         pin_memory: true
         drop_last: true
         num_labels: 10
-        num_domains: 2
+        num_domains: 1
         test_unlabelled: true
         attach_label_to_end: none # false if attach to start none if dont mask
 
@@ -111,13 +111,13 @@ model:
         # unfrozen_layers: 1
     
     punct_head:
-        punct_num_fc_layers: 1
+        punct_num_fc_layers: 2
         fc_dropout: 0.1
         activation: 'relu'
         log_softmax: false
         use_transformer_init: true
         loss: 'dice'
-        bilstm: true
+        bilstm: false
 
     domain_head:
         domain_num_fc_layers: 1
@@ -140,7 +140,8 @@ model:
 
     frozen_lr:
         - 1e-2
-        - 5e-3
+        - 1e-2
+        - 1e-2
 
     optim:
         name: adamw
diff --git a/experiment/info.log b/experiment/info.log
index 188b5f1..e69de29 100644
Binary files a/experiment/info.log and b/experiment/info.log differ
