Global seed set to 42
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Using native 16bit precision.
Global seed set to 42
initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1

  | Name                       | Type                 | Params
--------------------------------------------------------------------
0 | transformer                | ElectraModel         | 108 M 
1 | punct_classifier           | TokenClassifier      | 1.2 M 
2 | domain_classifier          | SequenceClassifier   | 4.7 M 
3 | punctuation_loss           | FocalDiceLoss        | 0     
4 | domain_loss                | CrossEntropyLoss     | 0     
5 | agg_loss                   | AggregatorLoss       | 0     
6 | punct_class_report         | ClassificationReport | 0     
7 | chunked_punct_class_report | ClassificationReport | 0     
8 | domain_class_report        | ClassificationReport | 0     
--------------------------------------------------------------------
5.9 M     Trainable params
108 M     Non-trainable params
114 M     Total params
Epoch 0, global step 24: val_loss reached 0.26052 (best 0.26052), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_09-59-35/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.26-epoch=0.ckpt" as top 3
Epoch 1, global step 49: val_loss reached 0.25144 (best 0.25144), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_09-59-35/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.25-epoch=1.ckpt" as top 3
Epoch 2, global step 74: val_loss reached 0.22275 (best 0.22275), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_09-59-35/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.22-epoch=2.ckpt" as top 3
Epoch 3, step 99: val_loss was not in top 3
Epoch 4, step 124: val_loss was not in top 3
Epoch 5, global step 149: val_loss reached 0.25037 (best 0.22275), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_09-59-35/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.25-epoch=5.ckpt" as top 3
Epoch 6, global step 174: val_loss reached 0.22806 (best 0.22275), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_09-59-35/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.23-epoch=6.ckpt" as top 3
Epoch 7, global step 199: val_loss reached 0.22968 (best 0.22275), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_09-59-35/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.23-epoch=7.ckpt" as top 3
Saving latest checkpoint...
Global seed set to 42

  | Name                       | Type                 | Params
--------------------------------------------------------------------
0 | transformer                | ElectraModel         | 108 M 
1 | punct_classifier           | TokenClassifier      | 1.2 M 
2 | domain_classifier          | SequenceClassifier   | 4.7 M 
3 | punctuation_loss           | FocalDiceLoss        | 0     
4 | domain_loss                | CrossEntropyLoss     | 0     
5 | agg_loss                   | AggregatorLoss       | 0     
6 | punct_class_report         | ClassificationReport | 0     
7 | chunked_punct_class_report | ClassificationReport | 0     
8 | domain_class_report        | ClassificationReport | 0     
--------------------------------------------------------------------
13.0 M    Trainable params
101 M     Non-trainable params
114 M     Total params
Epoch 0, step 224: val_loss was not in top 3
Epoch 1, step 249: val_loss was not in top 3
Epoch 2, step 274: val_loss was not in top 3
Epoch 3, step 299: val_loss was not in top 3
Epoch 4, step 324: val_loss was not in top 3
Epoch 5, step 349: val_loss was not in top 3
Epoch 6, step 374: val_loss was not in top 3
Epoch 7, step 399: val_loss was not in top 3
Global seed set to 42

  | Name                       | Type                 | Params
--------------------------------------------------------------------
0 | transformer                | ElectraModel         | 108 M 
1 | punct_classifier           | TokenClassifier      | 1.2 M 
2 | domain_classifier          | SequenceClassifier   | 4.7 M 
3 | punctuation_loss           | FocalDiceLoss        | 0     
4 | domain_loss                | CrossEntropyLoss     | 0     
5 | agg_loss                   | AggregatorLoss       | 0     
6 | punct_class_report         | ClassificationReport | 0     
7 | chunked_punct_class_report | ClassificationReport | 0     
8 | domain_class_report        | ClassificationReport | 0     
--------------------------------------------------------------------
20.1 M    Trainable params
94.7 M    Non-trainable params
114 M     Total params
