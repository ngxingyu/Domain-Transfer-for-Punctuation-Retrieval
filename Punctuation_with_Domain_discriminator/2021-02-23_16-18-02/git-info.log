commit hash: e2bf4242d91a7135bd579a89ad728d2fdf402c2c
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/cmd-args.log b/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/cmd-args.log
deleted file mode 100644
index 11a5d8e..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/cmd-args.log
+++ /dev/null
@@ -1 +0,0 @@
-main.py
\ No newline at end of file
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/events.out.tfevents.1614048839.Titan.11764.0 b/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/events.out.tfevents.1614048839.Titan.11764.0
deleted file mode 100644
index be1285b..0000000
Binary files a/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/events.out.tfevents.1614048839.Titan.11764.0 and /dev/null differ
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/git-info.log b/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/git-info.log
deleted file mode 100644
index 2a1c93d..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/git-info.log
+++ /dev/null
@@ -1,1677 +0,0 @@
-commit hash: a95e08f7dafab6a88b25b93525195e2018fcf89f
-diff --git a/README.md b/README.md
-index 4792b93..e60eff3 100644
---- a/README.md
-+++ b/README.md
-@@ -92,6 +92,7 @@ bash ~/project/experiment/data/disfl2csv.sh /home/nxingyu/data/LDC99T42/treebank
- bash ~/project/bin/processandsplit.sh ./switchboard_processed.csv 8 1 1
- 
- bash ~/project/experiment/data/utt2csv.sh /home/nxingyu/data/utt switchboardutt_processed.csv
-+bash ~/project/bin/processandsplit.sh ./switchboardutt_processed.csv 8 1 1
- sed -i 1i"id,transcript" switchboard*
- 
- python ~/project/processcsv.py -i ~/data/ted_talks_en.csv -o ~/data/ted_talks_processed.csv -c 2000
-diff --git a/experiment/config.yaml b/experiment/config.yaml
-index aecc0bb..46df5bb 100644
---- a/experiment/config.yaml
-+++ b/experiment/config.yaml
-@@ -4,7 +4,7 @@ trainer:
-     num_nodes: 1
-     max_epochs: 8
-     max_steps: null # precedence over max_epochs
--    accumulate_grad_batches: 2 # accumulates grads every k batches
-+    accumulate_grad_batches: 8 # accumulates grads every k batches
-     gradient_clip_val: 0
-     amp_level: O1 # O1/O2 for mixed precision
-     precision: 16 # Should be set to 16 for O1 and O2, default is 16 as PT ignores it when am_level is O0
-@@ -32,12 +32,12 @@ trainer:
-     # resume_from_checkpoint: null
- 
- exp_manager:
--    exp_dir: /home/nxingyu2/project/ # /root/project # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
-+    exp_dir: /home/nxingyu/project/ # /root/project # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
-     name: Punctuation_with_Domain_discriminator  # The name of your model
-     create_tensorboard_logger: true  # Whether you want exp_manger to create a tb logger
-     create_checkpoint_callback: true 
--base_path: /home/nxingyu2/data # /root/data # 
--tmp_path: /home/nxingyu2/data/tmp # /tmp # 
-+base_path: /home/nxingyu/data # /root/data # 
-+tmp_path: /home/nxingyu/data/tmp # /tmp # 
- log_dir: null
- 
- model:
-@@ -75,15 +75,17 @@ model:
-     punct_class_weights: false #false
-     
-     dataset:
--        data_dir: /home/nxingyu2/data # /root/data # 
-+        data_dir: /home/nxingyu/data # /root/data # 
-         labelled:
-             # - ${base_path}/ted2010 #
-             - ${base_path}/ted_talks_processed #
-             # - ${base_path}/open_subtitles_processed #  
-+            # - ${base_path}/switchboardutt_processed #
-         unlabelled:
-             # - ${base_path}/ted_talks_processed #
-             # - ${base_path}/open_subtitles_processed #  
--            # parameters for dataset preprocessing
-+            # - ${base_path}/switchboardutt_processed
-+        # parameters for dataset preprocessing
-         max_seq_length: 128
-         pad_label: ''
-         ignore_extra_tokens: false
-@@ -101,7 +103,7 @@ model:
-         train_ds:
-             shuffle: true
-             num_samples: -1
--            batch_size: 32
-+            batch_size: 16
-             manual_len: 20000 #default 0 84074
- 
-         validation_ds:
-@@ -110,7 +112,7 @@ model:
-             # ds_item: null # expected format: [PATH_TO_DEV1,PATH_TO_DEV2] (Note no space between the paths and square brackets)
-             shuffle: true
-             num_samples: -1
--            batch_size: 32 #4
-+            batch_size: 16 #4
- 
-     tokenizer:
-         tokenizer_name: ${model.language_model.pretrained_model_name} # or sentencepiece
-@@ -126,12 +128,12 @@ model:
-         # unfrozen_layers: 1
-     
-     punct_head:
--        punct_num_fc_layers: 3
-+        punct_num_fc_layers: 0
-         fc_dropout: 0.1
-         activation: 'gelu'
-         log_softmax: false
-         use_transformer_init: true
--        loss: 'dice'
-+        loss: 'crf'
-         bilstm: false
- 
-     domain_head:
-@@ -147,7 +149,7 @@ model:
-     
-     dice_loss:
-         epsilon: 0.01
--        alpha: 3
-+        alpha: 4
-         macro_average: true
- 
-     focal_loss: 
-diff --git a/experiment/data/processdff.py b/experiment/data/processdff.py
-index b456a43..9353683 100644
---- a/experiment/data/processdff.py
-+++ b/experiment/data/processdff.py
-@@ -42,7 +42,7 @@ def remove_disf(text):
-     return s
- 
- def to_emdash(s):
--    return re.sub('--','',s)
-+    return re.sub('--','—',s)
- 
- def strip_accents(s):
-    return ''.join(c for c in unicodedata.normalize('NFKD', s)
-diff --git a/experiment/data/processutt.py b/experiment/data/processutt.py
-index d6c1af1..2b9aa76 100644
---- a/experiment/data/processutt.py
-+++ b/experiment/data/processutt.py
-@@ -42,7 +42,7 @@ def remove_disf(text):
-     return s
- 
- def to_emdash(s):
--    return re.sub('--','',s)
-+    return re.sub('--','—',s)
- 
- def strip_accents(s):
-    return ''.join(c for c in unicodedata.normalize('NFKD', s)
-diff --git a/experiment/data/punctuation_count.sh b/experiment/data/punctuation_count.sh
-index f5d71be..469cc15 100644
---- a/experiment/data/punctuation_count.sh
-+++ b/experiment/data/punctuation_count.sh
-@@ -1,6 +1,6 @@
- for split in "dev" "test" "train"
- do
--for file in /home/nxingyu2/data/open*.$split.csv
-+for file in /home/$USER/data/switch*.$split.csv
- do
-  echo $file
-  sed -E 's/[^[:punct:]]//g;s/(.)/\1x/g' $file  | tr 'x' '\n' | sort | uniq -c | awk '{array[$2]=$1; sum+=$1} END { for (i in array) printf "%-20s %-15d %6.2f%%\n", i, array[i], array[i]/sum*100}' | sort -r -k2,2 -n
-diff --git a/experiment/info.log b/experiment/info.log
-index 7d07c8a..e69de29 100644
---- a/experiment/info.log
-+++ b/experiment/info.log
-@@ -1,1341 +0,0 @@
--[INFO] - GPU available: True, used: True
--[INFO] - TPU available: None, using: 0 TPU cores
--[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
--[INFO] - Using native 16bit precision.
--[INFO] - shuffling train set
--[INFO] - initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.02
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7ff2c4092a30>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 4.7 M 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--5.9 M     Trainable params
--108 M     Non-trainable params
--114 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          78.98      44.46      56.89      80644
--! (label_id: 1)                                          0.04       2.04       0.08         98
--# (label_id: 2)                                          4.92      15.57       7.47       8270
--, (label_id: 3)                                          1.99       0.27       0.47       5934
--- (label_id: 4)                                          0.64       3.85       1.10        572
--. (label_id: 5)                                          6.34       3.38       4.41       5092
--: (label_id: 6)                                          0.19      20.34       0.38        118
--? (label_id: 7)                                          0.00       0.00       0.00        462
--… (label_id: 8)                                          0.04       5.26       0.08         38
---------------------
--micro avg                                               36.93      36.93      36.93     101228
--macro avg                                               10.35      10.57       7.88     101228
--weighted avg                                            63.76      36.93      46.19     101228
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    35854.00        20.00      4032.00      2572.00       284.00      2412.00        52.00       166.00         2.00
--     3840.00         2.00       232.00       400.00        42.00       298.00        10.00        34.00         2.00
--    21412.00        46.00      1288.00      1784.00        84.00      1388.00        22.00       150.00        18.00
--      662.00         0.00       116.00        16.00         2.00        10.00         0.00         0.00         0.00
--     2430.00         2.00       832.00        86.00        22.00        40.00         4.00         0.00         0.00
--     2196.00         0.00       100.00       202.00        12.00       172.00         6.00        22.00         2.00
--    10048.00        28.00       742.00       722.00        62.00       696.00        24.00        86.00        12.00
--      316.00         0.00        38.00         0.00         4.00         0.00         0.00         0.00         0.00
--     3886.00         0.00       890.00       152.00        60.00        76.00         0.00         4.00         2.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00        858
---------------------
--micro avg                                              100.00     100.00     100.00        858
--macro avg                                              100.00     100.00     100.00        858
--weighted avg                                           100.00     100.00     100.00        858
--
---------------------
--           0
--      858.00
---------------------
--
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.41      91.92      94.59     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         86.21      89.77      87.95      54804
--, (label_id: 3)                                         42.62      62.03      50.53      40800
--- (label_id: 4)                                         69.89      60.05      64.60       3464
--. (label_id: 5)                                         57.56      74.40      64.91      33424
--: (label_id: 6)                                         16.67      24.14      19.72        812
--? (label_id: 7)                                         65.62      29.42      40.62       2828
--… (label_id: 8)                                          1.33       7.27       2.25        220
---------------------
--micro avg                                               88.40      88.40      88.40     659880
--macro avg                                               48.59      48.78      47.24     659880
--weighted avg                                            90.59      88.40      89.23     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   480808.00        16.00      5380.00      4796.00      1016.00      1340.00        96.00       120.00        40.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     7796.00         0.00     49196.00         8.00        44.00        24.00         0.00         0.00         0.00
--    26532.00       224.00        48.00     25308.00       172.00      6400.00       188.00       420.00        84.00
--      828.00         0.00        64.00         4.00      2080.00         0.00         0.00         0.00         0.00
--     6328.00       196.00       104.00      9840.00       104.00     24868.00       300.00      1388.00        72.00
--      184.00        12.00         0.00       340.00         0.00       396.00       196.00        40.00         8.00
--      116.00        16.00         4.00       132.00         0.00       156.00        12.00       832.00         0.00
--      464.00         8.00         8.00       372.00        48.00       240.00        20.00        28.00        16.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 0, global step 49: val_loss reached 0.30009 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=0.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.50      88.95      93.03     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         67.87      92.39      78.25      54804
--, (label_id: 3)                                         41.27      74.84      53.20      40800
--- (label_id: 4)                                         82.54      50.23      62.46       3464
--. (label_id: 5)                                         68.11      62.47      65.17      33424
--: (label_id: 6)                                         43.10      12.32      19.16        812
--? (label_id: 7)                                         64.81      24.75      35.82       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               86.36      86.36      86.36     659880
--macro avg                                               51.69      45.11      45.23     659880
--weighted avg                                            89.68      86.36      87.33     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   465264.00        28.00      4072.00      5152.00       888.00      1396.00       180.00       172.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--    23120.00         0.00     50632.00       256.00       564.00        20.00         0.00         8.00         0.00
--    30964.00       180.00        72.00     30536.00       212.00     10932.00       284.00       708.00       104.00
--      356.00         0.00         0.00         0.00      1740.00        12.00         0.00         0.00         0.00
--     3248.00       228.00        24.00      4672.00        60.00     20880.00       248.00      1240.00        56.00
--       16.00         0.00         0.00        24.00         0.00        92.00       100.00         0.00         0.00
--       88.00        36.00         4.00       160.00         0.00        92.00         0.00       700.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 1, global step 99: val_loss reached 0.33170 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.33-epoch=1.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.41      97.01      96.20     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         94.34      88.26      91.20      54804
--, (label_id: 3)                                         56.69      58.49      57.58      40800
--- (label_id: 4)                                         87.42      48.15      62.10       3464
--. (label_id: 5)                                         70.05      64.34      67.07      33424
--: (label_id: 6)                                         58.54      11.82      19.67        812
--? (label_id: 7)                                         55.41      36.92      44.31       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.53      91.53      91.53     659880
--macro avg                                               57.54      45.00      48.68     659880
--weighted avg                                            91.28      91.53      91.33     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   507420.00        60.00      6400.00     12064.00      1516.00      3824.00       220.00       276.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2776.00         0.00     48372.00         8.00        96.00        20.00         0.00         0.00         0.00
--     9396.00       160.00         8.00     23864.00       124.00      7724.00       232.00       508.00        80.00
--      240.00         0.00         0.00         0.00      1668.00         0.00         0.00         0.00         0.00
--     3024.00       192.00        20.00      4588.00        60.00     21504.00       256.00      1000.00        56.00
--        8.00         0.00         0.00         8.00         0.00        52.00        96.00         0.00         0.00
--      192.00        60.00         4.00       268.00         0.00       300.00         8.00      1044.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 2, global step 149: val_loss reached 0.31563 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.32-epoch=2.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.90      96.12      96.01     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         89.97      88.46      89.21      54804
--, (label_id: 3)                                         53.45      64.22      58.34      40800
--- (label_id: 4)                                         82.01      53.70      64.90       3464
--. (label_id: 5)                                         71.61      60.91      65.83      33424
--: (label_id: 6)                                         22.89      22.66      22.77        812
--? (label_id: 7)                                         66.35      29.28      40.63       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.03      91.03      91.03     659880
--macro avg                                               53.57      46.15      48.63     659880
--weighted avg                                            91.17      91.03      91.00     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   502752.00        56.00      6284.00     10168.00      1144.00      3256.00       196.00       308.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     5080.00         0.00     48480.00        36.00       268.00        20.00         0.00         0.00         0.00
--    12200.00       184.00        24.00     26200.00       148.00      9364.00       200.00       608.00        92.00
--      404.00         0.00         0.00         4.00      1860.00         0.00         0.00         0.00         0.00
--     2368.00       196.00        12.00      4080.00        44.00     20360.00       232.00      1072.00        68.00
--      160.00         4.00         0.00       164.00         0.00       280.00       184.00        12.00         0.00
--       92.00        32.00         4.00       148.00         0.00       144.00         0.00       828.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 3, global step 199: val_loss reached 0.31315 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.31-epoch=3.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.75      95.17      95.95     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         89.22      90.48      89.85      54804
--, (label_id: 3)                                         51.13      69.58      58.95      40800
--- (label_id: 4)                                         77.34      59.12      67.02       3464
--. (label_id: 5)                                         70.86      63.12      66.76      33424
--: (label_id: 6)                                         57.14       9.85      16.81        812
--? (label_id: 7)                                         58.43      35.79      44.39       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               90.92      90.92      90.92     659880
--macro avg                                               55.65      47.01      48.86     659880
--weighted avg                                            91.58      90.92      91.11     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   497780.00        44.00      5156.00      7900.00      1008.00      2248.00       148.00       156.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     5716.00         0.00     49584.00        60.00       180.00        32.00         0.00         0.00         0.00
--    15936.00       176.00        44.00     28388.00       180.00      9708.00       364.00       620.00       100.00
--      588.00         0.00         4.00         8.00      2048.00         0.00         0.00         0.00         0.00
--     2884.00       208.00        12.00      4220.00        48.00     21096.00       212.00      1032.00        60.00
--        0.00         0.00         0.00         8.00         0.00        44.00        80.00         8.00         0.00
--      152.00        44.00         4.00       216.00         0.00       296.00         8.00      1012.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 4, step 249: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.94      96.58      96.26     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         96.14      86.64      91.15      54804
--, (label_id: 3)                                         57.41      61.25      59.27      40800
--- (label_id: 4)                                         76.69      60.39      67.57       3464
--. (label_id: 5)                                         68.11      71.82      69.91      33424
--: (label_id: 6)                                         25.76      16.75      20.30        812
--? (label_id: 7)                                         57.68      39.32      46.76       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.68      91.68      91.68     659880
--macro avg                                               53.08      48.08      50.14     659880
--weighted avg                                            91.72      91.68      91.66     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   505172.00        48.00      7272.00      9648.00      1116.00      2808.00       196.00       196.00        68.00
--        0.00         0.00         0.00         4.00         0.00         0.00         0.00         0.00         0.00
--     1848.00         0.00     47484.00         8.00        28.00        20.00         0.00         0.00         0.00
--    11408.00       148.00        24.00     24992.00       172.00      6064.00       204.00       448.00        76.00
--      616.00         0.00        12.00         8.00      2092.00         0.00         0.00         0.00         0.00
--     3736.00       216.00         8.00      5828.00        56.00     24004.00       272.00      1056.00        68.00
--      124.00         4.00         0.00        88.00         0.00       152.00       136.00        16.00         8.00
--      152.00        56.00         4.00       224.00         0.00       376.00         4.00      1112.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 5, global step 299: val_loss reached 0.30916 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.31-epoch=5.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.63      96.00      96.31     523056
--! (label_id: 1)                                         66.67       1.69       3.31        472
--# (label_id: 2)                                         94.65      89.24      91.87      54804
--, (label_id: 3)                                         56.09      64.01      59.79      40800
--- (label_id: 4)                                         76.31      60.62      67.57       3464
--. (label_id: 5)                                         66.81      74.69      70.53      33424
--: (label_id: 6)                                         30.77      15.76      20.85        812
--? (label_id: 7)                                         67.66      35.22      46.33       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.74      91.74      91.74     659880
--macro avg                                               61.73      48.58      50.73     659880
--weighted avg                                            92.08      91.74      91.82     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   502128.00        52.00      5844.00      7976.00      1084.00      2108.00       192.00       188.00        60.00
--        0.00         8.00         0.00         4.00         0.00         0.00         0.00         0.00         0.00
--     2660.00         0.00     48908.00        16.00        68.00        20.00         0.00         0.00         0.00
--    13400.00       144.00        28.00     26116.00       156.00      6024.00       200.00       408.00        84.00
--      636.00         0.00        12.00         4.00      2100.00         0.00         0.00         0.00         0.00
--     4040.00       228.00         8.00      6476.00        56.00     24964.00       292.00      1224.00        76.00
--       72.00         4.00         0.00        76.00         0.00       124.00       128.00        12.00         0.00
--      120.00        36.00         4.00       132.00         0.00       184.00         0.00       996.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 6, global step 349: val_loss reached 0.29901 (best 0.29901), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=6.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.22      96.51      96.36     523056
--! (label_id: 1)                                         50.00       1.69       3.28        472
--# (label_id: 2)                                         94.99      88.69      91.73      54804
--, (label_id: 3)                                         58.33      60.13      59.21      40800
--- (label_id: 4)                                         76.36      60.05      67.23       3464
--. (label_id: 5)                                         67.13      74.43      70.59      33424
--: (label_id: 6)                                         29.60      18.23      22.56        812
--? (label_id: 7)                                         63.15      38.05      47.48       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.85      91.85      91.85     659880
--macro avg                                               59.53      48.64      50.94     659880
--weighted avg                                            91.90      91.85      91.82     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   504792.00        52.00      6164.00      9436.00      1132.00      2604.00       196.00       204.00        68.00
--        0.00         8.00         0.00         4.00         0.00         4.00         0.00         0.00         0.00
--     2464.00         0.00     48608.00        24.00        56.00        20.00         0.00         0.00         0.00
--    11076.00       136.00        12.00     24532.00       140.00      5508.00       184.00       396.00        76.00
--      624.00         0.00        12.00         8.00      2080.00         0.00         0.00         0.00         0.00
--     3876.00       228.00         8.00      6516.00        56.00     24876.00       284.00      1136.00        76.00
--       84.00         4.00         0.00        96.00         0.00       152.00       148.00        16.00         0.00
--      140.00        44.00         0.00       184.00         0.00       260.00         0.00      1076.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 7, global step 399: val_loss reached 0.29477 (best 0.29477), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.29-epoch=7.ckpt" as top 3
--[INFO] - Saving latest checkpoint...
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.001
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7ff309dcf1f0>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 4.7 M 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--13.0 M    Trainable params
--101 M     Non-trainable params
--114 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.42      96.72      96.57      80644
--! (label_id: 1)                                        100.00       2.04       4.00         98
--# (label_id: 2)                                         94.98      88.83      91.80       8270
--, (label_id: 3)                                         58.52      61.21      59.84       5934
--- (label_id: 4)                                         76.96      61.89      68.60        572
--. (label_id: 5)                                         68.39      74.94      71.51       5092
--: (label_id: 6)                                         27.91      20.34      23.53        118
--? (label_id: 7)                                         61.36      35.06      44.63        462
--… (label_id: 8)                                          0.00       0.00       0.00         38
---------------------
--micro avg                                               92.21      92.21      92.21     101228
--macro avg                                               64.95      49.00      51.17     101228
--weighted avg                                            92.29      92.21      92.16     101228
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    78002.00         8.00       918.00      1312.00       170.00       410.00        30.00        34.00        12.00
--        0.00         2.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      372.00         0.00      7346.00         6.00        10.00         0.00         0.00         0.00         0.00
--     1618.00        30.00         2.00      3632.00        26.00       800.00        24.00        62.00        12.00
--      104.00         0.00         2.00         0.00       354.00         0.00         0.00         0.00         0.00
--      510.00        48.00         2.00       936.00        12.00      3816.00        40.00       202.00        14.00
--       16.00         0.00         0.00        18.00         0.00        26.00        24.00         2.00         0.00
--       22.00        10.00         0.00        30.00         0.00        40.00         0.00       162.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00        858
---------------------
--micro avg                                              100.00     100.00     100.00        858
--macro avg                                              100.00     100.00     100.00        858
--weighted avg                                           100.00     100.00     100.00        858
--
---------------------
--           0
--      858.00
---------------------
--
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.70      94.08      95.86     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.41      91.56      91.98      54804
--, (label_id: 3)                                         54.08      65.15      59.10      40800
--- (label_id: 4)                                         45.58      75.06      56.72       3464
--. (label_id: 5)                                         64.27      82.86      72.39      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         48.94      68.32      57.02       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.09      91.09      91.09     659880
--macro avg                                               44.78      53.00      48.12     659880
--weighted avg                                            92.17      91.09      91.48     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   492100.00        24.00      4224.00      5312.00       620.00       972.00       224.00       160.00        44.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     4076.00         0.00     50176.00        16.00        16.00        12.00         0.00         0.00         0.00
--    17824.00       140.00        12.00     26580.00       152.00      3988.00       196.00       172.00        84.00
--     2804.00         0.00       248.00        36.00      2600.00        16.00         0.00         0.00         0.00
--     5728.00       256.00       136.00      8184.00        76.00     27696.00       372.00       564.00        84.00
--        0.00         0.00         0.00         0.00         0.00         8.00         0.00         0.00         0.00
--      524.00        52.00         8.00       672.00         0.00       732.00        20.00      1932.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 0, step 449: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.41      96.35      96.88     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         91.96      94.02      92.98      54804
--, (label_id: 3)                                         64.21      66.16      65.17      40800
--- (label_id: 4)                                         82.47      58.66      68.56       3464
--. (label_id: 5)                                         71.30      82.13      76.33      33424
--: (label_id: 6)                                          2.63       0.99       1.43        812
--? (label_id: 7)                                         60.28      67.19      63.55       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.03      93.03      93.03     659880
--macro avg                                               52.25      51.72      51.65     659880
--weighted avg                                            93.13      93.03      93.04     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   503984.00        60.00      3212.00      6736.00      1244.00      1548.00       212.00       328.00        56.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     4456.00         0.00     51528.00        16.00        24.00        12.00         0.00         0.00         0.00
--    10468.00       140.00        20.00     26992.00       136.00      3768.00       240.00       188.00        88.00
--      404.00         0.00        12.00        12.00      2032.00         4.00         0.00         0.00         0.00
--     3520.00       232.00        32.00      6420.00        28.00     27452.00       340.00       412.00        68.00
--       36.00         0.00         0.00       232.00         0.00        28.00         8.00         0.00         0.00
--      188.00        40.00         0.00       392.00         0.00       612.00        12.00      1900.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 1, step 499: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.66      94.87      95.76     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         73.52      98.98      84.37      54804
--, (label_id: 3)                                         65.92      59.67      62.64      40800
--- (label_id: 4)                                         82.48      50.00      62.26       3464
--. (label_id: 5)                                         78.47      72.58      75.41      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         64.87      64.78      64.83       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.32      91.32      91.32     659880
--macro avg                                               51.33      48.99      49.47     659880
--weighted avg                                            91.49      91.32      91.21     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   496212.00       116.00       536.00     12196.00       908.00      2632.00       292.00       364.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--    18644.00         0.00     54244.00       160.00       700.00        32.00         0.00         0.00         0.00
--     5632.00       136.00         8.00     24344.00       112.00      6032.00       280.00       296.00        88.00
--      216.00         0.00         0.00       140.00      1732.00        12.00         0.00         0.00         0.00
--     2204.00       196.00        16.00      3624.00        12.00     24260.00       212.00       336.00        56.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      148.00        24.00         0.00       336.00         0.00       456.00        28.00      1832.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 2, step 549: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.60      97.50      97.05     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         93.99      91.64      92.80      54804
--, (label_id: 3)                                         68.55      61.10      64.61      40800
--- (label_id: 4)                                         81.77      49.19      61.43       3464
--. (label_id: 5)                                         71.94      82.38      76.81      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         82.00      50.92      62.83       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.32      93.32      93.32     659880
--macro avg                                               54.98      48.08      50.61     659880
--weighted avg                                            93.04      93.32      93.11     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   510004.00        64.00      4520.00      9228.00      1444.00      2020.00       252.00       360.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2996.00         0.00     50220.00        92.00       108.00        16.00         0.00         0.00         0.00
--     6636.00       144.00        24.00     24928.00       188.00      3764.00       220.00       388.00        72.00
--      304.00         0.00        20.00        48.00      1704.00         8.00         0.00         0.00         0.00
--     3036.00       248.00        20.00      6364.00        20.00     27536.00       340.00       640.00        72.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--       80.00        16.00         0.00       140.00         0.00        80.00         0.00      1440.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 3, step 599: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.93      97.24      97.09     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         94.66      91.04      92.81      54804
--, (label_id: 3)                                         66.63      64.82      65.72      40800
--- (label_id: 4)                                         75.88      62.47      68.52       3464
--. (label_id: 5)                                         73.34      81.40      77.16      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         70.49      69.59      70.04       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.40      93.40      93.40     659880
--macro avg                                               53.10      51.84      52.37     659880
--weighted avg                                            93.23      93.40      93.30     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508644.00        56.00      4712.00      8096.00      1072.00      1648.00       216.00       220.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2504.00         0.00     49892.00       252.00        44.00        16.00         0.00         0.00         0.00
--     8032.00       164.00        52.00     26448.00       168.00      4252.00       268.00       236.00        72.00
--      560.00         0.00       108.00         4.00      2164.00        16.00         0.00         0.00         0.00
--     3152.00       228.00        40.00      5656.00        16.00     27208.00       320.00       404.00        72.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      164.00        24.00         0.00       344.00         0.00       284.00         8.00      1968.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 4, step 649: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.34      96.76      97.05     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.54      93.20      92.87      54804
--, (label_id: 3)                                         64.62      68.42      66.47      40800
--- (label_id: 4)                                         82.26      58.89      68.64       3464
--. (label_id: 5)                                         74.47      80.59      77.41      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         69.26      71.71      70.47       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.36      93.36      93.36     659880
--macro avg                                               53.39      52.17      52.54     659880
--weighted avg                                            93.34      93.36      93.33     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   506088.00        44.00      3608.00      7132.00      1100.00      1496.00       172.00       204.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     3760.00         0.00     51080.00       244.00        92.00        20.00         0.00         0.00         0.00
--     9524.00       176.00        44.00     27916.00       216.00      4680.00       320.00       232.00        92.00
--      396.00         0.00        28.00         4.00      2040.00        12.00         0.00         0.00         0.00
--     3032.00       228.00        44.00      5172.00        16.00     26936.00       312.00       364.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      256.00        24.00         0.00       332.00         0.00       280.00         8.00      2028.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 5, step 699: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.17      97.08      97.12     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.93      92.96      92.95      54804
--, (label_id: 3)                                         66.75      65.61      66.17      40800
--- (label_id: 4)                                         75.56      66.40      70.68       3464
--. (label_id: 5)                                         74.11      81.07      77.43      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         72.03      70.30      71.15       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.48      93.48      93.48     659880
--macro avg                                               53.17      52.60      52.83     659880
--weighted avg                                            93.32      93.48      93.39     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   507784.00        56.00      3732.00      7964.00       892.00      1656.00       216.00       220.00        68.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     3532.00         0.00     50948.00       244.00        84.00        16.00         0.00         0.00         0.00
--     8000.00       148.00        44.00     26768.00       172.00      4380.00       284.00       220.00        88.00
--      652.00         0.00        60.00        12.00      2300.00        20.00         0.00         0.00         0.00
--     2912.00       244.00        20.00      5504.00        16.00     27096.00       304.00       400.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      176.00        24.00         0.00       308.00         0.00       256.00         8.00      1988.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 6, step 749: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.17      97.07      97.12     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.94      92.98      92.96      54804
--, (label_id: 3)                                         66.60      66.25      66.42      40800
--- (label_id: 4)                                         75.19      66.86      70.78       3464
--. (label_id: 5)                                         74.75      80.94      77.72      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         73.88      70.01      71.90       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.51      93.51      93.51     659880
--macro avg                                               53.39      52.68      52.99     659880
--weighted avg                                            93.36      93.51      93.43     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   507744.00        56.00      3724.00      7944.00       876.00      1664.00       220.00       220.00        68.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     3528.00         0.00     50956.00       244.00        84.00        16.00         0.00         0.00         0.00
--     8112.00       152.00        44.00     27028.00       172.00      4464.00       292.00       232.00        88.00
--      672.00         0.00        60.00        12.00      2316.00        20.00         0.00         0.00         0.00
--     2832.00       240.00        20.00      5280.00        16.00     27052.00       292.00       396.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      168.00        24.00         0.00       292.00         0.00       208.00         8.00      1980.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 7, step 799: val_loss was not in top 3
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.0004
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7ff29c24fa60>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 4.7 M 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--20.1 M    Trainable params
--94.7 M    Non-trainable params
--114 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.30      97.36      97.33      80644
--! (label_id: 1)                                          0.00       0.00       0.00         98
--# (label_id: 2)                                         92.84      93.11      92.97       8270
--, (label_id: 3)                                         66.91      67.21      67.06       5934
--- (label_id: 4)                                         77.08      68.18      72.36        572
--. (label_id: 5)                                         76.94      80.60      78.73       5092
--: (label_id: 6)                                          0.00       0.00       0.00        118
--? (label_id: 7)                                         76.61      72.29      74.39        462
--… (label_id: 8)                                          0.00       0.00       0.00         38
---------------------
--micro avg                                               93.88      93.88      93.88     101228
--macro avg                                               54.19      53.19      53.65     101228
--weighted avg                                            93.68      93.88      93.77     101228
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    78518.00        10.00       552.00      1142.00       140.00       256.00        32.00        36.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      544.00         0.00      7700.00        38.00        12.00         0.00         0.00         0.00         0.00
--     1122.00        32.00         4.00      3988.00        28.00       698.00        42.00        32.00        14.00
--      102.00         0.00        12.00         0.00       390.00         2.00         0.00         0.00         0.00
--      340.00        50.00         2.00       722.00         2.00      4104.00        42.00        60.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--       18.00         6.00         0.00        44.00         0.00        32.00         2.00       334.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00        858
---------------------
--micro avg                                              100.00     100.00     100.00        858
--macro avg                                              100.00     100.00     100.00        858
--weighted avg                                           100.00     100.00     100.00        858
--
---------------------
--           0
--      858.00
---------------------
--
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.70      97.18      96.94     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         90.59      92.02      91.30      54804
--, (label_id: 3)                                         65.34      65.67      65.50      40800
--- (label_id: 4)                                         85.28      45.50      59.34       3464
--. (label_id: 5)                                         76.92      76.16      76.54      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         67.59      62.23      64.80       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.10      93.10      93.10     659880
--macro avg                                               53.60      48.75      50.49     659880
--weighted avg                                            92.84      93.10      92.94     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508300.00        60.00      4336.00      9072.00      1240.00      2136.00       204.00       252.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     4560.00         0.00     50432.00       212.00       436.00        32.00         0.00         0.00         0.00
--     7488.00       172.00         8.00     26792.00       200.00      5416.00       384.00       436.00       108.00
--      256.00         0.00        12.00         4.00      1576.00         0.00         0.00         0.00         0.00
--     2240.00       216.00        16.00      4512.00        12.00     25456.00       216.00       380.00        44.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      212.00        24.00         0.00       208.00         0.00       384.00         8.00      1760.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 0, step 849: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.12      98.10      96.59     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         93.92      90.84      92.36      54804
--, (label_id: 3)                                         71.82      48.62      57.98      40800
--- (label_id: 4)                                         75.00      55.08      63.52       3464
--. (label_id: 5)                                         72.29      78.12      75.09      33424
--: (label_id: 6)                                        100.00       0.49       0.98        812
--? (label_id: 7)                                         86.41      35.08      49.90       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               92.71      92.71      92.71     659880
--macro avg                                               66.06      45.15      48.49     659880
--weighted avg                                            92.19      92.71      92.17     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   513120.00       140.00      4940.00     15176.00      1240.00      3752.00       372.00       596.00       104.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2864.00         0.00     49784.00        84.00       232.00        40.00         0.00         0.00         0.00
--     3644.00        64.00         0.00     19836.00        76.00      3500.00       168.00       276.00        56.00
--      560.00         0.00        60.00        16.00      1908.00         0.00         0.00         0.00         0.00
--     2820.00       252.00        20.00      5616.00         8.00     26112.00       268.00       964.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         4.00         0.00         0.00
--       48.00        16.00         0.00        72.00         0.00        20.00         0.00       992.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 1, step 899: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          94.93      95.85      95.39     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         98.21      69.76      81.58      54804
--, (label_id: 3)                                         54.91      72.97      62.66      40800
--- (label_id: 4)                                         86.86      27.48      41.75       3464
--. (label_id: 5)                                         66.94      75.06      70.77      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                        100.00       1.56       3.06       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               90.23      90.23      90.23     659880
--macro avg                                               55.76      38.08      39.47     659880
--weighted avg                                            91.07      90.23      90.08     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   501340.00        48.00     16152.00      6100.00      2028.00      1720.00       188.00       488.00        52.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      476.00         0.00     38232.00        24.00       176.00        20.00         0.00         0.00         0.00
--    15484.00       220.00       100.00     29772.00       252.00      6596.00       360.00      1348.00        88.00
--      136.00         0.00         8.00         0.00       952.00         0.00         0.00         0.00         0.00
--     5620.00       204.00       312.00      4904.00        56.00     25088.00       264.00       948.00        80.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00        44.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 2, step 949: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.95      94.26      95.58     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         88.08      93.86      90.88      54804
--, (label_id: 3)                                         59.30      62.47      60.85      40800
--- (label_id: 4)                                         43.12      67.32      52.57       3464
--. (label_id: 5)                                         70.00      76.39      73.06      33424
--: (label_id: 6)                                          0.91       5.42       1.56        812
--? (label_id: 7)                                         55.40      63.08      58.99       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               90.87      90.87      90.87     659880
--macro avg                                               45.97      51.42      48.17     659880
--weighted avg                                            91.84      90.87      91.31     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   493028.00        76.00      2376.00      9040.00       652.00      2780.00       252.00       280.00        72.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     6864.00         0.00     51440.00        16.00        68.00         4.00         0.00         8.00         0.00
--    11812.00       120.00       108.00     25488.00       156.00      4628.00       268.00       324.00        76.00
--     2344.00         0.00       504.00       212.00      2332.00        16.00         0.00         0.00         0.00
--     4468.00       256.00       144.00      5276.00        72.00     25532.00       244.00       412.00        68.00
--     3964.00         4.00       212.00       368.00       176.00        56.00        44.00        20.00         0.00
--      576.00        16.00        20.00       400.00         8.00       408.00         4.00      1784.00         4.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 3, step 999: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.73      96.49      96.61     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         97.10      88.69      92.71      54804
--, (label_id: 3)                                         61.91      66.92      64.32      40800
--- (label_id: 4)                                         62.18      61.32      61.74       3464
--. (label_id: 5)                                         71.48      77.96      74.58      33424
--: (label_id: 6)                                          4.21       1.97       2.68        812
--? (label_id: 7)                                         54.34      71.71      61.83       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               92.57      92.57      92.57     659880
--macro avg                                               49.77      51.67      50.50     659880
--weighted avg                                            92.75      92.57      92.63     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   504696.00        68.00      5900.00      7576.00      1048.00      1924.00       240.00       236.00        52.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1396.00         0.00     48608.00        20.00        24.00        12.00         0.00         0.00         0.00
--    10964.00       132.00        64.00     27304.00       216.00      4920.00       236.00       192.00        72.00
--     1020.00         0.00       132.00       128.00      2124.00        12.00         0.00         0.00         0.00
--     4196.00       248.00        88.00      5064.00        40.00     26056.00       304.00       372.00        84.00
--      200.00         0.00         8.00       152.00         0.00         4.00        16.00         0.00         0.00
--      584.00        24.00         4.00       556.00        12.00       496.00        16.00      2028.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 4, step 1049: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          94.84      98.08      96.43     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         98.53      81.48      89.20      54804
--, (label_id: 3)                                         67.47      60.25      63.66      40800
--- (label_id: 4)                                         65.13      58.89      61.86       3464
--. (label_id: 5)                                         77.35      72.15      74.66      33424
--: (label_id: 6)                                          6.67       2.46       3.60        812
--? (label_id: 7)                                         66.26      60.82      63.42       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               92.46      92.46      92.46     659880
--macro avg                                               52.92      48.24      50.31     659880
--weighted avg                                            92.08      92.46      92.17     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   513024.00        92.00      9884.00     11672.00      1184.00      4168.00       344.00       472.00        84.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      600.00         0.00     44652.00        20.00        28.00        16.00         0.00         0.00         0.00
--     6192.00       148.00        32.00     24584.00       132.00      4776.00       208.00       272.00        92.00
--      828.00         0.00       204.00        60.00      2040.00         0.00         0.00         0.00         0.00
--     2096.00       216.00        32.00      4068.00        16.00     24116.00       236.00       364.00        32.00
--      168.00         0.00         0.00        40.00        64.00         8.00        20.00         0.00         0.00
--      148.00        16.00         0.00       356.00         0.00       340.00         4.00      1720.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 5, step 1099: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.42      97.26      96.84     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         96.89      90.07      93.36      54804
--, (label_id: 3)                                         64.67      65.10      64.88      40800
--- (label_id: 4)                                         61.01      63.97      62.46       3464
--. (label_id: 5)                                         75.87      75.59      75.73      33424
--: (label_id: 6)                                         14.29       2.46       4.20        812
--? (label_id: 7)                                         59.57      67.33      63.21       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.05      93.05      93.05     659880
--macro avg                                               52.08      51.31      51.19     659880
--weighted avg                                            92.91      93.05      92.96     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508716.00        68.00      5096.00      8936.00      1036.00      3024.00       280.00       372.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1492.00         0.00     49364.00        32.00        36.00        24.00         0.00         0.00         0.00
--     9016.00       172.00        36.00     26560.00       132.00      4504.00       284.00       264.00       104.00
--     1076.00         0.00       276.00        64.00      2216.00         0.00         0.00         0.00         0.00
--     2492.00       216.00        32.00      4728.00        24.00     25264.00       216.00       288.00        40.00
--       60.00         0.00         0.00        40.00        12.00         8.00        20.00         0.00         0.00
--      204.00        16.00         0.00       440.00         8.00       600.00        12.00      1904.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 6, step 1149: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.49      97.24      96.86     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         96.73      90.36      93.44      54804
--, (label_id: 3)                                         64.80      65.04      64.92      40800
--- (label_id: 4)                                         64.12      62.12      63.11       3464
--. (label_id: 5)                                         75.35      76.33      75.84      33424
--: (label_id: 6)                                         22.73       2.46       4.44        812
--? (label_id: 7)                                         58.91      68.74      63.45       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.09      93.09      93.09     659880
--macro avg                                               53.24      51.37      51.34     659880
--weighted avg                                            92.95      93.09      93.00     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508616.00        72.00      4992.00      8792.00      1104.00      2864.00       280.00       364.00        56.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1572.00         0.00     49520.00        40.00        36.00        24.00         0.00         0.00         0.00
--     9072.00       152.00        36.00     26536.00       128.00      4416.00       280.00       240.00        88.00
--      920.00         0.00       224.00        60.00      2152.00         0.00         0.00         0.00         0.00
--     2604.00       224.00        32.00      4892.00        28.00     25512.00       220.00       280.00        64.00
--       28.00         0.00         0.00        24.00         8.00         8.00        20.00         0.00         0.00
--      244.00        24.00         0.00       456.00         8.00       600.00        12.00      1944.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 7, step 1199: val_loss was not in top 3
--[INFO] - GPU available: True, used: True
--[INFO] - TPU available: None, using: 0 TPU cores
--[INFO] - Using environment variable NODE_RANK for node rank (0).
--[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.25      97.27      96.76     650284
--! (label_id: 1)                                          0.00       0.00       0.00        380
--# (label_id: 2)                                         97.23      89.79      93.36      68496
--, (label_id: 3)                                         62.58      64.85      63.69      52348
--- (label_id: 4)                                         49.90      60.65      54.75       3212
--. (label_id: 5)                                         79.01      73.40      76.10      46276
--: (label_id: 6)                                         20.00       2.25       4.05        888
--? (label_id: 7)                                         60.00      67.50      63.53       4000
--… (label_id: 8)                                          0.00       0.00       0.00        260
---------------------
--micro avg                                               92.79      92.79      92.79     826144
--macro avg                                               51.66      50.63      50.25     826144
--weighted avg                                            92.72      92.79      92.72     826144
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   632504.00        36.00      6712.00     12044.00      1116.00      3904.00       244.00       476.00       108.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1596.00         0.00     61504.00        28.00        52.00        76.00         0.00         0.00         0.00
--    11756.00       140.00         8.00     33948.00        68.00      7492.00       300.00       432.00       104.00
--     1636.00         0.00       232.00        36.00      1948.00        52.00         0.00         0.00         0.00
--     2480.00       180.00        28.00      5584.00        16.00     33968.00       304.00       392.00        40.00
--       20.00         0.00         0.00        28.00        12.00        20.00        20.00         0.00         0.00
--      292.00        24.00        12.00       680.00         0.00       764.00        20.00      2700.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Chunked Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.57      97.15      96.86     327564
--! (label_id: 1)                                          0.00       0.00       0.00        184
--# (label_id: 2)                                         97.23      90.48      93.73      34404
--, (label_id: 3)                                         63.38      67.07      65.18      26324
--- (label_id: 4)                                         50.74      63.34      56.35       1724
--. (label_id: 5)                                         80.87      76.47      78.61      23376
--: (label_id: 6)                                          8.33       0.88       1.59        456
--? (label_id: 7)                                         59.61      72.62      65.47       2016
--… (label_id: 8)                                          0.00       0.00       0.00         92
---------------------
--micro avg                                               93.10      93.10      93.10     416140
--macro avg                                               50.75      52.00      50.86     416140
--weighted avg                                            93.12      93.10      93.08     416140
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   318220.00        20.00      3140.00      5728.00       532.00      1500.00       124.00       184.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      788.00         0.00     31128.00         8.00        32.00        60.00         0.00         0.00         0.00
--     6236.00        84.00         0.00     17656.00        48.00      3444.00       144.00       220.00        24.00
--      872.00         0.00       128.00        16.00      1092.00        44.00         0.00         0.00         0.00
--     1240.00        72.00         8.00      2568.00        16.00     17876.00       168.00       148.00         8.00
--       16.00         0.00         0.00         4.00         4.00        20.00         4.00         0.00         0.00
--      192.00         8.00         0.00       344.00         0.00       432.00        16.00      1464.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       6884
---------------------
--micro avg                                              100.00     100.00     100.00       6884
--macro avg                                              100.00     100.00     100.00       6884
--weighted avg                                           100.00     100.00     100.00       6884
--
---------------------
--           0
--     6884.00
---------------------
--
--[INFO] - saving to /home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/test.txt
--[INFO] - Internal process exited
-diff --git a/experiment/outputs/2021-02-23/08-18-26/testing.log b/experiment/outputs/2021-02-23/08-18-26/testing.log
-index f00f863..2597221 100644
---- a/experiment/outputs/2021-02-23/08-18-26/testing.log
-+++ b/experiment/outputs/2021-02-23/08-18-26/testing.log
-@@ -1 +1,74 @@
- [2021-02-23 08:18:38,771][root][INFO] - shuffling train set
-+[2021-02-23 08:44:12,424][root][INFO] - Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          95.20      95.06      95.13   33617452
-+! (label_id: 1)                                         21.65      40.73      28.27     578585
-+# (label_id: 2)                                         89.63      94.36      91.93    6976446
-+, (label_id: 3)                                         52.02      49.20      50.57    2858145
-+- (label_id: 4)                                         52.90      37.64      43.98     255633
-+. (label_id: 5)                                         67.03      64.56      65.77    5425019
-+: (label_id: 6)                                          0.00       0.00       0.00      15576
-+? (label_id: 7)                                         66.11      48.89      56.21    1415356
-+… (label_id: 8)                                         28.23      27.42      27.82     482702
-+-------------------
-+micro avg                                               86.40      86.40      86.40   51624912
-+macro avg                                               52.53      50.87      51.07   51624912
-+weighted avg                                            86.61      86.40      86.42   51624912
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 31955872.00     33316.00    385671.00    438274.00     53505.00    443163.00      7682.00    120484.00    128329.00
-+    66565.00    235635.00       761.00    176016.00      8738.00    506812.00       944.00     64244.00     28918.00
-+   714124.00       536.00   6582626.00      7720.00     19841.00     15709.00      1649.00      1336.00      1001.00
-+   288086.00     97827.00       833.00   1406100.00     11576.00    706306.00       912.00    121425.00     69959.00
-+    56237.00      2410.00       944.00      5163.00     96209.00     18095.00        96.00      1041.00      1680.00
-+   390319.00    174383.00      3985.00    635086.00     21274.00   3502327.00      3717.00    389488.00    104418.00
-+        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-+    75395.00     24645.00       937.00     80919.00      3444.00    153187.00       136.00    691913.00     16045.00
-+    70772.00      9833.00       689.00    108867.00     41046.00     79420.00       440.00     25425.00    132352.00
-+-------------------
-+
-+[2021-02-23 08:44:12,434][root][INFO] - Chunked Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          95.59      96.37      95.98   16876740
-+! (label_id: 1)                                         21.47      41.98      28.41     290645
-+# (label_id: 2)                                         95.04      95.14      95.09    3541392
-+, (label_id: 3)                                         52.20      49.91      51.03    1447727
-+- (label_id: 4)                                         53.56      38.01      44.47     130953
-+. (label_id: 5)                                         68.20      65.03      66.58    2759312
-+: (label_id: 6)                                          0.00       0.00       0.00       7645
-+? (label_id: 7)                                         66.66      50.42      57.42     716850
-+… (label_id: 8)                                         28.64      27.84      28.23     243286
-+-------------------
-+micro avg                                               87.46      87.46      87.46   26014552
-+macro avg                                               53.49      51.63      51.91   26014552
-+weighted avg                                            87.71      87.46      87.50   26014552
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 16264699.00     14196.00    169436.00    215171.00     26620.00    202508.00      3785.00     54437.00     63531.00
-+    33928.00    122012.00       272.00     91962.00      4505.00    266896.00       504.00     33168.00     15114.00
-+   151602.00       248.00   3369444.00      3788.00     10412.00      7913.00       881.00       624.00       328.00
-+   147638.00     49831.00       344.00    722501.00      5999.00    360923.00       448.00     60458.00     35874.00
-+    28414.00      1192.00       464.00      2722.00     49780.00      8964.00        32.00       537.00       840.00
-+   177113.00     85795.00      1072.00    314405.00     10733.00   1794350.00      1747.00    194183.00     51583.00
-+        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-+    37372.00     12602.00       168.00     41387.00      1825.00     79031.00        64.00    361456.00      8297.00
-+    35974.00      4769.00       192.00     55791.00     21079.00     38727.00       184.00     11987.00     67719.00
-+-------------------
-+
-+[2021-02-23 08:44:12,439][root][INFO] - Domain report: 
-+label                                                precision    recall       f1           support   
-+0 (label_id: 0)                                        100.00     100.00     100.00     411653
-+-------------------
-+micro avg                                              100.00     100.00     100.00     411653
-+macro avg                                              100.00     100.00     100.00     411653
-+weighted avg                                           100.00     100.00     100.00     411653
-+
-+-------------------
-+           0
-+   411653.00
-+-------------------
-+
-+[2021-02-23 08:44:12,439][root][INFO] - saving to /home/nxingyu/project/Punctuation_with_Domain_discriminator/opendice33acc42021-02-22_09-49-04//test.txt
-+[2021-02-23 08:44:12,539][wandb.sdk.internal.internal][INFO] - Internal process exited
-diff --git a/experiment/outputs/2021-02-23/08-20-55/testing.log b/experiment/outputs/2021-02-23/08-20-55/testing.log
-index 717645a..7100fd1 100644
---- a/experiment/outputs/2021-02-23/08-20-55/testing.log
-+++ b/experiment/outputs/2021-02-23/08-20-55/testing.log
-@@ -1 +1,74 @@
- [2021-02-23 08:21:08,018][root][INFO] - shuffling train set
-+[2021-02-23 09:05:21,673][root][INFO] - Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          94.88      97.99      96.41   33617452
-+! (label_id: 1)                                         33.89       9.66      15.04     578585
-+# (label_id: 2)                                         99.49      99.10      99.30    6976446
-+, (label_id: 3)                                         52.51      39.66      45.19    2858145
-+- (label_id: 4)                                         56.89      22.57      32.32     255633
-+. (label_id: 5)                                         62.04      77.10      68.76    5425019
-+: (label_id: 6)                                         77.05      41.40      53.86      15576
-+? (label_id: 7)                                         70.01      36.10      47.64    1415356
-+… (label_id: 8)                                         57.21       6.15      11.10     482702
-+-------------------
-+micro avg                                               88.78      88.78      88.78   51624912
-+macro avg                                               67.11      47.75      52.18   51624912
-+weighted avg                                            87.80      88.78      87.68   51624912
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 32940746.00     42247.00     56263.00    637305.00    117974.00    572846.00      3579.00    174660.00    172542.00
-+    10770.00     55899.00        88.00     35948.00      1672.00     46823.00       184.00      8367.00      5210.00
-+    27771.00       545.00   6913637.00      1128.00      1968.00      2819.00        16.00       480.00       560.00
-+   163910.00    113876.00       544.00   1133679.00     17942.00    526536.00       840.00    121929.00     79630.00
-+    19931.00      1771.00       104.00      4132.00     57687.00     14847.00        40.00       600.00      2282.00
-+   403834.00    347864.00      5066.00    988029.00     38393.00   4182951.00      4372.00    597272.00    174593.00
-+      608.00         0.00         0.00       505.00       360.00       288.00      6449.00        32.00       128.00
-+    48028.00     16247.00       712.00     54579.00      4683.00     76459.00        80.00    510999.00     18088.00
-+     1745.00       136.00        32.00      2840.00     14954.00      1450.00        16.00      1017.00     29669.00
-+-------------------
-+
-+[2021-02-23 09:05:21,682][root][INFO] - Chunked Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          95.08      98.11      96.57   16876740
-+! (label_id: 1)                                         33.70      10.09      15.54     290645
-+# (label_id: 2)                                         99.61      99.52      99.57    3541392
-+, (label_id: 3)                                         52.66      40.24      45.62    1447727
-+- (label_id: 4)                                         57.66      22.91      32.79     130953
-+. (label_id: 5)                                         62.89      77.75      69.53    2759312
-+: (label_id: 6)                                         78.52      42.08      54.79       7645
-+? (label_id: 7)                                         70.98      37.06      48.70     716850
-+… (label_id: 8)                                         58.27       6.35      11.46     243286
-+-------------------
-+micro avg                                               89.00      89.00      89.00   26014552
-+macro avg                                               67.71      48.24      52.73   26014552
-+weighted avg                                            88.03      89.00      87.92   26014552
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 16557577.00     19231.00     15829.00    319520.00     60251.00    272070.00      1746.00     82502.00     86301.00
-+     5837.00     29340.00        16.00     18850.00       800.00     24913.00       120.00      4276.00      2921.00
-+    11597.00        88.00   3524547.00       280.00       800.00       737.00         8.00        88.00        96.00
-+    83677.00     57621.00       136.00    582598.00      9566.00    269820.00       440.00     61935.00     40462.00
-+    10150.00       904.00        56.00      2011.00     29998.00      7605.00        16.00       240.00      1049.00
-+   183939.00    175228.00       744.00    495087.00     19564.00   2145232.00      2058.00    301633.00     87509.00
-+      176.00         0.00         0.00       296.00       128.00       168.00      3217.00        16.00        96.00
-+    22954.00      8169.00        64.00     27597.00      2353.00     38063.00        32.00    265680.00      9397.00
-+      833.00        64.00         0.00      1488.00      7493.00       704.00         8.00       480.00     15455.00
-+-------------------
-+
-+[2021-02-23 09:05:21,687][root][INFO] - Domain report: 
-+label                                                precision    recall       f1           support   
-+0 (label_id: 0)                                        100.00     100.00     100.00     411653
-+-------------------
-+micro avg                                              100.00     100.00     100.00     411653
-+macro avg                                              100.00     100.00     100.00     411653
-+weighted avg                                           100.00     100.00     100.00     411653
-+
-+-------------------
-+           0
-+   411653.00
-+-------------------
-+
-+[2021-02-23 09:05:21,688][root][INFO] - saving to /home/nxingyu/project/Punctuation_with_Domain_discriminator/opencrfacc42021-02-22_09-48-50//test.txt
-+[2021-02-23 09:05:21,785][wandb.sdk.internal.internal][INFO] - Internal process exited
-diff --git a/experiment/testing.py b/experiment/testing.py
-index 3e967b0..e033bc0 100644
---- a/experiment/testing.py
-+++ b/experiment/testing.py
-@@ -20,7 +20,7 @@ import atexit
- from copy import deepcopy
- import snoop
- snoop.install()
--exp='opencrfacc42021-02-22_09-48-50'
-+exp='2021-02-23_09-24-44'
- @hydra.main(config_path=f"../Punctuation_with_Domain_discriminator/{exp}/",config_name="hparams.yaml")
- def main(cfg : DictConfig) -> None:
-     torch.set_printoptions(sci_mode=False)
-@@ -41,7 +41,7 @@ def main(cfg : DictConfig) -> None:
-                     max_seq_length=model.dm.max_seq_length,
-                     punct_label_ids=model.dm.punct_label_ids,
-                     label_map=model.dm.label_map,
--                    labelled=['/home/nxingyu/data/open_subtitles_processed'],
-+                    labelled=['/home/nxingyu/data/ted_talks_processed'],
-                     unlabelled=[],
-                     tokenizer=model.dm.tokenizer,
-                     randomize=model.dm.val_shuffle,
-@@ -49,7 +49,7 @@ def main(cfg : DictConfig) -> None:
-                     tmp_path=model.dm.tmp_path,
-                     attach_label_to_end=model.dm.attach_label_to_end,
-                     no_space_label=model.dm.no_space_label,
--                    pad_start=0,
-+                    pad_start=model.dm.pad_start,
-                     )
-     model.hparams.log_dir=f"/home/nxingyu/project/Punctuation_with_Domain_discriminator/{exp}/"
-     trainer = pl.Trainer(**cfg.trainer)
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/hparams.yaml b/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/hparams.yaml
deleted file mode 100644
index a11d7ad..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/hparams.yaml
+++ /dev/null
@@ -1,127 +0,0 @@
-seed: 42
-trainer:
-  gpus: 1
-  num_nodes: 1
-  max_epochs: 8
-  max_steps: null
-  accumulate_grad_batches: 8
-  gradient_clip_val: 0
-  amp_level: O1
-  precision: 16
-  accelerator: ddp
-  checkpoint_callback: false
-  logger: false
-  log_every_n_steps: 1
-  val_check_interval: 1.0
-  resume_from_checkpoint: null
-exp_manager:
-  exp_dir: /home/nxingyu/project/
-  name: Punctuation_with_Domain_discriminator
-  create_tensorboard_logger: true
-  create_checkpoint_callback: true
-base_path: /home/nxingyu/data
-tmp_path: /home/nxingyu/data/tmp
-log_dir: /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41
-model:
-  nemo_path: null
-  transformer_path: google/electra-base-discriminator
-  unfrozen: 0
-  maximum_unfrozen: 2
-  unfreeze_step: 1
-  punct_label_ids:
-  - ''
-  - ','
-  - .
-  - '?'
-  - '-'
-  - '!'
-  - ':'
-  - …
-  label_map:
-    —: ','
-    ;: .
-  no_space_label: '#'
-  test_chunk_percent: 0.5
-  pad_start_and_end: 0
-  punct_class_weights: false
-  dataset:
-    data_dir: /home/nxingyu/data
-    labelled:
-    - /home/nxingyu/data/ted_talks_processed
-    unlabelled: null
-    max_seq_length: 128
-    pad_label: ''
-    ignore_extra_tokens: false
-    ignore_start_end: false
-    use_cache: false
-    num_workers: 8
-    pin_memory: false
-    drop_last: true
-    num_labels: 9
-    num_domains: 2
-    test_unlabelled: true
-    attach_label_to_end: null
-    pad_start: 64
-    train_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 16
-      manual_len: 20000
-    validation_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 16
-  tokenizer:
-    tokenizer_name: google/electra-base-discriminator
-    vocab_file: null
-    tokenizer_model: null
-    special_tokens: null
-  language_model:
-    pretrained_model_name: google/electra-base-discriminator
-    lm_checkpoint: null
-    config_file: null
-    config: null
-  punct_head:
-    punct_num_fc_layers: 0
-    fc_dropout: 0.1
-    activation: gelu
-    log_softmax: false
-    use_transformer_init: true
-    loss: crf
-    bilstm: false
-  domain_head:
-    domain_num_fc_layers: 3
-    fc_dropout: 0.1
-    activation: relu
-    log_softmax: false
-    use_transformer_init: true
-    loss: cel
-    gamma: 0.01
-    pooling: mean_max
-    idx_conditioned_on: 0
-  dice_loss:
-    epsilon: 0.01
-    alpha: 4
-    macro_average: true
-  focal_loss:
-    gamma: 3
-  frozen_lr:
-  - 0.02
-  - 0.001
-  - 0.0004
-  - 0.0001
-  - 1.0e-05
-  - 1.0e-06
-  - 1.0e-07
-  optim:
-    name: adamw
-    lr: 0.01
-    weight_decay: 0.0
-    sched:
-      name: CosineAnnealing
-      warmup_steps: null
-      warmup_ratio: 0.1
-      min_lr: 1.0e-08
-      last_epoch: -1
-      monitor: val_loss
-      reduce_on_plateau: false
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/lightning_logs.txt b/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/lightning_logs.txt
deleted file mode 100644
index 981d544..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/lightning_logs.txt
+++ /dev/null
@@ -1,86 +0,0 @@
-Global seed set to 42
-GPU available: True, used: True
-TPU available: None, using: 0 TPU cores
-LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
-Using native 16bit precision.
-Global seed set to 42
-initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 6.9 K 
-2 | domain_classifier          | SequenceClassifier   | 4.7 M 
-3 | punctuation_loss           | LinearChainCRF       | 99    
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-4.7 M     Trainable params
-108 M     Non-trainable params
-113 M     Total params
-Epoch 0, global step 24: val_loss reached 45.59620 (best 45.59620), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=45.60-epoch=0.ckpt" as top 3
-Epoch 1, global step 49: val_loss reached 31.71823 (best 31.71823), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=31.72-epoch=1.ckpt" as top 3
-Epoch 2, global step 74: val_loss reached 27.89115 (best 27.89115), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=27.89-epoch=2.ckpt" as top 3
-Epoch 3, global step 99: val_loss reached 26.52819 (best 26.52819), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=26.53-epoch=3.ckpt" as top 3
-Epoch 4, global step 124: val_loss reached 25.81643 (best 25.81643), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.82-epoch=4.ckpt" as top 3
-Epoch 5, global step 149: val_loss reached 25.47755 (best 25.47755), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.48-epoch=5.ckpt" as top 3
-Epoch 6, global step 174: val_loss reached 25.43966 (best 25.43966), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.44-epoch=6.ckpt" as top 3
-Epoch 7, global step 199: val_loss reached 25.39553 (best 25.39553), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.40-epoch=7.ckpt" as top 3
-Saving latest checkpoint...
-Global seed set to 42
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 6.9 K 
-2 | domain_classifier          | SequenceClassifier   | 4.7 M 
-3 | punctuation_loss           | LinearChainCRF       | 99    
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-11.8 M    Trainable params
-101 M     Non-trainable params
-113 M     Total params
-Epoch 0, global step 224: val_loss reached 25.39438 (best 25.39438), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.39-epoch=0.ckpt" as top 3
-Epoch 1, global step 249: val_loss reached 25.39347 (best 25.39347), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.39-epoch=1.ckpt" as top 3
-Epoch 2, global step 274: val_loss reached 25.39192 (best 25.39192), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.39-epoch=2.ckpt" as top 3
-Epoch 3, global step 299: val_loss reached 25.39093 (best 25.39093), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.39-epoch=3.ckpt" as top 3
-Epoch 4, global step 324: val_loss reached 25.38961 (best 25.38961), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.39-epoch=4.ckpt" as top 3
-Epoch 5, global step 349: val_loss reached 25.38882 (best 25.38882), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.39-epoch=5.ckpt" as top 3
-Epoch 6, global step 374: val_loss reached 25.38747 (best 25.38747), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.39-epoch=6.ckpt" as top 3
-Epoch 7, global step 399: val_loss reached 25.38644 (best 25.38644), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.39-epoch=7.ckpt" as top 3
-Global seed set to 42
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 6.9 K 
-2 | domain_classifier          | SequenceClassifier   | 4.7 M 
-3 | punctuation_loss           | LinearChainCRF       | 99    
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-18.9 M    Trainable params
-94.7 M    Non-trainable params
-113 M     Total params
-Epoch 0, global step 424: val_loss reached 25.38246 (best 25.38246), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.38-epoch=0.ckpt" as top 3
-Epoch 1, global step 449: val_loss reached 25.37870 (best 25.37870), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.38-epoch=1.ckpt" as top 3
-Epoch 2, global step 474: val_loss reached 25.37471 (best 25.37471), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.37-epoch=2.ckpt" as top 3
-Epoch 3, global step 499: val_loss reached 25.37089 (best 25.37089), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.37-epoch=3.ckpt" as top 3
-Epoch 4, global step 524: val_loss reached 25.36699 (best 25.36699), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.37-epoch=4.ckpt" as top 3
-Epoch 5, global step 549: val_loss reached 25.36334 (best 25.36334), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.36-epoch=5.ckpt" as top 3
-Epoch 6, global step 574: val_loss reached 25.35961 (best 25.35961), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.36-epoch=6.ckpt" as top 3
-Epoch 7, global step 599: val_loss reached 25.35567 (best 25.35567), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/checkpoints/Punctuation_with_Domain_discriminator---val_loss=25.36-epoch=7.ckpt" as top 3
-GPU available: True, used: True
-TPU available: None, using: 0 TPU cores
-Using environment variable NODE_RANK for node rank (0).
-LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/nemo_error_log.txt b/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/nemo_error_log.txt
deleted file mode 100644
index 5a2a8b3..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/nemo_error_log.txt
+++ /dev/null
@@ -1,31 +0,0 @@
-[NeMo W 2021-02-23 10:53:41 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
-[NeMo W 2021-02-23 10:53:53 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 10:53:53 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 10:53:57 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 10:53:57 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 10:53:57 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 10:53:59 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
-      warnings.warn(*args, **kwargs)
-    
-[NeMo W 2021-02-23 10:54:21 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
-      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
-    
-[NeMo W 2021-02-23 10:58:20 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f8bb4f64a90> was reported to be 199 (when accessing len(dataloader)), but 200 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-02-23 10:59:02 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f8bb4f64f70> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-02-23 13:04:14 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f8bb4f64610> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/nemo_log_globalrank-0_localrank-0.txt b/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/nemo_log_globalrank-0_localrank-0.txt
deleted file mode 100644
index 7fea4df..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/nemo_log_globalrank-0_localrank-0.txt
+++ /dev/null
@@ -1,33 +0,0 @@
-[NeMo I 2021-02-23 10:53:41 exp_manager:183] Experiments will be logged at /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41
-[NeMo I 2021-02-23 10:53:41 exp_manager:519] TensorboardLogger has been set up
-[NeMo W 2021-02-23 10:53:41 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
-[NeMo W 2021-02-23 10:53:53 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 10:53:53 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 10:53:57 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 10:53:57 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 10:53:57 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 10:53:59 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
-      warnings.warn(*args, **kwargs)
-    
-[NeMo W 2021-02-23 10:54:21 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
-      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
-    
-[NeMo W 2021-02-23 10:58:20 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f8bb4f64a90> was reported to be 199 (when accessing len(dataloader)), but 200 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-02-23 10:59:02 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f8bb4f64f70> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-02-23 13:04:14 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f8bb4f64610> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/test.txt b/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/test.txt
deleted file mode 100644
index d99568c..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_10-53-41/test.txt
+++ /dev/null
@@ -1,85 +0,0 @@
-Punct report
-
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          95.07      95.61      95.34     684726
-! (label_id: 1)                                          0.00       0.00       0.00        358
-# (label_id: 2)                                         86.77      95.98      91.14      71989
-, (label_id: 3)                                         65.18      40.96      50.30      54369
-- (label_id: 4)                                         67.36      50.19      57.53       3335
-. (label_id: 5)                                         69.10      69.12      69.11      48200
-: (label_id: 6)                                          0.49       8.67       0.93        796
-? (label_id: 7)                                         69.03      12.27      20.84       3887
-… (label_id: 8)                                          0.00       0.00       0.00        247
--------------------
-micro avg                                               90.05      90.05      90.05     867907
-macro avg                                               50.33      41.42      42.80     867907
-weighted avg                                            90.69      90.05      90.08     867907
-
--------------------
-                       !           #           ,           -           .           :           ?           …
-   654648.00        69.00      1711.00     21458.00      1433.00      8231.00       106.00       813.00       108.00
-       16.00         0.00         0.00         0.00         0.00         8.00         0.00         8.00         0.00
-     9330.00         1.00     69092.00       518.00        50.00       573.00        16.00        45.00         0.00
-     5691.00       113.00         8.00     22268.00        98.00      5159.00       233.00       522.00        72.00
-      703.00         0.00         9.00        16.00      1674.00        83.00         0.00         0.00         0.00
-     3142.00       167.00        58.00      9147.00        32.00     33316.00       372.00      1939.00        43.00
-    11139.00         0.00      1110.00       872.00        48.00       772.00        69.00        83.00        24.00
-       57.00         8.00         1.00        90.00         0.00        58.00         0.00       477.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--------------------
-
-Chunked Punct report
-
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          95.28      95.70      95.49     345075
-! (label_id: 1)                                          0.00       0.00       0.00        175
-# (label_id: 2)                                         87.15      96.50      91.59      35837
-, (label_id: 3)                                         65.30      41.94      51.07      27384
-- (label_id: 4)                                         68.43      49.86      57.69       1765
-. (label_id: 5)                                         71.02      71.69      71.35      24284
-: (label_id: 6)                                          0.57       9.20       1.07        435
-? (label_id: 7)                                         78.90      14.09      23.91       1938
-… (label_id: 8)                                          0.00       0.00       0.00         89
--------------------
-micro avg                                               90.37      90.37      90.37     436982
-macro avg                                               51.85      42.11      43.57     436982
-weighted avg                                            91.06      90.37      90.42     436982
-
--------------------
-                       !           #           ,           -           .           :           ?           …
-   330220.00        43.00       682.00     10699.00       761.00      3727.00        70.00       298.00        65.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-     4532.00         0.00     34581.00       247.00        34.00       248.00         8.00        28.00         0.00
-     2995.00        88.00         8.00     11484.00        58.00      2460.00       167.00       318.00         8.00
-      316.00         0.00         9.00         8.00       880.00        73.00         0.00         0.00         0.00
-     1436.00        44.00         0.00      4480.00        24.00     17409.00       150.00       955.00        16.00
-     5552.00         0.00       557.00       442.00         8.00       342.00        40.00        66.00         0.00
-       24.00         0.00         0.00        24.00         0.00        25.00         0.00       273.00         0.00
-        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--------------------
-
-Domain report
-
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                        100.00     100.00     100.00       7237
--------------------
-micro avg                                              100.00     100.00     100.00       7237
-macro avg                                              100.00     100.00     100.00       7237
-weighted avg                                           100.00     100.00     100.00       7237
-
--------------------
-           0
-     7237.00
--------------------
-
-
-test_loss: 25.047338485717773
-punct_precision: 50.333866119384766
-punct_f1: 42.79826736450195
-punct_recall: 41.42171859741211
-chunked_punct_precision: 51.85090637207031
-chunked_punct_f1: 43.57420349121094
-chunked_punct_recall: 42.106319427490234
-domain_precision: 100.0
-domain_f1: 100.0
-domain_recall: 100.0
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/cmd-args.log b/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/cmd-args.log
deleted file mode 100644
index 11a5d8e..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/cmd-args.log
+++ /dev/null
@@ -1 +0,0 @@
-main.py
\ No newline at end of file
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/events.out.tfevents.1614057734.Titan.19391.0 b/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/events.out.tfevents.1614057734.Titan.19391.0
deleted file mode 100644
index efdb484..0000000
Binary files a/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/events.out.tfevents.1614057734.Titan.19391.0 and /dev/null differ
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/git-info.log b/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/git-info.log
deleted file mode 100644
index e2432fb..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/git-info.log
+++ /dev/null
@@ -1,1701 +0,0 @@
-commit hash: a95e08f7dafab6a88b25b93525195e2018fcf89f
-diff --git a/README.md b/README.md
-index 4792b93..e60eff3 100644
---- a/README.md
-+++ b/README.md
-@@ -92,6 +92,7 @@ bash ~/project/experiment/data/disfl2csv.sh /home/nxingyu/data/LDC99T42/treebank
- bash ~/project/bin/processandsplit.sh ./switchboard_processed.csv 8 1 1
- 
- bash ~/project/experiment/data/utt2csv.sh /home/nxingyu/data/utt switchboardutt_processed.csv
-+bash ~/project/bin/processandsplit.sh ./switchboardutt_processed.csv 8 1 1
- sed -i 1i"id,transcript" switchboard*
- 
- python ~/project/processcsv.py -i ~/data/ted_talks_en.csv -o ~/data/ted_talks_processed.csv -c 2000
-diff --git a/experiment/config.yaml b/experiment/config.yaml
-index aecc0bb..4253922 100644
---- a/experiment/config.yaml
-+++ b/experiment/config.yaml
-@@ -4,7 +4,7 @@ trainer:
-     num_nodes: 1
-     max_epochs: 8
-     max_steps: null # precedence over max_epochs
--    accumulate_grad_batches: 2 # accumulates grads every k batches
-+    accumulate_grad_batches: 4 # accumulates grads every k batches
-     gradient_clip_val: 0
-     amp_level: O1 # O1/O2 for mixed precision
-     precision: 16 # Should be set to 16 for O1 and O2, default is 16 as PT ignores it when am_level is O0
-@@ -32,12 +32,12 @@ trainer:
-     # resume_from_checkpoint: null
- 
- exp_manager:
--    exp_dir: /home/nxingyu2/project/ # /root/project # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
-+    exp_dir: /home/nxingyu/project/ # /root/project # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
-     name: Punctuation_with_Domain_discriminator  # The name of your model
-     create_tensorboard_logger: true  # Whether you want exp_manger to create a tb logger
-     create_checkpoint_callback: true 
--base_path: /home/nxingyu2/data # /root/data # 
--tmp_path: /home/nxingyu2/data/tmp # /tmp # 
-+base_path: /home/nxingyu/data # /root/data # 
-+tmp_path: /home/nxingyu/data/tmp # /tmp # 
- log_dir: null
- 
- model:
-@@ -75,15 +75,17 @@ model:
-     punct_class_weights: false #false
-     
-     dataset:
--        data_dir: /home/nxingyu2/data # /root/data # 
-+        data_dir: /home/nxingyu/data # /root/data # 
-         labelled:
-             # - ${base_path}/ted2010 #
-             - ${base_path}/ted_talks_processed #
-             # - ${base_path}/open_subtitles_processed #  
-+            # - ${base_path}/switchboardutt_processed #
-         unlabelled:
-             # - ${base_path}/ted_talks_processed #
-             # - ${base_path}/open_subtitles_processed #  
--            # parameters for dataset preprocessing
-+            # - ${base_path}/switchboardutt_processed
-+        # parameters for dataset preprocessing
-         max_seq_length: 128
-         pad_label: ''
-         ignore_extra_tokens: false
-@@ -101,7 +103,7 @@ model:
-         train_ds:
-             shuffle: true
-             num_samples: -1
--            batch_size: 32
-+            batch_size: 16
-             manual_len: 20000 #default 0 84074
- 
-         validation_ds:
-@@ -110,7 +112,7 @@ model:
-             # ds_item: null # expected format: [PATH_TO_DEV1,PATH_TO_DEV2] (Note no space between the paths and square brackets)
-             shuffle: true
-             num_samples: -1
--            batch_size: 32 #4
-+            batch_size: 16 #4
- 
-     tokenizer:
-         tokenizer_name: ${model.language_model.pretrained_model_name} # or sentencepiece
-@@ -147,7 +149,7 @@ model:
-     
-     dice_loss:
-         epsilon: 0.01
--        alpha: 3
-+        alpha: 1
-         macro_average: true
- 
-     focal_loss: 
-diff --git a/experiment/data/disfl2csv.sh b/experiment/data/disfl2csv.sh
-index 84d8b69..48148a0 100644
---- a/experiment/data/disfl2csv.sh
-+++ b/experiment/data/disfl2csv.sh
-@@ -4,10 +4,10 @@ echo "in $1"
- echo "out $2"
- :> "$2"
- DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
--echo 'talk_id,transcript'> "$2"
-+# echo 'talk_id,transcript'> "$2"
- #echo "filenames, transcript" > opensubtitles.csv
- for folder in $1/*; do
--    for filename in $folder/*.dfl; do
-+    for filename in $folder/*.dff; do
-         echo $filename
-         python $DIR/processdff.py -i $filename -o $2
-         #echo "$filename, \"$transcript\"" >> opensubtitles.csv
-diff --git a/experiment/data/processdff.py b/experiment/data/processdff.py
-index b456a43..7e76f7f 100644
---- a/experiment/data/processdff.py
-+++ b/experiment/data/processdff.py
-@@ -42,7 +42,7 @@ def remove_disf(text):
-     return s
- 
- def to_emdash(s):
--    return re.sub('--','',s)
-+    return re.sub('--','…',s)
- 
- def strip_accents(s):
-    return ''.join(c for c in unicodedata.normalize('NFKD', s)
-diff --git a/experiment/data/processutt.py b/experiment/data/processutt.py
-index d6c1af1..d809a43 100644
---- a/experiment/data/processutt.py
-+++ b/experiment/data/processutt.py
-@@ -42,7 +42,7 @@ def remove_disf(text):
-     return s
- 
- def to_emdash(s):
--    return re.sub('--','',s)
-+    return re.sub('--','…',s)
- 
- def strip_accents(s):
-    return ''.join(c for c in unicodedata.normalize('NFKD', s)
-diff --git a/experiment/data/punctuation_count.sh b/experiment/data/punctuation_count.sh
-index f5d71be..469cc15 100644
---- a/experiment/data/punctuation_count.sh
-+++ b/experiment/data/punctuation_count.sh
-@@ -1,6 +1,6 @@
- for split in "dev" "test" "train"
- do
--for file in /home/nxingyu2/data/open*.$split.csv
-+for file in /home/$USER/data/switch*.$split.csv
- do
-  echo $file
-  sed -E 's/[^[:punct:]]//g;s/(.)/\1x/g' $file  | tr 'x' '\n' | sort | uniq -c | awk '{array[$2]=$1; sum+=$1} END { for (i in array) printf "%-20s %-15d %6.2f%%\n", i, array[i], array[i]/sum*100}' | sort -r -k2,2 -n
-diff --git a/experiment/data/utt2csv.sh b/experiment/data/utt2csv.sh
-index 7e03880..446d32a 100644
---- a/experiment/data/utt2csv.sh
-+++ b/experiment/data/utt2csv.sh
-@@ -4,7 +4,7 @@ echo "in $1"
- echo "out $2"
- :> "$2"
- DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
--echo 'talk_id,transcript'> "$2"
-+# echo 'talk_id,transcript'> "$2"
- #echo "filenames, transcript" > opensubtitles.csv
- for folder in $1/sw*; do
-     for filename in $folder/*.utt; do
-diff --git a/experiment/info.log b/experiment/info.log
-index 7d07c8a..e69de29 100644
---- a/experiment/info.log
-+++ b/experiment/info.log
-@@ -1,1341 +0,0 @@
--[INFO] - GPU available: True, used: True
--[INFO] - TPU available: None, using: 0 TPU cores
--[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
--[INFO] - Using native 16bit precision.
--[INFO] - shuffling train set
--[INFO] - initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.02
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7ff2c4092a30>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 4.7 M 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--5.9 M     Trainable params
--108 M     Non-trainable params
--114 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          78.98      44.46      56.89      80644
--! (label_id: 1)                                          0.04       2.04       0.08         98
--# (label_id: 2)                                          4.92      15.57       7.47       8270
--, (label_id: 3)                                          1.99       0.27       0.47       5934
--- (label_id: 4)                                          0.64       3.85       1.10        572
--. (label_id: 5)                                          6.34       3.38       4.41       5092
--: (label_id: 6)                                          0.19      20.34       0.38        118
--? (label_id: 7)                                          0.00       0.00       0.00        462
--… (label_id: 8)                                          0.04       5.26       0.08         38
---------------------
--micro avg                                               36.93      36.93      36.93     101228
--macro avg                                               10.35      10.57       7.88     101228
--weighted avg                                            63.76      36.93      46.19     101228
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    35854.00        20.00      4032.00      2572.00       284.00      2412.00        52.00       166.00         2.00
--     3840.00         2.00       232.00       400.00        42.00       298.00        10.00        34.00         2.00
--    21412.00        46.00      1288.00      1784.00        84.00      1388.00        22.00       150.00        18.00
--      662.00         0.00       116.00        16.00         2.00        10.00         0.00         0.00         0.00
--     2430.00         2.00       832.00        86.00        22.00        40.00         4.00         0.00         0.00
--     2196.00         0.00       100.00       202.00        12.00       172.00         6.00        22.00         2.00
--    10048.00        28.00       742.00       722.00        62.00       696.00        24.00        86.00        12.00
--      316.00         0.00        38.00         0.00         4.00         0.00         0.00         0.00         0.00
--     3886.00         0.00       890.00       152.00        60.00        76.00         0.00         4.00         2.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00        858
---------------------
--micro avg                                              100.00     100.00     100.00        858
--macro avg                                              100.00     100.00     100.00        858
--weighted avg                                           100.00     100.00     100.00        858
--
---------------------
--           0
--      858.00
---------------------
--
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.41      91.92      94.59     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         86.21      89.77      87.95      54804
--, (label_id: 3)                                         42.62      62.03      50.53      40800
--- (label_id: 4)                                         69.89      60.05      64.60       3464
--. (label_id: 5)                                         57.56      74.40      64.91      33424
--: (label_id: 6)                                         16.67      24.14      19.72        812
--? (label_id: 7)                                         65.62      29.42      40.62       2828
--… (label_id: 8)                                          1.33       7.27       2.25        220
---------------------
--micro avg                                               88.40      88.40      88.40     659880
--macro avg                                               48.59      48.78      47.24     659880
--weighted avg                                            90.59      88.40      89.23     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   480808.00        16.00      5380.00      4796.00      1016.00      1340.00        96.00       120.00        40.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     7796.00         0.00     49196.00         8.00        44.00        24.00         0.00         0.00         0.00
--    26532.00       224.00        48.00     25308.00       172.00      6400.00       188.00       420.00        84.00
--      828.00         0.00        64.00         4.00      2080.00         0.00         0.00         0.00         0.00
--     6328.00       196.00       104.00      9840.00       104.00     24868.00       300.00      1388.00        72.00
--      184.00        12.00         0.00       340.00         0.00       396.00       196.00        40.00         8.00
--      116.00        16.00         4.00       132.00         0.00       156.00        12.00       832.00         0.00
--      464.00         8.00         8.00       372.00        48.00       240.00        20.00        28.00        16.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 0, global step 49: val_loss reached 0.30009 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=0.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.50      88.95      93.03     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         67.87      92.39      78.25      54804
--, (label_id: 3)                                         41.27      74.84      53.20      40800
--- (label_id: 4)                                         82.54      50.23      62.46       3464
--. (label_id: 5)                                         68.11      62.47      65.17      33424
--: (label_id: 6)                                         43.10      12.32      19.16        812
--? (label_id: 7)                                         64.81      24.75      35.82       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               86.36      86.36      86.36     659880
--macro avg                                               51.69      45.11      45.23     659880
--weighted avg                                            89.68      86.36      87.33     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   465264.00        28.00      4072.00      5152.00       888.00      1396.00       180.00       172.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--    23120.00         0.00     50632.00       256.00       564.00        20.00         0.00         8.00         0.00
--    30964.00       180.00        72.00     30536.00       212.00     10932.00       284.00       708.00       104.00
--      356.00         0.00         0.00         0.00      1740.00        12.00         0.00         0.00         0.00
--     3248.00       228.00        24.00      4672.00        60.00     20880.00       248.00      1240.00        56.00
--       16.00         0.00         0.00        24.00         0.00        92.00       100.00         0.00         0.00
--       88.00        36.00         4.00       160.00         0.00        92.00         0.00       700.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 1, global step 99: val_loss reached 0.33170 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.33-epoch=1.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.41      97.01      96.20     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         94.34      88.26      91.20      54804
--, (label_id: 3)                                         56.69      58.49      57.58      40800
--- (label_id: 4)                                         87.42      48.15      62.10       3464
--. (label_id: 5)                                         70.05      64.34      67.07      33424
--: (label_id: 6)                                         58.54      11.82      19.67        812
--? (label_id: 7)                                         55.41      36.92      44.31       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.53      91.53      91.53     659880
--macro avg                                               57.54      45.00      48.68     659880
--weighted avg                                            91.28      91.53      91.33     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   507420.00        60.00      6400.00     12064.00      1516.00      3824.00       220.00       276.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2776.00         0.00     48372.00         8.00        96.00        20.00         0.00         0.00         0.00
--     9396.00       160.00         8.00     23864.00       124.00      7724.00       232.00       508.00        80.00
--      240.00         0.00         0.00         0.00      1668.00         0.00         0.00         0.00         0.00
--     3024.00       192.00        20.00      4588.00        60.00     21504.00       256.00      1000.00        56.00
--        8.00         0.00         0.00         8.00         0.00        52.00        96.00         0.00         0.00
--      192.00        60.00         4.00       268.00         0.00       300.00         8.00      1044.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 2, global step 149: val_loss reached 0.31563 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.32-epoch=2.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.90      96.12      96.01     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         89.97      88.46      89.21      54804
--, (label_id: 3)                                         53.45      64.22      58.34      40800
--- (label_id: 4)                                         82.01      53.70      64.90       3464
--. (label_id: 5)                                         71.61      60.91      65.83      33424
--: (label_id: 6)                                         22.89      22.66      22.77        812
--? (label_id: 7)                                         66.35      29.28      40.63       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.03      91.03      91.03     659880
--macro avg                                               53.57      46.15      48.63     659880
--weighted avg                                            91.17      91.03      91.00     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   502752.00        56.00      6284.00     10168.00      1144.00      3256.00       196.00       308.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     5080.00         0.00     48480.00        36.00       268.00        20.00         0.00         0.00         0.00
--    12200.00       184.00        24.00     26200.00       148.00      9364.00       200.00       608.00        92.00
--      404.00         0.00         0.00         4.00      1860.00         0.00         0.00         0.00         0.00
--     2368.00       196.00        12.00      4080.00        44.00     20360.00       232.00      1072.00        68.00
--      160.00         4.00         0.00       164.00         0.00       280.00       184.00        12.00         0.00
--       92.00        32.00         4.00       148.00         0.00       144.00         0.00       828.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 3, global step 199: val_loss reached 0.31315 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.31-epoch=3.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.75      95.17      95.95     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         89.22      90.48      89.85      54804
--, (label_id: 3)                                         51.13      69.58      58.95      40800
--- (label_id: 4)                                         77.34      59.12      67.02       3464
--. (label_id: 5)                                         70.86      63.12      66.76      33424
--: (label_id: 6)                                         57.14       9.85      16.81        812
--? (label_id: 7)                                         58.43      35.79      44.39       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               90.92      90.92      90.92     659880
--macro avg                                               55.65      47.01      48.86     659880
--weighted avg                                            91.58      90.92      91.11     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   497780.00        44.00      5156.00      7900.00      1008.00      2248.00       148.00       156.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     5716.00         0.00     49584.00        60.00       180.00        32.00         0.00         0.00         0.00
--    15936.00       176.00        44.00     28388.00       180.00      9708.00       364.00       620.00       100.00
--      588.00         0.00         4.00         8.00      2048.00         0.00         0.00         0.00         0.00
--     2884.00       208.00        12.00      4220.00        48.00     21096.00       212.00      1032.00        60.00
--        0.00         0.00         0.00         8.00         0.00        44.00        80.00         8.00         0.00
--      152.00        44.00         4.00       216.00         0.00       296.00         8.00      1012.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 4, step 249: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.94      96.58      96.26     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         96.14      86.64      91.15      54804
--, (label_id: 3)                                         57.41      61.25      59.27      40800
--- (label_id: 4)                                         76.69      60.39      67.57       3464
--. (label_id: 5)                                         68.11      71.82      69.91      33424
--: (label_id: 6)                                         25.76      16.75      20.30        812
--? (label_id: 7)                                         57.68      39.32      46.76       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.68      91.68      91.68     659880
--macro avg                                               53.08      48.08      50.14     659880
--weighted avg                                            91.72      91.68      91.66     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   505172.00        48.00      7272.00      9648.00      1116.00      2808.00       196.00       196.00        68.00
--        0.00         0.00         0.00         4.00         0.00         0.00         0.00         0.00         0.00
--     1848.00         0.00     47484.00         8.00        28.00        20.00         0.00         0.00         0.00
--    11408.00       148.00        24.00     24992.00       172.00      6064.00       204.00       448.00        76.00
--      616.00         0.00        12.00         8.00      2092.00         0.00         0.00         0.00         0.00
--     3736.00       216.00         8.00      5828.00        56.00     24004.00       272.00      1056.00        68.00
--      124.00         4.00         0.00        88.00         0.00       152.00       136.00        16.00         8.00
--      152.00        56.00         4.00       224.00         0.00       376.00         4.00      1112.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 5, global step 299: val_loss reached 0.30916 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.31-epoch=5.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.63      96.00      96.31     523056
--! (label_id: 1)                                         66.67       1.69       3.31        472
--# (label_id: 2)                                         94.65      89.24      91.87      54804
--, (label_id: 3)                                         56.09      64.01      59.79      40800
--- (label_id: 4)                                         76.31      60.62      67.57       3464
--. (label_id: 5)                                         66.81      74.69      70.53      33424
--: (label_id: 6)                                         30.77      15.76      20.85        812
--? (label_id: 7)                                         67.66      35.22      46.33       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.74      91.74      91.74     659880
--macro avg                                               61.73      48.58      50.73     659880
--weighted avg                                            92.08      91.74      91.82     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   502128.00        52.00      5844.00      7976.00      1084.00      2108.00       192.00       188.00        60.00
--        0.00         8.00         0.00         4.00         0.00         0.00         0.00         0.00         0.00
--     2660.00         0.00     48908.00        16.00        68.00        20.00         0.00         0.00         0.00
--    13400.00       144.00        28.00     26116.00       156.00      6024.00       200.00       408.00        84.00
--      636.00         0.00        12.00         4.00      2100.00         0.00         0.00         0.00         0.00
--     4040.00       228.00         8.00      6476.00        56.00     24964.00       292.00      1224.00        76.00
--       72.00         4.00         0.00        76.00         0.00       124.00       128.00        12.00         0.00
--      120.00        36.00         4.00       132.00         0.00       184.00         0.00       996.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 6, global step 349: val_loss reached 0.29901 (best 0.29901), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=6.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.22      96.51      96.36     523056
--! (label_id: 1)                                         50.00       1.69       3.28        472
--# (label_id: 2)                                         94.99      88.69      91.73      54804
--, (label_id: 3)                                         58.33      60.13      59.21      40800
--- (label_id: 4)                                         76.36      60.05      67.23       3464
--. (label_id: 5)                                         67.13      74.43      70.59      33424
--: (label_id: 6)                                         29.60      18.23      22.56        812
--? (label_id: 7)                                         63.15      38.05      47.48       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.85      91.85      91.85     659880
--macro avg                                               59.53      48.64      50.94     659880
--weighted avg                                            91.90      91.85      91.82     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   504792.00        52.00      6164.00      9436.00      1132.00      2604.00       196.00       204.00        68.00
--        0.00         8.00         0.00         4.00         0.00         4.00         0.00         0.00         0.00
--     2464.00         0.00     48608.00        24.00        56.00        20.00         0.00         0.00         0.00
--    11076.00       136.00        12.00     24532.00       140.00      5508.00       184.00       396.00        76.00
--      624.00         0.00        12.00         8.00      2080.00         0.00         0.00         0.00         0.00
--     3876.00       228.00         8.00      6516.00        56.00     24876.00       284.00      1136.00        76.00
--       84.00         4.00         0.00        96.00         0.00       152.00       148.00        16.00         0.00
--      140.00        44.00         0.00       184.00         0.00       260.00         0.00      1076.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 7, global step 399: val_loss reached 0.29477 (best 0.29477), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.29-epoch=7.ckpt" as top 3
--[INFO] - Saving latest checkpoint...
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.001
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7ff309dcf1f0>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 4.7 M 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--13.0 M    Trainable params
--101 M     Non-trainable params
--114 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.42      96.72      96.57      80644
--! (label_id: 1)                                        100.00       2.04       4.00         98
--# (label_id: 2)                                         94.98      88.83      91.80       8270
--, (label_id: 3)                                         58.52      61.21      59.84       5934
--- (label_id: 4)                                         76.96      61.89      68.60        572
--. (label_id: 5)                                         68.39      74.94      71.51       5092
--: (label_id: 6)                                         27.91      20.34      23.53        118
--? (label_id: 7)                                         61.36      35.06      44.63        462
--… (label_id: 8)                                          0.00       0.00       0.00         38
---------------------
--micro avg                                               92.21      92.21      92.21     101228
--macro avg                                               64.95      49.00      51.17     101228
--weighted avg                                            92.29      92.21      92.16     101228
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    78002.00         8.00       918.00      1312.00       170.00       410.00        30.00        34.00        12.00
--        0.00         2.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      372.00         0.00      7346.00         6.00        10.00         0.00         0.00         0.00         0.00
--     1618.00        30.00         2.00      3632.00        26.00       800.00        24.00        62.00        12.00
--      104.00         0.00         2.00         0.00       354.00         0.00         0.00         0.00         0.00
--      510.00        48.00         2.00       936.00        12.00      3816.00        40.00       202.00        14.00
--       16.00         0.00         0.00        18.00         0.00        26.00        24.00         2.00         0.00
--       22.00        10.00         0.00        30.00         0.00        40.00         0.00       162.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00        858
---------------------
--micro avg                                              100.00     100.00     100.00        858
--macro avg                                              100.00     100.00     100.00        858
--weighted avg                                           100.00     100.00     100.00        858
--
---------------------
--           0
--      858.00
---------------------
--
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.70      94.08      95.86     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.41      91.56      91.98      54804
--, (label_id: 3)                                         54.08      65.15      59.10      40800
--- (label_id: 4)                                         45.58      75.06      56.72       3464
--. (label_id: 5)                                         64.27      82.86      72.39      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         48.94      68.32      57.02       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.09      91.09      91.09     659880
--macro avg                                               44.78      53.00      48.12     659880
--weighted avg                                            92.17      91.09      91.48     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   492100.00        24.00      4224.00      5312.00       620.00       972.00       224.00       160.00        44.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     4076.00         0.00     50176.00        16.00        16.00        12.00         0.00         0.00         0.00
--    17824.00       140.00        12.00     26580.00       152.00      3988.00       196.00       172.00        84.00
--     2804.00         0.00       248.00        36.00      2600.00        16.00         0.00         0.00         0.00
--     5728.00       256.00       136.00      8184.00        76.00     27696.00       372.00       564.00        84.00
--        0.00         0.00         0.00         0.00         0.00         8.00         0.00         0.00         0.00
--      524.00        52.00         8.00       672.00         0.00       732.00        20.00      1932.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 0, step 449: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.41      96.35      96.88     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         91.96      94.02      92.98      54804
--, (label_id: 3)                                         64.21      66.16      65.17      40800
--- (label_id: 4)                                         82.47      58.66      68.56       3464
--. (label_id: 5)                                         71.30      82.13      76.33      33424
--: (label_id: 6)                                          2.63       0.99       1.43        812
--? (label_id: 7)                                         60.28      67.19      63.55       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.03      93.03      93.03     659880
--macro avg                                               52.25      51.72      51.65     659880
--weighted avg                                            93.13      93.03      93.04     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   503984.00        60.00      3212.00      6736.00      1244.00      1548.00       212.00       328.00        56.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     4456.00         0.00     51528.00        16.00        24.00        12.00         0.00         0.00         0.00
--    10468.00       140.00        20.00     26992.00       136.00      3768.00       240.00       188.00        88.00
--      404.00         0.00        12.00        12.00      2032.00         4.00         0.00         0.00         0.00
--     3520.00       232.00        32.00      6420.00        28.00     27452.00       340.00       412.00        68.00
--       36.00         0.00         0.00       232.00         0.00        28.00         8.00         0.00         0.00
--      188.00        40.00         0.00       392.00         0.00       612.00        12.00      1900.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 1, step 499: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.66      94.87      95.76     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         73.52      98.98      84.37      54804
--, (label_id: 3)                                         65.92      59.67      62.64      40800
--- (label_id: 4)                                         82.48      50.00      62.26       3464
--. (label_id: 5)                                         78.47      72.58      75.41      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         64.87      64.78      64.83       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.32      91.32      91.32     659880
--macro avg                                               51.33      48.99      49.47     659880
--weighted avg                                            91.49      91.32      91.21     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   496212.00       116.00       536.00     12196.00       908.00      2632.00       292.00       364.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--    18644.00         0.00     54244.00       160.00       700.00        32.00         0.00         0.00         0.00
--     5632.00       136.00         8.00     24344.00       112.00      6032.00       280.00       296.00        88.00
--      216.00         0.00         0.00       140.00      1732.00        12.00         0.00         0.00         0.00
--     2204.00       196.00        16.00      3624.00        12.00     24260.00       212.00       336.00        56.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      148.00        24.00         0.00       336.00         0.00       456.00        28.00      1832.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 2, step 549: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.60      97.50      97.05     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         93.99      91.64      92.80      54804
--, (label_id: 3)                                         68.55      61.10      64.61      40800
--- (label_id: 4)                                         81.77      49.19      61.43       3464
--. (label_id: 5)                                         71.94      82.38      76.81      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         82.00      50.92      62.83       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.32      93.32      93.32     659880
--macro avg                                               54.98      48.08      50.61     659880
--weighted avg                                            93.04      93.32      93.11     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   510004.00        64.00      4520.00      9228.00      1444.00      2020.00       252.00       360.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2996.00         0.00     50220.00        92.00       108.00        16.00         0.00         0.00         0.00
--     6636.00       144.00        24.00     24928.00       188.00      3764.00       220.00       388.00        72.00
--      304.00         0.00        20.00        48.00      1704.00         8.00         0.00         0.00         0.00
--     3036.00       248.00        20.00      6364.00        20.00     27536.00       340.00       640.00        72.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--       80.00        16.00         0.00       140.00         0.00        80.00         0.00      1440.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 3, step 599: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.93      97.24      97.09     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         94.66      91.04      92.81      54804
--, (label_id: 3)                                         66.63      64.82      65.72      40800
--- (label_id: 4)                                         75.88      62.47      68.52       3464
--. (label_id: 5)                                         73.34      81.40      77.16      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         70.49      69.59      70.04       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.40      93.40      93.40     659880
--macro avg                                               53.10      51.84      52.37     659880
--weighted avg                                            93.23      93.40      93.30     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508644.00        56.00      4712.00      8096.00      1072.00      1648.00       216.00       220.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2504.00         0.00     49892.00       252.00        44.00        16.00         0.00         0.00         0.00
--     8032.00       164.00        52.00     26448.00       168.00      4252.00       268.00       236.00        72.00
--      560.00         0.00       108.00         4.00      2164.00        16.00         0.00         0.00         0.00
--     3152.00       228.00        40.00      5656.00        16.00     27208.00       320.00       404.00        72.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      164.00        24.00         0.00       344.00         0.00       284.00         8.00      1968.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 4, step 649: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.34      96.76      97.05     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.54      93.20      92.87      54804
--, (label_id: 3)                                         64.62      68.42      66.47      40800
--- (label_id: 4)                                         82.26      58.89      68.64       3464
--. (label_id: 5)                                         74.47      80.59      77.41      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         69.26      71.71      70.47       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.36      93.36      93.36     659880
--macro avg                                               53.39      52.17      52.54     659880
--weighted avg                                            93.34      93.36      93.33     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   506088.00        44.00      3608.00      7132.00      1100.00      1496.00       172.00       204.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     3760.00         0.00     51080.00       244.00        92.00        20.00         0.00         0.00         0.00
--     9524.00       176.00        44.00     27916.00       216.00      4680.00       320.00       232.00        92.00
--      396.00         0.00        28.00         4.00      2040.00        12.00         0.00         0.00         0.00
--     3032.00       228.00        44.00      5172.00        16.00     26936.00       312.00       364.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      256.00        24.00         0.00       332.00         0.00       280.00         8.00      2028.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 5, step 699: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.17      97.08      97.12     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.93      92.96      92.95      54804
--, (label_id: 3)                                         66.75      65.61      66.17      40800
--- (label_id: 4)                                         75.56      66.40      70.68       3464
--. (label_id: 5)                                         74.11      81.07      77.43      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         72.03      70.30      71.15       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.48      93.48      93.48     659880
--macro avg                                               53.17      52.60      52.83     659880
--weighted avg                                            93.32      93.48      93.39     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   507784.00        56.00      3732.00      7964.00       892.00      1656.00       216.00       220.00        68.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     3532.00         0.00     50948.00       244.00        84.00        16.00         0.00         0.00         0.00
--     8000.00       148.00        44.00     26768.00       172.00      4380.00       284.00       220.00        88.00
--      652.00         0.00        60.00        12.00      2300.00        20.00         0.00         0.00         0.00
--     2912.00       244.00        20.00      5504.00        16.00     27096.00       304.00       400.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      176.00        24.00         0.00       308.00         0.00       256.00         8.00      1988.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 6, step 749: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.17      97.07      97.12     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.94      92.98      92.96      54804
--, (label_id: 3)                                         66.60      66.25      66.42      40800
--- (label_id: 4)                                         75.19      66.86      70.78       3464
--. (label_id: 5)                                         74.75      80.94      77.72      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         73.88      70.01      71.90       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.51      93.51      93.51     659880
--macro avg                                               53.39      52.68      52.99     659880
--weighted avg                                            93.36      93.51      93.43     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   507744.00        56.00      3724.00      7944.00       876.00      1664.00       220.00       220.00        68.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     3528.00         0.00     50956.00       244.00        84.00        16.00         0.00         0.00         0.00
--     8112.00       152.00        44.00     27028.00       172.00      4464.00       292.00       232.00        88.00
--      672.00         0.00        60.00        12.00      2316.00        20.00         0.00         0.00         0.00
--     2832.00       240.00        20.00      5280.00        16.00     27052.00       292.00       396.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      168.00        24.00         0.00       292.00         0.00       208.00         8.00      1980.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 7, step 799: val_loss was not in top 3
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.0004
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7ff29c24fa60>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 4.7 M 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--20.1 M    Trainable params
--94.7 M    Non-trainable params
--114 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.30      97.36      97.33      80644
--! (label_id: 1)                                          0.00       0.00       0.00         98
--# (label_id: 2)                                         92.84      93.11      92.97       8270
--, (label_id: 3)                                         66.91      67.21      67.06       5934
--- (label_id: 4)                                         77.08      68.18      72.36        572
--. (label_id: 5)                                         76.94      80.60      78.73       5092
--: (label_id: 6)                                          0.00       0.00       0.00        118
--? (label_id: 7)                                         76.61      72.29      74.39        462
--… (label_id: 8)                                          0.00       0.00       0.00         38
---------------------
--micro avg                                               93.88      93.88      93.88     101228
--macro avg                                               54.19      53.19      53.65     101228
--weighted avg                                            93.68      93.88      93.77     101228
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    78518.00        10.00       552.00      1142.00       140.00       256.00        32.00        36.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      544.00         0.00      7700.00        38.00        12.00         0.00         0.00         0.00         0.00
--     1122.00        32.00         4.00      3988.00        28.00       698.00        42.00        32.00        14.00
--      102.00         0.00        12.00         0.00       390.00         2.00         0.00         0.00         0.00
--      340.00        50.00         2.00       722.00         2.00      4104.00        42.00        60.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--       18.00         6.00         0.00        44.00         0.00        32.00         2.00       334.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00        858
---------------------
--micro avg                                              100.00     100.00     100.00        858
--macro avg                                              100.00     100.00     100.00        858
--weighted avg                                           100.00     100.00     100.00        858
--
---------------------
--           0
--      858.00
---------------------
--
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.70      97.18      96.94     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         90.59      92.02      91.30      54804
--, (label_id: 3)                                         65.34      65.67      65.50      40800
--- (label_id: 4)                                         85.28      45.50      59.34       3464
--. (label_id: 5)                                         76.92      76.16      76.54      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         67.59      62.23      64.80       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.10      93.10      93.10     659880
--macro avg                                               53.60      48.75      50.49     659880
--weighted avg                                            92.84      93.10      92.94     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508300.00        60.00      4336.00      9072.00      1240.00      2136.00       204.00       252.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     4560.00         0.00     50432.00       212.00       436.00        32.00         0.00         0.00         0.00
--     7488.00       172.00         8.00     26792.00       200.00      5416.00       384.00       436.00       108.00
--      256.00         0.00        12.00         4.00      1576.00         0.00         0.00         0.00         0.00
--     2240.00       216.00        16.00      4512.00        12.00     25456.00       216.00       380.00        44.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      212.00        24.00         0.00       208.00         0.00       384.00         8.00      1760.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 0, step 849: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.12      98.10      96.59     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         93.92      90.84      92.36      54804
--, (label_id: 3)                                         71.82      48.62      57.98      40800
--- (label_id: 4)                                         75.00      55.08      63.52       3464
--. (label_id: 5)                                         72.29      78.12      75.09      33424
--: (label_id: 6)                                        100.00       0.49       0.98        812
--? (label_id: 7)                                         86.41      35.08      49.90       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               92.71      92.71      92.71     659880
--macro avg                                               66.06      45.15      48.49     659880
--weighted avg                                            92.19      92.71      92.17     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   513120.00       140.00      4940.00     15176.00      1240.00      3752.00       372.00       596.00       104.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2864.00         0.00     49784.00        84.00       232.00        40.00         0.00         0.00         0.00
--     3644.00        64.00         0.00     19836.00        76.00      3500.00       168.00       276.00        56.00
--      560.00         0.00        60.00        16.00      1908.00         0.00         0.00         0.00         0.00
--     2820.00       252.00        20.00      5616.00         8.00     26112.00       268.00       964.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         4.00         0.00         0.00
--       48.00        16.00         0.00        72.00         0.00        20.00         0.00       992.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 1, step 899: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          94.93      95.85      95.39     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         98.21      69.76      81.58      54804
--, (label_id: 3)                                         54.91      72.97      62.66      40800
--- (label_id: 4)                                         86.86      27.48      41.75       3464
--. (label_id: 5)                                         66.94      75.06      70.77      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                        100.00       1.56       3.06       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               90.23      90.23      90.23     659880
--macro avg                                               55.76      38.08      39.47     659880
--weighted avg                                            91.07      90.23      90.08     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   501340.00        48.00     16152.00      6100.00      2028.00      1720.00       188.00       488.00        52.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      476.00         0.00     38232.00        24.00       176.00        20.00         0.00         0.00         0.00
--    15484.00       220.00       100.00     29772.00       252.00      6596.00       360.00      1348.00        88.00
--      136.00         0.00         8.00         0.00       952.00         0.00         0.00         0.00         0.00
--     5620.00       204.00       312.00      4904.00        56.00     25088.00       264.00       948.00        80.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00        44.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 2, step 949: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.95      94.26      95.58     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         88.08      93.86      90.88      54804
--, (label_id: 3)                                         59.30      62.47      60.85      40800
--- (label_id: 4)                                         43.12      67.32      52.57       3464
--. (label_id: 5)                                         70.00      76.39      73.06      33424
--: (label_id: 6)                                          0.91       5.42       1.56        812
--? (label_id: 7)                                         55.40      63.08      58.99       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               90.87      90.87      90.87     659880
--macro avg                                               45.97      51.42      48.17     659880
--weighted avg                                            91.84      90.87      91.31     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   493028.00        76.00      2376.00      9040.00       652.00      2780.00       252.00       280.00        72.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     6864.00         0.00     51440.00        16.00        68.00         4.00         0.00         8.00         0.00
--    11812.00       120.00       108.00     25488.00       156.00      4628.00       268.00       324.00        76.00
--     2344.00         0.00       504.00       212.00      2332.00        16.00         0.00         0.00         0.00
--     4468.00       256.00       144.00      5276.00        72.00     25532.00       244.00       412.00        68.00
--     3964.00         4.00       212.00       368.00       176.00        56.00        44.00        20.00         0.00
--      576.00        16.00        20.00       400.00         8.00       408.00         4.00      1784.00         4.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 3, step 999: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.73      96.49      96.61     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         97.10      88.69      92.71      54804
--, (label_id: 3)                                         61.91      66.92      64.32      40800
--- (label_id: 4)                                         62.18      61.32      61.74       3464
--. (label_id: 5)                                         71.48      77.96      74.58      33424
--: (label_id: 6)                                          4.21       1.97       2.68        812
--? (label_id: 7)                                         54.34      71.71      61.83       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               92.57      92.57      92.57     659880
--macro avg                                               49.77      51.67      50.50     659880
--weighted avg                                            92.75      92.57      92.63     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   504696.00        68.00      5900.00      7576.00      1048.00      1924.00       240.00       236.00        52.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1396.00         0.00     48608.00        20.00        24.00        12.00         0.00         0.00         0.00
--    10964.00       132.00        64.00     27304.00       216.00      4920.00       236.00       192.00        72.00
--     1020.00         0.00       132.00       128.00      2124.00        12.00         0.00         0.00         0.00
--     4196.00       248.00        88.00      5064.00        40.00     26056.00       304.00       372.00        84.00
--      200.00         0.00         8.00       152.00         0.00         4.00        16.00         0.00         0.00
--      584.00        24.00         4.00       556.00        12.00       496.00        16.00      2028.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 4, step 1049: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          94.84      98.08      96.43     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         98.53      81.48      89.20      54804
--, (label_id: 3)                                         67.47      60.25      63.66      40800
--- (label_id: 4)                                         65.13      58.89      61.86       3464
--. (label_id: 5)                                         77.35      72.15      74.66      33424
--: (label_id: 6)                                          6.67       2.46       3.60        812
--? (label_id: 7)                                         66.26      60.82      63.42       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               92.46      92.46      92.46     659880
--macro avg                                               52.92      48.24      50.31     659880
--weighted avg                                            92.08      92.46      92.17     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   513024.00        92.00      9884.00     11672.00      1184.00      4168.00       344.00       472.00        84.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      600.00         0.00     44652.00        20.00        28.00        16.00         0.00         0.00         0.00
--     6192.00       148.00        32.00     24584.00       132.00      4776.00       208.00       272.00        92.00
--      828.00         0.00       204.00        60.00      2040.00         0.00         0.00         0.00         0.00
--     2096.00       216.00        32.00      4068.00        16.00     24116.00       236.00       364.00        32.00
--      168.00         0.00         0.00        40.00        64.00         8.00        20.00         0.00         0.00
--      148.00        16.00         0.00       356.00         0.00       340.00         4.00      1720.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 5, step 1099: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.42      97.26      96.84     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         96.89      90.07      93.36      54804
--, (label_id: 3)                                         64.67      65.10      64.88      40800
--- (label_id: 4)                                         61.01      63.97      62.46       3464
--. (label_id: 5)                                         75.87      75.59      75.73      33424
--: (label_id: 6)                                         14.29       2.46       4.20        812
--? (label_id: 7)                                         59.57      67.33      63.21       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.05      93.05      93.05     659880
--macro avg                                               52.08      51.31      51.19     659880
--weighted avg                                            92.91      93.05      92.96     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508716.00        68.00      5096.00      8936.00      1036.00      3024.00       280.00       372.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1492.00         0.00     49364.00        32.00        36.00        24.00         0.00         0.00         0.00
--     9016.00       172.00        36.00     26560.00       132.00      4504.00       284.00       264.00       104.00
--     1076.00         0.00       276.00        64.00      2216.00         0.00         0.00         0.00         0.00
--     2492.00       216.00        32.00      4728.00        24.00     25264.00       216.00       288.00        40.00
--       60.00         0.00         0.00        40.00        12.00         8.00        20.00         0.00         0.00
--      204.00        16.00         0.00       440.00         8.00       600.00        12.00      1904.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 6, step 1149: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.49      97.24      96.86     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         96.73      90.36      93.44      54804
--, (label_id: 3)                                         64.80      65.04      64.92      40800
--- (label_id: 4)                                         64.12      62.12      63.11       3464
--. (label_id: 5)                                         75.35      76.33      75.84      33424
--: (label_id: 6)                                         22.73       2.46       4.44        812
--? (label_id: 7)                                         58.91      68.74      63.45       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.09      93.09      93.09     659880
--macro avg                                               53.24      51.37      51.34     659880
--weighted avg                                            92.95      93.09      93.00     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508616.00        72.00      4992.00      8792.00      1104.00      2864.00       280.00       364.00        56.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1572.00         0.00     49520.00        40.00        36.00        24.00         0.00         0.00         0.00
--     9072.00       152.00        36.00     26536.00       128.00      4416.00       280.00       240.00        88.00
--      920.00         0.00       224.00        60.00      2152.00         0.00         0.00         0.00         0.00
--     2604.00       224.00        32.00      4892.00        28.00     25512.00       220.00       280.00        64.00
--       28.00         0.00         0.00        24.00         8.00         8.00        20.00         0.00         0.00
--      244.00        24.00         0.00       456.00         8.00       600.00        12.00      1944.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 7, step 1199: val_loss was not in top 3
--[INFO] - GPU available: True, used: True
--[INFO] - TPU available: None, using: 0 TPU cores
--[INFO] - Using environment variable NODE_RANK for node rank (0).
--[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.25      97.27      96.76     650284
--! (label_id: 1)                                          0.00       0.00       0.00        380
--# (label_id: 2)                                         97.23      89.79      93.36      68496
--, (label_id: 3)                                         62.58      64.85      63.69      52348
--- (label_id: 4)                                         49.90      60.65      54.75       3212
--. (label_id: 5)                                         79.01      73.40      76.10      46276
--: (label_id: 6)                                         20.00       2.25       4.05        888
--? (label_id: 7)                                         60.00      67.50      63.53       4000
--… (label_id: 8)                                          0.00       0.00       0.00        260
---------------------
--micro avg                                               92.79      92.79      92.79     826144
--macro avg                                               51.66      50.63      50.25     826144
--weighted avg                                            92.72      92.79      92.72     826144
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   632504.00        36.00      6712.00     12044.00      1116.00      3904.00       244.00       476.00       108.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1596.00         0.00     61504.00        28.00        52.00        76.00         0.00         0.00         0.00
--    11756.00       140.00         8.00     33948.00        68.00      7492.00       300.00       432.00       104.00
--     1636.00         0.00       232.00        36.00      1948.00        52.00         0.00         0.00         0.00
--     2480.00       180.00        28.00      5584.00        16.00     33968.00       304.00       392.00        40.00
--       20.00         0.00         0.00        28.00        12.00        20.00        20.00         0.00         0.00
--      292.00        24.00        12.00       680.00         0.00       764.00        20.00      2700.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Chunked Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.57      97.15      96.86     327564
--! (label_id: 1)                                          0.00       0.00       0.00        184
--# (label_id: 2)                                         97.23      90.48      93.73      34404
--, (label_id: 3)                                         63.38      67.07      65.18      26324
--- (label_id: 4)                                         50.74      63.34      56.35       1724
--. (label_id: 5)                                         80.87      76.47      78.61      23376
--: (label_id: 6)                                          8.33       0.88       1.59        456
--? (label_id: 7)                                         59.61      72.62      65.47       2016
--… (label_id: 8)                                          0.00       0.00       0.00         92
---------------------
--micro avg                                               93.10      93.10      93.10     416140
--macro avg                                               50.75      52.00      50.86     416140
--weighted avg                                            93.12      93.10      93.08     416140
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   318220.00        20.00      3140.00      5728.00       532.00      1500.00       124.00       184.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      788.00         0.00     31128.00         8.00        32.00        60.00         0.00         0.00         0.00
--     6236.00        84.00         0.00     17656.00        48.00      3444.00       144.00       220.00        24.00
--      872.00         0.00       128.00        16.00      1092.00        44.00         0.00         0.00         0.00
--     1240.00        72.00         8.00      2568.00        16.00     17876.00       168.00       148.00         8.00
--       16.00         0.00         0.00         4.00         4.00        20.00         4.00         0.00         0.00
--      192.00         8.00         0.00       344.00         0.00       432.00        16.00      1464.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       6884
---------------------
--micro avg                                              100.00     100.00     100.00       6884
--macro avg                                              100.00     100.00     100.00       6884
--weighted avg                                           100.00     100.00     100.00       6884
--
---------------------
--           0
--     6884.00
---------------------
--
--[INFO] - saving to /home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/test.txt
--[INFO] - Internal process exited
-diff --git a/experiment/outputs/2021-02-23/08-18-26/testing.log b/experiment/outputs/2021-02-23/08-18-26/testing.log
-index f00f863..2597221 100644
---- a/experiment/outputs/2021-02-23/08-18-26/testing.log
-+++ b/experiment/outputs/2021-02-23/08-18-26/testing.log
-@@ -1 +1,74 @@
- [2021-02-23 08:18:38,771][root][INFO] - shuffling train set
-+[2021-02-23 08:44:12,424][root][INFO] - Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          95.20      95.06      95.13   33617452
-+! (label_id: 1)                                         21.65      40.73      28.27     578585
-+# (label_id: 2)                                         89.63      94.36      91.93    6976446
-+, (label_id: 3)                                         52.02      49.20      50.57    2858145
-+- (label_id: 4)                                         52.90      37.64      43.98     255633
-+. (label_id: 5)                                         67.03      64.56      65.77    5425019
-+: (label_id: 6)                                          0.00       0.00       0.00      15576
-+? (label_id: 7)                                         66.11      48.89      56.21    1415356
-+… (label_id: 8)                                         28.23      27.42      27.82     482702
-+-------------------
-+micro avg                                               86.40      86.40      86.40   51624912
-+macro avg                                               52.53      50.87      51.07   51624912
-+weighted avg                                            86.61      86.40      86.42   51624912
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 31955872.00     33316.00    385671.00    438274.00     53505.00    443163.00      7682.00    120484.00    128329.00
-+    66565.00    235635.00       761.00    176016.00      8738.00    506812.00       944.00     64244.00     28918.00
-+   714124.00       536.00   6582626.00      7720.00     19841.00     15709.00      1649.00      1336.00      1001.00
-+   288086.00     97827.00       833.00   1406100.00     11576.00    706306.00       912.00    121425.00     69959.00
-+    56237.00      2410.00       944.00      5163.00     96209.00     18095.00        96.00      1041.00      1680.00
-+   390319.00    174383.00      3985.00    635086.00     21274.00   3502327.00      3717.00    389488.00    104418.00
-+        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-+    75395.00     24645.00       937.00     80919.00      3444.00    153187.00       136.00    691913.00     16045.00
-+    70772.00      9833.00       689.00    108867.00     41046.00     79420.00       440.00     25425.00    132352.00
-+-------------------
-+
-+[2021-02-23 08:44:12,434][root][INFO] - Chunked Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          95.59      96.37      95.98   16876740
-+! (label_id: 1)                                         21.47      41.98      28.41     290645
-+# (label_id: 2)                                         95.04      95.14      95.09    3541392
-+, (label_id: 3)                                         52.20      49.91      51.03    1447727
-+- (label_id: 4)                                         53.56      38.01      44.47     130953
-+. (label_id: 5)                                         68.20      65.03      66.58    2759312
-+: (label_id: 6)                                          0.00       0.00       0.00       7645
-+? (label_id: 7)                                         66.66      50.42      57.42     716850
-+… (label_id: 8)                                         28.64      27.84      28.23     243286
-+-------------------
-+micro avg                                               87.46      87.46      87.46   26014552
-+macro avg                                               53.49      51.63      51.91   26014552
-+weighted avg                                            87.71      87.46      87.50   26014552
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 16264699.00     14196.00    169436.00    215171.00     26620.00    202508.00      3785.00     54437.00     63531.00
-+    33928.00    122012.00       272.00     91962.00      4505.00    266896.00       504.00     33168.00     15114.00
-+   151602.00       248.00   3369444.00      3788.00     10412.00      7913.00       881.00       624.00       328.00
-+   147638.00     49831.00       344.00    722501.00      5999.00    360923.00       448.00     60458.00     35874.00
-+    28414.00      1192.00       464.00      2722.00     49780.00      8964.00        32.00       537.00       840.00
-+   177113.00     85795.00      1072.00    314405.00     10733.00   1794350.00      1747.00    194183.00     51583.00
-+        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-+    37372.00     12602.00       168.00     41387.00      1825.00     79031.00        64.00    361456.00      8297.00
-+    35974.00      4769.00       192.00     55791.00     21079.00     38727.00       184.00     11987.00     67719.00
-+-------------------
-+
-+[2021-02-23 08:44:12,439][root][INFO] - Domain report: 
-+label                                                precision    recall       f1           support   
-+0 (label_id: 0)                                        100.00     100.00     100.00     411653
-+-------------------
-+micro avg                                              100.00     100.00     100.00     411653
-+macro avg                                              100.00     100.00     100.00     411653
-+weighted avg                                           100.00     100.00     100.00     411653
-+
-+-------------------
-+           0
-+   411653.00
-+-------------------
-+
-+[2021-02-23 08:44:12,439][root][INFO] - saving to /home/nxingyu/project/Punctuation_with_Domain_discriminator/opendice33acc42021-02-22_09-49-04//test.txt
-+[2021-02-23 08:44:12,539][wandb.sdk.internal.internal][INFO] - Internal process exited
-diff --git a/experiment/outputs/2021-02-23/08-20-55/testing.log b/experiment/outputs/2021-02-23/08-20-55/testing.log
-index 717645a..7100fd1 100644
---- a/experiment/outputs/2021-02-23/08-20-55/testing.log
-+++ b/experiment/outputs/2021-02-23/08-20-55/testing.log
-@@ -1 +1,74 @@
- [2021-02-23 08:21:08,018][root][INFO] - shuffling train set
-+[2021-02-23 09:05:21,673][root][INFO] - Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          94.88      97.99      96.41   33617452
-+! (label_id: 1)                                         33.89       9.66      15.04     578585
-+# (label_id: 2)                                         99.49      99.10      99.30    6976446
-+, (label_id: 3)                                         52.51      39.66      45.19    2858145
-+- (label_id: 4)                                         56.89      22.57      32.32     255633
-+. (label_id: 5)                                         62.04      77.10      68.76    5425019
-+: (label_id: 6)                                         77.05      41.40      53.86      15576
-+? (label_id: 7)                                         70.01      36.10      47.64    1415356
-+… (label_id: 8)                                         57.21       6.15      11.10     482702
-+-------------------
-+micro avg                                               88.78      88.78      88.78   51624912
-+macro avg                                               67.11      47.75      52.18   51624912
-+weighted avg                                            87.80      88.78      87.68   51624912
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 32940746.00     42247.00     56263.00    637305.00    117974.00    572846.00      3579.00    174660.00    172542.00
-+    10770.00     55899.00        88.00     35948.00      1672.00     46823.00       184.00      8367.00      5210.00
-+    27771.00       545.00   6913637.00      1128.00      1968.00      2819.00        16.00       480.00       560.00
-+   163910.00    113876.00       544.00   1133679.00     17942.00    526536.00       840.00    121929.00     79630.00
-+    19931.00      1771.00       104.00      4132.00     57687.00     14847.00        40.00       600.00      2282.00
-+   403834.00    347864.00      5066.00    988029.00     38393.00   4182951.00      4372.00    597272.00    174593.00
-+      608.00         0.00         0.00       505.00       360.00       288.00      6449.00        32.00       128.00
-+    48028.00     16247.00       712.00     54579.00      4683.00     76459.00        80.00    510999.00     18088.00
-+     1745.00       136.00        32.00      2840.00     14954.00      1450.00        16.00      1017.00     29669.00
-+-------------------
-+
-+[2021-02-23 09:05:21,682][root][INFO] - Chunked Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          95.08      98.11      96.57   16876740
-+! (label_id: 1)                                         33.70      10.09      15.54     290645
-+# (label_id: 2)                                         99.61      99.52      99.57    3541392
-+, (label_id: 3)                                         52.66      40.24      45.62    1447727
-+- (label_id: 4)                                         57.66      22.91      32.79     130953
-+. (label_id: 5)                                         62.89      77.75      69.53    2759312
-+: (label_id: 6)                                         78.52      42.08      54.79       7645
-+? (label_id: 7)                                         70.98      37.06      48.70     716850
-+… (label_id: 8)                                         58.27       6.35      11.46     243286
-+-------------------
-+micro avg                                               89.00      89.00      89.00   26014552
-+macro avg                                               67.71      48.24      52.73   26014552
-+weighted avg                                            88.03      89.00      87.92   26014552
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 16557577.00     19231.00     15829.00    319520.00     60251.00    272070.00      1746.00     82502.00     86301.00
-+     5837.00     29340.00        16.00     18850.00       800.00     24913.00       120.00      4276.00      2921.00
-+    11597.00        88.00   3524547.00       280.00       800.00       737.00         8.00        88.00        96.00
-+    83677.00     57621.00       136.00    582598.00      9566.00    269820.00       440.00     61935.00     40462.00
-+    10150.00       904.00        56.00      2011.00     29998.00      7605.00        16.00       240.00      1049.00
-+   183939.00    175228.00       744.00    495087.00     19564.00   2145232.00      2058.00    301633.00     87509.00
-+      176.00         0.00         0.00       296.00       128.00       168.00      3217.00        16.00        96.00
-+    22954.00      8169.00        64.00     27597.00      2353.00     38063.00        32.00    265680.00      9397.00
-+      833.00        64.00         0.00      1488.00      7493.00       704.00         8.00       480.00     15455.00
-+-------------------
-+
-+[2021-02-23 09:05:21,687][root][INFO] - Domain report: 
-+label                                                precision    recall       f1           support   
-+0 (label_id: 0)                                        100.00     100.00     100.00     411653
-+-------------------
-+micro avg                                              100.00     100.00     100.00     411653
-+macro avg                                              100.00     100.00     100.00     411653
-+weighted avg                                           100.00     100.00     100.00     411653
-+
-+-------------------
-+           0
-+   411653.00
-+-------------------
-+
-+[2021-02-23 09:05:21,688][root][INFO] - saving to /home/nxingyu/project/Punctuation_with_Domain_discriminator/opencrfacc42021-02-22_09-48-50//test.txt
-+[2021-02-23 09:05:21,785][wandb.sdk.internal.internal][INFO] - Internal process exited
-diff --git a/experiment/testing.py b/experiment/testing.py
-index 3e967b0..77f95ad 100644
---- a/experiment/testing.py
-+++ b/experiment/testing.py
-@@ -1,3 +1,8 @@
-+
-+
-+
-+
-+
- #%%
- import hydra
- import numpy as np
-@@ -20,7 +25,7 @@ import atexit
- from copy import deepcopy
- import snoop
- snoop.install()
--exp='opencrfacc42021-02-22_09-48-50'
-+exp='2021-02-23_09-59-35'
- @hydra.main(config_path=f"../Punctuation_with_Domain_discriminator/{exp}/",config_name="hparams.yaml")
- def main(cfg : DictConfig) -> None:
-     torch.set_printoptions(sci_mode=False)
-@@ -41,7 +46,7 @@ def main(cfg : DictConfig) -> None:
-                     max_seq_length=model.dm.max_seq_length,
-                     punct_label_ids=model.dm.punct_label_ids,
-                     label_map=model.dm.label_map,
--                    labelled=['/home/nxingyu/data/open_subtitles_processed'],
-+                    labelled=['/home/nxingyu/data/ted_talks_processed'],
-                     unlabelled=[],
-                     tokenizer=model.dm.tokenizer,
-                     randomize=model.dm.val_shuffle,
-@@ -49,7 +54,7 @@ def main(cfg : DictConfig) -> None:
-                     tmp_path=model.dm.tmp_path,
-                     attach_label_to_end=model.dm.attach_label_to_end,
-                     no_space_label=model.dm.no_space_label,
--                    pad_start=0,
-+                    pad_start=model.dm.pad_start,
-                     )
-     model.hparams.log_dir=f"/home/nxingyu/project/Punctuation_with_Domain_discriminator/{exp}/"
-     trainer = pl.Trainer(**cfg.trainer)
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/hparams.yaml b/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/hparams.yaml
deleted file mode 100644
index 9a31646..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/hparams.yaml
+++ /dev/null
@@ -1,127 +0,0 @@
-seed: 42
-trainer:
-  gpus: 1
-  num_nodes: 1
-  max_epochs: 8
-  max_steps: null
-  accumulate_grad_batches: 4
-  gradient_clip_val: 0
-  amp_level: O1
-  precision: 16
-  accelerator: ddp
-  checkpoint_callback: false
-  logger: false
-  log_every_n_steps: 1
-  val_check_interval: 1.0
-  resume_from_checkpoint: null
-exp_manager:
-  exp_dir: /home/nxingyu/project/
-  name: Punctuation_with_Domain_discriminator
-  create_tensorboard_logger: true
-  create_checkpoint_callback: true
-base_path: /home/nxingyu/data
-tmp_path: /home/nxingyu/data/tmp
-log_dir: /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53
-model:
-  nemo_path: null
-  transformer_path: google/electra-base-discriminator
-  unfrozen: 0
-  maximum_unfrozen: 2
-  unfreeze_step: 1
-  punct_label_ids:
-  - ''
-  - ','
-  - .
-  - '?'
-  - '-'
-  - '!'
-  - ':'
-  - …
-  label_map:
-    —: ','
-    ;: .
-  no_space_label: '#'
-  test_chunk_percent: 0.5
-  pad_start_and_end: 0
-  punct_class_weights: false
-  dataset:
-    data_dir: /home/nxingyu/data
-    labelled:
-    - /home/nxingyu/data/ted_talks_processed
-    unlabelled: null
-    max_seq_length: 128
-    pad_label: ''
-    ignore_extra_tokens: false
-    ignore_start_end: false
-    use_cache: false
-    num_workers: 8
-    pin_memory: false
-    drop_last: true
-    num_labels: 9
-    num_domains: 2
-    test_unlabelled: true
-    attach_label_to_end: null
-    pad_start: 64
-    train_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 16
-      manual_len: 20000
-    validation_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 16
-  tokenizer:
-    tokenizer_name: google/electra-base-discriminator
-    vocab_file: null
-    tokenizer_model: null
-    special_tokens: null
-  language_model:
-    pretrained_model_name: google/electra-base-discriminator
-    lm_checkpoint: null
-    config_file: null
-    config: null
-  punct_head:
-    punct_num_fc_layers: 3
-    fc_dropout: 0.1
-    activation: gelu
-    log_softmax: false
-    use_transformer_init: true
-    loss: dice
-    bilstm: false
-  domain_head:
-    domain_num_fc_layers: 3
-    fc_dropout: 0.1
-    activation: relu
-    log_softmax: false
-    use_transformer_init: true
-    loss: cel
-    gamma: 0.01
-    pooling: mean_max
-    idx_conditioned_on: 0
-  dice_loss:
-    epsilon: 0.01
-    alpha: 1
-    macro_average: true
-  focal_loss:
-    gamma: 3
-  frozen_lr:
-  - 0.02
-  - 0.001
-  - 0.0004
-  - 0.0001
-  - 1.0e-05
-  - 1.0e-06
-  - 1.0e-07
-  optim:
-    name: adamw
-    lr: 0.01
-    weight_decay: 0.0
-    sched:
-      name: CosineAnnealing
-      warmup_steps: null
-      warmup_ratio: 0.1
-      min_lr: 1.0e-08
-      last_epoch: -1
-      monitor: val_loss
-      reduce_on_plateau: false
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/lightning_logs.txt b/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/lightning_logs.txt
deleted file mode 100644
index 16f43eb..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/lightning_logs.txt
+++ /dev/null
@@ -1,81 +0,0 @@
-Global seed set to 42
-GPU available: True, used: True
-TPU available: None, using: 0 TPU cores
-LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
-Using native 16bit precision.
-Global seed set to 42
-initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 1.2 M 
-2 | domain_classifier          | SequenceClassifier   | 4.7 M 
-3 | punctuation_loss           | FocalDiceLoss        | 0     
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-5.9 M     Trainable params
-108 M     Non-trainable params
-114 M     Total params
-Epoch 0, global step 49: val_loss reached 0.48610 (best 0.48610), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.49-epoch=0.ckpt" as top 3
-Epoch 1, global step 99: val_loss reached 0.55032 (best 0.48610), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.55-epoch=1.ckpt" as top 3
-Epoch 2, global step 149: val_loss reached 0.51516 (best 0.48610), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.52-epoch=2.ckpt" as top 3
-Epoch 3, global step 199: val_loss reached 0.54436 (best 0.48610), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.54-epoch=3.ckpt" as top 3
-Epoch 4, global step 249: val_loss reached 0.52642 (best 0.48610), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.53-epoch=4.ckpt" as top 3
-Epoch 5, global step 299: val_loss reached 0.52050 (best 0.48610), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.52-epoch=5.ckpt" as top 3
-Epoch 6, global step 349: val_loss reached 0.51866 (best 0.48610), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.52-epoch=6.ckpt" as top 3
-Epoch 7, step 399: val_loss was not in top 3
-Saving latest checkpoint...
-Global seed set to 42
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 1.2 M 
-2 | domain_classifier          | SequenceClassifier   | 4.7 M 
-3 | punctuation_loss           | FocalDiceLoss        | 0     
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-13.0 M    Trainable params
-101 M     Non-trainable params
-114 M     Total params
-Epoch 0, step 449: val_loss was not in top 3
-Epoch 1, step 499: val_loss was not in top 3
-Epoch 2, step 549: val_loss was not in top 3
-Epoch 3, step 599: val_loss was not in top 3
-Epoch 4, step 649: val_loss was not in top 3
-Epoch 5, step 699: val_loss was not in top 3
-Epoch 6, step 749: val_loss was not in top 3
-Epoch 7, step 799: val_loss was not in top 3
-Global seed set to 42
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 1.2 M 
-2 | domain_classifier          | SequenceClassifier   | 4.7 M 
-3 | punctuation_loss           | FocalDiceLoss        | 0     
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-20.1 M    Trainable params
-94.7 M    Non-trainable params
-114 M     Total params
-Epoch 0, step 849: val_loss was not in top 3
-Epoch 1, step 899: val_loss was not in top 3
-Epoch 2, step 949: val_loss was not in top 3
-Epoch 3, step 999: val_loss was not in top 3
-Epoch 4, step 1049: val_loss was not in top 3
-Epoch 5, step 1099: val_loss was not in top 3
-Epoch 6, step 1149: val_loss was not in top 3
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/nemo_error_log.txt b/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/nemo_error_log.txt
deleted file mode 100644
index f0dd2a2..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/nemo_error_log.txt
+++ /dev/null
@@ -1,28 +0,0 @@
-[NeMo W 2021-02-23 13:21:53 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
-[NeMo W 2021-02-23 13:22:09 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:09 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:13 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:13 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:13 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:14 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
-      warnings.warn(*args, **kwargs)
-    
-[NeMo W 2021-02-23 13:25:56 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7ff96c4cafa0> was reported to be 199 (when accessing len(dataloader)), but 200 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-02-23 13:26:21 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7ff96c4cafd0> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-02-23 13:56:20 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
-      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
-    
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/nemo_log_globalrank-0_localrank-0.txt b/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/nemo_log_globalrank-0_localrank-0.txt
deleted file mode 100644
index 969bca2..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53/nemo_log_globalrank-0_localrank-0.txt
+++ /dev/null
@@ -1,30 +0,0 @@
-[NeMo I 2021-02-23 13:21:53 exp_manager:183] Experiments will be logged at /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-21-53
-[NeMo I 2021-02-23 13:21:53 exp_manager:519] TensorboardLogger has been set up
-[NeMo W 2021-02-23 13:21:53 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
-[NeMo W 2021-02-23 13:22:09 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:09 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:13 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:13 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:13 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:14 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
-      warnings.warn(*args, **kwargs)
-    
-[NeMo W 2021-02-23 13:25:56 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7ff96c4cafa0> was reported to be 199 (when accessing len(dataloader)), but 200 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-02-23 13:26:21 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7ff96c4cafd0> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-02-23 13:56:20 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
-      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
-    
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/cmd-args.log b/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/cmd-args.log
deleted file mode 100644
index 11a5d8e..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/cmd-args.log
+++ /dev/null
@@ -1 +0,0 @@
-main.py
\ No newline at end of file
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/events.out.tfevents.1614057775.Titan.20522.0 b/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/events.out.tfevents.1614057775.Titan.20522.0
deleted file mode 100644
index e17ceb7..0000000
Binary files a/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/events.out.tfevents.1614057775.Titan.20522.0 and /dev/null differ
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/git-info.log b/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/git-info.log
deleted file mode 100644
index 45b9727..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/git-info.log
+++ /dev/null
@@ -1,1701 +0,0 @@
-commit hash: a95e08f7dafab6a88b25b93525195e2018fcf89f
-diff --git a/README.md b/README.md
-index 4792b93..e60eff3 100644
---- a/README.md
-+++ b/README.md
-@@ -92,6 +92,7 @@ bash ~/project/experiment/data/disfl2csv.sh /home/nxingyu/data/LDC99T42/treebank
- bash ~/project/bin/processandsplit.sh ./switchboard_processed.csv 8 1 1
- 
- bash ~/project/experiment/data/utt2csv.sh /home/nxingyu/data/utt switchboardutt_processed.csv
-+bash ~/project/bin/processandsplit.sh ./switchboardutt_processed.csv 8 1 1
- sed -i 1i"id,transcript" switchboard*
- 
- python ~/project/processcsv.py -i ~/data/ted_talks_en.csv -o ~/data/ted_talks_processed.csv -c 2000
-diff --git a/experiment/config.yaml b/experiment/config.yaml
-index aecc0bb..2a92896 100644
---- a/experiment/config.yaml
-+++ b/experiment/config.yaml
-@@ -4,7 +4,7 @@ trainer:
-     num_nodes: 1
-     max_epochs: 8
-     max_steps: null # precedence over max_epochs
--    accumulate_grad_batches: 2 # accumulates grads every k batches
-+    accumulate_grad_batches: 4 # accumulates grads every k batches
-     gradient_clip_val: 0
-     amp_level: O1 # O1/O2 for mixed precision
-     precision: 16 # Should be set to 16 for O1 and O2, default is 16 as PT ignores it when am_level is O0
-@@ -32,12 +32,12 @@ trainer:
-     # resume_from_checkpoint: null
- 
- exp_manager:
--    exp_dir: /home/nxingyu2/project/ # /root/project # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
-+    exp_dir: /home/nxingyu/project/ # /root/project # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
-     name: Punctuation_with_Domain_discriminator  # The name of your model
-     create_tensorboard_logger: true  # Whether you want exp_manger to create a tb logger
-     create_checkpoint_callback: true 
--base_path: /home/nxingyu2/data # /root/data # 
--tmp_path: /home/nxingyu2/data/tmp # /tmp # 
-+base_path: /home/nxingyu/data # /root/data # 
-+tmp_path: /home/nxingyu/data/tmp # /tmp # 
- log_dir: null
- 
- model:
-@@ -75,15 +75,17 @@ model:
-     punct_class_weights: false #false
-     
-     dataset:
--        data_dir: /home/nxingyu2/data # /root/data # 
-+        data_dir: /home/nxingyu/data # /root/data # 
-         labelled:
-             # - ${base_path}/ted2010 #
-             - ${base_path}/ted_talks_processed #
-             # - ${base_path}/open_subtitles_processed #  
-+            # - ${base_path}/switchboardutt_processed #
-         unlabelled:
-             # - ${base_path}/ted_talks_processed #
-             # - ${base_path}/open_subtitles_processed #  
--            # parameters for dataset preprocessing
-+            # - ${base_path}/switchboardutt_processed
-+        # parameters for dataset preprocessing
-         max_seq_length: 128
-         pad_label: ''
-         ignore_extra_tokens: false
-@@ -101,7 +103,7 @@ model:
-         train_ds:
-             shuffle: true
-             num_samples: -1
--            batch_size: 32
-+            batch_size: 16
-             manual_len: 20000 #default 0 84074
- 
-         validation_ds:
-@@ -110,7 +112,7 @@ model:
-             # ds_item: null # expected format: [PATH_TO_DEV1,PATH_TO_DEV2] (Note no space between the paths and square brackets)
-             shuffle: true
-             num_samples: -1
--            batch_size: 32 #4
-+            batch_size: 16 #4
- 
-     tokenizer:
-         tokenizer_name: ${model.language_model.pretrained_model_name} # or sentencepiece
-@@ -147,7 +149,7 @@ model:
-     
-     dice_loss:
-         epsilon: 0.01
--        alpha: 3
-+        alpha: 2
-         macro_average: true
- 
-     focal_loss: 
-diff --git a/experiment/data/disfl2csv.sh b/experiment/data/disfl2csv.sh
-index 84d8b69..48148a0 100644
---- a/experiment/data/disfl2csv.sh
-+++ b/experiment/data/disfl2csv.sh
-@@ -4,10 +4,10 @@ echo "in $1"
- echo "out $2"
- :> "$2"
- DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
--echo 'talk_id,transcript'> "$2"
-+# echo 'talk_id,transcript'> "$2"
- #echo "filenames, transcript" > opensubtitles.csv
- for folder in $1/*; do
--    for filename in $folder/*.dfl; do
-+    for filename in $folder/*.dff; do
-         echo $filename
-         python $DIR/processdff.py -i $filename -o $2
-         #echo "$filename, \"$transcript\"" >> opensubtitles.csv
-diff --git a/experiment/data/processdff.py b/experiment/data/processdff.py
-index b456a43..7e76f7f 100644
---- a/experiment/data/processdff.py
-+++ b/experiment/data/processdff.py
-@@ -42,7 +42,7 @@ def remove_disf(text):
-     return s
- 
- def to_emdash(s):
--    return re.sub('--','',s)
-+    return re.sub('--','…',s)
- 
- def strip_accents(s):
-    return ''.join(c for c in unicodedata.normalize('NFKD', s)
-diff --git a/experiment/data/processutt.py b/experiment/data/processutt.py
-index d6c1af1..d809a43 100644
---- a/experiment/data/processutt.py
-+++ b/experiment/data/processutt.py
-@@ -42,7 +42,7 @@ def remove_disf(text):
-     return s
- 
- def to_emdash(s):
--    return re.sub('--','',s)
-+    return re.sub('--','…',s)
- 
- def strip_accents(s):
-    return ''.join(c for c in unicodedata.normalize('NFKD', s)
-diff --git a/experiment/data/punctuation_count.sh b/experiment/data/punctuation_count.sh
-index f5d71be..469cc15 100644
---- a/experiment/data/punctuation_count.sh
-+++ b/experiment/data/punctuation_count.sh
-@@ -1,6 +1,6 @@
- for split in "dev" "test" "train"
- do
--for file in /home/nxingyu2/data/open*.$split.csv
-+for file in /home/$USER/data/switch*.$split.csv
- do
-  echo $file
-  sed -E 's/[^[:punct:]]//g;s/(.)/\1x/g' $file  | tr 'x' '\n' | sort | uniq -c | awk '{array[$2]=$1; sum+=$1} END { for (i in array) printf "%-20s %-15d %6.2f%%\n", i, array[i], array[i]/sum*100}' | sort -r -k2,2 -n
-diff --git a/experiment/data/utt2csv.sh b/experiment/data/utt2csv.sh
-index 7e03880..446d32a 100644
---- a/experiment/data/utt2csv.sh
-+++ b/experiment/data/utt2csv.sh
-@@ -4,7 +4,7 @@ echo "in $1"
- echo "out $2"
- :> "$2"
- DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
--echo 'talk_id,transcript'> "$2"
-+# echo 'talk_id,transcript'> "$2"
- #echo "filenames, transcript" > opensubtitles.csv
- for folder in $1/sw*; do
-     for filename in $folder/*.utt; do
-diff --git a/experiment/info.log b/experiment/info.log
-index 7d07c8a..e69de29 100644
---- a/experiment/info.log
-+++ b/experiment/info.log
-@@ -1,1341 +0,0 @@
--[INFO] - GPU available: True, used: True
--[INFO] - TPU available: None, using: 0 TPU cores
--[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
--[INFO] - Using native 16bit precision.
--[INFO] - shuffling train set
--[INFO] - initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.02
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7ff2c4092a30>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 4.7 M 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--5.9 M     Trainable params
--108 M     Non-trainable params
--114 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          78.98      44.46      56.89      80644
--! (label_id: 1)                                          0.04       2.04       0.08         98
--# (label_id: 2)                                          4.92      15.57       7.47       8270
--, (label_id: 3)                                          1.99       0.27       0.47       5934
--- (label_id: 4)                                          0.64       3.85       1.10        572
--. (label_id: 5)                                          6.34       3.38       4.41       5092
--: (label_id: 6)                                          0.19      20.34       0.38        118
--? (label_id: 7)                                          0.00       0.00       0.00        462
--… (label_id: 8)                                          0.04       5.26       0.08         38
---------------------
--micro avg                                               36.93      36.93      36.93     101228
--macro avg                                               10.35      10.57       7.88     101228
--weighted avg                                            63.76      36.93      46.19     101228
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    35854.00        20.00      4032.00      2572.00       284.00      2412.00        52.00       166.00         2.00
--     3840.00         2.00       232.00       400.00        42.00       298.00        10.00        34.00         2.00
--    21412.00        46.00      1288.00      1784.00        84.00      1388.00        22.00       150.00        18.00
--      662.00         0.00       116.00        16.00         2.00        10.00         0.00         0.00         0.00
--     2430.00         2.00       832.00        86.00        22.00        40.00         4.00         0.00         0.00
--     2196.00         0.00       100.00       202.00        12.00       172.00         6.00        22.00         2.00
--    10048.00        28.00       742.00       722.00        62.00       696.00        24.00        86.00        12.00
--      316.00         0.00        38.00         0.00         4.00         0.00         0.00         0.00         0.00
--     3886.00         0.00       890.00       152.00        60.00        76.00         0.00         4.00         2.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00        858
---------------------
--micro avg                                              100.00     100.00     100.00        858
--macro avg                                              100.00     100.00     100.00        858
--weighted avg                                           100.00     100.00     100.00        858
--
---------------------
--           0
--      858.00
---------------------
--
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.41      91.92      94.59     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         86.21      89.77      87.95      54804
--, (label_id: 3)                                         42.62      62.03      50.53      40800
--- (label_id: 4)                                         69.89      60.05      64.60       3464
--. (label_id: 5)                                         57.56      74.40      64.91      33424
--: (label_id: 6)                                         16.67      24.14      19.72        812
--? (label_id: 7)                                         65.62      29.42      40.62       2828
--… (label_id: 8)                                          1.33       7.27       2.25        220
---------------------
--micro avg                                               88.40      88.40      88.40     659880
--macro avg                                               48.59      48.78      47.24     659880
--weighted avg                                            90.59      88.40      89.23     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   480808.00        16.00      5380.00      4796.00      1016.00      1340.00        96.00       120.00        40.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     7796.00         0.00     49196.00         8.00        44.00        24.00         0.00         0.00         0.00
--    26532.00       224.00        48.00     25308.00       172.00      6400.00       188.00       420.00        84.00
--      828.00         0.00        64.00         4.00      2080.00         0.00         0.00         0.00         0.00
--     6328.00       196.00       104.00      9840.00       104.00     24868.00       300.00      1388.00        72.00
--      184.00        12.00         0.00       340.00         0.00       396.00       196.00        40.00         8.00
--      116.00        16.00         4.00       132.00         0.00       156.00        12.00       832.00         0.00
--      464.00         8.00         8.00       372.00        48.00       240.00        20.00        28.00        16.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 0, global step 49: val_loss reached 0.30009 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=0.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.50      88.95      93.03     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         67.87      92.39      78.25      54804
--, (label_id: 3)                                         41.27      74.84      53.20      40800
--- (label_id: 4)                                         82.54      50.23      62.46       3464
--. (label_id: 5)                                         68.11      62.47      65.17      33424
--: (label_id: 6)                                         43.10      12.32      19.16        812
--? (label_id: 7)                                         64.81      24.75      35.82       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               86.36      86.36      86.36     659880
--macro avg                                               51.69      45.11      45.23     659880
--weighted avg                                            89.68      86.36      87.33     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   465264.00        28.00      4072.00      5152.00       888.00      1396.00       180.00       172.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--    23120.00         0.00     50632.00       256.00       564.00        20.00         0.00         8.00         0.00
--    30964.00       180.00        72.00     30536.00       212.00     10932.00       284.00       708.00       104.00
--      356.00         0.00         0.00         0.00      1740.00        12.00         0.00         0.00         0.00
--     3248.00       228.00        24.00      4672.00        60.00     20880.00       248.00      1240.00        56.00
--       16.00         0.00         0.00        24.00         0.00        92.00       100.00         0.00         0.00
--       88.00        36.00         4.00       160.00         0.00        92.00         0.00       700.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 1, global step 99: val_loss reached 0.33170 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.33-epoch=1.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.41      97.01      96.20     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         94.34      88.26      91.20      54804
--, (label_id: 3)                                         56.69      58.49      57.58      40800
--- (label_id: 4)                                         87.42      48.15      62.10       3464
--. (label_id: 5)                                         70.05      64.34      67.07      33424
--: (label_id: 6)                                         58.54      11.82      19.67        812
--? (label_id: 7)                                         55.41      36.92      44.31       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.53      91.53      91.53     659880
--macro avg                                               57.54      45.00      48.68     659880
--weighted avg                                            91.28      91.53      91.33     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   507420.00        60.00      6400.00     12064.00      1516.00      3824.00       220.00       276.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2776.00         0.00     48372.00         8.00        96.00        20.00         0.00         0.00         0.00
--     9396.00       160.00         8.00     23864.00       124.00      7724.00       232.00       508.00        80.00
--      240.00         0.00         0.00         0.00      1668.00         0.00         0.00         0.00         0.00
--     3024.00       192.00        20.00      4588.00        60.00     21504.00       256.00      1000.00        56.00
--        8.00         0.00         0.00         8.00         0.00        52.00        96.00         0.00         0.00
--      192.00        60.00         4.00       268.00         0.00       300.00         8.00      1044.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 2, global step 149: val_loss reached 0.31563 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.32-epoch=2.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.90      96.12      96.01     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         89.97      88.46      89.21      54804
--, (label_id: 3)                                         53.45      64.22      58.34      40800
--- (label_id: 4)                                         82.01      53.70      64.90       3464
--. (label_id: 5)                                         71.61      60.91      65.83      33424
--: (label_id: 6)                                         22.89      22.66      22.77        812
--? (label_id: 7)                                         66.35      29.28      40.63       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.03      91.03      91.03     659880
--macro avg                                               53.57      46.15      48.63     659880
--weighted avg                                            91.17      91.03      91.00     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   502752.00        56.00      6284.00     10168.00      1144.00      3256.00       196.00       308.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     5080.00         0.00     48480.00        36.00       268.00        20.00         0.00         0.00         0.00
--    12200.00       184.00        24.00     26200.00       148.00      9364.00       200.00       608.00        92.00
--      404.00         0.00         0.00         4.00      1860.00         0.00         0.00         0.00         0.00
--     2368.00       196.00        12.00      4080.00        44.00     20360.00       232.00      1072.00        68.00
--      160.00         4.00         0.00       164.00         0.00       280.00       184.00        12.00         0.00
--       92.00        32.00         4.00       148.00         0.00       144.00         0.00       828.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 3, global step 199: val_loss reached 0.31315 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.31-epoch=3.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.75      95.17      95.95     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         89.22      90.48      89.85      54804
--, (label_id: 3)                                         51.13      69.58      58.95      40800
--- (label_id: 4)                                         77.34      59.12      67.02       3464
--. (label_id: 5)                                         70.86      63.12      66.76      33424
--: (label_id: 6)                                         57.14       9.85      16.81        812
--? (label_id: 7)                                         58.43      35.79      44.39       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               90.92      90.92      90.92     659880
--macro avg                                               55.65      47.01      48.86     659880
--weighted avg                                            91.58      90.92      91.11     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   497780.00        44.00      5156.00      7900.00      1008.00      2248.00       148.00       156.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     5716.00         0.00     49584.00        60.00       180.00        32.00         0.00         0.00         0.00
--    15936.00       176.00        44.00     28388.00       180.00      9708.00       364.00       620.00       100.00
--      588.00         0.00         4.00         8.00      2048.00         0.00         0.00         0.00         0.00
--     2884.00       208.00        12.00      4220.00        48.00     21096.00       212.00      1032.00        60.00
--        0.00         0.00         0.00         8.00         0.00        44.00        80.00         8.00         0.00
--      152.00        44.00         4.00       216.00         0.00       296.00         8.00      1012.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 4, step 249: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.94      96.58      96.26     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         96.14      86.64      91.15      54804
--, (label_id: 3)                                         57.41      61.25      59.27      40800
--- (label_id: 4)                                         76.69      60.39      67.57       3464
--. (label_id: 5)                                         68.11      71.82      69.91      33424
--: (label_id: 6)                                         25.76      16.75      20.30        812
--? (label_id: 7)                                         57.68      39.32      46.76       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.68      91.68      91.68     659880
--macro avg                                               53.08      48.08      50.14     659880
--weighted avg                                            91.72      91.68      91.66     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   505172.00        48.00      7272.00      9648.00      1116.00      2808.00       196.00       196.00        68.00
--        0.00         0.00         0.00         4.00         0.00         0.00         0.00         0.00         0.00
--     1848.00         0.00     47484.00         8.00        28.00        20.00         0.00         0.00         0.00
--    11408.00       148.00        24.00     24992.00       172.00      6064.00       204.00       448.00        76.00
--      616.00         0.00        12.00         8.00      2092.00         0.00         0.00         0.00         0.00
--     3736.00       216.00         8.00      5828.00        56.00     24004.00       272.00      1056.00        68.00
--      124.00         4.00         0.00        88.00         0.00       152.00       136.00        16.00         8.00
--      152.00        56.00         4.00       224.00         0.00       376.00         4.00      1112.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 5, global step 299: val_loss reached 0.30916 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.31-epoch=5.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.63      96.00      96.31     523056
--! (label_id: 1)                                         66.67       1.69       3.31        472
--# (label_id: 2)                                         94.65      89.24      91.87      54804
--, (label_id: 3)                                         56.09      64.01      59.79      40800
--- (label_id: 4)                                         76.31      60.62      67.57       3464
--. (label_id: 5)                                         66.81      74.69      70.53      33424
--: (label_id: 6)                                         30.77      15.76      20.85        812
--? (label_id: 7)                                         67.66      35.22      46.33       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.74      91.74      91.74     659880
--macro avg                                               61.73      48.58      50.73     659880
--weighted avg                                            92.08      91.74      91.82     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   502128.00        52.00      5844.00      7976.00      1084.00      2108.00       192.00       188.00        60.00
--        0.00         8.00         0.00         4.00         0.00         0.00         0.00         0.00         0.00
--     2660.00         0.00     48908.00        16.00        68.00        20.00         0.00         0.00         0.00
--    13400.00       144.00        28.00     26116.00       156.00      6024.00       200.00       408.00        84.00
--      636.00         0.00        12.00         4.00      2100.00         0.00         0.00         0.00         0.00
--     4040.00       228.00         8.00      6476.00        56.00     24964.00       292.00      1224.00        76.00
--       72.00         4.00         0.00        76.00         0.00       124.00       128.00        12.00         0.00
--      120.00        36.00         4.00       132.00         0.00       184.00         0.00       996.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 6, global step 349: val_loss reached 0.29901 (best 0.29901), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=6.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.22      96.51      96.36     523056
--! (label_id: 1)                                         50.00       1.69       3.28        472
--# (label_id: 2)                                         94.99      88.69      91.73      54804
--, (label_id: 3)                                         58.33      60.13      59.21      40800
--- (label_id: 4)                                         76.36      60.05      67.23       3464
--. (label_id: 5)                                         67.13      74.43      70.59      33424
--: (label_id: 6)                                         29.60      18.23      22.56        812
--? (label_id: 7)                                         63.15      38.05      47.48       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.85      91.85      91.85     659880
--macro avg                                               59.53      48.64      50.94     659880
--weighted avg                                            91.90      91.85      91.82     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   504792.00        52.00      6164.00      9436.00      1132.00      2604.00       196.00       204.00        68.00
--        0.00         8.00         0.00         4.00         0.00         4.00         0.00         0.00         0.00
--     2464.00         0.00     48608.00        24.00        56.00        20.00         0.00         0.00         0.00
--    11076.00       136.00        12.00     24532.00       140.00      5508.00       184.00       396.00        76.00
--      624.00         0.00        12.00         8.00      2080.00         0.00         0.00         0.00         0.00
--     3876.00       228.00         8.00      6516.00        56.00     24876.00       284.00      1136.00        76.00
--       84.00         4.00         0.00        96.00         0.00       152.00       148.00        16.00         0.00
--      140.00        44.00         0.00       184.00         0.00       260.00         0.00      1076.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 7, global step 399: val_loss reached 0.29477 (best 0.29477), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.29-epoch=7.ckpt" as top 3
--[INFO] - Saving latest checkpoint...
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.001
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7ff309dcf1f0>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 4.7 M 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--13.0 M    Trainable params
--101 M     Non-trainable params
--114 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.42      96.72      96.57      80644
--! (label_id: 1)                                        100.00       2.04       4.00         98
--# (label_id: 2)                                         94.98      88.83      91.80       8270
--, (label_id: 3)                                         58.52      61.21      59.84       5934
--- (label_id: 4)                                         76.96      61.89      68.60        572
--. (label_id: 5)                                         68.39      74.94      71.51       5092
--: (label_id: 6)                                         27.91      20.34      23.53        118
--? (label_id: 7)                                         61.36      35.06      44.63        462
--… (label_id: 8)                                          0.00       0.00       0.00         38
---------------------
--micro avg                                               92.21      92.21      92.21     101228
--macro avg                                               64.95      49.00      51.17     101228
--weighted avg                                            92.29      92.21      92.16     101228
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    78002.00         8.00       918.00      1312.00       170.00       410.00        30.00        34.00        12.00
--        0.00         2.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      372.00         0.00      7346.00         6.00        10.00         0.00         0.00         0.00         0.00
--     1618.00        30.00         2.00      3632.00        26.00       800.00        24.00        62.00        12.00
--      104.00         0.00         2.00         0.00       354.00         0.00         0.00         0.00         0.00
--      510.00        48.00         2.00       936.00        12.00      3816.00        40.00       202.00        14.00
--       16.00         0.00         0.00        18.00         0.00        26.00        24.00         2.00         0.00
--       22.00        10.00         0.00        30.00         0.00        40.00         0.00       162.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00        858
---------------------
--micro avg                                              100.00     100.00     100.00        858
--macro avg                                              100.00     100.00     100.00        858
--weighted avg                                           100.00     100.00     100.00        858
--
---------------------
--           0
--      858.00
---------------------
--
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.70      94.08      95.86     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.41      91.56      91.98      54804
--, (label_id: 3)                                         54.08      65.15      59.10      40800
--- (label_id: 4)                                         45.58      75.06      56.72       3464
--. (label_id: 5)                                         64.27      82.86      72.39      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         48.94      68.32      57.02       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.09      91.09      91.09     659880
--macro avg                                               44.78      53.00      48.12     659880
--weighted avg                                            92.17      91.09      91.48     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   492100.00        24.00      4224.00      5312.00       620.00       972.00       224.00       160.00        44.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     4076.00         0.00     50176.00        16.00        16.00        12.00         0.00         0.00         0.00
--    17824.00       140.00        12.00     26580.00       152.00      3988.00       196.00       172.00        84.00
--     2804.00         0.00       248.00        36.00      2600.00        16.00         0.00         0.00         0.00
--     5728.00       256.00       136.00      8184.00        76.00     27696.00       372.00       564.00        84.00
--        0.00         0.00         0.00         0.00         0.00         8.00         0.00         0.00         0.00
--      524.00        52.00         8.00       672.00         0.00       732.00        20.00      1932.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 0, step 449: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.41      96.35      96.88     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         91.96      94.02      92.98      54804
--, (label_id: 3)                                         64.21      66.16      65.17      40800
--- (label_id: 4)                                         82.47      58.66      68.56       3464
--. (label_id: 5)                                         71.30      82.13      76.33      33424
--: (label_id: 6)                                          2.63       0.99       1.43        812
--? (label_id: 7)                                         60.28      67.19      63.55       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.03      93.03      93.03     659880
--macro avg                                               52.25      51.72      51.65     659880
--weighted avg                                            93.13      93.03      93.04     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   503984.00        60.00      3212.00      6736.00      1244.00      1548.00       212.00       328.00        56.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     4456.00         0.00     51528.00        16.00        24.00        12.00         0.00         0.00         0.00
--    10468.00       140.00        20.00     26992.00       136.00      3768.00       240.00       188.00        88.00
--      404.00         0.00        12.00        12.00      2032.00         4.00         0.00         0.00         0.00
--     3520.00       232.00        32.00      6420.00        28.00     27452.00       340.00       412.00        68.00
--       36.00         0.00         0.00       232.00         0.00        28.00         8.00         0.00         0.00
--      188.00        40.00         0.00       392.00         0.00       612.00        12.00      1900.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 1, step 499: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.66      94.87      95.76     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         73.52      98.98      84.37      54804
--, (label_id: 3)                                         65.92      59.67      62.64      40800
--- (label_id: 4)                                         82.48      50.00      62.26       3464
--. (label_id: 5)                                         78.47      72.58      75.41      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         64.87      64.78      64.83       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.32      91.32      91.32     659880
--macro avg                                               51.33      48.99      49.47     659880
--weighted avg                                            91.49      91.32      91.21     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   496212.00       116.00       536.00     12196.00       908.00      2632.00       292.00       364.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--    18644.00         0.00     54244.00       160.00       700.00        32.00         0.00         0.00         0.00
--     5632.00       136.00         8.00     24344.00       112.00      6032.00       280.00       296.00        88.00
--      216.00         0.00         0.00       140.00      1732.00        12.00         0.00         0.00         0.00
--     2204.00       196.00        16.00      3624.00        12.00     24260.00       212.00       336.00        56.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      148.00        24.00         0.00       336.00         0.00       456.00        28.00      1832.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 2, step 549: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.60      97.50      97.05     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         93.99      91.64      92.80      54804
--, (label_id: 3)                                         68.55      61.10      64.61      40800
--- (label_id: 4)                                         81.77      49.19      61.43       3464
--. (label_id: 5)                                         71.94      82.38      76.81      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         82.00      50.92      62.83       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.32      93.32      93.32     659880
--macro avg                                               54.98      48.08      50.61     659880
--weighted avg                                            93.04      93.32      93.11     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   510004.00        64.00      4520.00      9228.00      1444.00      2020.00       252.00       360.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2996.00         0.00     50220.00        92.00       108.00        16.00         0.00         0.00         0.00
--     6636.00       144.00        24.00     24928.00       188.00      3764.00       220.00       388.00        72.00
--      304.00         0.00        20.00        48.00      1704.00         8.00         0.00         0.00         0.00
--     3036.00       248.00        20.00      6364.00        20.00     27536.00       340.00       640.00        72.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--       80.00        16.00         0.00       140.00         0.00        80.00         0.00      1440.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 3, step 599: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.93      97.24      97.09     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         94.66      91.04      92.81      54804
--, (label_id: 3)                                         66.63      64.82      65.72      40800
--- (label_id: 4)                                         75.88      62.47      68.52       3464
--. (label_id: 5)                                         73.34      81.40      77.16      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         70.49      69.59      70.04       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.40      93.40      93.40     659880
--macro avg                                               53.10      51.84      52.37     659880
--weighted avg                                            93.23      93.40      93.30     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508644.00        56.00      4712.00      8096.00      1072.00      1648.00       216.00       220.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2504.00         0.00     49892.00       252.00        44.00        16.00         0.00         0.00         0.00
--     8032.00       164.00        52.00     26448.00       168.00      4252.00       268.00       236.00        72.00
--      560.00         0.00       108.00         4.00      2164.00        16.00         0.00         0.00         0.00
--     3152.00       228.00        40.00      5656.00        16.00     27208.00       320.00       404.00        72.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      164.00        24.00         0.00       344.00         0.00       284.00         8.00      1968.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 4, step 649: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.34      96.76      97.05     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.54      93.20      92.87      54804
--, (label_id: 3)                                         64.62      68.42      66.47      40800
--- (label_id: 4)                                         82.26      58.89      68.64       3464
--. (label_id: 5)                                         74.47      80.59      77.41      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         69.26      71.71      70.47       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.36      93.36      93.36     659880
--macro avg                                               53.39      52.17      52.54     659880
--weighted avg                                            93.34      93.36      93.33     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   506088.00        44.00      3608.00      7132.00      1100.00      1496.00       172.00       204.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     3760.00         0.00     51080.00       244.00        92.00        20.00         0.00         0.00         0.00
--     9524.00       176.00        44.00     27916.00       216.00      4680.00       320.00       232.00        92.00
--      396.00         0.00        28.00         4.00      2040.00        12.00         0.00         0.00         0.00
--     3032.00       228.00        44.00      5172.00        16.00     26936.00       312.00       364.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      256.00        24.00         0.00       332.00         0.00       280.00         8.00      2028.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 5, step 699: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.17      97.08      97.12     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.93      92.96      92.95      54804
--, (label_id: 3)                                         66.75      65.61      66.17      40800
--- (label_id: 4)                                         75.56      66.40      70.68       3464
--. (label_id: 5)                                         74.11      81.07      77.43      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         72.03      70.30      71.15       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.48      93.48      93.48     659880
--macro avg                                               53.17      52.60      52.83     659880
--weighted avg                                            93.32      93.48      93.39     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   507784.00        56.00      3732.00      7964.00       892.00      1656.00       216.00       220.00        68.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     3532.00         0.00     50948.00       244.00        84.00        16.00         0.00         0.00         0.00
--     8000.00       148.00        44.00     26768.00       172.00      4380.00       284.00       220.00        88.00
--      652.00         0.00        60.00        12.00      2300.00        20.00         0.00         0.00         0.00
--     2912.00       244.00        20.00      5504.00        16.00     27096.00       304.00       400.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      176.00        24.00         0.00       308.00         0.00       256.00         8.00      1988.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 6, step 749: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.17      97.07      97.12     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.94      92.98      92.96      54804
--, (label_id: 3)                                         66.60      66.25      66.42      40800
--- (label_id: 4)                                         75.19      66.86      70.78       3464
--. (label_id: 5)                                         74.75      80.94      77.72      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         73.88      70.01      71.90       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.51      93.51      93.51     659880
--macro avg                                               53.39      52.68      52.99     659880
--weighted avg                                            93.36      93.51      93.43     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   507744.00        56.00      3724.00      7944.00       876.00      1664.00       220.00       220.00        68.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     3528.00         0.00     50956.00       244.00        84.00        16.00         0.00         0.00         0.00
--     8112.00       152.00        44.00     27028.00       172.00      4464.00       292.00       232.00        88.00
--      672.00         0.00        60.00        12.00      2316.00        20.00         0.00         0.00         0.00
--     2832.00       240.00        20.00      5280.00        16.00     27052.00       292.00       396.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      168.00        24.00         0.00       292.00         0.00       208.00         8.00      1980.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 7, step 799: val_loss was not in top 3
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.0004
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7ff29c24fa60>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 4.7 M 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--20.1 M    Trainable params
--94.7 M    Non-trainable params
--114 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.30      97.36      97.33      80644
--! (label_id: 1)                                          0.00       0.00       0.00         98
--# (label_id: 2)                                         92.84      93.11      92.97       8270
--, (label_id: 3)                                         66.91      67.21      67.06       5934
--- (label_id: 4)                                         77.08      68.18      72.36        572
--. (label_id: 5)                                         76.94      80.60      78.73       5092
--: (label_id: 6)                                          0.00       0.00       0.00        118
--? (label_id: 7)                                         76.61      72.29      74.39        462
--… (label_id: 8)                                          0.00       0.00       0.00         38
---------------------
--micro avg                                               93.88      93.88      93.88     101228
--macro avg                                               54.19      53.19      53.65     101228
--weighted avg                                            93.68      93.88      93.77     101228
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    78518.00        10.00       552.00      1142.00       140.00       256.00        32.00        36.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      544.00         0.00      7700.00        38.00        12.00         0.00         0.00         0.00         0.00
--     1122.00        32.00         4.00      3988.00        28.00       698.00        42.00        32.00        14.00
--      102.00         0.00        12.00         0.00       390.00         2.00         0.00         0.00         0.00
--      340.00        50.00         2.00       722.00         2.00      4104.00        42.00        60.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--       18.00         6.00         0.00        44.00         0.00        32.00         2.00       334.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00        858
---------------------
--micro avg                                              100.00     100.00     100.00        858
--macro avg                                              100.00     100.00     100.00        858
--weighted avg                                           100.00     100.00     100.00        858
--
---------------------
--           0
--      858.00
---------------------
--
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.70      97.18      96.94     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         90.59      92.02      91.30      54804
--, (label_id: 3)                                         65.34      65.67      65.50      40800
--- (label_id: 4)                                         85.28      45.50      59.34       3464
--. (label_id: 5)                                         76.92      76.16      76.54      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         67.59      62.23      64.80       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.10      93.10      93.10     659880
--macro avg                                               53.60      48.75      50.49     659880
--weighted avg                                            92.84      93.10      92.94     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508300.00        60.00      4336.00      9072.00      1240.00      2136.00       204.00       252.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     4560.00         0.00     50432.00       212.00       436.00        32.00         0.00         0.00         0.00
--     7488.00       172.00         8.00     26792.00       200.00      5416.00       384.00       436.00       108.00
--      256.00         0.00        12.00         4.00      1576.00         0.00         0.00         0.00         0.00
--     2240.00       216.00        16.00      4512.00        12.00     25456.00       216.00       380.00        44.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      212.00        24.00         0.00       208.00         0.00       384.00         8.00      1760.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 0, step 849: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.12      98.10      96.59     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         93.92      90.84      92.36      54804
--, (label_id: 3)                                         71.82      48.62      57.98      40800
--- (label_id: 4)                                         75.00      55.08      63.52       3464
--. (label_id: 5)                                         72.29      78.12      75.09      33424
--: (label_id: 6)                                        100.00       0.49       0.98        812
--? (label_id: 7)                                         86.41      35.08      49.90       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               92.71      92.71      92.71     659880
--macro avg                                               66.06      45.15      48.49     659880
--weighted avg                                            92.19      92.71      92.17     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   513120.00       140.00      4940.00     15176.00      1240.00      3752.00       372.00       596.00       104.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2864.00         0.00     49784.00        84.00       232.00        40.00         0.00         0.00         0.00
--     3644.00        64.00         0.00     19836.00        76.00      3500.00       168.00       276.00        56.00
--      560.00         0.00        60.00        16.00      1908.00         0.00         0.00         0.00         0.00
--     2820.00       252.00        20.00      5616.00         8.00     26112.00       268.00       964.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         4.00         0.00         0.00
--       48.00        16.00         0.00        72.00         0.00        20.00         0.00       992.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 1, step 899: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          94.93      95.85      95.39     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         98.21      69.76      81.58      54804
--, (label_id: 3)                                         54.91      72.97      62.66      40800
--- (label_id: 4)                                         86.86      27.48      41.75       3464
--. (label_id: 5)                                         66.94      75.06      70.77      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                        100.00       1.56       3.06       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               90.23      90.23      90.23     659880
--macro avg                                               55.76      38.08      39.47     659880
--weighted avg                                            91.07      90.23      90.08     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   501340.00        48.00     16152.00      6100.00      2028.00      1720.00       188.00       488.00        52.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      476.00         0.00     38232.00        24.00       176.00        20.00         0.00         0.00         0.00
--    15484.00       220.00       100.00     29772.00       252.00      6596.00       360.00      1348.00        88.00
--      136.00         0.00         8.00         0.00       952.00         0.00         0.00         0.00         0.00
--     5620.00       204.00       312.00      4904.00        56.00     25088.00       264.00       948.00        80.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00        44.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 2, step 949: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.95      94.26      95.58     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         88.08      93.86      90.88      54804
--, (label_id: 3)                                         59.30      62.47      60.85      40800
--- (label_id: 4)                                         43.12      67.32      52.57       3464
--. (label_id: 5)                                         70.00      76.39      73.06      33424
--: (label_id: 6)                                          0.91       5.42       1.56        812
--? (label_id: 7)                                         55.40      63.08      58.99       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               90.87      90.87      90.87     659880
--macro avg                                               45.97      51.42      48.17     659880
--weighted avg                                            91.84      90.87      91.31     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   493028.00        76.00      2376.00      9040.00       652.00      2780.00       252.00       280.00        72.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     6864.00         0.00     51440.00        16.00        68.00         4.00         0.00         8.00         0.00
--    11812.00       120.00       108.00     25488.00       156.00      4628.00       268.00       324.00        76.00
--     2344.00         0.00       504.00       212.00      2332.00        16.00         0.00         0.00         0.00
--     4468.00       256.00       144.00      5276.00        72.00     25532.00       244.00       412.00        68.00
--     3964.00         4.00       212.00       368.00       176.00        56.00        44.00        20.00         0.00
--      576.00        16.00        20.00       400.00         8.00       408.00         4.00      1784.00         4.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 3, step 999: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.73      96.49      96.61     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         97.10      88.69      92.71      54804
--, (label_id: 3)                                         61.91      66.92      64.32      40800
--- (label_id: 4)                                         62.18      61.32      61.74       3464
--. (label_id: 5)                                         71.48      77.96      74.58      33424
--: (label_id: 6)                                          4.21       1.97       2.68        812
--? (label_id: 7)                                         54.34      71.71      61.83       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               92.57      92.57      92.57     659880
--macro avg                                               49.77      51.67      50.50     659880
--weighted avg                                            92.75      92.57      92.63     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   504696.00        68.00      5900.00      7576.00      1048.00      1924.00       240.00       236.00        52.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1396.00         0.00     48608.00        20.00        24.00        12.00         0.00         0.00         0.00
--    10964.00       132.00        64.00     27304.00       216.00      4920.00       236.00       192.00        72.00
--     1020.00         0.00       132.00       128.00      2124.00        12.00         0.00         0.00         0.00
--     4196.00       248.00        88.00      5064.00        40.00     26056.00       304.00       372.00        84.00
--      200.00         0.00         8.00       152.00         0.00         4.00        16.00         0.00         0.00
--      584.00        24.00         4.00       556.00        12.00       496.00        16.00      2028.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 4, step 1049: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          94.84      98.08      96.43     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         98.53      81.48      89.20      54804
--, (label_id: 3)                                         67.47      60.25      63.66      40800
--- (label_id: 4)                                         65.13      58.89      61.86       3464
--. (label_id: 5)                                         77.35      72.15      74.66      33424
--: (label_id: 6)                                          6.67       2.46       3.60        812
--? (label_id: 7)                                         66.26      60.82      63.42       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               92.46      92.46      92.46     659880
--macro avg                                               52.92      48.24      50.31     659880
--weighted avg                                            92.08      92.46      92.17     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   513024.00        92.00      9884.00     11672.00      1184.00      4168.00       344.00       472.00        84.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      600.00         0.00     44652.00        20.00        28.00        16.00         0.00         0.00         0.00
--     6192.00       148.00        32.00     24584.00       132.00      4776.00       208.00       272.00        92.00
--      828.00         0.00       204.00        60.00      2040.00         0.00         0.00         0.00         0.00
--     2096.00       216.00        32.00      4068.00        16.00     24116.00       236.00       364.00        32.00
--      168.00         0.00         0.00        40.00        64.00         8.00        20.00         0.00         0.00
--      148.00        16.00         0.00       356.00         0.00       340.00         4.00      1720.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 5, step 1099: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.42      97.26      96.84     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         96.89      90.07      93.36      54804
--, (label_id: 3)                                         64.67      65.10      64.88      40800
--- (label_id: 4)                                         61.01      63.97      62.46       3464
--. (label_id: 5)                                         75.87      75.59      75.73      33424
--: (label_id: 6)                                         14.29       2.46       4.20        812
--? (label_id: 7)                                         59.57      67.33      63.21       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.05      93.05      93.05     659880
--macro avg                                               52.08      51.31      51.19     659880
--weighted avg                                            92.91      93.05      92.96     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508716.00        68.00      5096.00      8936.00      1036.00      3024.00       280.00       372.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1492.00         0.00     49364.00        32.00        36.00        24.00         0.00         0.00         0.00
--     9016.00       172.00        36.00     26560.00       132.00      4504.00       284.00       264.00       104.00
--     1076.00         0.00       276.00        64.00      2216.00         0.00         0.00         0.00         0.00
--     2492.00       216.00        32.00      4728.00        24.00     25264.00       216.00       288.00        40.00
--       60.00         0.00         0.00        40.00        12.00         8.00        20.00         0.00         0.00
--      204.00        16.00         0.00       440.00         8.00       600.00        12.00      1904.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 6, step 1149: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.49      97.24      96.86     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         96.73      90.36      93.44      54804
--, (label_id: 3)                                         64.80      65.04      64.92      40800
--- (label_id: 4)                                         64.12      62.12      63.11       3464
--. (label_id: 5)                                         75.35      76.33      75.84      33424
--: (label_id: 6)                                         22.73       2.46       4.44        812
--? (label_id: 7)                                         58.91      68.74      63.45       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.09      93.09      93.09     659880
--macro avg                                               53.24      51.37      51.34     659880
--weighted avg                                            92.95      93.09      93.00     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508616.00        72.00      4992.00      8792.00      1104.00      2864.00       280.00       364.00        56.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1572.00         0.00     49520.00        40.00        36.00        24.00         0.00         0.00         0.00
--     9072.00       152.00        36.00     26536.00       128.00      4416.00       280.00       240.00        88.00
--      920.00         0.00       224.00        60.00      2152.00         0.00         0.00         0.00         0.00
--     2604.00       224.00        32.00      4892.00        28.00     25512.00       220.00       280.00        64.00
--       28.00         0.00         0.00        24.00         8.00         8.00        20.00         0.00         0.00
--      244.00        24.00         0.00       456.00         8.00       600.00        12.00      1944.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 7, step 1199: val_loss was not in top 3
--[INFO] - GPU available: True, used: True
--[INFO] - TPU available: None, using: 0 TPU cores
--[INFO] - Using environment variable NODE_RANK for node rank (0).
--[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.25      97.27      96.76     650284
--! (label_id: 1)                                          0.00       0.00       0.00        380
--# (label_id: 2)                                         97.23      89.79      93.36      68496
--, (label_id: 3)                                         62.58      64.85      63.69      52348
--- (label_id: 4)                                         49.90      60.65      54.75       3212
--. (label_id: 5)                                         79.01      73.40      76.10      46276
--: (label_id: 6)                                         20.00       2.25       4.05        888
--? (label_id: 7)                                         60.00      67.50      63.53       4000
--… (label_id: 8)                                          0.00       0.00       0.00        260
---------------------
--micro avg                                               92.79      92.79      92.79     826144
--macro avg                                               51.66      50.63      50.25     826144
--weighted avg                                            92.72      92.79      92.72     826144
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   632504.00        36.00      6712.00     12044.00      1116.00      3904.00       244.00       476.00       108.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1596.00         0.00     61504.00        28.00        52.00        76.00         0.00         0.00         0.00
--    11756.00       140.00         8.00     33948.00        68.00      7492.00       300.00       432.00       104.00
--     1636.00         0.00       232.00        36.00      1948.00        52.00         0.00         0.00         0.00
--     2480.00       180.00        28.00      5584.00        16.00     33968.00       304.00       392.00        40.00
--       20.00         0.00         0.00        28.00        12.00        20.00        20.00         0.00         0.00
--      292.00        24.00        12.00       680.00         0.00       764.00        20.00      2700.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Chunked Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.57      97.15      96.86     327564
--! (label_id: 1)                                          0.00       0.00       0.00        184
--# (label_id: 2)                                         97.23      90.48      93.73      34404
--, (label_id: 3)                                         63.38      67.07      65.18      26324
--- (label_id: 4)                                         50.74      63.34      56.35       1724
--. (label_id: 5)                                         80.87      76.47      78.61      23376
--: (label_id: 6)                                          8.33       0.88       1.59        456
--? (label_id: 7)                                         59.61      72.62      65.47       2016
--… (label_id: 8)                                          0.00       0.00       0.00         92
---------------------
--micro avg                                               93.10      93.10      93.10     416140
--macro avg                                               50.75      52.00      50.86     416140
--weighted avg                                            93.12      93.10      93.08     416140
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   318220.00        20.00      3140.00      5728.00       532.00      1500.00       124.00       184.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      788.00         0.00     31128.00         8.00        32.00        60.00         0.00         0.00         0.00
--     6236.00        84.00         0.00     17656.00        48.00      3444.00       144.00       220.00        24.00
--      872.00         0.00       128.00        16.00      1092.00        44.00         0.00         0.00         0.00
--     1240.00        72.00         8.00      2568.00        16.00     17876.00       168.00       148.00         8.00
--       16.00         0.00         0.00         4.00         4.00        20.00         4.00         0.00         0.00
--      192.00         8.00         0.00       344.00         0.00       432.00        16.00      1464.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       6884
---------------------
--micro avg                                              100.00     100.00     100.00       6884
--macro avg                                              100.00     100.00     100.00       6884
--weighted avg                                           100.00     100.00     100.00       6884
--
---------------------
--           0
--     6884.00
---------------------
--
--[INFO] - saving to /home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/test.txt
--[INFO] - Internal process exited
-diff --git a/experiment/outputs/2021-02-23/08-18-26/testing.log b/experiment/outputs/2021-02-23/08-18-26/testing.log
-index f00f863..2597221 100644
---- a/experiment/outputs/2021-02-23/08-18-26/testing.log
-+++ b/experiment/outputs/2021-02-23/08-18-26/testing.log
-@@ -1 +1,74 @@
- [2021-02-23 08:18:38,771][root][INFO] - shuffling train set
-+[2021-02-23 08:44:12,424][root][INFO] - Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          95.20      95.06      95.13   33617452
-+! (label_id: 1)                                         21.65      40.73      28.27     578585
-+# (label_id: 2)                                         89.63      94.36      91.93    6976446
-+, (label_id: 3)                                         52.02      49.20      50.57    2858145
-+- (label_id: 4)                                         52.90      37.64      43.98     255633
-+. (label_id: 5)                                         67.03      64.56      65.77    5425019
-+: (label_id: 6)                                          0.00       0.00       0.00      15576
-+? (label_id: 7)                                         66.11      48.89      56.21    1415356
-+… (label_id: 8)                                         28.23      27.42      27.82     482702
-+-------------------
-+micro avg                                               86.40      86.40      86.40   51624912
-+macro avg                                               52.53      50.87      51.07   51624912
-+weighted avg                                            86.61      86.40      86.42   51624912
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 31955872.00     33316.00    385671.00    438274.00     53505.00    443163.00      7682.00    120484.00    128329.00
-+    66565.00    235635.00       761.00    176016.00      8738.00    506812.00       944.00     64244.00     28918.00
-+   714124.00       536.00   6582626.00      7720.00     19841.00     15709.00      1649.00      1336.00      1001.00
-+   288086.00     97827.00       833.00   1406100.00     11576.00    706306.00       912.00    121425.00     69959.00
-+    56237.00      2410.00       944.00      5163.00     96209.00     18095.00        96.00      1041.00      1680.00
-+   390319.00    174383.00      3985.00    635086.00     21274.00   3502327.00      3717.00    389488.00    104418.00
-+        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-+    75395.00     24645.00       937.00     80919.00      3444.00    153187.00       136.00    691913.00     16045.00
-+    70772.00      9833.00       689.00    108867.00     41046.00     79420.00       440.00     25425.00    132352.00
-+-------------------
-+
-+[2021-02-23 08:44:12,434][root][INFO] - Chunked Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          95.59      96.37      95.98   16876740
-+! (label_id: 1)                                         21.47      41.98      28.41     290645
-+# (label_id: 2)                                         95.04      95.14      95.09    3541392
-+, (label_id: 3)                                         52.20      49.91      51.03    1447727
-+- (label_id: 4)                                         53.56      38.01      44.47     130953
-+. (label_id: 5)                                         68.20      65.03      66.58    2759312
-+: (label_id: 6)                                          0.00       0.00       0.00       7645
-+? (label_id: 7)                                         66.66      50.42      57.42     716850
-+… (label_id: 8)                                         28.64      27.84      28.23     243286
-+-------------------
-+micro avg                                               87.46      87.46      87.46   26014552
-+macro avg                                               53.49      51.63      51.91   26014552
-+weighted avg                                            87.71      87.46      87.50   26014552
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 16264699.00     14196.00    169436.00    215171.00     26620.00    202508.00      3785.00     54437.00     63531.00
-+    33928.00    122012.00       272.00     91962.00      4505.00    266896.00       504.00     33168.00     15114.00
-+   151602.00       248.00   3369444.00      3788.00     10412.00      7913.00       881.00       624.00       328.00
-+   147638.00     49831.00       344.00    722501.00      5999.00    360923.00       448.00     60458.00     35874.00
-+    28414.00      1192.00       464.00      2722.00     49780.00      8964.00        32.00       537.00       840.00
-+   177113.00     85795.00      1072.00    314405.00     10733.00   1794350.00      1747.00    194183.00     51583.00
-+        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-+    37372.00     12602.00       168.00     41387.00      1825.00     79031.00        64.00    361456.00      8297.00
-+    35974.00      4769.00       192.00     55791.00     21079.00     38727.00       184.00     11987.00     67719.00
-+-------------------
-+
-+[2021-02-23 08:44:12,439][root][INFO] - Domain report: 
-+label                                                precision    recall       f1           support   
-+0 (label_id: 0)                                        100.00     100.00     100.00     411653
-+-------------------
-+micro avg                                              100.00     100.00     100.00     411653
-+macro avg                                              100.00     100.00     100.00     411653
-+weighted avg                                           100.00     100.00     100.00     411653
-+
-+-------------------
-+           0
-+   411653.00
-+-------------------
-+
-+[2021-02-23 08:44:12,439][root][INFO] - saving to /home/nxingyu/project/Punctuation_with_Domain_discriminator/opendice33acc42021-02-22_09-49-04//test.txt
-+[2021-02-23 08:44:12,539][wandb.sdk.internal.internal][INFO] - Internal process exited
-diff --git a/experiment/outputs/2021-02-23/08-20-55/testing.log b/experiment/outputs/2021-02-23/08-20-55/testing.log
-index 717645a..7100fd1 100644
---- a/experiment/outputs/2021-02-23/08-20-55/testing.log
-+++ b/experiment/outputs/2021-02-23/08-20-55/testing.log
-@@ -1 +1,74 @@
- [2021-02-23 08:21:08,018][root][INFO] - shuffling train set
-+[2021-02-23 09:05:21,673][root][INFO] - Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          94.88      97.99      96.41   33617452
-+! (label_id: 1)                                         33.89       9.66      15.04     578585
-+# (label_id: 2)                                         99.49      99.10      99.30    6976446
-+, (label_id: 3)                                         52.51      39.66      45.19    2858145
-+- (label_id: 4)                                         56.89      22.57      32.32     255633
-+. (label_id: 5)                                         62.04      77.10      68.76    5425019
-+: (label_id: 6)                                         77.05      41.40      53.86      15576
-+? (label_id: 7)                                         70.01      36.10      47.64    1415356
-+… (label_id: 8)                                         57.21       6.15      11.10     482702
-+-------------------
-+micro avg                                               88.78      88.78      88.78   51624912
-+macro avg                                               67.11      47.75      52.18   51624912
-+weighted avg                                            87.80      88.78      87.68   51624912
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 32940746.00     42247.00     56263.00    637305.00    117974.00    572846.00      3579.00    174660.00    172542.00
-+    10770.00     55899.00        88.00     35948.00      1672.00     46823.00       184.00      8367.00      5210.00
-+    27771.00       545.00   6913637.00      1128.00      1968.00      2819.00        16.00       480.00       560.00
-+   163910.00    113876.00       544.00   1133679.00     17942.00    526536.00       840.00    121929.00     79630.00
-+    19931.00      1771.00       104.00      4132.00     57687.00     14847.00        40.00       600.00      2282.00
-+   403834.00    347864.00      5066.00    988029.00     38393.00   4182951.00      4372.00    597272.00    174593.00
-+      608.00         0.00         0.00       505.00       360.00       288.00      6449.00        32.00       128.00
-+    48028.00     16247.00       712.00     54579.00      4683.00     76459.00        80.00    510999.00     18088.00
-+     1745.00       136.00        32.00      2840.00     14954.00      1450.00        16.00      1017.00     29669.00
-+-------------------
-+
-+[2021-02-23 09:05:21,682][root][INFO] - Chunked Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          95.08      98.11      96.57   16876740
-+! (label_id: 1)                                         33.70      10.09      15.54     290645
-+# (label_id: 2)                                         99.61      99.52      99.57    3541392
-+, (label_id: 3)                                         52.66      40.24      45.62    1447727
-+- (label_id: 4)                                         57.66      22.91      32.79     130953
-+. (label_id: 5)                                         62.89      77.75      69.53    2759312
-+: (label_id: 6)                                         78.52      42.08      54.79       7645
-+? (label_id: 7)                                         70.98      37.06      48.70     716850
-+… (label_id: 8)                                         58.27       6.35      11.46     243286
-+-------------------
-+micro avg                                               89.00      89.00      89.00   26014552
-+macro avg                                               67.71      48.24      52.73   26014552
-+weighted avg                                            88.03      89.00      87.92   26014552
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 16557577.00     19231.00     15829.00    319520.00     60251.00    272070.00      1746.00     82502.00     86301.00
-+     5837.00     29340.00        16.00     18850.00       800.00     24913.00       120.00      4276.00      2921.00
-+    11597.00        88.00   3524547.00       280.00       800.00       737.00         8.00        88.00        96.00
-+    83677.00     57621.00       136.00    582598.00      9566.00    269820.00       440.00     61935.00     40462.00
-+    10150.00       904.00        56.00      2011.00     29998.00      7605.00        16.00       240.00      1049.00
-+   183939.00    175228.00       744.00    495087.00     19564.00   2145232.00      2058.00    301633.00     87509.00
-+      176.00         0.00         0.00       296.00       128.00       168.00      3217.00        16.00        96.00
-+    22954.00      8169.00        64.00     27597.00      2353.00     38063.00        32.00    265680.00      9397.00
-+      833.00        64.00         0.00      1488.00      7493.00       704.00         8.00       480.00     15455.00
-+-------------------
-+
-+[2021-02-23 09:05:21,687][root][INFO] - Domain report: 
-+label                                                precision    recall       f1           support   
-+0 (label_id: 0)                                        100.00     100.00     100.00     411653
-+-------------------
-+micro avg                                              100.00     100.00     100.00     411653
-+macro avg                                              100.00     100.00     100.00     411653
-+weighted avg                                           100.00     100.00     100.00     411653
-+
-+-------------------
-+           0
-+   411653.00
-+-------------------
-+
-+[2021-02-23 09:05:21,688][root][INFO] - saving to /home/nxingyu/project/Punctuation_with_Domain_discriminator/opencrfacc42021-02-22_09-48-50//test.txt
-+[2021-02-23 09:05:21,785][wandb.sdk.internal.internal][INFO] - Internal process exited
-diff --git a/experiment/testing.py b/experiment/testing.py
-index 3e967b0..77f95ad 100644
---- a/experiment/testing.py
-+++ b/experiment/testing.py
-@@ -1,3 +1,8 @@
-+
-+
-+
-+
-+
- #%%
- import hydra
- import numpy as np
-@@ -20,7 +25,7 @@ import atexit
- from copy import deepcopy
- import snoop
- snoop.install()
--exp='opencrfacc42021-02-22_09-48-50'
-+exp='2021-02-23_09-59-35'
- @hydra.main(config_path=f"../Punctuation_with_Domain_discriminator/{exp}/",config_name="hparams.yaml")
- def main(cfg : DictConfig) -> None:
-     torch.set_printoptions(sci_mode=False)
-@@ -41,7 +46,7 @@ def main(cfg : DictConfig) -> None:
-                     max_seq_length=model.dm.max_seq_length,
-                     punct_label_ids=model.dm.punct_label_ids,
-                     label_map=model.dm.label_map,
--                    labelled=['/home/nxingyu/data/open_subtitles_processed'],
-+                    labelled=['/home/nxingyu/data/ted_talks_processed'],
-                     unlabelled=[],
-                     tokenizer=model.dm.tokenizer,
-                     randomize=model.dm.val_shuffle,
-@@ -49,7 +54,7 @@ def main(cfg : DictConfig) -> None:
-                     tmp_path=model.dm.tmp_path,
-                     attach_label_to_end=model.dm.attach_label_to_end,
-                     no_space_label=model.dm.no_space_label,
--                    pad_start=0,
-+                    pad_start=model.dm.pad_start,
-                     )
-     model.hparams.log_dir=f"/home/nxingyu/project/Punctuation_with_Domain_discriminator/{exp}/"
-     trainer = pl.Trainer(**cfg.trainer)
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/hparams.yaml b/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/hparams.yaml
deleted file mode 100644
index 144047a..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/hparams.yaml
+++ /dev/null
@@ -1,127 +0,0 @@
-seed: 42
-trainer:
-  gpus: 1
-  num_nodes: 1
-  max_epochs: 8
-  max_steps: null
-  accumulate_grad_batches: 4
-  gradient_clip_val: 0
-  amp_level: O1
-  precision: 16
-  accelerator: ddp
-  checkpoint_callback: false
-  logger: false
-  log_every_n_steps: 1
-  val_check_interval: 1.0
-  resume_from_checkpoint: null
-exp_manager:
-  exp_dir: /home/nxingyu/project/
-  name: Punctuation_with_Domain_discriminator
-  create_tensorboard_logger: true
-  create_checkpoint_callback: true
-base_path: /home/nxingyu/data
-tmp_path: /home/nxingyu/data/tmp
-log_dir: /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39
-model:
-  nemo_path: null
-  transformer_path: google/electra-base-discriminator
-  unfrozen: 0
-  maximum_unfrozen: 2
-  unfreeze_step: 1
-  punct_label_ids:
-  - ''
-  - ','
-  - .
-  - '?'
-  - '-'
-  - '!'
-  - ':'
-  - …
-  label_map:
-    —: ','
-    ;: .
-  no_space_label: '#'
-  test_chunk_percent: 0.5
-  pad_start_and_end: 0
-  punct_class_weights: false
-  dataset:
-    data_dir: /home/nxingyu/data
-    labelled:
-    - /home/nxingyu/data/ted_talks_processed
-    unlabelled: null
-    max_seq_length: 128
-    pad_label: ''
-    ignore_extra_tokens: false
-    ignore_start_end: false
-    use_cache: false
-    num_workers: 8
-    pin_memory: false
-    drop_last: true
-    num_labels: 9
-    num_domains: 2
-    test_unlabelled: true
-    attach_label_to_end: null
-    pad_start: 64
-    train_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 16
-      manual_len: 20000
-    validation_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 16
-  tokenizer:
-    tokenizer_name: google/electra-base-discriminator
-    vocab_file: null
-    tokenizer_model: null
-    special_tokens: null
-  language_model:
-    pretrained_model_name: google/electra-base-discriminator
-    lm_checkpoint: null
-    config_file: null
-    config: null
-  punct_head:
-    punct_num_fc_layers: 3
-    fc_dropout: 0.1
-    activation: gelu
-    log_softmax: false
-    use_transformer_init: true
-    loss: dice
-    bilstm: false
-  domain_head:
-    domain_num_fc_layers: 3
-    fc_dropout: 0.1
-    activation: relu
-    log_softmax: false
-    use_transformer_init: true
-    loss: cel
-    gamma: 0.01
-    pooling: mean_max
-    idx_conditioned_on: 0
-  dice_loss:
-    epsilon: 0.01
-    alpha: 2
-    macro_average: true
-  focal_loss:
-    gamma: 3
-  frozen_lr:
-  - 0.02
-  - 0.001
-  - 0.0004
-  - 0.0001
-  - 1.0e-05
-  - 1.0e-06
-  - 1.0e-07
-  optim:
-    name: adamw
-    lr: 0.01
-    weight_decay: 0.0
-    sched:
-      name: CosineAnnealing
-      warmup_steps: null
-      warmup_ratio: 0.1
-      min_lr: 1.0e-08
-      last_epoch: -1
-      monitor: val_loss
-      reduce_on_plateau: false
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/lightning_logs.txt b/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/lightning_logs.txt
deleted file mode 100644
index 7b87dcd..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/lightning_logs.txt
+++ /dev/null
@@ -1,81 +0,0 @@
-Global seed set to 42
-GPU available: True, used: True
-TPU available: None, using: 0 TPU cores
-LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
-Using native 16bit precision.
-Global seed set to 42
-initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 1.2 M 
-2 | domain_classifier          | SequenceClassifier   | 4.7 M 
-3 | punctuation_loss           | FocalDiceLoss        | 0     
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-5.9 M     Trainable params
-108 M     Non-trainable params
-114 M     Total params
-Epoch 0, global step 49: val_loss reached 0.35964 (best 0.35964), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.36-epoch=0.ckpt" as top 3
-Epoch 1, global step 99: val_loss reached 0.36382 (best 0.35964), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.36-epoch=1.ckpt" as top 3
-Epoch 2, global step 149: val_loss reached 0.33940 (best 0.33940), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.34-epoch=2.ckpt" as top 3
-Epoch 3, global step 199: val_loss reached 0.34583 (best 0.33940), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.35-epoch=3.ckpt" as top 3
-Epoch 4, global step 249: val_loss reached 0.34248 (best 0.33940), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.34-epoch=4.ckpt" as top 3
-Epoch 5, global step 299: val_loss reached 0.31391 (best 0.31391), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.31-epoch=5.ckpt" as top 3
-Epoch 6, global step 349: val_loss reached 0.30957 (best 0.30957), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.31-epoch=6.ckpt" as top 3
-Epoch 7, global step 399: val_loss reached 0.31761 (best 0.30957), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.32-epoch=7.ckpt" as top 3
-Saving latest checkpoint...
-Global seed set to 42
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 1.2 M 
-2 | domain_classifier          | SequenceClassifier   | 4.7 M 
-3 | punctuation_loss           | FocalDiceLoss        | 0     
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-13.0 M    Trainable params
-101 M     Non-trainable params
-114 M     Total params
-Epoch 0, step 449: val_loss was not in top 3
-Epoch 1, step 499: val_loss was not in top 3
-Epoch 2, step 549: val_loss was not in top 3
-Epoch 3, step 599: val_loss was not in top 3
-Epoch 4, step 649: val_loss was not in top 3
-Epoch 5, step 699: val_loss was not in top 3
-Epoch 6, step 749: val_loss was not in top 3
-Epoch 7, step 799: val_loss was not in top 3
-Global seed set to 42
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 1.2 M 
-2 | domain_classifier          | SequenceClassifier   | 4.7 M 
-3 | punctuation_loss           | FocalDiceLoss        | 0     
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-20.1 M    Trainable params
-94.7 M    Non-trainable params
-114 M     Total params
-Epoch 0, step 849: val_loss was not in top 3
-Epoch 1, step 899: val_loss was not in top 3
-Epoch 2, step 949: val_loss was not in top 3
-Epoch 3, step 999: val_loss was not in top 3
-Epoch 4, step 1049: val_loss was not in top 3
-Epoch 5, step 1099: val_loss was not in top 3
-Epoch 6, step 1149: val_loss was not in top 3
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/nemo_error_log.txt b/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/nemo_error_log.txt
deleted file mode 100644
index ec687c4..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/nemo_error_log.txt
+++ /dev/null
@@ -1,28 +0,0 @@
-[NeMo W 2021-02-23 13:22:39 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
-[NeMo W 2021-02-23 13:22:50 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:50 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:53 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:53 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:53 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:55 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
-      warnings.warn(*args, **kwargs)
-    
-[NeMo W 2021-02-23 13:26:35 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f47159069a0> was reported to be 199 (when accessing len(dataloader)), but 200 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-02-23 13:27:00 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f4715906f40> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-02-23 13:57:03 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
-      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
-    
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/nemo_log_globalrank-0_localrank-0.txt b/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/nemo_log_globalrank-0_localrank-0.txt
deleted file mode 100644
index c74071a..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39/nemo_log_globalrank-0_localrank-0.txt
+++ /dev/null
@@ -1,30 +0,0 @@
-[NeMo I 2021-02-23 13:22:39 exp_manager:183] Experiments will be logged at /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-22-39
-[NeMo I 2021-02-23 13:22:39 exp_manager:519] TensorboardLogger has been set up
-[NeMo W 2021-02-23 13:22:39 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
-[NeMo W 2021-02-23 13:22:50 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:50 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:53 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:53 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:53 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 13:22:55 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
-      warnings.warn(*args, **kwargs)
-    
-[NeMo W 2021-02-23 13:26:35 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f47159069a0> was reported to be 199 (when accessing len(dataloader)), but 200 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-02-23 13:27:00 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7f4715906f40> was reported to be 25 (when accessing len(dataloader)), but 26 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-02-23 13:57:03 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
-      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
-    
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-25-55/cmd-args.log b/Punctuation_with_Domain_discriminator/2021-02-23_13-25-55/cmd-args.log
deleted file mode 100644
index 11a5d8e..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_13-25-55/cmd-args.log
+++ /dev/null
@@ -1 +0,0 @@
-main.py
\ No newline at end of file
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-25-55/git-info.log b/Punctuation_with_Domain_discriminator/2021-02-23_13-25-55/git-info.log
deleted file mode 100644
index d5811dd..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_13-25-55/git-info.log
+++ /dev/null
@@ -1,1702 +0,0 @@
-commit hash: a95e08f7dafab6a88b25b93525195e2018fcf89f
-diff --git a/README.md b/README.md
-index 4792b93..e60eff3 100644
---- a/README.md
-+++ b/README.md
-@@ -92,6 +92,7 @@ bash ~/project/experiment/data/disfl2csv.sh /home/nxingyu/data/LDC99T42/treebank
- bash ~/project/bin/processandsplit.sh ./switchboard_processed.csv 8 1 1
- 
- bash ~/project/experiment/data/utt2csv.sh /home/nxingyu/data/utt switchboardutt_processed.csv
-+bash ~/project/bin/processandsplit.sh ./switchboardutt_processed.csv 8 1 1
- sed -i 1i"id,transcript" switchboard*
- 
- python ~/project/processcsv.py -i ~/data/ted_talks_en.csv -o ~/data/ted_talks_processed.csv -c 2000
-diff --git a/experiment/config.yaml b/experiment/config.yaml
-index aecc0bb..58d401d 100644
---- a/experiment/config.yaml
-+++ b/experiment/config.yaml
-@@ -4,7 +4,7 @@ trainer:
-     num_nodes: 1
-     max_epochs: 8
-     max_steps: null # precedence over max_epochs
--    accumulate_grad_batches: 2 # accumulates grads every k batches
-+    accumulate_grad_batches: 4 # accumulates grads every k batches
-     gradient_clip_val: 0
-     amp_level: O1 # O1/O2 for mixed precision
-     precision: 16 # Should be set to 16 for O1 and O2, default is 16 as PT ignores it when am_level is O0
-@@ -32,12 +32,12 @@ trainer:
-     # resume_from_checkpoint: null
- 
- exp_manager:
--    exp_dir: /home/nxingyu2/project/ # /root/project # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
-+    exp_dir: /home/nxingyu/project/ # /root/project # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
-     name: Punctuation_with_Domain_discriminator  # The name of your model
-     create_tensorboard_logger: true  # Whether you want exp_manger to create a tb logger
-     create_checkpoint_callback: true 
--base_path: /home/nxingyu2/data # /root/data # 
--tmp_path: /home/nxingyu2/data/tmp # /tmp # 
-+base_path: /home/nxingyu/data # /root/data # 
-+tmp_path: /home/nxingyu/data/tmp # /tmp # 
- log_dir: null
- 
- model:
-@@ -75,15 +75,17 @@ model:
-     punct_class_weights: false #false
-     
-     dataset:
--        data_dir: /home/nxingyu2/data # /root/data # 
-+        data_dir: /home/nxingyu/data # /root/data # 
-         labelled:
-             # - ${base_path}/ted2010 #
--            - ${base_path}/ted_talks_processed #
-+            # - ${base_path}/ted_talks_processed #
-             # - ${base_path}/open_subtitles_processed #  
-+            - ${base_path}/switchboardutt_processed #
-         unlabelled:
-             # - ${base_path}/ted_talks_processed #
-             # - ${base_path}/open_subtitles_processed #  
--            # parameters for dataset preprocessing
-+            # - ${base_path}/switchboardutt_processed
-+        # parameters for dataset preprocessing
-         max_seq_length: 128
-         pad_label: ''
-         ignore_extra_tokens: false
-@@ -101,7 +103,7 @@ model:
-         train_ds:
-             shuffle: true
-             num_samples: -1
--            batch_size: 32
-+            batch_size: 16
-             manual_len: 20000 #default 0 84074
- 
-         validation_ds:
-@@ -110,7 +112,7 @@ model:
-             # ds_item: null # expected format: [PATH_TO_DEV1,PATH_TO_DEV2] (Note no space between the paths and square brackets)
-             shuffle: true
-             num_samples: -1
--            batch_size: 32 #4
-+            batch_size: 16 #4
- 
-     tokenizer:
-         tokenizer_name: ${model.language_model.pretrained_model_name} # or sentencepiece
-@@ -147,7 +149,7 @@ model:
-     
-     dice_loss:
-         epsilon: 0.01
--        alpha: 3
-+        alpha: 2
-         macro_average: true
- 
-     focal_loss: 
-diff --git a/experiment/data/disfl2csv.sh b/experiment/data/disfl2csv.sh
-index 84d8b69..48148a0 100644
---- a/experiment/data/disfl2csv.sh
-+++ b/experiment/data/disfl2csv.sh
-@@ -4,10 +4,10 @@ echo "in $1"
- echo "out $2"
- :> "$2"
- DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
--echo 'talk_id,transcript'> "$2"
-+# echo 'talk_id,transcript'> "$2"
- #echo "filenames, transcript" > opensubtitles.csv
- for folder in $1/*; do
--    for filename in $folder/*.dfl; do
-+    for filename in $folder/*.dff; do
-         echo $filename
-         python $DIR/processdff.py -i $filename -o $2
-         #echo "$filename, \"$transcript\"" >> opensubtitles.csv
-diff --git a/experiment/data/processdff.py b/experiment/data/processdff.py
-index b456a43..7e76f7f 100644
---- a/experiment/data/processdff.py
-+++ b/experiment/data/processdff.py
-@@ -42,7 +42,7 @@ def remove_disf(text):
-     return s
- 
- def to_emdash(s):
--    return re.sub('--','',s)
-+    return re.sub('--','…',s)
- 
- def strip_accents(s):
-    return ''.join(c for c in unicodedata.normalize('NFKD', s)
-diff --git a/experiment/data/processutt.py b/experiment/data/processutt.py
-index d6c1af1..d809a43 100644
---- a/experiment/data/processutt.py
-+++ b/experiment/data/processutt.py
-@@ -42,7 +42,7 @@ def remove_disf(text):
-     return s
- 
- def to_emdash(s):
--    return re.sub('--','',s)
-+    return re.sub('--','…',s)
- 
- def strip_accents(s):
-    return ''.join(c for c in unicodedata.normalize('NFKD', s)
-diff --git a/experiment/data/punctuation_count.sh b/experiment/data/punctuation_count.sh
-index f5d71be..469cc15 100644
---- a/experiment/data/punctuation_count.sh
-+++ b/experiment/data/punctuation_count.sh
-@@ -1,6 +1,6 @@
- for split in "dev" "test" "train"
- do
--for file in /home/nxingyu2/data/open*.$split.csv
-+for file in /home/$USER/data/switch*.$split.csv
- do
-  echo $file
-  sed -E 's/[^[:punct:]]//g;s/(.)/\1x/g' $file  | tr 'x' '\n' | sort | uniq -c | awk '{array[$2]=$1; sum+=$1} END { for (i in array) printf "%-20s %-15d %6.2f%%\n", i, array[i], array[i]/sum*100}' | sort -r -k2,2 -n
-diff --git a/experiment/data/utt2csv.sh b/experiment/data/utt2csv.sh
-index 7e03880..446d32a 100644
---- a/experiment/data/utt2csv.sh
-+++ b/experiment/data/utt2csv.sh
-@@ -4,7 +4,7 @@ echo "in $1"
- echo "out $2"
- :> "$2"
- DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
--echo 'talk_id,transcript'> "$2"
-+# echo 'talk_id,transcript'> "$2"
- #echo "filenames, transcript" > opensubtitles.csv
- for folder in $1/sw*; do
-     for filename in $folder/*.utt; do
-diff --git a/experiment/info.log b/experiment/info.log
-index 7d07c8a..e69de29 100644
---- a/experiment/info.log
-+++ b/experiment/info.log
-@@ -1,1341 +0,0 @@
--[INFO] - GPU available: True, used: True
--[INFO] - TPU available: None, using: 0 TPU cores
--[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
--[INFO] - Using native 16bit precision.
--[INFO] - shuffling train set
--[INFO] - initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.02
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7ff2c4092a30>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 4.7 M 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--5.9 M     Trainable params
--108 M     Non-trainable params
--114 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          78.98      44.46      56.89      80644
--! (label_id: 1)                                          0.04       2.04       0.08         98
--# (label_id: 2)                                          4.92      15.57       7.47       8270
--, (label_id: 3)                                          1.99       0.27       0.47       5934
--- (label_id: 4)                                          0.64       3.85       1.10        572
--. (label_id: 5)                                          6.34       3.38       4.41       5092
--: (label_id: 6)                                          0.19      20.34       0.38        118
--? (label_id: 7)                                          0.00       0.00       0.00        462
--… (label_id: 8)                                          0.04       5.26       0.08         38
---------------------
--micro avg                                               36.93      36.93      36.93     101228
--macro avg                                               10.35      10.57       7.88     101228
--weighted avg                                            63.76      36.93      46.19     101228
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    35854.00        20.00      4032.00      2572.00       284.00      2412.00        52.00       166.00         2.00
--     3840.00         2.00       232.00       400.00        42.00       298.00        10.00        34.00         2.00
--    21412.00        46.00      1288.00      1784.00        84.00      1388.00        22.00       150.00        18.00
--      662.00         0.00       116.00        16.00         2.00        10.00         0.00         0.00         0.00
--     2430.00         2.00       832.00        86.00        22.00        40.00         4.00         0.00         0.00
--     2196.00         0.00       100.00       202.00        12.00       172.00         6.00        22.00         2.00
--    10048.00        28.00       742.00       722.00        62.00       696.00        24.00        86.00        12.00
--      316.00         0.00        38.00         0.00         4.00         0.00         0.00         0.00         0.00
--     3886.00         0.00       890.00       152.00        60.00        76.00         0.00         4.00         2.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00        858
---------------------
--micro avg                                              100.00     100.00     100.00        858
--macro avg                                              100.00     100.00     100.00        858
--weighted avg                                           100.00     100.00     100.00        858
--
---------------------
--           0
--      858.00
---------------------
--
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.41      91.92      94.59     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         86.21      89.77      87.95      54804
--, (label_id: 3)                                         42.62      62.03      50.53      40800
--- (label_id: 4)                                         69.89      60.05      64.60       3464
--. (label_id: 5)                                         57.56      74.40      64.91      33424
--: (label_id: 6)                                         16.67      24.14      19.72        812
--? (label_id: 7)                                         65.62      29.42      40.62       2828
--… (label_id: 8)                                          1.33       7.27       2.25        220
---------------------
--micro avg                                               88.40      88.40      88.40     659880
--macro avg                                               48.59      48.78      47.24     659880
--weighted avg                                            90.59      88.40      89.23     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   480808.00        16.00      5380.00      4796.00      1016.00      1340.00        96.00       120.00        40.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     7796.00         0.00     49196.00         8.00        44.00        24.00         0.00         0.00         0.00
--    26532.00       224.00        48.00     25308.00       172.00      6400.00       188.00       420.00        84.00
--      828.00         0.00        64.00         4.00      2080.00         0.00         0.00         0.00         0.00
--     6328.00       196.00       104.00      9840.00       104.00     24868.00       300.00      1388.00        72.00
--      184.00        12.00         0.00       340.00         0.00       396.00       196.00        40.00         8.00
--      116.00        16.00         4.00       132.00         0.00       156.00        12.00       832.00         0.00
--      464.00         8.00         8.00       372.00        48.00       240.00        20.00        28.00        16.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 0, global step 49: val_loss reached 0.30009 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=0.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.50      88.95      93.03     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         67.87      92.39      78.25      54804
--, (label_id: 3)                                         41.27      74.84      53.20      40800
--- (label_id: 4)                                         82.54      50.23      62.46       3464
--. (label_id: 5)                                         68.11      62.47      65.17      33424
--: (label_id: 6)                                         43.10      12.32      19.16        812
--? (label_id: 7)                                         64.81      24.75      35.82       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               86.36      86.36      86.36     659880
--macro avg                                               51.69      45.11      45.23     659880
--weighted avg                                            89.68      86.36      87.33     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   465264.00        28.00      4072.00      5152.00       888.00      1396.00       180.00       172.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--    23120.00         0.00     50632.00       256.00       564.00        20.00         0.00         8.00         0.00
--    30964.00       180.00        72.00     30536.00       212.00     10932.00       284.00       708.00       104.00
--      356.00         0.00         0.00         0.00      1740.00        12.00         0.00         0.00         0.00
--     3248.00       228.00        24.00      4672.00        60.00     20880.00       248.00      1240.00        56.00
--       16.00         0.00         0.00        24.00         0.00        92.00       100.00         0.00         0.00
--       88.00        36.00         4.00       160.00         0.00        92.00         0.00       700.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 1, global step 99: val_loss reached 0.33170 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.33-epoch=1.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.41      97.01      96.20     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         94.34      88.26      91.20      54804
--, (label_id: 3)                                         56.69      58.49      57.58      40800
--- (label_id: 4)                                         87.42      48.15      62.10       3464
--. (label_id: 5)                                         70.05      64.34      67.07      33424
--: (label_id: 6)                                         58.54      11.82      19.67        812
--? (label_id: 7)                                         55.41      36.92      44.31       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.53      91.53      91.53     659880
--macro avg                                               57.54      45.00      48.68     659880
--weighted avg                                            91.28      91.53      91.33     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   507420.00        60.00      6400.00     12064.00      1516.00      3824.00       220.00       276.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2776.00         0.00     48372.00         8.00        96.00        20.00         0.00         0.00         0.00
--     9396.00       160.00         8.00     23864.00       124.00      7724.00       232.00       508.00        80.00
--      240.00         0.00         0.00         0.00      1668.00         0.00         0.00         0.00         0.00
--     3024.00       192.00        20.00      4588.00        60.00     21504.00       256.00      1000.00        56.00
--        8.00         0.00         0.00         8.00         0.00        52.00        96.00         0.00         0.00
--      192.00        60.00         4.00       268.00         0.00       300.00         8.00      1044.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 2, global step 149: val_loss reached 0.31563 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.32-epoch=2.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.90      96.12      96.01     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         89.97      88.46      89.21      54804
--, (label_id: 3)                                         53.45      64.22      58.34      40800
--- (label_id: 4)                                         82.01      53.70      64.90       3464
--. (label_id: 5)                                         71.61      60.91      65.83      33424
--: (label_id: 6)                                         22.89      22.66      22.77        812
--? (label_id: 7)                                         66.35      29.28      40.63       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.03      91.03      91.03     659880
--macro avg                                               53.57      46.15      48.63     659880
--weighted avg                                            91.17      91.03      91.00     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   502752.00        56.00      6284.00     10168.00      1144.00      3256.00       196.00       308.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     5080.00         0.00     48480.00        36.00       268.00        20.00         0.00         0.00         0.00
--    12200.00       184.00        24.00     26200.00       148.00      9364.00       200.00       608.00        92.00
--      404.00         0.00         0.00         4.00      1860.00         0.00         0.00         0.00         0.00
--     2368.00       196.00        12.00      4080.00        44.00     20360.00       232.00      1072.00        68.00
--      160.00         4.00         0.00       164.00         0.00       280.00       184.00        12.00         0.00
--       92.00        32.00         4.00       148.00         0.00       144.00         0.00       828.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 3, global step 199: val_loss reached 0.31315 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.31-epoch=3.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.75      95.17      95.95     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         89.22      90.48      89.85      54804
--, (label_id: 3)                                         51.13      69.58      58.95      40800
--- (label_id: 4)                                         77.34      59.12      67.02       3464
--. (label_id: 5)                                         70.86      63.12      66.76      33424
--: (label_id: 6)                                         57.14       9.85      16.81        812
--? (label_id: 7)                                         58.43      35.79      44.39       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               90.92      90.92      90.92     659880
--macro avg                                               55.65      47.01      48.86     659880
--weighted avg                                            91.58      90.92      91.11     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   497780.00        44.00      5156.00      7900.00      1008.00      2248.00       148.00       156.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     5716.00         0.00     49584.00        60.00       180.00        32.00         0.00         0.00         0.00
--    15936.00       176.00        44.00     28388.00       180.00      9708.00       364.00       620.00       100.00
--      588.00         0.00         4.00         8.00      2048.00         0.00         0.00         0.00         0.00
--     2884.00       208.00        12.00      4220.00        48.00     21096.00       212.00      1032.00        60.00
--        0.00         0.00         0.00         8.00         0.00        44.00        80.00         8.00         0.00
--      152.00        44.00         4.00       216.00         0.00       296.00         8.00      1012.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 4, step 249: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.94      96.58      96.26     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         96.14      86.64      91.15      54804
--, (label_id: 3)                                         57.41      61.25      59.27      40800
--- (label_id: 4)                                         76.69      60.39      67.57       3464
--. (label_id: 5)                                         68.11      71.82      69.91      33424
--: (label_id: 6)                                         25.76      16.75      20.30        812
--? (label_id: 7)                                         57.68      39.32      46.76       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.68      91.68      91.68     659880
--macro avg                                               53.08      48.08      50.14     659880
--weighted avg                                            91.72      91.68      91.66     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   505172.00        48.00      7272.00      9648.00      1116.00      2808.00       196.00       196.00        68.00
--        0.00         0.00         0.00         4.00         0.00         0.00         0.00         0.00         0.00
--     1848.00         0.00     47484.00         8.00        28.00        20.00         0.00         0.00         0.00
--    11408.00       148.00        24.00     24992.00       172.00      6064.00       204.00       448.00        76.00
--      616.00         0.00        12.00         8.00      2092.00         0.00         0.00         0.00         0.00
--     3736.00       216.00         8.00      5828.00        56.00     24004.00       272.00      1056.00        68.00
--      124.00         4.00         0.00        88.00         0.00       152.00       136.00        16.00         8.00
--      152.00        56.00         4.00       224.00         0.00       376.00         4.00      1112.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 5, global step 299: val_loss reached 0.30916 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.31-epoch=5.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.63      96.00      96.31     523056
--! (label_id: 1)                                         66.67       1.69       3.31        472
--# (label_id: 2)                                         94.65      89.24      91.87      54804
--, (label_id: 3)                                         56.09      64.01      59.79      40800
--- (label_id: 4)                                         76.31      60.62      67.57       3464
--. (label_id: 5)                                         66.81      74.69      70.53      33424
--: (label_id: 6)                                         30.77      15.76      20.85        812
--? (label_id: 7)                                         67.66      35.22      46.33       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.74      91.74      91.74     659880
--macro avg                                               61.73      48.58      50.73     659880
--weighted avg                                            92.08      91.74      91.82     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   502128.00        52.00      5844.00      7976.00      1084.00      2108.00       192.00       188.00        60.00
--        0.00         8.00         0.00         4.00         0.00         0.00         0.00         0.00         0.00
--     2660.00         0.00     48908.00        16.00        68.00        20.00         0.00         0.00         0.00
--    13400.00       144.00        28.00     26116.00       156.00      6024.00       200.00       408.00        84.00
--      636.00         0.00        12.00         4.00      2100.00         0.00         0.00         0.00         0.00
--     4040.00       228.00         8.00      6476.00        56.00     24964.00       292.00      1224.00        76.00
--       72.00         4.00         0.00        76.00         0.00       124.00       128.00        12.00         0.00
--      120.00        36.00         4.00       132.00         0.00       184.00         0.00       996.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 6, global step 349: val_loss reached 0.29901 (best 0.29901), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=6.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.22      96.51      96.36     523056
--! (label_id: 1)                                         50.00       1.69       3.28        472
--# (label_id: 2)                                         94.99      88.69      91.73      54804
--, (label_id: 3)                                         58.33      60.13      59.21      40800
--- (label_id: 4)                                         76.36      60.05      67.23       3464
--. (label_id: 5)                                         67.13      74.43      70.59      33424
--: (label_id: 6)                                         29.60      18.23      22.56        812
--? (label_id: 7)                                         63.15      38.05      47.48       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.85      91.85      91.85     659880
--macro avg                                               59.53      48.64      50.94     659880
--weighted avg                                            91.90      91.85      91.82     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   504792.00        52.00      6164.00      9436.00      1132.00      2604.00       196.00       204.00        68.00
--        0.00         8.00         0.00         4.00         0.00         4.00         0.00         0.00         0.00
--     2464.00         0.00     48608.00        24.00        56.00        20.00         0.00         0.00         0.00
--    11076.00       136.00        12.00     24532.00       140.00      5508.00       184.00       396.00        76.00
--      624.00         0.00        12.00         8.00      2080.00         0.00         0.00         0.00         0.00
--     3876.00       228.00         8.00      6516.00        56.00     24876.00       284.00      1136.00        76.00
--       84.00         4.00         0.00        96.00         0.00       152.00       148.00        16.00         0.00
--      140.00        44.00         0.00       184.00         0.00       260.00         0.00      1076.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 7, global step 399: val_loss reached 0.29477 (best 0.29477), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.29-epoch=7.ckpt" as top 3
--[INFO] - Saving latest checkpoint...
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.001
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7ff309dcf1f0>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 4.7 M 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--13.0 M    Trainable params
--101 M     Non-trainable params
--114 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.42      96.72      96.57      80644
--! (label_id: 1)                                        100.00       2.04       4.00         98
--# (label_id: 2)                                         94.98      88.83      91.80       8270
--, (label_id: 3)                                         58.52      61.21      59.84       5934
--- (label_id: 4)                                         76.96      61.89      68.60        572
--. (label_id: 5)                                         68.39      74.94      71.51       5092
--: (label_id: 6)                                         27.91      20.34      23.53        118
--? (label_id: 7)                                         61.36      35.06      44.63        462
--… (label_id: 8)                                          0.00       0.00       0.00         38
---------------------
--micro avg                                               92.21      92.21      92.21     101228
--macro avg                                               64.95      49.00      51.17     101228
--weighted avg                                            92.29      92.21      92.16     101228
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    78002.00         8.00       918.00      1312.00       170.00       410.00        30.00        34.00        12.00
--        0.00         2.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      372.00         0.00      7346.00         6.00        10.00         0.00         0.00         0.00         0.00
--     1618.00        30.00         2.00      3632.00        26.00       800.00        24.00        62.00        12.00
--      104.00         0.00         2.00         0.00       354.00         0.00         0.00         0.00         0.00
--      510.00        48.00         2.00       936.00        12.00      3816.00        40.00       202.00        14.00
--       16.00         0.00         0.00        18.00         0.00        26.00        24.00         2.00         0.00
--       22.00        10.00         0.00        30.00         0.00        40.00         0.00       162.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00        858
---------------------
--micro avg                                              100.00     100.00     100.00        858
--macro avg                                              100.00     100.00     100.00        858
--weighted avg                                           100.00     100.00     100.00        858
--
---------------------
--           0
--      858.00
---------------------
--
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.70      94.08      95.86     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.41      91.56      91.98      54804
--, (label_id: 3)                                         54.08      65.15      59.10      40800
--- (label_id: 4)                                         45.58      75.06      56.72       3464
--. (label_id: 5)                                         64.27      82.86      72.39      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         48.94      68.32      57.02       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.09      91.09      91.09     659880
--macro avg                                               44.78      53.00      48.12     659880
--weighted avg                                            92.17      91.09      91.48     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   492100.00        24.00      4224.00      5312.00       620.00       972.00       224.00       160.00        44.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     4076.00         0.00     50176.00        16.00        16.00        12.00         0.00         0.00         0.00
--    17824.00       140.00        12.00     26580.00       152.00      3988.00       196.00       172.00        84.00
--     2804.00         0.00       248.00        36.00      2600.00        16.00         0.00         0.00         0.00
--     5728.00       256.00       136.00      8184.00        76.00     27696.00       372.00       564.00        84.00
--        0.00         0.00         0.00         0.00         0.00         8.00         0.00         0.00         0.00
--      524.00        52.00         8.00       672.00         0.00       732.00        20.00      1932.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 0, step 449: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.41      96.35      96.88     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         91.96      94.02      92.98      54804
--, (label_id: 3)                                         64.21      66.16      65.17      40800
--- (label_id: 4)                                         82.47      58.66      68.56       3464
--. (label_id: 5)                                         71.30      82.13      76.33      33424
--: (label_id: 6)                                          2.63       0.99       1.43        812
--? (label_id: 7)                                         60.28      67.19      63.55       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.03      93.03      93.03     659880
--macro avg                                               52.25      51.72      51.65     659880
--weighted avg                                            93.13      93.03      93.04     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   503984.00        60.00      3212.00      6736.00      1244.00      1548.00       212.00       328.00        56.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     4456.00         0.00     51528.00        16.00        24.00        12.00         0.00         0.00         0.00
--    10468.00       140.00        20.00     26992.00       136.00      3768.00       240.00       188.00        88.00
--      404.00         0.00        12.00        12.00      2032.00         4.00         0.00         0.00         0.00
--     3520.00       232.00        32.00      6420.00        28.00     27452.00       340.00       412.00        68.00
--       36.00         0.00         0.00       232.00         0.00        28.00         8.00         0.00         0.00
--      188.00        40.00         0.00       392.00         0.00       612.00        12.00      1900.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 1, step 499: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.66      94.87      95.76     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         73.52      98.98      84.37      54804
--, (label_id: 3)                                         65.92      59.67      62.64      40800
--- (label_id: 4)                                         82.48      50.00      62.26       3464
--. (label_id: 5)                                         78.47      72.58      75.41      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         64.87      64.78      64.83       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.32      91.32      91.32     659880
--macro avg                                               51.33      48.99      49.47     659880
--weighted avg                                            91.49      91.32      91.21     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   496212.00       116.00       536.00     12196.00       908.00      2632.00       292.00       364.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--    18644.00         0.00     54244.00       160.00       700.00        32.00         0.00         0.00         0.00
--     5632.00       136.00         8.00     24344.00       112.00      6032.00       280.00       296.00        88.00
--      216.00         0.00         0.00       140.00      1732.00        12.00         0.00         0.00         0.00
--     2204.00       196.00        16.00      3624.00        12.00     24260.00       212.00       336.00        56.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      148.00        24.00         0.00       336.00         0.00       456.00        28.00      1832.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 2, step 549: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.60      97.50      97.05     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         93.99      91.64      92.80      54804
--, (label_id: 3)                                         68.55      61.10      64.61      40800
--- (label_id: 4)                                         81.77      49.19      61.43       3464
--. (label_id: 5)                                         71.94      82.38      76.81      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         82.00      50.92      62.83       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.32      93.32      93.32     659880
--macro avg                                               54.98      48.08      50.61     659880
--weighted avg                                            93.04      93.32      93.11     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   510004.00        64.00      4520.00      9228.00      1444.00      2020.00       252.00       360.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2996.00         0.00     50220.00        92.00       108.00        16.00         0.00         0.00         0.00
--     6636.00       144.00        24.00     24928.00       188.00      3764.00       220.00       388.00        72.00
--      304.00         0.00        20.00        48.00      1704.00         8.00         0.00         0.00         0.00
--     3036.00       248.00        20.00      6364.00        20.00     27536.00       340.00       640.00        72.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--       80.00        16.00         0.00       140.00         0.00        80.00         0.00      1440.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 3, step 599: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.93      97.24      97.09     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         94.66      91.04      92.81      54804
--, (label_id: 3)                                         66.63      64.82      65.72      40800
--- (label_id: 4)                                         75.88      62.47      68.52       3464
--. (label_id: 5)                                         73.34      81.40      77.16      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         70.49      69.59      70.04       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.40      93.40      93.40     659880
--macro avg                                               53.10      51.84      52.37     659880
--weighted avg                                            93.23      93.40      93.30     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508644.00        56.00      4712.00      8096.00      1072.00      1648.00       216.00       220.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2504.00         0.00     49892.00       252.00        44.00        16.00         0.00         0.00         0.00
--     8032.00       164.00        52.00     26448.00       168.00      4252.00       268.00       236.00        72.00
--      560.00         0.00       108.00         4.00      2164.00        16.00         0.00         0.00         0.00
--     3152.00       228.00        40.00      5656.00        16.00     27208.00       320.00       404.00        72.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      164.00        24.00         0.00       344.00         0.00       284.00         8.00      1968.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 4, step 649: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.34      96.76      97.05     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.54      93.20      92.87      54804
--, (label_id: 3)                                         64.62      68.42      66.47      40800
--- (label_id: 4)                                         82.26      58.89      68.64       3464
--. (label_id: 5)                                         74.47      80.59      77.41      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         69.26      71.71      70.47       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.36      93.36      93.36     659880
--macro avg                                               53.39      52.17      52.54     659880
--weighted avg                                            93.34      93.36      93.33     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   506088.00        44.00      3608.00      7132.00      1100.00      1496.00       172.00       204.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     3760.00         0.00     51080.00       244.00        92.00        20.00         0.00         0.00         0.00
--     9524.00       176.00        44.00     27916.00       216.00      4680.00       320.00       232.00        92.00
--      396.00         0.00        28.00         4.00      2040.00        12.00         0.00         0.00         0.00
--     3032.00       228.00        44.00      5172.00        16.00     26936.00       312.00       364.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      256.00        24.00         0.00       332.00         0.00       280.00         8.00      2028.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 5, step 699: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.17      97.08      97.12     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.93      92.96      92.95      54804
--, (label_id: 3)                                         66.75      65.61      66.17      40800
--- (label_id: 4)                                         75.56      66.40      70.68       3464
--. (label_id: 5)                                         74.11      81.07      77.43      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         72.03      70.30      71.15       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.48      93.48      93.48     659880
--macro avg                                               53.17      52.60      52.83     659880
--weighted avg                                            93.32      93.48      93.39     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   507784.00        56.00      3732.00      7964.00       892.00      1656.00       216.00       220.00        68.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     3532.00         0.00     50948.00       244.00        84.00        16.00         0.00         0.00         0.00
--     8000.00       148.00        44.00     26768.00       172.00      4380.00       284.00       220.00        88.00
--      652.00         0.00        60.00        12.00      2300.00        20.00         0.00         0.00         0.00
--     2912.00       244.00        20.00      5504.00        16.00     27096.00       304.00       400.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      176.00        24.00         0.00       308.00         0.00       256.00         8.00      1988.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 6, step 749: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.17      97.07      97.12     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.94      92.98      92.96      54804
--, (label_id: 3)                                         66.60      66.25      66.42      40800
--- (label_id: 4)                                         75.19      66.86      70.78       3464
--. (label_id: 5)                                         74.75      80.94      77.72      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         73.88      70.01      71.90       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.51      93.51      93.51     659880
--macro avg                                               53.39      52.68      52.99     659880
--weighted avg                                            93.36      93.51      93.43     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   507744.00        56.00      3724.00      7944.00       876.00      1664.00       220.00       220.00        68.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     3528.00         0.00     50956.00       244.00        84.00        16.00         0.00         0.00         0.00
--     8112.00       152.00        44.00     27028.00       172.00      4464.00       292.00       232.00        88.00
--      672.00         0.00        60.00        12.00      2316.00        20.00         0.00         0.00         0.00
--     2832.00       240.00        20.00      5280.00        16.00     27052.00       292.00       396.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      168.00        24.00         0.00       292.00         0.00       208.00         8.00      1980.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 7, step 799: val_loss was not in top 3
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.0004
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7ff29c24fa60>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 4.7 M 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--20.1 M    Trainable params
--94.7 M    Non-trainable params
--114 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.30      97.36      97.33      80644
--! (label_id: 1)                                          0.00       0.00       0.00         98
--# (label_id: 2)                                         92.84      93.11      92.97       8270
--, (label_id: 3)                                         66.91      67.21      67.06       5934
--- (label_id: 4)                                         77.08      68.18      72.36        572
--. (label_id: 5)                                         76.94      80.60      78.73       5092
--: (label_id: 6)                                          0.00       0.00       0.00        118
--? (label_id: 7)                                         76.61      72.29      74.39        462
--… (label_id: 8)                                          0.00       0.00       0.00         38
---------------------
--micro avg                                               93.88      93.88      93.88     101228
--macro avg                                               54.19      53.19      53.65     101228
--weighted avg                                            93.68      93.88      93.77     101228
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    78518.00        10.00       552.00      1142.00       140.00       256.00        32.00        36.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      544.00         0.00      7700.00        38.00        12.00         0.00         0.00         0.00         0.00
--     1122.00        32.00         4.00      3988.00        28.00       698.00        42.00        32.00        14.00
--      102.00         0.00        12.00         0.00       390.00         2.00         0.00         0.00         0.00
--      340.00        50.00         2.00       722.00         2.00      4104.00        42.00        60.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--       18.00         6.00         0.00        44.00         0.00        32.00         2.00       334.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00        858
---------------------
--micro avg                                              100.00     100.00     100.00        858
--macro avg                                              100.00     100.00     100.00        858
--weighted avg                                           100.00     100.00     100.00        858
--
---------------------
--           0
--      858.00
---------------------
--
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.70      97.18      96.94     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         90.59      92.02      91.30      54804
--, (label_id: 3)                                         65.34      65.67      65.50      40800
--- (label_id: 4)                                         85.28      45.50      59.34       3464
--. (label_id: 5)                                         76.92      76.16      76.54      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         67.59      62.23      64.80       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.10      93.10      93.10     659880
--macro avg                                               53.60      48.75      50.49     659880
--weighted avg                                            92.84      93.10      92.94     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508300.00        60.00      4336.00      9072.00      1240.00      2136.00       204.00       252.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     4560.00         0.00     50432.00       212.00       436.00        32.00         0.00         0.00         0.00
--     7488.00       172.00         8.00     26792.00       200.00      5416.00       384.00       436.00       108.00
--      256.00         0.00        12.00         4.00      1576.00         0.00         0.00         0.00         0.00
--     2240.00       216.00        16.00      4512.00        12.00     25456.00       216.00       380.00        44.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      212.00        24.00         0.00       208.00         0.00       384.00         8.00      1760.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 0, step 849: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.12      98.10      96.59     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         93.92      90.84      92.36      54804
--, (label_id: 3)                                         71.82      48.62      57.98      40800
--- (label_id: 4)                                         75.00      55.08      63.52       3464
--. (label_id: 5)                                         72.29      78.12      75.09      33424
--: (label_id: 6)                                        100.00       0.49       0.98        812
--? (label_id: 7)                                         86.41      35.08      49.90       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               92.71      92.71      92.71     659880
--macro avg                                               66.06      45.15      48.49     659880
--weighted avg                                            92.19      92.71      92.17     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   513120.00       140.00      4940.00     15176.00      1240.00      3752.00       372.00       596.00       104.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2864.00         0.00     49784.00        84.00       232.00        40.00         0.00         0.00         0.00
--     3644.00        64.00         0.00     19836.00        76.00      3500.00       168.00       276.00        56.00
--      560.00         0.00        60.00        16.00      1908.00         0.00         0.00         0.00         0.00
--     2820.00       252.00        20.00      5616.00         8.00     26112.00       268.00       964.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         4.00         0.00         0.00
--       48.00        16.00         0.00        72.00         0.00        20.00         0.00       992.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 1, step 899: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          94.93      95.85      95.39     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         98.21      69.76      81.58      54804
--, (label_id: 3)                                         54.91      72.97      62.66      40800
--- (label_id: 4)                                         86.86      27.48      41.75       3464
--. (label_id: 5)                                         66.94      75.06      70.77      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                        100.00       1.56       3.06       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               90.23      90.23      90.23     659880
--macro avg                                               55.76      38.08      39.47     659880
--weighted avg                                            91.07      90.23      90.08     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   501340.00        48.00     16152.00      6100.00      2028.00      1720.00       188.00       488.00        52.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      476.00         0.00     38232.00        24.00       176.00        20.00         0.00         0.00         0.00
--    15484.00       220.00       100.00     29772.00       252.00      6596.00       360.00      1348.00        88.00
--      136.00         0.00         8.00         0.00       952.00         0.00         0.00         0.00         0.00
--     5620.00       204.00       312.00      4904.00        56.00     25088.00       264.00       948.00        80.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00        44.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 2, step 949: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.95      94.26      95.58     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         88.08      93.86      90.88      54804
--, (label_id: 3)                                         59.30      62.47      60.85      40800
--- (label_id: 4)                                         43.12      67.32      52.57       3464
--. (label_id: 5)                                         70.00      76.39      73.06      33424
--: (label_id: 6)                                          0.91       5.42       1.56        812
--? (label_id: 7)                                         55.40      63.08      58.99       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               90.87      90.87      90.87     659880
--macro avg                                               45.97      51.42      48.17     659880
--weighted avg                                            91.84      90.87      91.31     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   493028.00        76.00      2376.00      9040.00       652.00      2780.00       252.00       280.00        72.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     6864.00         0.00     51440.00        16.00        68.00         4.00         0.00         8.00         0.00
--    11812.00       120.00       108.00     25488.00       156.00      4628.00       268.00       324.00        76.00
--     2344.00         0.00       504.00       212.00      2332.00        16.00         0.00         0.00         0.00
--     4468.00       256.00       144.00      5276.00        72.00     25532.00       244.00       412.00        68.00
--     3964.00         4.00       212.00       368.00       176.00        56.00        44.00        20.00         0.00
--      576.00        16.00        20.00       400.00         8.00       408.00         4.00      1784.00         4.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 3, step 999: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.73      96.49      96.61     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         97.10      88.69      92.71      54804
--, (label_id: 3)                                         61.91      66.92      64.32      40800
--- (label_id: 4)                                         62.18      61.32      61.74       3464
--. (label_id: 5)                                         71.48      77.96      74.58      33424
--: (label_id: 6)                                          4.21       1.97       2.68        812
--? (label_id: 7)                                         54.34      71.71      61.83       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               92.57      92.57      92.57     659880
--macro avg                                               49.77      51.67      50.50     659880
--weighted avg                                            92.75      92.57      92.63     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   504696.00        68.00      5900.00      7576.00      1048.00      1924.00       240.00       236.00        52.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1396.00         0.00     48608.00        20.00        24.00        12.00         0.00         0.00         0.00
--    10964.00       132.00        64.00     27304.00       216.00      4920.00       236.00       192.00        72.00
--     1020.00         0.00       132.00       128.00      2124.00        12.00         0.00         0.00         0.00
--     4196.00       248.00        88.00      5064.00        40.00     26056.00       304.00       372.00        84.00
--      200.00         0.00         8.00       152.00         0.00         4.00        16.00         0.00         0.00
--      584.00        24.00         4.00       556.00        12.00       496.00        16.00      2028.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 4, step 1049: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          94.84      98.08      96.43     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         98.53      81.48      89.20      54804
--, (label_id: 3)                                         67.47      60.25      63.66      40800
--- (label_id: 4)                                         65.13      58.89      61.86       3464
--. (label_id: 5)                                         77.35      72.15      74.66      33424
--: (label_id: 6)                                          6.67       2.46       3.60        812
--? (label_id: 7)                                         66.26      60.82      63.42       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               92.46      92.46      92.46     659880
--macro avg                                               52.92      48.24      50.31     659880
--weighted avg                                            92.08      92.46      92.17     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   513024.00        92.00      9884.00     11672.00      1184.00      4168.00       344.00       472.00        84.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      600.00         0.00     44652.00        20.00        28.00        16.00         0.00         0.00         0.00
--     6192.00       148.00        32.00     24584.00       132.00      4776.00       208.00       272.00        92.00
--      828.00         0.00       204.00        60.00      2040.00         0.00         0.00         0.00         0.00
--     2096.00       216.00        32.00      4068.00        16.00     24116.00       236.00       364.00        32.00
--      168.00         0.00         0.00        40.00        64.00         8.00        20.00         0.00         0.00
--      148.00        16.00         0.00       356.00         0.00       340.00         4.00      1720.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 5, step 1099: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.42      97.26      96.84     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         96.89      90.07      93.36      54804
--, (label_id: 3)                                         64.67      65.10      64.88      40800
--- (label_id: 4)                                         61.01      63.97      62.46       3464
--. (label_id: 5)                                         75.87      75.59      75.73      33424
--: (label_id: 6)                                         14.29       2.46       4.20        812
--? (label_id: 7)                                         59.57      67.33      63.21       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.05      93.05      93.05     659880
--macro avg                                               52.08      51.31      51.19     659880
--weighted avg                                            92.91      93.05      92.96     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508716.00        68.00      5096.00      8936.00      1036.00      3024.00       280.00       372.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1492.00         0.00     49364.00        32.00        36.00        24.00         0.00         0.00         0.00
--     9016.00       172.00        36.00     26560.00       132.00      4504.00       284.00       264.00       104.00
--     1076.00         0.00       276.00        64.00      2216.00         0.00         0.00         0.00         0.00
--     2492.00       216.00        32.00      4728.00        24.00     25264.00       216.00       288.00        40.00
--       60.00         0.00         0.00        40.00        12.00         8.00        20.00         0.00         0.00
--      204.00        16.00         0.00       440.00         8.00       600.00        12.00      1904.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 6, step 1149: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.49      97.24      96.86     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         96.73      90.36      93.44      54804
--, (label_id: 3)                                         64.80      65.04      64.92      40800
--- (label_id: 4)                                         64.12      62.12      63.11       3464
--. (label_id: 5)                                         75.35      76.33      75.84      33424
--: (label_id: 6)                                         22.73       2.46       4.44        812
--? (label_id: 7)                                         58.91      68.74      63.45       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.09      93.09      93.09     659880
--macro avg                                               53.24      51.37      51.34     659880
--weighted avg                                            92.95      93.09      93.00     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508616.00        72.00      4992.00      8792.00      1104.00      2864.00       280.00       364.00        56.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1572.00         0.00     49520.00        40.00        36.00        24.00         0.00         0.00         0.00
--     9072.00       152.00        36.00     26536.00       128.00      4416.00       280.00       240.00        88.00
--      920.00         0.00       224.00        60.00      2152.00         0.00         0.00         0.00         0.00
--     2604.00       224.00        32.00      4892.00        28.00     25512.00       220.00       280.00        64.00
--       28.00         0.00         0.00        24.00         8.00         8.00        20.00         0.00         0.00
--      244.00        24.00         0.00       456.00         8.00       600.00        12.00      1944.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 7, step 1199: val_loss was not in top 3
--[INFO] - GPU available: True, used: True
--[INFO] - TPU available: None, using: 0 TPU cores
--[INFO] - Using environment variable NODE_RANK for node rank (0).
--[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.25      97.27      96.76     650284
--! (label_id: 1)                                          0.00       0.00       0.00        380
--# (label_id: 2)                                         97.23      89.79      93.36      68496
--, (label_id: 3)                                         62.58      64.85      63.69      52348
--- (label_id: 4)                                         49.90      60.65      54.75       3212
--. (label_id: 5)                                         79.01      73.40      76.10      46276
--: (label_id: 6)                                         20.00       2.25       4.05        888
--? (label_id: 7)                                         60.00      67.50      63.53       4000
--… (label_id: 8)                                          0.00       0.00       0.00        260
---------------------
--micro avg                                               92.79      92.79      92.79     826144
--macro avg                                               51.66      50.63      50.25     826144
--weighted avg                                            92.72      92.79      92.72     826144
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   632504.00        36.00      6712.00     12044.00      1116.00      3904.00       244.00       476.00       108.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1596.00         0.00     61504.00        28.00        52.00        76.00         0.00         0.00         0.00
--    11756.00       140.00         8.00     33948.00        68.00      7492.00       300.00       432.00       104.00
--     1636.00         0.00       232.00        36.00      1948.00        52.00         0.00         0.00         0.00
--     2480.00       180.00        28.00      5584.00        16.00     33968.00       304.00       392.00        40.00
--       20.00         0.00         0.00        28.00        12.00        20.00        20.00         0.00         0.00
--      292.00        24.00        12.00       680.00         0.00       764.00        20.00      2700.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Chunked Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.57      97.15      96.86     327564
--! (label_id: 1)                                          0.00       0.00       0.00        184
--# (label_id: 2)                                         97.23      90.48      93.73      34404
--, (label_id: 3)                                         63.38      67.07      65.18      26324
--- (label_id: 4)                                         50.74      63.34      56.35       1724
--. (label_id: 5)                                         80.87      76.47      78.61      23376
--: (label_id: 6)                                          8.33       0.88       1.59        456
--? (label_id: 7)                                         59.61      72.62      65.47       2016
--… (label_id: 8)                                          0.00       0.00       0.00         92
---------------------
--micro avg                                               93.10      93.10      93.10     416140
--macro avg                                               50.75      52.00      50.86     416140
--weighted avg                                            93.12      93.10      93.08     416140
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   318220.00        20.00      3140.00      5728.00       532.00      1500.00       124.00       184.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      788.00         0.00     31128.00         8.00        32.00        60.00         0.00         0.00         0.00
--     6236.00        84.00         0.00     17656.00        48.00      3444.00       144.00       220.00        24.00
--      872.00         0.00       128.00        16.00      1092.00        44.00         0.00         0.00         0.00
--     1240.00        72.00         8.00      2568.00        16.00     17876.00       168.00       148.00         8.00
--       16.00         0.00         0.00         4.00         4.00        20.00         4.00         0.00         0.00
--      192.00         8.00         0.00       344.00         0.00       432.00        16.00      1464.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       6884
---------------------
--micro avg                                              100.00     100.00     100.00       6884
--macro avg                                              100.00     100.00     100.00       6884
--weighted avg                                           100.00     100.00     100.00       6884
--
---------------------
--           0
--     6884.00
---------------------
--
--[INFO] - saving to /home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/test.txt
--[INFO] - Internal process exited
-diff --git a/experiment/outputs/2021-02-23/08-18-26/testing.log b/experiment/outputs/2021-02-23/08-18-26/testing.log
-index f00f863..2597221 100644
---- a/experiment/outputs/2021-02-23/08-18-26/testing.log
-+++ b/experiment/outputs/2021-02-23/08-18-26/testing.log
-@@ -1 +1,74 @@
- [2021-02-23 08:18:38,771][root][INFO] - shuffling train set
-+[2021-02-23 08:44:12,424][root][INFO] - Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          95.20      95.06      95.13   33617452
-+! (label_id: 1)                                         21.65      40.73      28.27     578585
-+# (label_id: 2)                                         89.63      94.36      91.93    6976446
-+, (label_id: 3)                                         52.02      49.20      50.57    2858145
-+- (label_id: 4)                                         52.90      37.64      43.98     255633
-+. (label_id: 5)                                         67.03      64.56      65.77    5425019
-+: (label_id: 6)                                          0.00       0.00       0.00      15576
-+? (label_id: 7)                                         66.11      48.89      56.21    1415356
-+… (label_id: 8)                                         28.23      27.42      27.82     482702
-+-------------------
-+micro avg                                               86.40      86.40      86.40   51624912
-+macro avg                                               52.53      50.87      51.07   51624912
-+weighted avg                                            86.61      86.40      86.42   51624912
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 31955872.00     33316.00    385671.00    438274.00     53505.00    443163.00      7682.00    120484.00    128329.00
-+    66565.00    235635.00       761.00    176016.00      8738.00    506812.00       944.00     64244.00     28918.00
-+   714124.00       536.00   6582626.00      7720.00     19841.00     15709.00      1649.00      1336.00      1001.00
-+   288086.00     97827.00       833.00   1406100.00     11576.00    706306.00       912.00    121425.00     69959.00
-+    56237.00      2410.00       944.00      5163.00     96209.00     18095.00        96.00      1041.00      1680.00
-+   390319.00    174383.00      3985.00    635086.00     21274.00   3502327.00      3717.00    389488.00    104418.00
-+        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-+    75395.00     24645.00       937.00     80919.00      3444.00    153187.00       136.00    691913.00     16045.00
-+    70772.00      9833.00       689.00    108867.00     41046.00     79420.00       440.00     25425.00    132352.00
-+-------------------
-+
-+[2021-02-23 08:44:12,434][root][INFO] - Chunked Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          95.59      96.37      95.98   16876740
-+! (label_id: 1)                                         21.47      41.98      28.41     290645
-+# (label_id: 2)                                         95.04      95.14      95.09    3541392
-+, (label_id: 3)                                         52.20      49.91      51.03    1447727
-+- (label_id: 4)                                         53.56      38.01      44.47     130953
-+. (label_id: 5)                                         68.20      65.03      66.58    2759312
-+: (label_id: 6)                                          0.00       0.00       0.00       7645
-+? (label_id: 7)                                         66.66      50.42      57.42     716850
-+… (label_id: 8)                                         28.64      27.84      28.23     243286
-+-------------------
-+micro avg                                               87.46      87.46      87.46   26014552
-+macro avg                                               53.49      51.63      51.91   26014552
-+weighted avg                                            87.71      87.46      87.50   26014552
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 16264699.00     14196.00    169436.00    215171.00     26620.00    202508.00      3785.00     54437.00     63531.00
-+    33928.00    122012.00       272.00     91962.00      4505.00    266896.00       504.00     33168.00     15114.00
-+   151602.00       248.00   3369444.00      3788.00     10412.00      7913.00       881.00       624.00       328.00
-+   147638.00     49831.00       344.00    722501.00      5999.00    360923.00       448.00     60458.00     35874.00
-+    28414.00      1192.00       464.00      2722.00     49780.00      8964.00        32.00       537.00       840.00
-+   177113.00     85795.00      1072.00    314405.00     10733.00   1794350.00      1747.00    194183.00     51583.00
-+        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-+    37372.00     12602.00       168.00     41387.00      1825.00     79031.00        64.00    361456.00      8297.00
-+    35974.00      4769.00       192.00     55791.00     21079.00     38727.00       184.00     11987.00     67719.00
-+-------------------
-+
-+[2021-02-23 08:44:12,439][root][INFO] - Domain report: 
-+label                                                precision    recall       f1           support   
-+0 (label_id: 0)                                        100.00     100.00     100.00     411653
-+-------------------
-+micro avg                                              100.00     100.00     100.00     411653
-+macro avg                                              100.00     100.00     100.00     411653
-+weighted avg                                           100.00     100.00     100.00     411653
-+
-+-------------------
-+           0
-+   411653.00
-+-------------------
-+
-+[2021-02-23 08:44:12,439][root][INFO] - saving to /home/nxingyu/project/Punctuation_with_Domain_discriminator/opendice33acc42021-02-22_09-49-04//test.txt
-+[2021-02-23 08:44:12,539][wandb.sdk.internal.internal][INFO] - Internal process exited
-diff --git a/experiment/outputs/2021-02-23/08-20-55/testing.log b/experiment/outputs/2021-02-23/08-20-55/testing.log
-index 717645a..7100fd1 100644
---- a/experiment/outputs/2021-02-23/08-20-55/testing.log
-+++ b/experiment/outputs/2021-02-23/08-20-55/testing.log
-@@ -1 +1,74 @@
- [2021-02-23 08:21:08,018][root][INFO] - shuffling train set
-+[2021-02-23 09:05:21,673][root][INFO] - Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          94.88      97.99      96.41   33617452
-+! (label_id: 1)                                         33.89       9.66      15.04     578585
-+# (label_id: 2)                                         99.49      99.10      99.30    6976446
-+, (label_id: 3)                                         52.51      39.66      45.19    2858145
-+- (label_id: 4)                                         56.89      22.57      32.32     255633
-+. (label_id: 5)                                         62.04      77.10      68.76    5425019
-+: (label_id: 6)                                         77.05      41.40      53.86      15576
-+? (label_id: 7)                                         70.01      36.10      47.64    1415356
-+… (label_id: 8)                                         57.21       6.15      11.10     482702
-+-------------------
-+micro avg                                               88.78      88.78      88.78   51624912
-+macro avg                                               67.11      47.75      52.18   51624912
-+weighted avg                                            87.80      88.78      87.68   51624912
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 32940746.00     42247.00     56263.00    637305.00    117974.00    572846.00      3579.00    174660.00    172542.00
-+    10770.00     55899.00        88.00     35948.00      1672.00     46823.00       184.00      8367.00      5210.00
-+    27771.00       545.00   6913637.00      1128.00      1968.00      2819.00        16.00       480.00       560.00
-+   163910.00    113876.00       544.00   1133679.00     17942.00    526536.00       840.00    121929.00     79630.00
-+    19931.00      1771.00       104.00      4132.00     57687.00     14847.00        40.00       600.00      2282.00
-+   403834.00    347864.00      5066.00    988029.00     38393.00   4182951.00      4372.00    597272.00    174593.00
-+      608.00         0.00         0.00       505.00       360.00       288.00      6449.00        32.00       128.00
-+    48028.00     16247.00       712.00     54579.00      4683.00     76459.00        80.00    510999.00     18088.00
-+     1745.00       136.00        32.00      2840.00     14954.00      1450.00        16.00      1017.00     29669.00
-+-------------------
-+
-+[2021-02-23 09:05:21,682][root][INFO] - Chunked Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          95.08      98.11      96.57   16876740
-+! (label_id: 1)                                         33.70      10.09      15.54     290645
-+# (label_id: 2)                                         99.61      99.52      99.57    3541392
-+, (label_id: 3)                                         52.66      40.24      45.62    1447727
-+- (label_id: 4)                                         57.66      22.91      32.79     130953
-+. (label_id: 5)                                         62.89      77.75      69.53    2759312
-+: (label_id: 6)                                         78.52      42.08      54.79       7645
-+? (label_id: 7)                                         70.98      37.06      48.70     716850
-+… (label_id: 8)                                         58.27       6.35      11.46     243286
-+-------------------
-+micro avg                                               89.00      89.00      89.00   26014552
-+macro avg                                               67.71      48.24      52.73   26014552
-+weighted avg                                            88.03      89.00      87.92   26014552
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 16557577.00     19231.00     15829.00    319520.00     60251.00    272070.00      1746.00     82502.00     86301.00
-+     5837.00     29340.00        16.00     18850.00       800.00     24913.00       120.00      4276.00      2921.00
-+    11597.00        88.00   3524547.00       280.00       800.00       737.00         8.00        88.00        96.00
-+    83677.00     57621.00       136.00    582598.00      9566.00    269820.00       440.00     61935.00     40462.00
-+    10150.00       904.00        56.00      2011.00     29998.00      7605.00        16.00       240.00      1049.00
-+   183939.00    175228.00       744.00    495087.00     19564.00   2145232.00      2058.00    301633.00     87509.00
-+      176.00         0.00         0.00       296.00       128.00       168.00      3217.00        16.00        96.00
-+    22954.00      8169.00        64.00     27597.00      2353.00     38063.00        32.00    265680.00      9397.00
-+      833.00        64.00         0.00      1488.00      7493.00       704.00         8.00       480.00     15455.00
-+-------------------
-+
-+[2021-02-23 09:05:21,687][root][INFO] - Domain report: 
-+label                                                precision    recall       f1           support   
-+0 (label_id: 0)                                        100.00     100.00     100.00     411653
-+-------------------
-+micro avg                                              100.00     100.00     100.00     411653
-+macro avg                                              100.00     100.00     100.00     411653
-+weighted avg                                           100.00     100.00     100.00     411653
-+
-+-------------------
-+           0
-+   411653.00
-+-------------------
-+
-+[2021-02-23 09:05:21,688][root][INFO] - saving to /home/nxingyu/project/Punctuation_with_Domain_discriminator/opencrfacc42021-02-22_09-48-50//test.txt
-+[2021-02-23 09:05:21,785][wandb.sdk.internal.internal][INFO] - Internal process exited
-diff --git a/experiment/testing.py b/experiment/testing.py
-index 3e967b0..77f95ad 100644
---- a/experiment/testing.py
-+++ b/experiment/testing.py
-@@ -1,3 +1,8 @@
-+
-+
-+
-+
-+
- #%%
- import hydra
- import numpy as np
-@@ -20,7 +25,7 @@ import atexit
- from copy import deepcopy
- import snoop
- snoop.install()
--exp='opencrfacc42021-02-22_09-48-50'
-+exp='2021-02-23_09-59-35'
- @hydra.main(config_path=f"../Punctuation_with_Domain_discriminator/{exp}/",config_name="hparams.yaml")
- def main(cfg : DictConfig) -> None:
-     torch.set_printoptions(sci_mode=False)
-@@ -41,7 +46,7 @@ def main(cfg : DictConfig) -> None:
-                     max_seq_length=model.dm.max_seq_length,
-                     punct_label_ids=model.dm.punct_label_ids,
-                     label_map=model.dm.label_map,
--                    labelled=['/home/nxingyu/data/open_subtitles_processed'],
-+                    labelled=['/home/nxingyu/data/ted_talks_processed'],
-                     unlabelled=[],
-                     tokenizer=model.dm.tokenizer,
-                     randomize=model.dm.val_shuffle,
-@@ -49,7 +54,7 @@ def main(cfg : DictConfig) -> None:
-                     tmp_path=model.dm.tmp_path,
-                     attach_label_to_end=model.dm.attach_label_to_end,
-                     no_space_label=model.dm.no_space_label,
--                    pad_start=0,
-+                    pad_start=model.dm.pad_start,
-                     )
-     model.hparams.log_dir=f"/home/nxingyu/project/Punctuation_with_Domain_discriminator/{exp}/"
-     trainer = pl.Trainer(**cfg.trainer)
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-25-55/lightning_logs.txt b/Punctuation_with_Domain_discriminator/2021-02-23_13-25-55/lightning_logs.txt
deleted file mode 100644
index 697743d..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_13-25-55/lightning_logs.txt
+++ /dev/null
@@ -1,5 +0,0 @@
-Global seed set to 42
-GPU available: True, used: True
-TPU available: None, using: 0 TPU cores
-LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
-Using native 16bit precision.
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-25-55/nemo_error_log.txt b/Punctuation_with_Domain_discriminator/2021-02-23_13-25-55/nemo_error_log.txt
deleted file mode 100644
index a1ab78d..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_13-25-55/nemo_error_log.txt
+++ /dev/null
@@ -1 +0,0 @@
-[NeMo W 2021-02-23 13:25:55 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_13-25-55/nemo_log_globalrank-0_localrank-0.txt b/Punctuation_with_Domain_discriminator/2021-02-23_13-25-55/nemo_log_globalrank-0_localrank-0.txt
deleted file mode 100644
index 91bb0e1..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_13-25-55/nemo_log_globalrank-0_localrank-0.txt
+++ /dev/null
@@ -1,3 +0,0 @@
-[NeMo I 2021-02-23 13:25:55 exp_manager:183] Experiments will be logged at /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_13-25-55
-[NeMo I 2021-02-23 13:25:55 exp_manager:519] TensorboardLogger has been set up
-[NeMo W 2021-02-23 13:25:55 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/cmd-args.log b/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/cmd-args.log
deleted file mode 100644
index 11a5d8e..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/cmd-args.log
+++ /dev/null
@@ -1 +0,0 @@
-main.py
\ No newline at end of file
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/events.out.tfevents.1614062508.Titan.20608.0 b/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/events.out.tfevents.1614062508.Titan.20608.0
deleted file mode 100644
index 23c3a1c..0000000
Binary files a/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/events.out.tfevents.1614062508.Titan.20608.0 and /dev/null differ
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/git-info.log b/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/git-info.log
deleted file mode 100644
index 7f34a55..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/git-info.log
+++ /dev/null
@@ -1,1745 +0,0 @@
-commit hash: a95e08f7dafab6a88b25b93525195e2018fcf89f
-diff --git a/README.md b/README.md
-index 4792b93..54a7ce0 100644
---- a/README.md
-+++ b/README.md
-@@ -91,8 +91,9 @@ bash ~/project/get-data.sh
- bash ~/project/experiment/data/disfl2csv.sh /home/nxingyu/data/LDC99T42/treebank_3/dysfl/dff/swbd /home/nxingyu/data/switchboard_processed.csv
- bash ~/project/bin/processandsplit.sh ./switchboard_processed.csv 8 1 1
- 
--bash ~/project/experiment/data/utt2csv.sh /home/nxingyu/data/utt switchboardutt_processed.csv
--sed -i 1i"id,transcript" switchboard*
-+bash ~/project/experiment/data/utt2csv.sh /home/nxingyu/data/utt /home/nxingyu/data/switchboardutt_processed.csv
-+bash ~/project/bin/processandsplit.sh ./switchboardutt_processed.csv 8 1 1
-+sed -i 1i"id,transcript" switchboard_*
- 
- python ~/project/processcsv.py -i ~/data/ted_talks_en.csv -o ~/data/ted_talks_processed.csv -c 2000
- bash ~/project/bin/processandsplit.sh ./ted_talks_processed.csv 8 1 1
-diff --git a/experiment/config.yaml b/experiment/config.yaml
-index aecc0bb..bf671c1 100644
---- a/experiment/config.yaml
-+++ b/experiment/config.yaml
-@@ -4,7 +4,7 @@ trainer:
-     num_nodes: 1
-     max_epochs: 8
-     max_steps: null # precedence over max_epochs
--    accumulate_grad_batches: 2 # accumulates grads every k batches
-+    accumulate_grad_batches: 32 # accumulates grads every k batches
-     gradient_clip_val: 0
-     amp_level: O1 # O1/O2 for mixed precision
-     precision: 16 # Should be set to 16 for O1 and O2, default is 16 as PT ignores it when am_level is O0
-@@ -32,12 +32,12 @@ trainer:
-     # resume_from_checkpoint: null
- 
- exp_manager:
--    exp_dir: /home/nxingyu2/project/ # /root/project # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
-+    exp_dir: /home/nxingyu/project/ # /root/project # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
-     name: Punctuation_with_Domain_discriminator  # The name of your model
-     create_tensorboard_logger: true  # Whether you want exp_manger to create a tb logger
-     create_checkpoint_callback: true 
--base_path: /home/nxingyu2/data # /root/data # 
--tmp_path: /home/nxingyu2/data/tmp # /tmp # 
-+base_path: /home/nxingyu/data # /root/data # 
-+tmp_path: /home/nxingyu/data/tmp # /tmp # 
- log_dir: null
- 
- model:
-@@ -75,15 +75,17 @@ model:
-     punct_class_weights: false #false
-     
-     dataset:
--        data_dir: /home/nxingyu2/data # /root/data # 
-+        data_dir: /home/nxingyu/data # /root/data # 
-         labelled:
-             # - ${base_path}/ted2010 #
--            - ${base_path}/ted_talks_processed #
-+            # - ${base_path}/ted_talks_processed #
-             # - ${base_path}/open_subtitles_processed #  
-+            - ${base_path}/switchboardutt_processed #
-         unlabelled:
-             # - ${base_path}/ted_talks_processed #
-             # - ${base_path}/open_subtitles_processed #  
--            # parameters for dataset preprocessing
-+            # - ${base_path}/switchboardutt_processed
-+        # parameters for dataset preprocessing
-         max_seq_length: 128
-         pad_label: ''
-         ignore_extra_tokens: false
-@@ -101,7 +103,7 @@ model:
-         train_ds:
-             shuffle: true
-             num_samples: -1
--            batch_size: 32
-+            batch_size: 8
-             manual_len: 20000 #default 0 84074
- 
-         validation_ds:
-@@ -110,7 +112,7 @@ model:
-             # ds_item: null # expected format: [PATH_TO_DEV1,PATH_TO_DEV2] (Note no space between the paths and square brackets)
-             shuffle: true
-             num_samples: -1
--            batch_size: 32 #4
-+            batch_size: 8 #4
- 
-     tokenizer:
-         tokenizer_name: ${model.language_model.pretrained_model_name} # or sentencepiece
-@@ -126,12 +128,12 @@ model:
-         # unfrozen_layers: 1
-     
-     punct_head:
--        punct_num_fc_layers: 3
-+        punct_num_fc_layers: 0
-         fc_dropout: 0.1
-         activation: 'gelu'
-         log_softmax: false
-         use_transformer_init: true
--        loss: 'dice'
-+        loss: 'crf'
-         bilstm: false
- 
-     domain_head:
-@@ -147,7 +149,7 @@ model:
-     
-     dice_loss:
-         epsilon: 0.01
--        alpha: 3
-+        alpha: 2
-         macro_average: true
- 
-     focal_loss: 
-diff --git a/experiment/data/disfl2csv.sh b/experiment/data/disfl2csv.sh
-index 84d8b69..48148a0 100644
---- a/experiment/data/disfl2csv.sh
-+++ b/experiment/data/disfl2csv.sh
-@@ -4,10 +4,10 @@ echo "in $1"
- echo "out $2"
- :> "$2"
- DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
--echo 'talk_id,transcript'> "$2"
-+# echo 'talk_id,transcript'> "$2"
- #echo "filenames, transcript" > opensubtitles.csv
- for folder in $1/*; do
--    for filename in $folder/*.dfl; do
-+    for filename in $folder/*.dff; do
-         echo $filename
-         python $DIR/processdff.py -i $filename -o $2
-         #echo "$filename, \"$transcript\"" >> opensubtitles.csv
-diff --git a/experiment/data/processdff.py b/experiment/data/processdff.py
-index b456a43..7e76f7f 100644
---- a/experiment/data/processdff.py
-+++ b/experiment/data/processdff.py
-@@ -42,7 +42,7 @@ def remove_disf(text):
-     return s
- 
- def to_emdash(s):
--    return re.sub('--','',s)
-+    return re.sub('--','…',s)
- 
- def strip_accents(s):
-    return ''.join(c for c in unicodedata.normalize('NFKD', s)
-diff --git a/experiment/data/processutt.py b/experiment/data/processutt.py
-index d6c1af1..d809a43 100644
---- a/experiment/data/processutt.py
-+++ b/experiment/data/processutt.py
-@@ -42,7 +42,7 @@ def remove_disf(text):
-     return s
- 
- def to_emdash(s):
--    return re.sub('--','',s)
-+    return re.sub('--','…',s)
- 
- def strip_accents(s):
-    return ''.join(c for c in unicodedata.normalize('NFKD', s)
-diff --git a/experiment/data/punctuation_count.sh b/experiment/data/punctuation_count.sh
-index f5d71be..29ca0ca 100644
---- a/experiment/data/punctuation_count.sh
-+++ b/experiment/data/punctuation_count.sh
-@@ -1,8 +1,28 @@
- for split in "dev" "test" "train"
- do
--for file in /home/nxingyu2/data/open*.$split.csv
-+for file in /home/$USER/data/switch*.$split.csv
- do
-  echo $file
-  sed -E 's/[^[:punct:]]//g;s/(.)/\1x/g' $file  | tr 'x' '\n' | sort | uniq -c | awk '{array[$2]=$1; sum+=$1} END { for (i in array) printf "%-20s %-15d %6.2f%%\n", i, array[i], array[i]/sum*100}' | sort -r -k2,2 -n
- done
--done
-\ No newline at end of file
-+done
-+
-+# 205429 & 26199 & 16520 &
-+# 100843 & 13457 &  9141 &
-+#      0 &     0 &     0 &
-+#  22730 &  3331 &  2012 &
-+#   6765 &   808 &   528 &
-+#      0 &     0 &    16 &
-+#      0 &     0 &     0 &
-+#     77 &     5 &     6 &
-+#  18720 &  3133 &  2249 &
-+
-+# 0.57938 & 0.55822 & 0.54214 &
-+# 0.28441 & 0.28673 & 0.29998 &
-+# 0.00000 & 0.00000 & 0.00000 &
-+# 0.06411 & 0.07097 & 0.06603 &
-+# 0.01908 & 0.01722 & 0.01733 &
-+# 0.00000 & 0.00000 & 0.00053 &
-+# 0.00000 & 0.00000 & 0.00000 &
-+# 0.00022 & 0.00011 & 0.00020 &
-+# 0.05280 & 0.06675 & 0.07381 &
-diff --git a/experiment/data/utt2csv.sh b/experiment/data/utt2csv.sh
-index 7e03880..446d32a 100644
---- a/experiment/data/utt2csv.sh
-+++ b/experiment/data/utt2csv.sh
-@@ -4,7 +4,7 @@ echo "in $1"
- echo "out $2"
- :> "$2"
- DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
--echo 'talk_id,transcript'> "$2"
-+# echo 'talk_id,transcript'> "$2"
- #echo "filenames, transcript" > opensubtitles.csv
- for folder in $1/sw*; do
-     for filename in $folder/*.utt; do
-diff --git a/experiment/info.log b/experiment/info.log
-index 7d07c8a..e69de29 100644
---- a/experiment/info.log
-+++ b/experiment/info.log
-@@ -1,1341 +0,0 @@
--[INFO] - GPU available: True, used: True
--[INFO] - TPU available: None, using: 0 TPU cores
--[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
--[INFO] - Using native 16bit precision.
--[INFO] - shuffling train set
--[INFO] - initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.02
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7ff2c4092a30>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 4.7 M 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--5.9 M     Trainable params
--108 M     Non-trainable params
--114 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          78.98      44.46      56.89      80644
--! (label_id: 1)                                          0.04       2.04       0.08         98
--# (label_id: 2)                                          4.92      15.57       7.47       8270
--, (label_id: 3)                                          1.99       0.27       0.47       5934
--- (label_id: 4)                                          0.64       3.85       1.10        572
--. (label_id: 5)                                          6.34       3.38       4.41       5092
--: (label_id: 6)                                          0.19      20.34       0.38        118
--? (label_id: 7)                                          0.00       0.00       0.00        462
--… (label_id: 8)                                          0.04       5.26       0.08         38
---------------------
--micro avg                                               36.93      36.93      36.93     101228
--macro avg                                               10.35      10.57       7.88     101228
--weighted avg                                            63.76      36.93      46.19     101228
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    35854.00        20.00      4032.00      2572.00       284.00      2412.00        52.00       166.00         2.00
--     3840.00         2.00       232.00       400.00        42.00       298.00        10.00        34.00         2.00
--    21412.00        46.00      1288.00      1784.00        84.00      1388.00        22.00       150.00        18.00
--      662.00         0.00       116.00        16.00         2.00        10.00         0.00         0.00         0.00
--     2430.00         2.00       832.00        86.00        22.00        40.00         4.00         0.00         0.00
--     2196.00         0.00       100.00       202.00        12.00       172.00         6.00        22.00         2.00
--    10048.00        28.00       742.00       722.00        62.00       696.00        24.00        86.00        12.00
--      316.00         0.00        38.00         0.00         4.00         0.00         0.00         0.00         0.00
--     3886.00         0.00       890.00       152.00        60.00        76.00         0.00         4.00         2.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00        858
---------------------
--micro avg                                              100.00     100.00     100.00        858
--macro avg                                              100.00     100.00     100.00        858
--weighted avg                                           100.00     100.00     100.00        858
--
---------------------
--           0
--      858.00
---------------------
--
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.41      91.92      94.59     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         86.21      89.77      87.95      54804
--, (label_id: 3)                                         42.62      62.03      50.53      40800
--- (label_id: 4)                                         69.89      60.05      64.60       3464
--. (label_id: 5)                                         57.56      74.40      64.91      33424
--: (label_id: 6)                                         16.67      24.14      19.72        812
--? (label_id: 7)                                         65.62      29.42      40.62       2828
--… (label_id: 8)                                          1.33       7.27       2.25        220
---------------------
--micro avg                                               88.40      88.40      88.40     659880
--macro avg                                               48.59      48.78      47.24     659880
--weighted avg                                            90.59      88.40      89.23     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   480808.00        16.00      5380.00      4796.00      1016.00      1340.00        96.00       120.00        40.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     7796.00         0.00     49196.00         8.00        44.00        24.00         0.00         0.00         0.00
--    26532.00       224.00        48.00     25308.00       172.00      6400.00       188.00       420.00        84.00
--      828.00         0.00        64.00         4.00      2080.00         0.00         0.00         0.00         0.00
--     6328.00       196.00       104.00      9840.00       104.00     24868.00       300.00      1388.00        72.00
--      184.00        12.00         0.00       340.00         0.00       396.00       196.00        40.00         8.00
--      116.00        16.00         4.00       132.00         0.00       156.00        12.00       832.00         0.00
--      464.00         8.00         8.00       372.00        48.00       240.00        20.00        28.00        16.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 0, global step 49: val_loss reached 0.30009 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=0.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.50      88.95      93.03     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         67.87      92.39      78.25      54804
--, (label_id: 3)                                         41.27      74.84      53.20      40800
--- (label_id: 4)                                         82.54      50.23      62.46       3464
--. (label_id: 5)                                         68.11      62.47      65.17      33424
--: (label_id: 6)                                         43.10      12.32      19.16        812
--? (label_id: 7)                                         64.81      24.75      35.82       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               86.36      86.36      86.36     659880
--macro avg                                               51.69      45.11      45.23     659880
--weighted avg                                            89.68      86.36      87.33     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   465264.00        28.00      4072.00      5152.00       888.00      1396.00       180.00       172.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--    23120.00         0.00     50632.00       256.00       564.00        20.00         0.00         8.00         0.00
--    30964.00       180.00        72.00     30536.00       212.00     10932.00       284.00       708.00       104.00
--      356.00         0.00         0.00         0.00      1740.00        12.00         0.00         0.00         0.00
--     3248.00       228.00        24.00      4672.00        60.00     20880.00       248.00      1240.00        56.00
--       16.00         0.00         0.00        24.00         0.00        92.00       100.00         0.00         0.00
--       88.00        36.00         4.00       160.00         0.00        92.00         0.00       700.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 1, global step 99: val_loss reached 0.33170 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.33-epoch=1.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.41      97.01      96.20     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         94.34      88.26      91.20      54804
--, (label_id: 3)                                         56.69      58.49      57.58      40800
--- (label_id: 4)                                         87.42      48.15      62.10       3464
--. (label_id: 5)                                         70.05      64.34      67.07      33424
--: (label_id: 6)                                         58.54      11.82      19.67        812
--? (label_id: 7)                                         55.41      36.92      44.31       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.53      91.53      91.53     659880
--macro avg                                               57.54      45.00      48.68     659880
--weighted avg                                            91.28      91.53      91.33     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   507420.00        60.00      6400.00     12064.00      1516.00      3824.00       220.00       276.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2776.00         0.00     48372.00         8.00        96.00        20.00         0.00         0.00         0.00
--     9396.00       160.00         8.00     23864.00       124.00      7724.00       232.00       508.00        80.00
--      240.00         0.00         0.00         0.00      1668.00         0.00         0.00         0.00         0.00
--     3024.00       192.00        20.00      4588.00        60.00     21504.00       256.00      1000.00        56.00
--        8.00         0.00         0.00         8.00         0.00        52.00        96.00         0.00         0.00
--      192.00        60.00         4.00       268.00         0.00       300.00         8.00      1044.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 2, global step 149: val_loss reached 0.31563 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.32-epoch=2.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.90      96.12      96.01     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         89.97      88.46      89.21      54804
--, (label_id: 3)                                         53.45      64.22      58.34      40800
--- (label_id: 4)                                         82.01      53.70      64.90       3464
--. (label_id: 5)                                         71.61      60.91      65.83      33424
--: (label_id: 6)                                         22.89      22.66      22.77        812
--? (label_id: 7)                                         66.35      29.28      40.63       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.03      91.03      91.03     659880
--macro avg                                               53.57      46.15      48.63     659880
--weighted avg                                            91.17      91.03      91.00     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   502752.00        56.00      6284.00     10168.00      1144.00      3256.00       196.00       308.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     5080.00         0.00     48480.00        36.00       268.00        20.00         0.00         0.00         0.00
--    12200.00       184.00        24.00     26200.00       148.00      9364.00       200.00       608.00        92.00
--      404.00         0.00         0.00         4.00      1860.00         0.00         0.00         0.00         0.00
--     2368.00       196.00        12.00      4080.00        44.00     20360.00       232.00      1072.00        68.00
--      160.00         4.00         0.00       164.00         0.00       280.00       184.00        12.00         0.00
--       92.00        32.00         4.00       148.00         0.00       144.00         0.00       828.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 3, global step 199: val_loss reached 0.31315 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.31-epoch=3.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.75      95.17      95.95     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         89.22      90.48      89.85      54804
--, (label_id: 3)                                         51.13      69.58      58.95      40800
--- (label_id: 4)                                         77.34      59.12      67.02       3464
--. (label_id: 5)                                         70.86      63.12      66.76      33424
--: (label_id: 6)                                         57.14       9.85      16.81        812
--? (label_id: 7)                                         58.43      35.79      44.39       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               90.92      90.92      90.92     659880
--macro avg                                               55.65      47.01      48.86     659880
--weighted avg                                            91.58      90.92      91.11     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   497780.00        44.00      5156.00      7900.00      1008.00      2248.00       148.00       156.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     5716.00         0.00     49584.00        60.00       180.00        32.00         0.00         0.00         0.00
--    15936.00       176.00        44.00     28388.00       180.00      9708.00       364.00       620.00       100.00
--      588.00         0.00         4.00         8.00      2048.00         0.00         0.00         0.00         0.00
--     2884.00       208.00        12.00      4220.00        48.00     21096.00       212.00      1032.00        60.00
--        0.00         0.00         0.00         8.00         0.00        44.00        80.00         8.00         0.00
--      152.00        44.00         4.00       216.00         0.00       296.00         8.00      1012.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 4, step 249: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.94      96.58      96.26     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         96.14      86.64      91.15      54804
--, (label_id: 3)                                         57.41      61.25      59.27      40800
--- (label_id: 4)                                         76.69      60.39      67.57       3464
--. (label_id: 5)                                         68.11      71.82      69.91      33424
--: (label_id: 6)                                         25.76      16.75      20.30        812
--? (label_id: 7)                                         57.68      39.32      46.76       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.68      91.68      91.68     659880
--macro avg                                               53.08      48.08      50.14     659880
--weighted avg                                            91.72      91.68      91.66     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   505172.00        48.00      7272.00      9648.00      1116.00      2808.00       196.00       196.00        68.00
--        0.00         0.00         0.00         4.00         0.00         0.00         0.00         0.00         0.00
--     1848.00         0.00     47484.00         8.00        28.00        20.00         0.00         0.00         0.00
--    11408.00       148.00        24.00     24992.00       172.00      6064.00       204.00       448.00        76.00
--      616.00         0.00        12.00         8.00      2092.00         0.00         0.00         0.00         0.00
--     3736.00       216.00         8.00      5828.00        56.00     24004.00       272.00      1056.00        68.00
--      124.00         4.00         0.00        88.00         0.00       152.00       136.00        16.00         8.00
--      152.00        56.00         4.00       224.00         0.00       376.00         4.00      1112.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 5, global step 299: val_loss reached 0.30916 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.31-epoch=5.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.63      96.00      96.31     523056
--! (label_id: 1)                                         66.67       1.69       3.31        472
--# (label_id: 2)                                         94.65      89.24      91.87      54804
--, (label_id: 3)                                         56.09      64.01      59.79      40800
--- (label_id: 4)                                         76.31      60.62      67.57       3464
--. (label_id: 5)                                         66.81      74.69      70.53      33424
--: (label_id: 6)                                         30.77      15.76      20.85        812
--? (label_id: 7)                                         67.66      35.22      46.33       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.74      91.74      91.74     659880
--macro avg                                               61.73      48.58      50.73     659880
--weighted avg                                            92.08      91.74      91.82     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   502128.00        52.00      5844.00      7976.00      1084.00      2108.00       192.00       188.00        60.00
--        0.00         8.00         0.00         4.00         0.00         0.00         0.00         0.00         0.00
--     2660.00         0.00     48908.00        16.00        68.00        20.00         0.00         0.00         0.00
--    13400.00       144.00        28.00     26116.00       156.00      6024.00       200.00       408.00        84.00
--      636.00         0.00        12.00         4.00      2100.00         0.00         0.00         0.00         0.00
--     4040.00       228.00         8.00      6476.00        56.00     24964.00       292.00      1224.00        76.00
--       72.00         4.00         0.00        76.00         0.00       124.00       128.00        12.00         0.00
--      120.00        36.00         4.00       132.00         0.00       184.00         0.00       996.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 6, global step 349: val_loss reached 0.29901 (best 0.29901), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=6.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.22      96.51      96.36     523056
--! (label_id: 1)                                         50.00       1.69       3.28        472
--# (label_id: 2)                                         94.99      88.69      91.73      54804
--, (label_id: 3)                                         58.33      60.13      59.21      40800
--- (label_id: 4)                                         76.36      60.05      67.23       3464
--. (label_id: 5)                                         67.13      74.43      70.59      33424
--: (label_id: 6)                                         29.60      18.23      22.56        812
--? (label_id: 7)                                         63.15      38.05      47.48       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.85      91.85      91.85     659880
--macro avg                                               59.53      48.64      50.94     659880
--weighted avg                                            91.90      91.85      91.82     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   504792.00        52.00      6164.00      9436.00      1132.00      2604.00       196.00       204.00        68.00
--        0.00         8.00         0.00         4.00         0.00         4.00         0.00         0.00         0.00
--     2464.00         0.00     48608.00        24.00        56.00        20.00         0.00         0.00         0.00
--    11076.00       136.00        12.00     24532.00       140.00      5508.00       184.00       396.00        76.00
--      624.00         0.00        12.00         8.00      2080.00         0.00         0.00         0.00         0.00
--     3876.00       228.00         8.00      6516.00        56.00     24876.00       284.00      1136.00        76.00
--       84.00         4.00         0.00        96.00         0.00       152.00       148.00        16.00         0.00
--      140.00        44.00         0.00       184.00         0.00       260.00         0.00      1076.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 7, global step 399: val_loss reached 0.29477 (best 0.29477), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.29-epoch=7.ckpt" as top 3
--[INFO] - Saving latest checkpoint...
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.001
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7ff309dcf1f0>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 4.7 M 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--13.0 M    Trainable params
--101 M     Non-trainable params
--114 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.42      96.72      96.57      80644
--! (label_id: 1)                                        100.00       2.04       4.00         98
--# (label_id: 2)                                         94.98      88.83      91.80       8270
--, (label_id: 3)                                         58.52      61.21      59.84       5934
--- (label_id: 4)                                         76.96      61.89      68.60        572
--. (label_id: 5)                                         68.39      74.94      71.51       5092
--: (label_id: 6)                                         27.91      20.34      23.53        118
--? (label_id: 7)                                         61.36      35.06      44.63        462
--… (label_id: 8)                                          0.00       0.00       0.00         38
---------------------
--micro avg                                               92.21      92.21      92.21     101228
--macro avg                                               64.95      49.00      51.17     101228
--weighted avg                                            92.29      92.21      92.16     101228
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    78002.00         8.00       918.00      1312.00       170.00       410.00        30.00        34.00        12.00
--        0.00         2.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      372.00         0.00      7346.00         6.00        10.00         0.00         0.00         0.00         0.00
--     1618.00        30.00         2.00      3632.00        26.00       800.00        24.00        62.00        12.00
--      104.00         0.00         2.00         0.00       354.00         0.00         0.00         0.00         0.00
--      510.00        48.00         2.00       936.00        12.00      3816.00        40.00       202.00        14.00
--       16.00         0.00         0.00        18.00         0.00        26.00        24.00         2.00         0.00
--       22.00        10.00         0.00        30.00         0.00        40.00         0.00       162.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00        858
---------------------
--micro avg                                              100.00     100.00     100.00        858
--macro avg                                              100.00     100.00     100.00        858
--weighted avg                                           100.00     100.00     100.00        858
--
---------------------
--           0
--      858.00
---------------------
--
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.70      94.08      95.86     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.41      91.56      91.98      54804
--, (label_id: 3)                                         54.08      65.15      59.10      40800
--- (label_id: 4)                                         45.58      75.06      56.72       3464
--. (label_id: 5)                                         64.27      82.86      72.39      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         48.94      68.32      57.02       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.09      91.09      91.09     659880
--macro avg                                               44.78      53.00      48.12     659880
--weighted avg                                            92.17      91.09      91.48     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   492100.00        24.00      4224.00      5312.00       620.00       972.00       224.00       160.00        44.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     4076.00         0.00     50176.00        16.00        16.00        12.00         0.00         0.00         0.00
--    17824.00       140.00        12.00     26580.00       152.00      3988.00       196.00       172.00        84.00
--     2804.00         0.00       248.00        36.00      2600.00        16.00         0.00         0.00         0.00
--     5728.00       256.00       136.00      8184.00        76.00     27696.00       372.00       564.00        84.00
--        0.00         0.00         0.00         0.00         0.00         8.00         0.00         0.00         0.00
--      524.00        52.00         8.00       672.00         0.00       732.00        20.00      1932.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 0, step 449: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.41      96.35      96.88     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         91.96      94.02      92.98      54804
--, (label_id: 3)                                         64.21      66.16      65.17      40800
--- (label_id: 4)                                         82.47      58.66      68.56       3464
--. (label_id: 5)                                         71.30      82.13      76.33      33424
--: (label_id: 6)                                          2.63       0.99       1.43        812
--? (label_id: 7)                                         60.28      67.19      63.55       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.03      93.03      93.03     659880
--macro avg                                               52.25      51.72      51.65     659880
--weighted avg                                            93.13      93.03      93.04     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   503984.00        60.00      3212.00      6736.00      1244.00      1548.00       212.00       328.00        56.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     4456.00         0.00     51528.00        16.00        24.00        12.00         0.00         0.00         0.00
--    10468.00       140.00        20.00     26992.00       136.00      3768.00       240.00       188.00        88.00
--      404.00         0.00        12.00        12.00      2032.00         4.00         0.00         0.00         0.00
--     3520.00       232.00        32.00      6420.00        28.00     27452.00       340.00       412.00        68.00
--       36.00         0.00         0.00       232.00         0.00        28.00         8.00         0.00         0.00
--      188.00        40.00         0.00       392.00         0.00       612.00        12.00      1900.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 1, step 499: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.66      94.87      95.76     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         73.52      98.98      84.37      54804
--, (label_id: 3)                                         65.92      59.67      62.64      40800
--- (label_id: 4)                                         82.48      50.00      62.26       3464
--. (label_id: 5)                                         78.47      72.58      75.41      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         64.87      64.78      64.83       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.32      91.32      91.32     659880
--macro avg                                               51.33      48.99      49.47     659880
--weighted avg                                            91.49      91.32      91.21     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   496212.00       116.00       536.00     12196.00       908.00      2632.00       292.00       364.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--    18644.00         0.00     54244.00       160.00       700.00        32.00         0.00         0.00         0.00
--     5632.00       136.00         8.00     24344.00       112.00      6032.00       280.00       296.00        88.00
--      216.00         0.00         0.00       140.00      1732.00        12.00         0.00         0.00         0.00
--     2204.00       196.00        16.00      3624.00        12.00     24260.00       212.00       336.00        56.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      148.00        24.00         0.00       336.00         0.00       456.00        28.00      1832.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 2, step 549: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.60      97.50      97.05     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         93.99      91.64      92.80      54804
--, (label_id: 3)                                         68.55      61.10      64.61      40800
--- (label_id: 4)                                         81.77      49.19      61.43       3464
--. (label_id: 5)                                         71.94      82.38      76.81      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         82.00      50.92      62.83       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.32      93.32      93.32     659880
--macro avg                                               54.98      48.08      50.61     659880
--weighted avg                                            93.04      93.32      93.11     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   510004.00        64.00      4520.00      9228.00      1444.00      2020.00       252.00       360.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2996.00         0.00     50220.00        92.00       108.00        16.00         0.00         0.00         0.00
--     6636.00       144.00        24.00     24928.00       188.00      3764.00       220.00       388.00        72.00
--      304.00         0.00        20.00        48.00      1704.00         8.00         0.00         0.00         0.00
--     3036.00       248.00        20.00      6364.00        20.00     27536.00       340.00       640.00        72.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--       80.00        16.00         0.00       140.00         0.00        80.00         0.00      1440.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 3, step 599: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.93      97.24      97.09     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         94.66      91.04      92.81      54804
--, (label_id: 3)                                         66.63      64.82      65.72      40800
--- (label_id: 4)                                         75.88      62.47      68.52       3464
--. (label_id: 5)                                         73.34      81.40      77.16      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         70.49      69.59      70.04       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.40      93.40      93.40     659880
--macro avg                                               53.10      51.84      52.37     659880
--weighted avg                                            93.23      93.40      93.30     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508644.00        56.00      4712.00      8096.00      1072.00      1648.00       216.00       220.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2504.00         0.00     49892.00       252.00        44.00        16.00         0.00         0.00         0.00
--     8032.00       164.00        52.00     26448.00       168.00      4252.00       268.00       236.00        72.00
--      560.00         0.00       108.00         4.00      2164.00        16.00         0.00         0.00         0.00
--     3152.00       228.00        40.00      5656.00        16.00     27208.00       320.00       404.00        72.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      164.00        24.00         0.00       344.00         0.00       284.00         8.00      1968.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 4, step 649: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.34      96.76      97.05     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.54      93.20      92.87      54804
--, (label_id: 3)                                         64.62      68.42      66.47      40800
--- (label_id: 4)                                         82.26      58.89      68.64       3464
--. (label_id: 5)                                         74.47      80.59      77.41      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         69.26      71.71      70.47       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.36      93.36      93.36     659880
--macro avg                                               53.39      52.17      52.54     659880
--weighted avg                                            93.34      93.36      93.33     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   506088.00        44.00      3608.00      7132.00      1100.00      1496.00       172.00       204.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     3760.00         0.00     51080.00       244.00        92.00        20.00         0.00         0.00         0.00
--     9524.00       176.00        44.00     27916.00       216.00      4680.00       320.00       232.00        92.00
--      396.00         0.00        28.00         4.00      2040.00        12.00         0.00         0.00         0.00
--     3032.00       228.00        44.00      5172.00        16.00     26936.00       312.00       364.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      256.00        24.00         0.00       332.00         0.00       280.00         8.00      2028.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 5, step 699: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.17      97.08      97.12     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.93      92.96      92.95      54804
--, (label_id: 3)                                         66.75      65.61      66.17      40800
--- (label_id: 4)                                         75.56      66.40      70.68       3464
--. (label_id: 5)                                         74.11      81.07      77.43      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         72.03      70.30      71.15       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.48      93.48      93.48     659880
--macro avg                                               53.17      52.60      52.83     659880
--weighted avg                                            93.32      93.48      93.39     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   507784.00        56.00      3732.00      7964.00       892.00      1656.00       216.00       220.00        68.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     3532.00         0.00     50948.00       244.00        84.00        16.00         0.00         0.00         0.00
--     8000.00       148.00        44.00     26768.00       172.00      4380.00       284.00       220.00        88.00
--      652.00         0.00        60.00        12.00      2300.00        20.00         0.00         0.00         0.00
--     2912.00       244.00        20.00      5504.00        16.00     27096.00       304.00       400.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      176.00        24.00         0.00       308.00         0.00       256.00         8.00      1988.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 6, step 749: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.17      97.07      97.12     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.94      92.98      92.96      54804
--, (label_id: 3)                                         66.60      66.25      66.42      40800
--- (label_id: 4)                                         75.19      66.86      70.78       3464
--. (label_id: 5)                                         74.75      80.94      77.72      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         73.88      70.01      71.90       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.51      93.51      93.51     659880
--macro avg                                               53.39      52.68      52.99     659880
--weighted avg                                            93.36      93.51      93.43     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   507744.00        56.00      3724.00      7944.00       876.00      1664.00       220.00       220.00        68.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     3528.00         0.00     50956.00       244.00        84.00        16.00         0.00         0.00         0.00
--     8112.00       152.00        44.00     27028.00       172.00      4464.00       292.00       232.00        88.00
--      672.00         0.00        60.00        12.00      2316.00        20.00         0.00         0.00         0.00
--     2832.00       240.00        20.00      5280.00        16.00     27052.00       292.00       396.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      168.00        24.00         0.00       292.00         0.00       208.00         8.00      1980.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 7, step 799: val_loss was not in top 3
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.0004
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7ff29c24fa60>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 4.7 M 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--20.1 M    Trainable params
--94.7 M    Non-trainable params
--114 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.30      97.36      97.33      80644
--! (label_id: 1)                                          0.00       0.00       0.00         98
--# (label_id: 2)                                         92.84      93.11      92.97       8270
--, (label_id: 3)                                         66.91      67.21      67.06       5934
--- (label_id: 4)                                         77.08      68.18      72.36        572
--. (label_id: 5)                                         76.94      80.60      78.73       5092
--: (label_id: 6)                                          0.00       0.00       0.00        118
--? (label_id: 7)                                         76.61      72.29      74.39        462
--… (label_id: 8)                                          0.00       0.00       0.00         38
---------------------
--micro avg                                               93.88      93.88      93.88     101228
--macro avg                                               54.19      53.19      53.65     101228
--weighted avg                                            93.68      93.88      93.77     101228
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    78518.00        10.00       552.00      1142.00       140.00       256.00        32.00        36.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      544.00         0.00      7700.00        38.00        12.00         0.00         0.00         0.00         0.00
--     1122.00        32.00         4.00      3988.00        28.00       698.00        42.00        32.00        14.00
--      102.00         0.00        12.00         0.00       390.00         2.00         0.00         0.00         0.00
--      340.00        50.00         2.00       722.00         2.00      4104.00        42.00        60.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--       18.00         6.00         0.00        44.00         0.00        32.00         2.00       334.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00        858
---------------------
--micro avg                                              100.00     100.00     100.00        858
--macro avg                                              100.00     100.00     100.00        858
--weighted avg                                           100.00     100.00     100.00        858
--
---------------------
--           0
--      858.00
---------------------
--
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.70      97.18      96.94     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         90.59      92.02      91.30      54804
--, (label_id: 3)                                         65.34      65.67      65.50      40800
--- (label_id: 4)                                         85.28      45.50      59.34       3464
--. (label_id: 5)                                         76.92      76.16      76.54      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         67.59      62.23      64.80       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.10      93.10      93.10     659880
--macro avg                                               53.60      48.75      50.49     659880
--weighted avg                                            92.84      93.10      92.94     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508300.00        60.00      4336.00      9072.00      1240.00      2136.00       204.00       252.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     4560.00         0.00     50432.00       212.00       436.00        32.00         0.00         0.00         0.00
--     7488.00       172.00         8.00     26792.00       200.00      5416.00       384.00       436.00       108.00
--      256.00         0.00        12.00         4.00      1576.00         0.00         0.00         0.00         0.00
--     2240.00       216.00        16.00      4512.00        12.00     25456.00       216.00       380.00        44.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      212.00        24.00         0.00       208.00         0.00       384.00         8.00      1760.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 0, step 849: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.12      98.10      96.59     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         93.92      90.84      92.36      54804
--, (label_id: 3)                                         71.82      48.62      57.98      40800
--- (label_id: 4)                                         75.00      55.08      63.52       3464
--. (label_id: 5)                                         72.29      78.12      75.09      33424
--: (label_id: 6)                                        100.00       0.49       0.98        812
--? (label_id: 7)                                         86.41      35.08      49.90       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               92.71      92.71      92.71     659880
--macro avg                                               66.06      45.15      48.49     659880
--weighted avg                                            92.19      92.71      92.17     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   513120.00       140.00      4940.00     15176.00      1240.00      3752.00       372.00       596.00       104.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2864.00         0.00     49784.00        84.00       232.00        40.00         0.00         0.00         0.00
--     3644.00        64.00         0.00     19836.00        76.00      3500.00       168.00       276.00        56.00
--      560.00         0.00        60.00        16.00      1908.00         0.00         0.00         0.00         0.00
--     2820.00       252.00        20.00      5616.00         8.00     26112.00       268.00       964.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         4.00         0.00         0.00
--       48.00        16.00         0.00        72.00         0.00        20.00         0.00       992.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 1, step 899: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          94.93      95.85      95.39     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         98.21      69.76      81.58      54804
--, (label_id: 3)                                         54.91      72.97      62.66      40800
--- (label_id: 4)                                         86.86      27.48      41.75       3464
--. (label_id: 5)                                         66.94      75.06      70.77      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                        100.00       1.56       3.06       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               90.23      90.23      90.23     659880
--macro avg                                               55.76      38.08      39.47     659880
--weighted avg                                            91.07      90.23      90.08     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   501340.00        48.00     16152.00      6100.00      2028.00      1720.00       188.00       488.00        52.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      476.00         0.00     38232.00        24.00       176.00        20.00         0.00         0.00         0.00
--    15484.00       220.00       100.00     29772.00       252.00      6596.00       360.00      1348.00        88.00
--      136.00         0.00         8.00         0.00       952.00         0.00         0.00         0.00         0.00
--     5620.00       204.00       312.00      4904.00        56.00     25088.00       264.00       948.00        80.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00        44.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 2, step 949: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.95      94.26      95.58     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         88.08      93.86      90.88      54804
--, (label_id: 3)                                         59.30      62.47      60.85      40800
--- (label_id: 4)                                         43.12      67.32      52.57       3464
--. (label_id: 5)                                         70.00      76.39      73.06      33424
--: (label_id: 6)                                          0.91       5.42       1.56        812
--? (label_id: 7)                                         55.40      63.08      58.99       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               90.87      90.87      90.87     659880
--macro avg                                               45.97      51.42      48.17     659880
--weighted avg                                            91.84      90.87      91.31     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   493028.00        76.00      2376.00      9040.00       652.00      2780.00       252.00       280.00        72.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     6864.00         0.00     51440.00        16.00        68.00         4.00         0.00         8.00         0.00
--    11812.00       120.00       108.00     25488.00       156.00      4628.00       268.00       324.00        76.00
--     2344.00         0.00       504.00       212.00      2332.00        16.00         0.00         0.00         0.00
--     4468.00       256.00       144.00      5276.00        72.00     25532.00       244.00       412.00        68.00
--     3964.00         4.00       212.00       368.00       176.00        56.00        44.00        20.00         0.00
--      576.00        16.00        20.00       400.00         8.00       408.00         4.00      1784.00         4.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 3, step 999: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.73      96.49      96.61     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         97.10      88.69      92.71      54804
--, (label_id: 3)                                         61.91      66.92      64.32      40800
--- (label_id: 4)                                         62.18      61.32      61.74       3464
--. (label_id: 5)                                         71.48      77.96      74.58      33424
--: (label_id: 6)                                          4.21       1.97       2.68        812
--? (label_id: 7)                                         54.34      71.71      61.83       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               92.57      92.57      92.57     659880
--macro avg                                               49.77      51.67      50.50     659880
--weighted avg                                            92.75      92.57      92.63     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   504696.00        68.00      5900.00      7576.00      1048.00      1924.00       240.00       236.00        52.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1396.00         0.00     48608.00        20.00        24.00        12.00         0.00         0.00         0.00
--    10964.00       132.00        64.00     27304.00       216.00      4920.00       236.00       192.00        72.00
--     1020.00         0.00       132.00       128.00      2124.00        12.00         0.00         0.00         0.00
--     4196.00       248.00        88.00      5064.00        40.00     26056.00       304.00       372.00        84.00
--      200.00         0.00         8.00       152.00         0.00         4.00        16.00         0.00         0.00
--      584.00        24.00         4.00       556.00        12.00       496.00        16.00      2028.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 4, step 1049: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          94.84      98.08      96.43     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         98.53      81.48      89.20      54804
--, (label_id: 3)                                         67.47      60.25      63.66      40800
--- (label_id: 4)                                         65.13      58.89      61.86       3464
--. (label_id: 5)                                         77.35      72.15      74.66      33424
--: (label_id: 6)                                          6.67       2.46       3.60        812
--? (label_id: 7)                                         66.26      60.82      63.42       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               92.46      92.46      92.46     659880
--macro avg                                               52.92      48.24      50.31     659880
--weighted avg                                            92.08      92.46      92.17     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   513024.00        92.00      9884.00     11672.00      1184.00      4168.00       344.00       472.00        84.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      600.00         0.00     44652.00        20.00        28.00        16.00         0.00         0.00         0.00
--     6192.00       148.00        32.00     24584.00       132.00      4776.00       208.00       272.00        92.00
--      828.00         0.00       204.00        60.00      2040.00         0.00         0.00         0.00         0.00
--     2096.00       216.00        32.00      4068.00        16.00     24116.00       236.00       364.00        32.00
--      168.00         0.00         0.00        40.00        64.00         8.00        20.00         0.00         0.00
--      148.00        16.00         0.00       356.00         0.00       340.00         4.00      1720.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 5, step 1099: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.42      97.26      96.84     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         96.89      90.07      93.36      54804
--, (label_id: 3)                                         64.67      65.10      64.88      40800
--- (label_id: 4)                                         61.01      63.97      62.46       3464
--. (label_id: 5)                                         75.87      75.59      75.73      33424
--: (label_id: 6)                                         14.29       2.46       4.20        812
--? (label_id: 7)                                         59.57      67.33      63.21       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.05      93.05      93.05     659880
--macro avg                                               52.08      51.31      51.19     659880
--weighted avg                                            92.91      93.05      92.96     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508716.00        68.00      5096.00      8936.00      1036.00      3024.00       280.00       372.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1492.00         0.00     49364.00        32.00        36.00        24.00         0.00         0.00         0.00
--     9016.00       172.00        36.00     26560.00       132.00      4504.00       284.00       264.00       104.00
--     1076.00         0.00       276.00        64.00      2216.00         0.00         0.00         0.00         0.00
--     2492.00       216.00        32.00      4728.00        24.00     25264.00       216.00       288.00        40.00
--       60.00         0.00         0.00        40.00        12.00         8.00        20.00         0.00         0.00
--      204.00        16.00         0.00       440.00         8.00       600.00        12.00      1904.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 6, step 1149: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.49      97.24      96.86     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         96.73      90.36      93.44      54804
--, (label_id: 3)                                         64.80      65.04      64.92      40800
--- (label_id: 4)                                         64.12      62.12      63.11       3464
--. (label_id: 5)                                         75.35      76.33      75.84      33424
--: (label_id: 6)                                         22.73       2.46       4.44        812
--? (label_id: 7)                                         58.91      68.74      63.45       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.09      93.09      93.09     659880
--macro avg                                               53.24      51.37      51.34     659880
--weighted avg                                            92.95      93.09      93.00     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508616.00        72.00      4992.00      8792.00      1104.00      2864.00       280.00       364.00        56.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1572.00         0.00     49520.00        40.00        36.00        24.00         0.00         0.00         0.00
--     9072.00       152.00        36.00     26536.00       128.00      4416.00       280.00       240.00        88.00
--      920.00         0.00       224.00        60.00      2152.00         0.00         0.00         0.00         0.00
--     2604.00       224.00        32.00      4892.00        28.00     25512.00       220.00       280.00        64.00
--       28.00         0.00         0.00        24.00         8.00         8.00        20.00         0.00         0.00
--      244.00        24.00         0.00       456.00         8.00       600.00        12.00      1944.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 7, step 1199: val_loss was not in top 3
--[INFO] - GPU available: True, used: True
--[INFO] - TPU available: None, using: 0 TPU cores
--[INFO] - Using environment variable NODE_RANK for node rank (0).
--[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.25      97.27      96.76     650284
--! (label_id: 1)                                          0.00       0.00       0.00        380
--# (label_id: 2)                                         97.23      89.79      93.36      68496
--, (label_id: 3)                                         62.58      64.85      63.69      52348
--- (label_id: 4)                                         49.90      60.65      54.75       3212
--. (label_id: 5)                                         79.01      73.40      76.10      46276
--: (label_id: 6)                                         20.00       2.25       4.05        888
--? (label_id: 7)                                         60.00      67.50      63.53       4000
--… (label_id: 8)                                          0.00       0.00       0.00        260
---------------------
--micro avg                                               92.79      92.79      92.79     826144
--macro avg                                               51.66      50.63      50.25     826144
--weighted avg                                            92.72      92.79      92.72     826144
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   632504.00        36.00      6712.00     12044.00      1116.00      3904.00       244.00       476.00       108.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1596.00         0.00     61504.00        28.00        52.00        76.00         0.00         0.00         0.00
--    11756.00       140.00         8.00     33948.00        68.00      7492.00       300.00       432.00       104.00
--     1636.00         0.00       232.00        36.00      1948.00        52.00         0.00         0.00         0.00
--     2480.00       180.00        28.00      5584.00        16.00     33968.00       304.00       392.00        40.00
--       20.00         0.00         0.00        28.00        12.00        20.00        20.00         0.00         0.00
--      292.00        24.00        12.00       680.00         0.00       764.00        20.00      2700.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Chunked Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.57      97.15      96.86     327564
--! (label_id: 1)                                          0.00       0.00       0.00        184
--# (label_id: 2)                                         97.23      90.48      93.73      34404
--, (label_id: 3)                                         63.38      67.07      65.18      26324
--- (label_id: 4)                                         50.74      63.34      56.35       1724
--. (label_id: 5)                                         80.87      76.47      78.61      23376
--: (label_id: 6)                                          8.33       0.88       1.59        456
--? (label_id: 7)                                         59.61      72.62      65.47       2016
--… (label_id: 8)                                          0.00       0.00       0.00         92
---------------------
--micro avg                                               93.10      93.10      93.10     416140
--macro avg                                               50.75      52.00      50.86     416140
--weighted avg                                            93.12      93.10      93.08     416140
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   318220.00        20.00      3140.00      5728.00       532.00      1500.00       124.00       184.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      788.00         0.00     31128.00         8.00        32.00        60.00         0.00         0.00         0.00
--     6236.00        84.00         0.00     17656.00        48.00      3444.00       144.00       220.00        24.00
--      872.00         0.00       128.00        16.00      1092.00        44.00         0.00         0.00         0.00
--     1240.00        72.00         8.00      2568.00        16.00     17876.00       168.00       148.00         8.00
--       16.00         0.00         0.00         4.00         4.00        20.00         4.00         0.00         0.00
--      192.00         8.00         0.00       344.00         0.00       432.00        16.00      1464.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       6884
---------------------
--micro avg                                              100.00     100.00     100.00       6884
--macro avg                                              100.00     100.00     100.00       6884
--weighted avg                                           100.00     100.00     100.00       6884
--
---------------------
--           0
--     6884.00
---------------------
--
--[INFO] - saving to /home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/test.txt
--[INFO] - Internal process exited
-diff --git a/experiment/outputs/2021-02-23/08-18-26/testing.log b/experiment/outputs/2021-02-23/08-18-26/testing.log
-index f00f863..2597221 100644
---- a/experiment/outputs/2021-02-23/08-18-26/testing.log
-+++ b/experiment/outputs/2021-02-23/08-18-26/testing.log
-@@ -1 +1,74 @@
- [2021-02-23 08:18:38,771][root][INFO] - shuffling train set
-+[2021-02-23 08:44:12,424][root][INFO] - Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          95.20      95.06      95.13   33617452
-+! (label_id: 1)                                         21.65      40.73      28.27     578585
-+# (label_id: 2)                                         89.63      94.36      91.93    6976446
-+, (label_id: 3)                                         52.02      49.20      50.57    2858145
-+- (label_id: 4)                                         52.90      37.64      43.98     255633
-+. (label_id: 5)                                         67.03      64.56      65.77    5425019
-+: (label_id: 6)                                          0.00       0.00       0.00      15576
-+? (label_id: 7)                                         66.11      48.89      56.21    1415356
-+… (label_id: 8)                                         28.23      27.42      27.82     482702
-+-------------------
-+micro avg                                               86.40      86.40      86.40   51624912
-+macro avg                                               52.53      50.87      51.07   51624912
-+weighted avg                                            86.61      86.40      86.42   51624912
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 31955872.00     33316.00    385671.00    438274.00     53505.00    443163.00      7682.00    120484.00    128329.00
-+    66565.00    235635.00       761.00    176016.00      8738.00    506812.00       944.00     64244.00     28918.00
-+   714124.00       536.00   6582626.00      7720.00     19841.00     15709.00      1649.00      1336.00      1001.00
-+   288086.00     97827.00       833.00   1406100.00     11576.00    706306.00       912.00    121425.00     69959.00
-+    56237.00      2410.00       944.00      5163.00     96209.00     18095.00        96.00      1041.00      1680.00
-+   390319.00    174383.00      3985.00    635086.00     21274.00   3502327.00      3717.00    389488.00    104418.00
-+        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-+    75395.00     24645.00       937.00     80919.00      3444.00    153187.00       136.00    691913.00     16045.00
-+    70772.00      9833.00       689.00    108867.00     41046.00     79420.00       440.00     25425.00    132352.00
-+-------------------
-+
-+[2021-02-23 08:44:12,434][root][INFO] - Chunked Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          95.59      96.37      95.98   16876740
-+! (label_id: 1)                                         21.47      41.98      28.41     290645
-+# (label_id: 2)                                         95.04      95.14      95.09    3541392
-+, (label_id: 3)                                         52.20      49.91      51.03    1447727
-+- (label_id: 4)                                         53.56      38.01      44.47     130953
-+. (label_id: 5)                                         68.20      65.03      66.58    2759312
-+: (label_id: 6)                                          0.00       0.00       0.00       7645
-+? (label_id: 7)                                         66.66      50.42      57.42     716850
-+… (label_id: 8)                                         28.64      27.84      28.23     243286
-+-------------------
-+micro avg                                               87.46      87.46      87.46   26014552
-+macro avg                                               53.49      51.63      51.91   26014552
-+weighted avg                                            87.71      87.46      87.50   26014552
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 16264699.00     14196.00    169436.00    215171.00     26620.00    202508.00      3785.00     54437.00     63531.00
-+    33928.00    122012.00       272.00     91962.00      4505.00    266896.00       504.00     33168.00     15114.00
-+   151602.00       248.00   3369444.00      3788.00     10412.00      7913.00       881.00       624.00       328.00
-+   147638.00     49831.00       344.00    722501.00      5999.00    360923.00       448.00     60458.00     35874.00
-+    28414.00      1192.00       464.00      2722.00     49780.00      8964.00        32.00       537.00       840.00
-+   177113.00     85795.00      1072.00    314405.00     10733.00   1794350.00      1747.00    194183.00     51583.00
-+        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-+    37372.00     12602.00       168.00     41387.00      1825.00     79031.00        64.00    361456.00      8297.00
-+    35974.00      4769.00       192.00     55791.00     21079.00     38727.00       184.00     11987.00     67719.00
-+-------------------
-+
-+[2021-02-23 08:44:12,439][root][INFO] - Domain report: 
-+label                                                precision    recall       f1           support   
-+0 (label_id: 0)                                        100.00     100.00     100.00     411653
-+-------------------
-+micro avg                                              100.00     100.00     100.00     411653
-+macro avg                                              100.00     100.00     100.00     411653
-+weighted avg                                           100.00     100.00     100.00     411653
-+
-+-------------------
-+           0
-+   411653.00
-+-------------------
-+
-+[2021-02-23 08:44:12,439][root][INFO] - saving to /home/nxingyu/project/Punctuation_with_Domain_discriminator/opendice33acc42021-02-22_09-49-04//test.txt
-+[2021-02-23 08:44:12,539][wandb.sdk.internal.internal][INFO] - Internal process exited
-diff --git a/experiment/outputs/2021-02-23/08-20-55/testing.log b/experiment/outputs/2021-02-23/08-20-55/testing.log
-index 717645a..7100fd1 100644
---- a/experiment/outputs/2021-02-23/08-20-55/testing.log
-+++ b/experiment/outputs/2021-02-23/08-20-55/testing.log
-@@ -1 +1,74 @@
- [2021-02-23 08:21:08,018][root][INFO] - shuffling train set
-+[2021-02-23 09:05:21,673][root][INFO] - Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          94.88      97.99      96.41   33617452
-+! (label_id: 1)                                         33.89       9.66      15.04     578585
-+# (label_id: 2)                                         99.49      99.10      99.30    6976446
-+, (label_id: 3)                                         52.51      39.66      45.19    2858145
-+- (label_id: 4)                                         56.89      22.57      32.32     255633
-+. (label_id: 5)                                         62.04      77.10      68.76    5425019
-+: (label_id: 6)                                         77.05      41.40      53.86      15576
-+? (label_id: 7)                                         70.01      36.10      47.64    1415356
-+… (label_id: 8)                                         57.21       6.15      11.10     482702
-+-------------------
-+micro avg                                               88.78      88.78      88.78   51624912
-+macro avg                                               67.11      47.75      52.18   51624912
-+weighted avg                                            87.80      88.78      87.68   51624912
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 32940746.00     42247.00     56263.00    637305.00    117974.00    572846.00      3579.00    174660.00    172542.00
-+    10770.00     55899.00        88.00     35948.00      1672.00     46823.00       184.00      8367.00      5210.00
-+    27771.00       545.00   6913637.00      1128.00      1968.00      2819.00        16.00       480.00       560.00
-+   163910.00    113876.00       544.00   1133679.00     17942.00    526536.00       840.00    121929.00     79630.00
-+    19931.00      1771.00       104.00      4132.00     57687.00     14847.00        40.00       600.00      2282.00
-+   403834.00    347864.00      5066.00    988029.00     38393.00   4182951.00      4372.00    597272.00    174593.00
-+      608.00         0.00         0.00       505.00       360.00       288.00      6449.00        32.00       128.00
-+    48028.00     16247.00       712.00     54579.00      4683.00     76459.00        80.00    510999.00     18088.00
-+     1745.00       136.00        32.00      2840.00     14954.00      1450.00        16.00      1017.00     29669.00
-+-------------------
-+
-+[2021-02-23 09:05:21,682][root][INFO] - Chunked Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          95.08      98.11      96.57   16876740
-+! (label_id: 1)                                         33.70      10.09      15.54     290645
-+# (label_id: 2)                                         99.61      99.52      99.57    3541392
-+, (label_id: 3)                                         52.66      40.24      45.62    1447727
-+- (label_id: 4)                                         57.66      22.91      32.79     130953
-+. (label_id: 5)                                         62.89      77.75      69.53    2759312
-+: (label_id: 6)                                         78.52      42.08      54.79       7645
-+? (label_id: 7)                                         70.98      37.06      48.70     716850
-+… (label_id: 8)                                         58.27       6.35      11.46     243286
-+-------------------
-+micro avg                                               89.00      89.00      89.00   26014552
-+macro avg                                               67.71      48.24      52.73   26014552
-+weighted avg                                            88.03      89.00      87.92   26014552
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 16557577.00     19231.00     15829.00    319520.00     60251.00    272070.00      1746.00     82502.00     86301.00
-+     5837.00     29340.00        16.00     18850.00       800.00     24913.00       120.00      4276.00      2921.00
-+    11597.00        88.00   3524547.00       280.00       800.00       737.00         8.00        88.00        96.00
-+    83677.00     57621.00       136.00    582598.00      9566.00    269820.00       440.00     61935.00     40462.00
-+    10150.00       904.00        56.00      2011.00     29998.00      7605.00        16.00       240.00      1049.00
-+   183939.00    175228.00       744.00    495087.00     19564.00   2145232.00      2058.00    301633.00     87509.00
-+      176.00         0.00         0.00       296.00       128.00       168.00      3217.00        16.00        96.00
-+    22954.00      8169.00        64.00     27597.00      2353.00     38063.00        32.00    265680.00      9397.00
-+      833.00        64.00         0.00      1488.00      7493.00       704.00         8.00       480.00     15455.00
-+-------------------
-+
-+[2021-02-23 09:05:21,687][root][INFO] - Domain report: 
-+label                                                precision    recall       f1           support   
-+0 (label_id: 0)                                        100.00     100.00     100.00     411653
-+-------------------
-+micro avg                                              100.00     100.00     100.00     411653
-+macro avg                                              100.00     100.00     100.00     411653
-+weighted avg                                           100.00     100.00     100.00     411653
-+
-+-------------------
-+           0
-+   411653.00
-+-------------------
-+
-+[2021-02-23 09:05:21,688][root][INFO] - saving to /home/nxingyu/project/Punctuation_with_Domain_discriminator/opencrfacc42021-02-22_09-48-50//test.txt
-+[2021-02-23 09:05:21,785][wandb.sdk.internal.internal][INFO] - Internal process exited
-diff --git a/experiment/testing.py b/experiment/testing.py
-index 3e967b0..77f95ad 100644
---- a/experiment/testing.py
-+++ b/experiment/testing.py
-@@ -1,3 +1,8 @@
-+
-+
-+
-+
-+
- #%%
- import hydra
- import numpy as np
-@@ -20,7 +25,7 @@ import atexit
- from copy import deepcopy
- import snoop
- snoop.install()
--exp='opencrfacc42021-02-22_09-48-50'
-+exp='2021-02-23_09-59-35'
- @hydra.main(config_path=f"../Punctuation_with_Domain_discriminator/{exp}/",config_name="hparams.yaml")
- def main(cfg : DictConfig) -> None:
-     torch.set_printoptions(sci_mode=False)
-@@ -41,7 +46,7 @@ def main(cfg : DictConfig) -> None:
-                     max_seq_length=model.dm.max_seq_length,
-                     punct_label_ids=model.dm.punct_label_ids,
-                     label_map=model.dm.label_map,
--                    labelled=['/home/nxingyu/data/open_subtitles_processed'],
-+                    labelled=['/home/nxingyu/data/ted_talks_processed'],
-                     unlabelled=[],
-                     tokenizer=model.dm.tokenizer,
-                     randomize=model.dm.val_shuffle,
-@@ -49,7 +54,7 @@ def main(cfg : DictConfig) -> None:
-                     tmp_path=model.dm.tmp_path,
-                     attach_label_to_end=model.dm.attach_label_to_end,
-                     no_space_label=model.dm.no_space_label,
--                    pad_start=0,
-+                    pad_start=model.dm.pad_start,
-                     )
-     model.hparams.log_dir=f"/home/nxingyu/project/Punctuation_with_Domain_discriminator/{exp}/"
-     trainer = pl.Trainer(**cfg.trainer)
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/hparams.yaml b/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/hparams.yaml
deleted file mode 100644
index 5d11726..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/hparams.yaml
+++ /dev/null
@@ -1,127 +0,0 @@
-seed: 42
-trainer:
-  gpus: 1
-  num_nodes: 1
-  max_epochs: 8
-  max_steps: null
-  accumulate_grad_batches: 32
-  gradient_clip_val: 0
-  amp_level: O1
-  precision: 16
-  accelerator: ddp
-  checkpoint_callback: false
-  logger: false
-  log_every_n_steps: 1
-  val_check_interval: 1.0
-  resume_from_checkpoint: null
-exp_manager:
-  exp_dir: /home/nxingyu/project/
-  name: Punctuation_with_Domain_discriminator
-  create_tensorboard_logger: true
-  create_checkpoint_callback: true
-base_path: /home/nxingyu/data
-tmp_path: /home/nxingyu/data/tmp
-log_dir: /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31
-model:
-  nemo_path: null
-  transformer_path: google/electra-base-discriminator
-  unfrozen: 0
-  maximum_unfrozen: 2
-  unfreeze_step: 1
-  punct_label_ids:
-  - ''
-  - ','
-  - .
-  - '?'
-  - '-'
-  - '!'
-  - ':'
-  - …
-  label_map:
-    —: ','
-    ;: .
-  no_space_label: '#'
-  test_chunk_percent: 0.5
-  pad_start_and_end: 0
-  punct_class_weights: false
-  dataset:
-    data_dir: /home/nxingyu/data
-    labelled:
-    - /home/nxingyu/data/switchboardutt_processed
-    unlabelled: null
-    max_seq_length: 128
-    pad_label: ''
-    ignore_extra_tokens: false
-    ignore_start_end: false
-    use_cache: false
-    num_workers: 8
-    pin_memory: false
-    drop_last: true
-    num_labels: 9
-    num_domains: 2
-    test_unlabelled: true
-    attach_label_to_end: null
-    pad_start: 64
-    train_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 8
-      manual_len: 20000
-    validation_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 8
-  tokenizer:
-    tokenizer_name: google/electra-base-discriminator
-    vocab_file: null
-    tokenizer_model: null
-    special_tokens: null
-  language_model:
-    pretrained_model_name: google/electra-base-discriminator
-    lm_checkpoint: null
-    config_file: null
-    config: null
-  punct_head:
-    punct_num_fc_layers: 0
-    fc_dropout: 0.1
-    activation: gelu
-    log_softmax: false
-    use_transformer_init: true
-    loss: crf
-    bilstm: false
-  domain_head:
-    domain_num_fc_layers: 3
-    fc_dropout: 0.1
-    activation: relu
-    log_softmax: false
-    use_transformer_init: true
-    loss: cel
-    gamma: 0.01
-    pooling: mean_max
-    idx_conditioned_on: 0
-  dice_loss:
-    epsilon: 0.01
-    alpha: 2
-    macro_average: true
-  focal_loss:
-    gamma: 3
-  frozen_lr:
-  - 0.02
-  - 0.001
-  - 0.0004
-  - 0.0001
-  - 1.0e-05
-  - 1.0e-06
-  - 1.0e-07
-  optim:
-    name: adamw
-    lr: 0.01
-    weight_decay: 0.0
-    sched:
-      name: CosineAnnealing
-      warmup_steps: null
-      warmup_ratio: 0.1
-      min_lr: 1.0e-08
-      last_epoch: -1
-      monitor: val_loss
-      reduce_on_plateau: false
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/lightning_logs.txt b/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/lightning_logs.txt
deleted file mode 100644
index df1e16b..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/lightning_logs.txt
+++ /dev/null
@@ -1,79 +0,0 @@
-Global seed set to 42
-GPU available: True, used: True
-TPU available: None, using: 0 TPU cores
-LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
-Using native 16bit precision.
-Global seed set to 42
-initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 6.9 K 
-2 | domain_classifier          | SequenceClassifier   | 4.7 M 
-3 | punctuation_loss           | LinearChainCRF       | 99    
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-4.7 M     Trainable params
-108 M     Non-trainable params
-113 M     Total params
-Epoch 0, global step 3: val_loss reached 281.30707 (best 281.30707), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=281.31-epoch=0.ckpt" as top 3
-Epoch 1, global step 7: val_loss reached 111.12069 (best 111.12069), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=111.12-epoch=1.ckpt" as top 3
-Epoch 2, global step 11: val_loss reached 66.87038 (best 66.87038), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=66.87-epoch=2.ckpt" as top 3
-Epoch 3, global step 15: val_loss reached 56.77756 (best 56.77756), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=56.78-epoch=3.ckpt" as top 3
-Epoch 4, global step 19: val_loss reached 52.57185 (best 52.57185), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=52.57-epoch=4.ckpt" as top 3
-Epoch 5, global step 23: val_loss reached 52.08538 (best 52.08538), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=52.09-epoch=5.ckpt" as top 3
-Epoch 6, global step 27: val_loss reached 50.67439 (best 50.67439), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=50.67-epoch=6.ckpt" as top 3
-Epoch 7, global step 31: val_loss reached 50.32340 (best 50.32340), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=50.32-epoch=7.ckpt" as top 3
-Saving latest checkpoint...
-Global seed set to 42
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 6.9 K 
-2 | domain_classifier          | SequenceClassifier   | 4.7 M 
-3 | punctuation_loss           | LinearChainCRF       | 99    
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-11.8 M    Trainable params
-101 M     Non-trainable params
-113 M     Total params
-Epoch 0, global step 35: val_loss reached 50.32174 (best 50.32174), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=50.32-epoch=0.ckpt" as top 3
-Epoch 1, global step 39: val_loss reached 50.31879 (best 50.31879), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=50.32-epoch=1.ckpt" as top 3
-Epoch 2, global step 43: val_loss reached 50.31577 (best 50.31577), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=50.32-epoch=2.ckpt" as top 3
-Epoch 3, global step 47: val_loss reached 50.31277 (best 50.31277), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=50.31-epoch=3.ckpt" as top 3
-Epoch 4, global step 51: val_loss reached 50.31012 (best 50.31012), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=50.31-epoch=4.ckpt" as top 3
-Epoch 5, global step 55: val_loss reached 50.30721 (best 50.30721), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=50.31-epoch=5.ckpt" as top 3
-Epoch 6, global step 59: val_loss reached 50.30328 (best 50.30328), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=50.30-epoch=6.ckpt" as top 3
-Epoch 7, global step 63: val_loss reached 50.30114 (best 50.30114), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=50.30-epoch=7.ckpt" as top 3
-Global seed set to 42
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 6.9 K 
-2 | domain_classifier          | SequenceClassifier   | 4.7 M 
-3 | punctuation_loss           | LinearChainCRF       | 99    
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-18.9 M    Trainable params
-94.7 M    Non-trainable params
-113 M     Total params
-Epoch 0, global step 67: val_loss reached 50.29556 (best 50.29556), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=50.30-epoch=0.ckpt" as top 3
-Epoch 1, global step 71: val_loss reached 50.29159 (best 50.29159), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=50.29-epoch=1.ckpt" as top 3
-Epoch 2, global step 75: val_loss reached 50.28576 (best 50.28576), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=50.29-epoch=2.ckpt" as top 3
-Epoch 3, global step 79: val_loss reached 50.28108 (best 50.28108), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=50.28-epoch=3.ckpt" as top 3
-Epoch 4, global step 83: val_loss reached 50.27547 (best 50.27547), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/checkpoints/Punctuation_with_Domain_discriminator---val_loss=50.28-epoch=4.ckpt" as top 3
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/nemo_error_log.txt b/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/nemo_error_log.txt
deleted file mode 100644
index b728d12..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/nemo_error_log.txt
+++ /dev/null
@@ -1,28 +0,0 @@
-[NeMo W 2021-02-23 14:41:31 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
-[NeMo W 2021-02-23 14:41:42 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:41:42 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:41:46 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:41:46 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:41:46 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:41:48 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
-      warnings.warn(*args, **kwargs)
-    
-[NeMo W 2021-02-23 14:42:09 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
-      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
-    
-[NeMo W 2021-02-23 14:42:54 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7fa5b1a86a00> was reported to be 115 (when accessing len(dataloader)), but 116 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-02-23 14:43:07 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7fa5b1a86820> was reported to be 14 (when accessing len(dataloader)), but 15 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/nemo_log_globalrank-0_localrank-0.txt b/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/nemo_log_globalrank-0_localrank-0.txt
deleted file mode 100644
index 7f5cdf1..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31/nemo_log_globalrank-0_localrank-0.txt
+++ /dev/null
@@ -1,30 +0,0 @@
-[NeMo I 2021-02-23 14:41:31 exp_manager:183] Experiments will be logged at /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-41-31
-[NeMo I 2021-02-23 14:41:31 exp_manager:519] TensorboardLogger has been set up
-[NeMo W 2021-02-23 14:41:31 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
-[NeMo W 2021-02-23 14:41:42 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:41:42 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:41:46 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:41:46 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:41:46 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:41:48 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
-      warnings.warn(*args, **kwargs)
-    
-[NeMo W 2021-02-23 14:42:09 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
-      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
-    
-[NeMo W 2021-02-23 14:42:54 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7fa5b1a86a00> was reported to be 115 (when accessing len(dataloader)), but 116 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
-[NeMo W 2021-02-23 14:43:07 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:447: UserWarning: Length of IterableDataset <data.punctuation_dataset_multi.PunctuationDomainDatasets object at 0x7fa5b1a86820> was reported to be 14 (when accessing len(dataloader)), but 15 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.
-      warnings.warn(warn_msg)
-    
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/cmd-args.log b/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/cmd-args.log
deleted file mode 100644
index 11a5d8e..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/cmd-args.log
+++ /dev/null
@@ -1 +0,0 @@
-main.py
\ No newline at end of file
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/events.out.tfevents.1614062703.Titan.24452.0 b/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/events.out.tfevents.1614062703.Titan.24452.0
deleted file mode 100644
index 23189b6..0000000
Binary files a/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/events.out.tfevents.1614062703.Titan.24452.0 and /dev/null differ
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/git-info.log b/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/git-info.log
deleted file mode 100644
index 9256b3c..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/git-info.log
+++ /dev/null
@@ -1,1731 +0,0 @@
-commit hash: a95e08f7dafab6a88b25b93525195e2018fcf89f
-diff --git a/README.md b/README.md
-index 4792b93..54a7ce0 100644
---- a/README.md
-+++ b/README.md
-@@ -91,8 +91,9 @@ bash ~/project/get-data.sh
- bash ~/project/experiment/data/disfl2csv.sh /home/nxingyu/data/LDC99T42/treebank_3/dysfl/dff/swbd /home/nxingyu/data/switchboard_processed.csv
- bash ~/project/bin/processandsplit.sh ./switchboard_processed.csv 8 1 1
- 
--bash ~/project/experiment/data/utt2csv.sh /home/nxingyu/data/utt switchboardutt_processed.csv
--sed -i 1i"id,transcript" switchboard*
-+bash ~/project/experiment/data/utt2csv.sh /home/nxingyu/data/utt /home/nxingyu/data/switchboardutt_processed.csv
-+bash ~/project/bin/processandsplit.sh ./switchboardutt_processed.csv 8 1 1
-+sed -i 1i"id,transcript" switchboard_*
- 
- python ~/project/processcsv.py -i ~/data/ted_talks_en.csv -o ~/data/ted_talks_processed.csv -c 2000
- bash ~/project/bin/processandsplit.sh ./ted_talks_processed.csv 8 1 1
-diff --git a/experiment/config.yaml b/experiment/config.yaml
-index aecc0bb..ffcdd79 100644
---- a/experiment/config.yaml
-+++ b/experiment/config.yaml
-@@ -4,7 +4,7 @@ trainer:
-     num_nodes: 1
-     max_epochs: 8
-     max_steps: null # precedence over max_epochs
--    accumulate_grad_batches: 2 # accumulates grads every k batches
-+    accumulate_grad_batches: 4 # accumulates grads every k batches
-     gradient_clip_val: 0
-     amp_level: O1 # O1/O2 for mixed precision
-     precision: 16 # Should be set to 16 for O1 and O2, default is 16 as PT ignores it when am_level is O0
-@@ -32,12 +32,12 @@ trainer:
-     # resume_from_checkpoint: null
- 
- exp_manager:
--    exp_dir: /home/nxingyu2/project/ # /root/project # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
-+    exp_dir: /home/nxingyu/project/ # /root/project # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
-     name: Punctuation_with_Domain_discriminator  # The name of your model
-     create_tensorboard_logger: true  # Whether you want exp_manger to create a tb logger
-     create_checkpoint_callback: true 
--base_path: /home/nxingyu2/data # /root/data # 
--tmp_path: /home/nxingyu2/data/tmp # /tmp # 
-+base_path: /home/nxingyu/data # /root/data # 
-+tmp_path: /home/nxingyu/data/tmp # /tmp # 
- log_dir: null
- 
- model:
-@@ -75,15 +75,17 @@ model:
-     punct_class_weights: false #false
-     
-     dataset:
--        data_dir: /home/nxingyu2/data # /root/data # 
-+        data_dir: /home/nxingyu/data # /root/data # 
-         labelled:
-             # - ${base_path}/ted2010 #
--            - ${base_path}/ted_talks_processed #
--            # - ${base_path}/open_subtitles_processed #  
-+            # - ${base_path}/ted_talks_processed #
-+            - ${base_path}/open_subtitles_processed #  
-+            # - ${base_path}/switchboardutt_processed #
-         unlabelled:
-             # - ${base_path}/ted_talks_processed #
-             # - ${base_path}/open_subtitles_processed #  
--            # parameters for dataset preprocessing
-+            # - ${base_path}/switchboardutt_processed
-+        # parameters for dataset preprocessing
-         max_seq_length: 128
-         pad_label: ''
-         ignore_extra_tokens: false
-@@ -101,7 +103,7 @@ model:
-         train_ds:
-             shuffle: true
-             num_samples: -1
--            batch_size: 32
-+            batch_size: 16
-             manual_len: 20000 #default 0 84074
- 
-         validation_ds:
-@@ -110,7 +112,7 @@ model:
-             # ds_item: null # expected format: [PATH_TO_DEV1,PATH_TO_DEV2] (Note no space between the paths and square brackets)
-             shuffle: true
-             num_samples: -1
--            batch_size: 32 #4
-+            batch_size: 16 #4
- 
-     tokenizer:
-         tokenizer_name: ${model.language_model.pretrained_model_name} # or sentencepiece
-@@ -147,7 +149,7 @@ model:
-     
-     dice_loss:
-         epsilon: 0.01
--        alpha: 3
-+        alpha: 2
-         macro_average: true
- 
-     focal_loss: 
-diff --git a/experiment/data/disfl2csv.sh b/experiment/data/disfl2csv.sh
-index 84d8b69..48148a0 100644
---- a/experiment/data/disfl2csv.sh
-+++ b/experiment/data/disfl2csv.sh
-@@ -4,10 +4,10 @@ echo "in $1"
- echo "out $2"
- :> "$2"
- DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
--echo 'talk_id,transcript'> "$2"
-+# echo 'talk_id,transcript'> "$2"
- #echo "filenames, transcript" > opensubtitles.csv
- for folder in $1/*; do
--    for filename in $folder/*.dfl; do
-+    for filename in $folder/*.dff; do
-         echo $filename
-         python $DIR/processdff.py -i $filename -o $2
-         #echo "$filename, \"$transcript\"" >> opensubtitles.csv
-diff --git a/experiment/data/processdff.py b/experiment/data/processdff.py
-index b456a43..7e76f7f 100644
---- a/experiment/data/processdff.py
-+++ b/experiment/data/processdff.py
-@@ -42,7 +42,7 @@ def remove_disf(text):
-     return s
- 
- def to_emdash(s):
--    return re.sub('--','',s)
-+    return re.sub('--','…',s)
- 
- def strip_accents(s):
-    return ''.join(c for c in unicodedata.normalize('NFKD', s)
-diff --git a/experiment/data/processutt.py b/experiment/data/processutt.py
-index d6c1af1..d809a43 100644
---- a/experiment/data/processutt.py
-+++ b/experiment/data/processutt.py
-@@ -42,7 +42,7 @@ def remove_disf(text):
-     return s
- 
- def to_emdash(s):
--    return re.sub('--','',s)
-+    return re.sub('--','…',s)
- 
- def strip_accents(s):
-    return ''.join(c for c in unicodedata.normalize('NFKD', s)
-diff --git a/experiment/data/punctuation_count.sh b/experiment/data/punctuation_count.sh
-index f5d71be..29ca0ca 100644
---- a/experiment/data/punctuation_count.sh
-+++ b/experiment/data/punctuation_count.sh
-@@ -1,8 +1,28 @@
- for split in "dev" "test" "train"
- do
--for file in /home/nxingyu2/data/open*.$split.csv
-+for file in /home/$USER/data/switch*.$split.csv
- do
-  echo $file
-  sed -E 's/[^[:punct:]]//g;s/(.)/\1x/g' $file  | tr 'x' '\n' | sort | uniq -c | awk '{array[$2]=$1; sum+=$1} END { for (i in array) printf "%-20s %-15d %6.2f%%\n", i, array[i], array[i]/sum*100}' | sort -r -k2,2 -n
- done
--done
-\ No newline at end of file
-+done
-+
-+# 205429 & 26199 & 16520 &
-+# 100843 & 13457 &  9141 &
-+#      0 &     0 &     0 &
-+#  22730 &  3331 &  2012 &
-+#   6765 &   808 &   528 &
-+#      0 &     0 &    16 &
-+#      0 &     0 &     0 &
-+#     77 &     5 &     6 &
-+#  18720 &  3133 &  2249 &
-+
-+# 0.57938 & 0.55822 & 0.54214 &
-+# 0.28441 & 0.28673 & 0.29998 &
-+# 0.00000 & 0.00000 & 0.00000 &
-+# 0.06411 & 0.07097 & 0.06603 &
-+# 0.01908 & 0.01722 & 0.01733 &
-+# 0.00000 & 0.00000 & 0.00053 &
-+# 0.00000 & 0.00000 & 0.00000 &
-+# 0.00022 & 0.00011 & 0.00020 &
-+# 0.05280 & 0.06675 & 0.07381 &
-diff --git a/experiment/data/utt2csv.sh b/experiment/data/utt2csv.sh
-index 7e03880..446d32a 100644
---- a/experiment/data/utt2csv.sh
-+++ b/experiment/data/utt2csv.sh
-@@ -4,7 +4,7 @@ echo "in $1"
- echo "out $2"
- :> "$2"
- DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
--echo 'talk_id,transcript'> "$2"
-+# echo 'talk_id,transcript'> "$2"
- #echo "filenames, transcript" > opensubtitles.csv
- for folder in $1/sw*; do
-     for filename in $folder/*.utt; do
-diff --git a/experiment/info.log b/experiment/info.log
-index 7d07c8a..e69de29 100644
---- a/experiment/info.log
-+++ b/experiment/info.log
-@@ -1,1341 +0,0 @@
--[INFO] - GPU available: True, used: True
--[INFO] - TPU available: None, using: 0 TPU cores
--[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
--[INFO] - Using native 16bit precision.
--[INFO] - shuffling train set
--[INFO] - initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.02
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7ff2c4092a30>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 4.7 M 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--5.9 M     Trainable params
--108 M     Non-trainable params
--114 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          78.98      44.46      56.89      80644
--! (label_id: 1)                                          0.04       2.04       0.08         98
--# (label_id: 2)                                          4.92      15.57       7.47       8270
--, (label_id: 3)                                          1.99       0.27       0.47       5934
--- (label_id: 4)                                          0.64       3.85       1.10        572
--. (label_id: 5)                                          6.34       3.38       4.41       5092
--: (label_id: 6)                                          0.19      20.34       0.38        118
--? (label_id: 7)                                          0.00       0.00       0.00        462
--… (label_id: 8)                                          0.04       5.26       0.08         38
---------------------
--micro avg                                               36.93      36.93      36.93     101228
--macro avg                                               10.35      10.57       7.88     101228
--weighted avg                                            63.76      36.93      46.19     101228
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    35854.00        20.00      4032.00      2572.00       284.00      2412.00        52.00       166.00         2.00
--     3840.00         2.00       232.00       400.00        42.00       298.00        10.00        34.00         2.00
--    21412.00        46.00      1288.00      1784.00        84.00      1388.00        22.00       150.00        18.00
--      662.00         0.00       116.00        16.00         2.00        10.00         0.00         0.00         0.00
--     2430.00         2.00       832.00        86.00        22.00        40.00         4.00         0.00         0.00
--     2196.00         0.00       100.00       202.00        12.00       172.00         6.00        22.00         2.00
--    10048.00        28.00       742.00       722.00        62.00       696.00        24.00        86.00        12.00
--      316.00         0.00        38.00         0.00         4.00         0.00         0.00         0.00         0.00
--     3886.00         0.00       890.00       152.00        60.00        76.00         0.00         4.00         2.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00        858
---------------------
--micro avg                                              100.00     100.00     100.00        858
--macro avg                                              100.00     100.00     100.00        858
--weighted avg                                           100.00     100.00     100.00        858
--
---------------------
--           0
--      858.00
---------------------
--
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.41      91.92      94.59     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         86.21      89.77      87.95      54804
--, (label_id: 3)                                         42.62      62.03      50.53      40800
--- (label_id: 4)                                         69.89      60.05      64.60       3464
--. (label_id: 5)                                         57.56      74.40      64.91      33424
--: (label_id: 6)                                         16.67      24.14      19.72        812
--? (label_id: 7)                                         65.62      29.42      40.62       2828
--… (label_id: 8)                                          1.33       7.27       2.25        220
---------------------
--micro avg                                               88.40      88.40      88.40     659880
--macro avg                                               48.59      48.78      47.24     659880
--weighted avg                                            90.59      88.40      89.23     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   480808.00        16.00      5380.00      4796.00      1016.00      1340.00        96.00       120.00        40.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     7796.00         0.00     49196.00         8.00        44.00        24.00         0.00         0.00         0.00
--    26532.00       224.00        48.00     25308.00       172.00      6400.00       188.00       420.00        84.00
--      828.00         0.00        64.00         4.00      2080.00         0.00         0.00         0.00         0.00
--     6328.00       196.00       104.00      9840.00       104.00     24868.00       300.00      1388.00        72.00
--      184.00        12.00         0.00       340.00         0.00       396.00       196.00        40.00         8.00
--      116.00        16.00         4.00       132.00         0.00       156.00        12.00       832.00         0.00
--      464.00         8.00         8.00       372.00        48.00       240.00        20.00        28.00        16.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 0, global step 49: val_loss reached 0.30009 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=0.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.50      88.95      93.03     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         67.87      92.39      78.25      54804
--, (label_id: 3)                                         41.27      74.84      53.20      40800
--- (label_id: 4)                                         82.54      50.23      62.46       3464
--. (label_id: 5)                                         68.11      62.47      65.17      33424
--: (label_id: 6)                                         43.10      12.32      19.16        812
--? (label_id: 7)                                         64.81      24.75      35.82       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               86.36      86.36      86.36     659880
--macro avg                                               51.69      45.11      45.23     659880
--weighted avg                                            89.68      86.36      87.33     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   465264.00        28.00      4072.00      5152.00       888.00      1396.00       180.00       172.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--    23120.00         0.00     50632.00       256.00       564.00        20.00         0.00         8.00         0.00
--    30964.00       180.00        72.00     30536.00       212.00     10932.00       284.00       708.00       104.00
--      356.00         0.00         0.00         0.00      1740.00        12.00         0.00         0.00         0.00
--     3248.00       228.00        24.00      4672.00        60.00     20880.00       248.00      1240.00        56.00
--       16.00         0.00         0.00        24.00         0.00        92.00       100.00         0.00         0.00
--       88.00        36.00         4.00       160.00         0.00        92.00         0.00       700.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 1, global step 99: val_loss reached 0.33170 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.33-epoch=1.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.41      97.01      96.20     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         94.34      88.26      91.20      54804
--, (label_id: 3)                                         56.69      58.49      57.58      40800
--- (label_id: 4)                                         87.42      48.15      62.10       3464
--. (label_id: 5)                                         70.05      64.34      67.07      33424
--: (label_id: 6)                                         58.54      11.82      19.67        812
--? (label_id: 7)                                         55.41      36.92      44.31       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.53      91.53      91.53     659880
--macro avg                                               57.54      45.00      48.68     659880
--weighted avg                                            91.28      91.53      91.33     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   507420.00        60.00      6400.00     12064.00      1516.00      3824.00       220.00       276.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2776.00         0.00     48372.00         8.00        96.00        20.00         0.00         0.00         0.00
--     9396.00       160.00         8.00     23864.00       124.00      7724.00       232.00       508.00        80.00
--      240.00         0.00         0.00         0.00      1668.00         0.00         0.00         0.00         0.00
--     3024.00       192.00        20.00      4588.00        60.00     21504.00       256.00      1000.00        56.00
--        8.00         0.00         0.00         8.00         0.00        52.00        96.00         0.00         0.00
--      192.00        60.00         4.00       268.00         0.00       300.00         8.00      1044.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 2, global step 149: val_loss reached 0.31563 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.32-epoch=2.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.90      96.12      96.01     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         89.97      88.46      89.21      54804
--, (label_id: 3)                                         53.45      64.22      58.34      40800
--- (label_id: 4)                                         82.01      53.70      64.90       3464
--. (label_id: 5)                                         71.61      60.91      65.83      33424
--: (label_id: 6)                                         22.89      22.66      22.77        812
--? (label_id: 7)                                         66.35      29.28      40.63       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.03      91.03      91.03     659880
--macro avg                                               53.57      46.15      48.63     659880
--weighted avg                                            91.17      91.03      91.00     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   502752.00        56.00      6284.00     10168.00      1144.00      3256.00       196.00       308.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     5080.00         0.00     48480.00        36.00       268.00        20.00         0.00         0.00         0.00
--    12200.00       184.00        24.00     26200.00       148.00      9364.00       200.00       608.00        92.00
--      404.00         0.00         0.00         4.00      1860.00         0.00         0.00         0.00         0.00
--     2368.00       196.00        12.00      4080.00        44.00     20360.00       232.00      1072.00        68.00
--      160.00         4.00         0.00       164.00         0.00       280.00       184.00        12.00         0.00
--       92.00        32.00         4.00       148.00         0.00       144.00         0.00       828.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 3, global step 199: val_loss reached 0.31315 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.31-epoch=3.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.75      95.17      95.95     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         89.22      90.48      89.85      54804
--, (label_id: 3)                                         51.13      69.58      58.95      40800
--- (label_id: 4)                                         77.34      59.12      67.02       3464
--. (label_id: 5)                                         70.86      63.12      66.76      33424
--: (label_id: 6)                                         57.14       9.85      16.81        812
--? (label_id: 7)                                         58.43      35.79      44.39       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               90.92      90.92      90.92     659880
--macro avg                                               55.65      47.01      48.86     659880
--weighted avg                                            91.58      90.92      91.11     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   497780.00        44.00      5156.00      7900.00      1008.00      2248.00       148.00       156.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     5716.00         0.00     49584.00        60.00       180.00        32.00         0.00         0.00         0.00
--    15936.00       176.00        44.00     28388.00       180.00      9708.00       364.00       620.00       100.00
--      588.00         0.00         4.00         8.00      2048.00         0.00         0.00         0.00         0.00
--     2884.00       208.00        12.00      4220.00        48.00     21096.00       212.00      1032.00        60.00
--        0.00         0.00         0.00         8.00         0.00        44.00        80.00         8.00         0.00
--      152.00        44.00         4.00       216.00         0.00       296.00         8.00      1012.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 4, step 249: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.94      96.58      96.26     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         96.14      86.64      91.15      54804
--, (label_id: 3)                                         57.41      61.25      59.27      40800
--- (label_id: 4)                                         76.69      60.39      67.57       3464
--. (label_id: 5)                                         68.11      71.82      69.91      33424
--: (label_id: 6)                                         25.76      16.75      20.30        812
--? (label_id: 7)                                         57.68      39.32      46.76       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.68      91.68      91.68     659880
--macro avg                                               53.08      48.08      50.14     659880
--weighted avg                                            91.72      91.68      91.66     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   505172.00        48.00      7272.00      9648.00      1116.00      2808.00       196.00       196.00        68.00
--        0.00         0.00         0.00         4.00         0.00         0.00         0.00         0.00         0.00
--     1848.00         0.00     47484.00         8.00        28.00        20.00         0.00         0.00         0.00
--    11408.00       148.00        24.00     24992.00       172.00      6064.00       204.00       448.00        76.00
--      616.00         0.00        12.00         8.00      2092.00         0.00         0.00         0.00         0.00
--     3736.00       216.00         8.00      5828.00        56.00     24004.00       272.00      1056.00        68.00
--      124.00         4.00         0.00        88.00         0.00       152.00       136.00        16.00         8.00
--      152.00        56.00         4.00       224.00         0.00       376.00         4.00      1112.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 5, global step 299: val_loss reached 0.30916 (best 0.30009), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.31-epoch=5.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.63      96.00      96.31     523056
--! (label_id: 1)                                         66.67       1.69       3.31        472
--# (label_id: 2)                                         94.65      89.24      91.87      54804
--, (label_id: 3)                                         56.09      64.01      59.79      40800
--- (label_id: 4)                                         76.31      60.62      67.57       3464
--. (label_id: 5)                                         66.81      74.69      70.53      33424
--: (label_id: 6)                                         30.77      15.76      20.85        812
--? (label_id: 7)                                         67.66      35.22      46.33       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.74      91.74      91.74     659880
--macro avg                                               61.73      48.58      50.73     659880
--weighted avg                                            92.08      91.74      91.82     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   502128.00        52.00      5844.00      7976.00      1084.00      2108.00       192.00       188.00        60.00
--        0.00         8.00         0.00         4.00         0.00         0.00         0.00         0.00         0.00
--     2660.00         0.00     48908.00        16.00        68.00        20.00         0.00         0.00         0.00
--    13400.00       144.00        28.00     26116.00       156.00      6024.00       200.00       408.00        84.00
--      636.00         0.00        12.00         4.00      2100.00         0.00         0.00         0.00         0.00
--     4040.00       228.00         8.00      6476.00        56.00     24964.00       292.00      1224.00        76.00
--       72.00         4.00         0.00        76.00         0.00       124.00       128.00        12.00         0.00
--      120.00        36.00         4.00       132.00         0.00       184.00         0.00       996.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 6, global step 349: val_loss reached 0.29901 (best 0.29901), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=6.ckpt" as top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.22      96.51      96.36     523056
--! (label_id: 1)                                         50.00       1.69       3.28        472
--# (label_id: 2)                                         94.99      88.69      91.73      54804
--, (label_id: 3)                                         58.33      60.13      59.21      40800
--- (label_id: 4)                                         76.36      60.05      67.23       3464
--. (label_id: 5)                                         67.13      74.43      70.59      33424
--: (label_id: 6)                                         29.60      18.23      22.56        812
--? (label_id: 7)                                         63.15      38.05      47.48       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.85      91.85      91.85     659880
--macro avg                                               59.53      48.64      50.94     659880
--weighted avg                                            91.90      91.85      91.82     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   504792.00        52.00      6164.00      9436.00      1132.00      2604.00       196.00       204.00        68.00
--        0.00         8.00         0.00         4.00         0.00         4.00         0.00         0.00         0.00
--     2464.00         0.00     48608.00        24.00        56.00        20.00         0.00         0.00         0.00
--    11076.00       136.00        12.00     24532.00       140.00      5508.00       184.00       396.00        76.00
--      624.00         0.00        12.00         8.00      2080.00         0.00         0.00         0.00         0.00
--     3876.00       228.00         8.00      6516.00        56.00     24876.00       284.00      1136.00        76.00
--       84.00         4.00         0.00        96.00         0.00       152.00       148.00        16.00         0.00
--      140.00        44.00         0.00       184.00         0.00       260.00         0.00      1076.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 7, global step 399: val_loss reached 0.29477 (best 0.29477), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.29-epoch=7.ckpt" as top 3
--[INFO] - Saving latest checkpoint...
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.001
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7ff309dcf1f0>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 4.7 M 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--13.0 M    Trainable params
--101 M     Non-trainable params
--114 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.42      96.72      96.57      80644
--! (label_id: 1)                                        100.00       2.04       4.00         98
--# (label_id: 2)                                         94.98      88.83      91.80       8270
--, (label_id: 3)                                         58.52      61.21      59.84       5934
--- (label_id: 4)                                         76.96      61.89      68.60        572
--. (label_id: 5)                                         68.39      74.94      71.51       5092
--: (label_id: 6)                                         27.91      20.34      23.53        118
--? (label_id: 7)                                         61.36      35.06      44.63        462
--… (label_id: 8)                                          0.00       0.00       0.00         38
---------------------
--micro avg                                               92.21      92.21      92.21     101228
--macro avg                                               64.95      49.00      51.17     101228
--weighted avg                                            92.29      92.21      92.16     101228
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    78002.00         8.00       918.00      1312.00       170.00       410.00        30.00        34.00        12.00
--        0.00         2.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      372.00         0.00      7346.00         6.00        10.00         0.00         0.00         0.00         0.00
--     1618.00        30.00         2.00      3632.00        26.00       800.00        24.00        62.00        12.00
--      104.00         0.00         2.00         0.00       354.00         0.00         0.00         0.00         0.00
--      510.00        48.00         2.00       936.00        12.00      3816.00        40.00       202.00        14.00
--       16.00         0.00         0.00        18.00         0.00        26.00        24.00         2.00         0.00
--       22.00        10.00         0.00        30.00         0.00        40.00         0.00       162.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00        858
---------------------
--micro avg                                              100.00     100.00     100.00        858
--macro avg                                              100.00     100.00     100.00        858
--weighted avg                                           100.00     100.00     100.00        858
--
---------------------
--           0
--      858.00
---------------------
--
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.70      94.08      95.86     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.41      91.56      91.98      54804
--, (label_id: 3)                                         54.08      65.15      59.10      40800
--- (label_id: 4)                                         45.58      75.06      56.72       3464
--. (label_id: 5)                                         64.27      82.86      72.39      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         48.94      68.32      57.02       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.09      91.09      91.09     659880
--macro avg                                               44.78      53.00      48.12     659880
--weighted avg                                            92.17      91.09      91.48     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   492100.00        24.00      4224.00      5312.00       620.00       972.00       224.00       160.00        44.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     4076.00         0.00     50176.00        16.00        16.00        12.00         0.00         0.00         0.00
--    17824.00       140.00        12.00     26580.00       152.00      3988.00       196.00       172.00        84.00
--     2804.00         0.00       248.00        36.00      2600.00        16.00         0.00         0.00         0.00
--     5728.00       256.00       136.00      8184.00        76.00     27696.00       372.00       564.00        84.00
--        0.00         0.00         0.00         0.00         0.00         8.00         0.00         0.00         0.00
--      524.00        52.00         8.00       672.00         0.00       732.00        20.00      1932.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 0, step 449: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.41      96.35      96.88     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         91.96      94.02      92.98      54804
--, (label_id: 3)                                         64.21      66.16      65.17      40800
--- (label_id: 4)                                         82.47      58.66      68.56       3464
--. (label_id: 5)                                         71.30      82.13      76.33      33424
--: (label_id: 6)                                          2.63       0.99       1.43        812
--? (label_id: 7)                                         60.28      67.19      63.55       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.03      93.03      93.03     659880
--macro avg                                               52.25      51.72      51.65     659880
--weighted avg                                            93.13      93.03      93.04     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   503984.00        60.00      3212.00      6736.00      1244.00      1548.00       212.00       328.00        56.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     4456.00         0.00     51528.00        16.00        24.00        12.00         0.00         0.00         0.00
--    10468.00       140.00        20.00     26992.00       136.00      3768.00       240.00       188.00        88.00
--      404.00         0.00        12.00        12.00      2032.00         4.00         0.00         0.00         0.00
--     3520.00       232.00        32.00      6420.00        28.00     27452.00       340.00       412.00        68.00
--       36.00         0.00         0.00       232.00         0.00        28.00         8.00         0.00         0.00
--      188.00        40.00         0.00       392.00         0.00       612.00        12.00      1900.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 1, step 499: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.66      94.87      95.76     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         73.52      98.98      84.37      54804
--, (label_id: 3)                                         65.92      59.67      62.64      40800
--- (label_id: 4)                                         82.48      50.00      62.26       3464
--. (label_id: 5)                                         78.47      72.58      75.41      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         64.87      64.78      64.83       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               91.32      91.32      91.32     659880
--macro avg                                               51.33      48.99      49.47     659880
--weighted avg                                            91.49      91.32      91.21     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   496212.00       116.00       536.00     12196.00       908.00      2632.00       292.00       364.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--    18644.00         0.00     54244.00       160.00       700.00        32.00         0.00         0.00         0.00
--     5632.00       136.00         8.00     24344.00       112.00      6032.00       280.00       296.00        88.00
--      216.00         0.00         0.00       140.00      1732.00        12.00         0.00         0.00         0.00
--     2204.00       196.00        16.00      3624.00        12.00     24260.00       212.00       336.00        56.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      148.00        24.00         0.00       336.00         0.00       456.00        28.00      1832.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 2, step 549: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.60      97.50      97.05     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         93.99      91.64      92.80      54804
--, (label_id: 3)                                         68.55      61.10      64.61      40800
--- (label_id: 4)                                         81.77      49.19      61.43       3464
--. (label_id: 5)                                         71.94      82.38      76.81      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         82.00      50.92      62.83       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.32      93.32      93.32     659880
--macro avg                                               54.98      48.08      50.61     659880
--weighted avg                                            93.04      93.32      93.11     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   510004.00        64.00      4520.00      9228.00      1444.00      2020.00       252.00       360.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2996.00         0.00     50220.00        92.00       108.00        16.00         0.00         0.00         0.00
--     6636.00       144.00        24.00     24928.00       188.00      3764.00       220.00       388.00        72.00
--      304.00         0.00        20.00        48.00      1704.00         8.00         0.00         0.00         0.00
--     3036.00       248.00        20.00      6364.00        20.00     27536.00       340.00       640.00        72.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--       80.00        16.00         0.00       140.00         0.00        80.00         0.00      1440.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 3, step 599: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.93      97.24      97.09     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         94.66      91.04      92.81      54804
--, (label_id: 3)                                         66.63      64.82      65.72      40800
--- (label_id: 4)                                         75.88      62.47      68.52       3464
--. (label_id: 5)                                         73.34      81.40      77.16      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         70.49      69.59      70.04       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.40      93.40      93.40     659880
--macro avg                                               53.10      51.84      52.37     659880
--weighted avg                                            93.23      93.40      93.30     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508644.00        56.00      4712.00      8096.00      1072.00      1648.00       216.00       220.00        76.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2504.00         0.00     49892.00       252.00        44.00        16.00         0.00         0.00         0.00
--     8032.00       164.00        52.00     26448.00       168.00      4252.00       268.00       236.00        72.00
--      560.00         0.00       108.00         4.00      2164.00        16.00         0.00         0.00         0.00
--     3152.00       228.00        40.00      5656.00        16.00     27208.00       320.00       404.00        72.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      164.00        24.00         0.00       344.00         0.00       284.00         8.00      1968.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 4, step 649: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.34      96.76      97.05     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.54      93.20      92.87      54804
--, (label_id: 3)                                         64.62      68.42      66.47      40800
--- (label_id: 4)                                         82.26      58.89      68.64       3464
--. (label_id: 5)                                         74.47      80.59      77.41      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         69.26      71.71      70.47       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.36      93.36      93.36     659880
--macro avg                                               53.39      52.17      52.54     659880
--weighted avg                                            93.34      93.36      93.33     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   506088.00        44.00      3608.00      7132.00      1100.00      1496.00       172.00       204.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     3760.00         0.00     51080.00       244.00        92.00        20.00         0.00         0.00         0.00
--     9524.00       176.00        44.00     27916.00       216.00      4680.00       320.00       232.00        92.00
--      396.00         0.00        28.00         4.00      2040.00        12.00         0.00         0.00         0.00
--     3032.00       228.00        44.00      5172.00        16.00     26936.00       312.00       364.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      256.00        24.00         0.00       332.00         0.00       280.00         8.00      2028.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 5, step 699: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.17      97.08      97.12     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.93      92.96      92.95      54804
--, (label_id: 3)                                         66.75      65.61      66.17      40800
--- (label_id: 4)                                         75.56      66.40      70.68       3464
--. (label_id: 5)                                         74.11      81.07      77.43      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         72.03      70.30      71.15       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.48      93.48      93.48     659880
--macro avg                                               53.17      52.60      52.83     659880
--weighted avg                                            93.32      93.48      93.39     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   507784.00        56.00      3732.00      7964.00       892.00      1656.00       216.00       220.00        68.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     3532.00         0.00     50948.00       244.00        84.00        16.00         0.00         0.00         0.00
--     8000.00       148.00        44.00     26768.00       172.00      4380.00       284.00       220.00        88.00
--      652.00         0.00        60.00        12.00      2300.00        20.00         0.00         0.00         0.00
--     2912.00       244.00        20.00      5504.00        16.00     27096.00       304.00       400.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      176.00        24.00         0.00       308.00         0.00       256.00         8.00      1988.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 6, step 749: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.17      97.07      97.12     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         92.94      92.98      92.96      54804
--, (label_id: 3)                                         66.60      66.25      66.42      40800
--- (label_id: 4)                                         75.19      66.86      70.78       3464
--. (label_id: 5)                                         74.75      80.94      77.72      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         73.88      70.01      71.90       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.51      93.51      93.51     659880
--macro avg                                               53.39      52.68      52.99     659880
--weighted avg                                            93.36      93.51      93.43     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   507744.00        56.00      3724.00      7944.00       876.00      1664.00       220.00       220.00        68.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     3528.00         0.00     50956.00       244.00        84.00        16.00         0.00         0.00         0.00
--     8112.00       152.00        44.00     27028.00       172.00      4464.00       292.00       232.00        88.00
--      672.00         0.00        60.00        12.00      2316.00        20.00         0.00         0.00         0.00
--     2832.00       240.00        20.00      5280.00        16.00     27052.00       292.00       396.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      168.00        24.00         0.00       292.00         0.00       208.00         8.00      1980.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 7, step 799: val_loss was not in top 3
--[INFO] - Optimizer config = AdamW (
--Parameter Group 0
--    amsgrad: False
--    betas: (0.9, 0.999)
--    eps: 1e-08
--    lr: 0.0004
--    weight_decay: 0.0
--)
--[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7ff29c24fa60>" 
--will be used during training (effective maximum steps = 400) - 
--Parameters : 
--(warmup_steps: null
--warmup_ratio: 0.1
--min_lr: 1.0e-08
--last_epoch: -1
--max_steps: 400
--)
--[INFO] - 
--  | Name                       | Type                 | Params
----------------------------------------------------------------------
--0 | transformer                | ElectraModel         | 108 M 
--1 | punct_classifier           | TokenClassifier      | 1.2 M 
--2 | domain_classifier          | SequenceClassifier   | 4.7 M 
--3 | punctuation_loss           | FocalDiceLoss        | 0     
--4 | domain_loss                | CrossEntropyLoss     | 0     
--5 | agg_loss                   | AggregatorLoss       | 0     
--6 | punct_class_report         | ClassificationReport | 0     
--7 | chunked_punct_class_report | ClassificationReport | 0     
--8 | domain_class_report        | ClassificationReport | 0     
----------------------------------------------------------------------
--20.1 M    Trainable params
--94.7 M    Non-trainable params
--114 M     Total params
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          97.30      97.36      97.33      80644
--! (label_id: 1)                                          0.00       0.00       0.00         98
--# (label_id: 2)                                         92.84      93.11      92.97       8270
--, (label_id: 3)                                         66.91      67.21      67.06       5934
--- (label_id: 4)                                         77.08      68.18      72.36        572
--. (label_id: 5)                                         76.94      80.60      78.73       5092
--: (label_id: 6)                                          0.00       0.00       0.00        118
--? (label_id: 7)                                         76.61      72.29      74.39        462
--… (label_id: 8)                                          0.00       0.00       0.00         38
---------------------
--micro avg                                               93.88      93.88      93.88     101228
--macro avg                                               54.19      53.19      53.65     101228
--weighted avg                                            93.68      93.88      93.77     101228
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--    78518.00        10.00       552.00      1142.00       140.00       256.00        32.00        36.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      544.00         0.00      7700.00        38.00        12.00         0.00         0.00         0.00         0.00
--     1122.00        32.00         4.00      3988.00        28.00       698.00        42.00        32.00        14.00
--      102.00         0.00        12.00         0.00       390.00         2.00         0.00         0.00         0.00
--      340.00        50.00         2.00       722.00         2.00      4104.00        42.00        60.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--       18.00         6.00         0.00        44.00         0.00        32.00         2.00       334.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00        858
---------------------
--micro avg                                              100.00     100.00     100.00        858
--macro avg                                              100.00     100.00     100.00        858
--weighted avg                                           100.00     100.00     100.00        858
--
---------------------
--           0
--      858.00
---------------------
--
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.70      97.18      96.94     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         90.59      92.02      91.30      54804
--, (label_id: 3)                                         65.34      65.67      65.50      40800
--- (label_id: 4)                                         85.28      45.50      59.34       3464
--. (label_id: 5)                                         76.92      76.16      76.54      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                         67.59      62.23      64.80       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.10      93.10      93.10     659880
--macro avg                                               53.60      48.75      50.49     659880
--weighted avg                                            92.84      93.10      92.94     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508300.00        60.00      4336.00      9072.00      1240.00      2136.00       204.00       252.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     4560.00         0.00     50432.00       212.00       436.00        32.00         0.00         0.00         0.00
--     7488.00       172.00         8.00     26792.00       200.00      5416.00       384.00       436.00       108.00
--      256.00         0.00        12.00         4.00      1576.00         0.00         0.00         0.00         0.00
--     2240.00       216.00        16.00      4512.00        12.00     25456.00       216.00       380.00        44.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      212.00        24.00         0.00       208.00         0.00       384.00         8.00      1760.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 0, step 849: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          95.12      98.10      96.59     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         93.92      90.84      92.36      54804
--, (label_id: 3)                                         71.82      48.62      57.98      40800
--- (label_id: 4)                                         75.00      55.08      63.52       3464
--. (label_id: 5)                                         72.29      78.12      75.09      33424
--: (label_id: 6)                                        100.00       0.49       0.98        812
--? (label_id: 7)                                         86.41      35.08      49.90       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               92.71      92.71      92.71     659880
--macro avg                                               66.06      45.15      48.49     659880
--weighted avg                                            92.19      92.71      92.17     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   513120.00       140.00      4940.00     15176.00      1240.00      3752.00       372.00       596.00       104.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     2864.00         0.00     49784.00        84.00       232.00        40.00         0.00         0.00         0.00
--     3644.00        64.00         0.00     19836.00        76.00      3500.00       168.00       276.00        56.00
--      560.00         0.00        60.00        16.00      1908.00         0.00         0.00         0.00         0.00
--     2820.00       252.00        20.00      5616.00         8.00     26112.00       268.00       964.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         4.00         0.00         0.00
--       48.00        16.00         0.00        72.00         0.00        20.00         0.00       992.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 1, step 899: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          94.93      95.85      95.39     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         98.21      69.76      81.58      54804
--, (label_id: 3)                                         54.91      72.97      62.66      40800
--- (label_id: 4)                                         86.86      27.48      41.75       3464
--. (label_id: 5)                                         66.94      75.06      70.77      33424
--: (label_id: 6)                                          0.00       0.00       0.00        812
--? (label_id: 7)                                        100.00       1.56       3.06       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               90.23      90.23      90.23     659880
--macro avg                                               55.76      38.08      39.47     659880
--weighted avg                                            91.07      90.23      90.08     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   501340.00        48.00     16152.00      6100.00      2028.00      1720.00       188.00       488.00        52.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      476.00         0.00     38232.00        24.00       176.00        20.00         0.00         0.00         0.00
--    15484.00       220.00       100.00     29772.00       252.00      6596.00       360.00      1348.00        88.00
--      136.00         0.00         8.00         0.00       952.00         0.00         0.00         0.00         0.00
--     5620.00       204.00       312.00      4904.00        56.00     25088.00       264.00       948.00        80.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00        44.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 2, step 949: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.95      94.26      95.58     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         88.08      93.86      90.88      54804
--, (label_id: 3)                                         59.30      62.47      60.85      40800
--- (label_id: 4)                                         43.12      67.32      52.57       3464
--. (label_id: 5)                                         70.00      76.39      73.06      33424
--: (label_id: 6)                                          0.91       5.42       1.56        812
--? (label_id: 7)                                         55.40      63.08      58.99       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               90.87      90.87      90.87     659880
--macro avg                                               45.97      51.42      48.17     659880
--weighted avg                                            91.84      90.87      91.31     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   493028.00        76.00      2376.00      9040.00       652.00      2780.00       252.00       280.00        72.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     6864.00         0.00     51440.00        16.00        68.00         4.00         0.00         8.00         0.00
--    11812.00       120.00       108.00     25488.00       156.00      4628.00       268.00       324.00        76.00
--     2344.00         0.00       504.00       212.00      2332.00        16.00         0.00         0.00         0.00
--     4468.00       256.00       144.00      5276.00        72.00     25532.00       244.00       412.00        68.00
--     3964.00         4.00       212.00       368.00       176.00        56.00        44.00        20.00         0.00
--      576.00        16.00        20.00       400.00         8.00       408.00         4.00      1784.00         4.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 3, step 999: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.73      96.49      96.61     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         97.10      88.69      92.71      54804
--, (label_id: 3)                                         61.91      66.92      64.32      40800
--- (label_id: 4)                                         62.18      61.32      61.74       3464
--. (label_id: 5)                                         71.48      77.96      74.58      33424
--: (label_id: 6)                                          4.21       1.97       2.68        812
--? (label_id: 7)                                         54.34      71.71      61.83       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               92.57      92.57      92.57     659880
--macro avg                                               49.77      51.67      50.50     659880
--weighted avg                                            92.75      92.57      92.63     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   504696.00        68.00      5900.00      7576.00      1048.00      1924.00       240.00       236.00        52.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1396.00         0.00     48608.00        20.00        24.00        12.00         0.00         0.00         0.00
--    10964.00       132.00        64.00     27304.00       216.00      4920.00       236.00       192.00        72.00
--     1020.00         0.00       132.00       128.00      2124.00        12.00         0.00         0.00         0.00
--     4196.00       248.00        88.00      5064.00        40.00     26056.00       304.00       372.00        84.00
--      200.00         0.00         8.00       152.00         0.00         4.00        16.00         0.00         0.00
--      584.00        24.00         4.00       556.00        12.00       496.00        16.00      2028.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 4, step 1049: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          94.84      98.08      96.43     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         98.53      81.48      89.20      54804
--, (label_id: 3)                                         67.47      60.25      63.66      40800
--- (label_id: 4)                                         65.13      58.89      61.86       3464
--. (label_id: 5)                                         77.35      72.15      74.66      33424
--: (label_id: 6)                                          6.67       2.46       3.60        812
--? (label_id: 7)                                         66.26      60.82      63.42       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               92.46      92.46      92.46     659880
--macro avg                                               52.92      48.24      50.31     659880
--weighted avg                                            92.08      92.46      92.17     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   513024.00        92.00      9884.00     11672.00      1184.00      4168.00       344.00       472.00        84.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      600.00         0.00     44652.00        20.00        28.00        16.00         0.00         0.00         0.00
--     6192.00       148.00        32.00     24584.00       132.00      4776.00       208.00       272.00        92.00
--      828.00         0.00       204.00        60.00      2040.00         0.00         0.00         0.00         0.00
--     2096.00       216.00        32.00      4068.00        16.00     24116.00       236.00       364.00        32.00
--      168.00         0.00         0.00        40.00        64.00         8.00        20.00         0.00         0.00
--      148.00        16.00         0.00       356.00         0.00       340.00         4.00      1720.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 5, step 1099: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.42      97.26      96.84     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         96.89      90.07      93.36      54804
--, (label_id: 3)                                         64.67      65.10      64.88      40800
--- (label_id: 4)                                         61.01      63.97      62.46       3464
--. (label_id: 5)                                         75.87      75.59      75.73      33424
--: (label_id: 6)                                         14.29       2.46       4.20        812
--? (label_id: 7)                                         59.57      67.33      63.21       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.05      93.05      93.05     659880
--macro avg                                               52.08      51.31      51.19     659880
--weighted avg                                            92.91      93.05      92.96     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508716.00        68.00      5096.00      8936.00      1036.00      3024.00       280.00       372.00        64.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1492.00         0.00     49364.00        32.00        36.00        24.00         0.00         0.00         0.00
--     9016.00       172.00        36.00     26560.00       132.00      4504.00       284.00       264.00       104.00
--     1076.00         0.00       276.00        64.00      2216.00         0.00         0.00         0.00         0.00
--     2492.00       216.00        32.00      4728.00        24.00     25264.00       216.00       288.00        40.00
--       60.00         0.00         0.00        40.00        12.00         8.00        20.00         0.00         0.00
--      204.00        16.00         0.00       440.00         8.00       600.00        12.00      1904.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 6, step 1149: val_loss was not in top 3
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.49      97.24      96.86     523056
--! (label_id: 1)                                          0.00       0.00       0.00        472
--# (label_id: 2)                                         96.73      90.36      93.44      54804
--, (label_id: 3)                                         64.80      65.04      64.92      40800
--- (label_id: 4)                                         64.12      62.12      63.11       3464
--. (label_id: 5)                                         75.35      76.33      75.84      33424
--: (label_id: 6)                                         22.73       2.46       4.44        812
--? (label_id: 7)                                         58.91      68.74      63.45       2828
--… (label_id: 8)                                          0.00       0.00       0.00        220
---------------------
--micro avg                                               93.09      93.09      93.09     659880
--macro avg                                               53.24      51.37      51.34     659880
--weighted avg                                            92.95      93.09      93.00     659880
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   508616.00        72.00      4992.00      8792.00      1104.00      2864.00       280.00       364.00        56.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1572.00         0.00     49520.00        40.00        36.00        24.00         0.00         0.00         0.00
--     9072.00       152.00        36.00     26536.00       128.00      4416.00       280.00       240.00        88.00
--      920.00         0.00       224.00        60.00      2152.00         0.00         0.00         0.00         0.00
--     2604.00       224.00        32.00      4892.00        28.00     25512.00       220.00       280.00        64.00
--       28.00         0.00         0.00        24.00         8.00         8.00        20.00         0.00         0.00
--      244.00        24.00         0.00       456.00         8.00       600.00        12.00      1944.00        12.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       5564
---------------------
--micro avg                                              100.00     100.00     100.00       5564
--macro avg                                              100.00     100.00     100.00       5564
--weighted avg                                           100.00     100.00     100.00       5564
--
---------------------
--           0
--     5564.00
---------------------
--
--[INFO] - Epoch 7, step 1199: val_loss was not in top 3
--[INFO] - GPU available: True, used: True
--[INFO] - TPU available: None, using: 0 TPU cores
--[INFO] - Using environment variable NODE_RANK for node rank (0).
--[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
--[INFO] - Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.25      97.27      96.76     650284
--! (label_id: 1)                                          0.00       0.00       0.00        380
--# (label_id: 2)                                         97.23      89.79      93.36      68496
--, (label_id: 3)                                         62.58      64.85      63.69      52348
--- (label_id: 4)                                         49.90      60.65      54.75       3212
--. (label_id: 5)                                         79.01      73.40      76.10      46276
--: (label_id: 6)                                         20.00       2.25       4.05        888
--? (label_id: 7)                                         60.00      67.50      63.53       4000
--… (label_id: 8)                                          0.00       0.00       0.00        260
---------------------
--micro avg                                               92.79      92.79      92.79     826144
--macro avg                                               51.66      50.63      50.25     826144
--weighted avg                                            92.72      92.79      92.72     826144
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   632504.00        36.00      6712.00     12044.00      1116.00      3904.00       244.00       476.00       108.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--     1596.00         0.00     61504.00        28.00        52.00        76.00         0.00         0.00         0.00
--    11756.00       140.00         8.00     33948.00        68.00      7492.00       300.00       432.00       104.00
--     1636.00         0.00       232.00        36.00      1948.00        52.00         0.00         0.00         0.00
--     2480.00       180.00        28.00      5584.00        16.00     33968.00       304.00       392.00        40.00
--       20.00         0.00         0.00        28.00        12.00        20.00        20.00         0.00         0.00
--      292.00        24.00        12.00       680.00         0.00       764.00        20.00      2700.00         8.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Chunked Punctuation report: 
--label                                                precision    recall       f1           support   
-- (label_id: 0)                                          96.57      97.15      96.86     327564
--! (label_id: 1)                                          0.00       0.00       0.00        184
--# (label_id: 2)                                         97.23      90.48      93.73      34404
--, (label_id: 3)                                         63.38      67.07      65.18      26324
--- (label_id: 4)                                         50.74      63.34      56.35       1724
--. (label_id: 5)                                         80.87      76.47      78.61      23376
--: (label_id: 6)                                          8.33       0.88       1.59        456
--? (label_id: 7)                                         59.61      72.62      65.47       2016
--… (label_id: 8)                                          0.00       0.00       0.00         92
---------------------
--micro avg                                               93.10      93.10      93.10     416140
--macro avg                                               50.75      52.00      50.86     416140
--weighted avg                                            93.12      93.10      93.08     416140
--
---------------------
--                       !           #           ,           -           .           :           ?           …
--   318220.00        20.00      3140.00      5728.00       532.00      1500.00       124.00       184.00        60.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
--      788.00         0.00     31128.00         8.00        32.00        60.00         0.00         0.00         0.00
--     6236.00        84.00         0.00     17656.00        48.00      3444.00       144.00       220.00        24.00
--      872.00         0.00       128.00        16.00      1092.00        44.00         0.00         0.00         0.00
--     1240.00        72.00         8.00      2568.00        16.00     17876.00       168.00       148.00         8.00
--       16.00         0.00         0.00         4.00         4.00        20.00         4.00         0.00         0.00
--      192.00         8.00         0.00       344.00         0.00       432.00        16.00      1464.00         0.00
--        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
---------------------
--
--[INFO] - Domain report: 
--label                                                precision    recall       f1           support   
--0 (label_id: 0)                                        100.00     100.00     100.00       6884
---------------------
--micro avg                                              100.00     100.00     100.00       6884
--macro avg                                              100.00     100.00     100.00       6884
--weighted avg                                           100.00     100.00     100.00       6884
--
---------------------
--           0
--     6884.00
---------------------
--
--[INFO] - saving to /home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-22_16-04-59/test.txt
--[INFO] - Internal process exited
-diff --git a/experiment/outputs/2021-02-23/08-18-26/testing.log b/experiment/outputs/2021-02-23/08-18-26/testing.log
-index f00f863..2597221 100644
---- a/experiment/outputs/2021-02-23/08-18-26/testing.log
-+++ b/experiment/outputs/2021-02-23/08-18-26/testing.log
-@@ -1 +1,74 @@
- [2021-02-23 08:18:38,771][root][INFO] - shuffling train set
-+[2021-02-23 08:44:12,424][root][INFO] - Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          95.20      95.06      95.13   33617452
-+! (label_id: 1)                                         21.65      40.73      28.27     578585
-+# (label_id: 2)                                         89.63      94.36      91.93    6976446
-+, (label_id: 3)                                         52.02      49.20      50.57    2858145
-+- (label_id: 4)                                         52.90      37.64      43.98     255633
-+. (label_id: 5)                                         67.03      64.56      65.77    5425019
-+: (label_id: 6)                                          0.00       0.00       0.00      15576
-+? (label_id: 7)                                         66.11      48.89      56.21    1415356
-+… (label_id: 8)                                         28.23      27.42      27.82     482702
-+-------------------
-+micro avg                                               86.40      86.40      86.40   51624912
-+macro avg                                               52.53      50.87      51.07   51624912
-+weighted avg                                            86.61      86.40      86.42   51624912
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 31955872.00     33316.00    385671.00    438274.00     53505.00    443163.00      7682.00    120484.00    128329.00
-+    66565.00    235635.00       761.00    176016.00      8738.00    506812.00       944.00     64244.00     28918.00
-+   714124.00       536.00   6582626.00      7720.00     19841.00     15709.00      1649.00      1336.00      1001.00
-+   288086.00     97827.00       833.00   1406100.00     11576.00    706306.00       912.00    121425.00     69959.00
-+    56237.00      2410.00       944.00      5163.00     96209.00     18095.00        96.00      1041.00      1680.00
-+   390319.00    174383.00      3985.00    635086.00     21274.00   3502327.00      3717.00    389488.00    104418.00
-+        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-+    75395.00     24645.00       937.00     80919.00      3444.00    153187.00       136.00    691913.00     16045.00
-+    70772.00      9833.00       689.00    108867.00     41046.00     79420.00       440.00     25425.00    132352.00
-+-------------------
-+
-+[2021-02-23 08:44:12,434][root][INFO] - Chunked Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          95.59      96.37      95.98   16876740
-+! (label_id: 1)                                         21.47      41.98      28.41     290645
-+# (label_id: 2)                                         95.04      95.14      95.09    3541392
-+, (label_id: 3)                                         52.20      49.91      51.03    1447727
-+- (label_id: 4)                                         53.56      38.01      44.47     130953
-+. (label_id: 5)                                         68.20      65.03      66.58    2759312
-+: (label_id: 6)                                          0.00       0.00       0.00       7645
-+? (label_id: 7)                                         66.66      50.42      57.42     716850
-+… (label_id: 8)                                         28.64      27.84      28.23     243286
-+-------------------
-+micro avg                                               87.46      87.46      87.46   26014552
-+macro avg                                               53.49      51.63      51.91   26014552
-+weighted avg                                            87.71      87.46      87.50   26014552
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 16264699.00     14196.00    169436.00    215171.00     26620.00    202508.00      3785.00     54437.00     63531.00
-+    33928.00    122012.00       272.00     91962.00      4505.00    266896.00       504.00     33168.00     15114.00
-+   151602.00       248.00   3369444.00      3788.00     10412.00      7913.00       881.00       624.00       328.00
-+   147638.00     49831.00       344.00    722501.00      5999.00    360923.00       448.00     60458.00     35874.00
-+    28414.00      1192.00       464.00      2722.00     49780.00      8964.00        32.00       537.00       840.00
-+   177113.00     85795.00      1072.00    314405.00     10733.00   1794350.00      1747.00    194183.00     51583.00
-+        0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00         0.00
-+    37372.00     12602.00       168.00     41387.00      1825.00     79031.00        64.00    361456.00      8297.00
-+    35974.00      4769.00       192.00     55791.00     21079.00     38727.00       184.00     11987.00     67719.00
-+-------------------
-+
-+[2021-02-23 08:44:12,439][root][INFO] - Domain report: 
-+label                                                precision    recall       f1           support   
-+0 (label_id: 0)                                        100.00     100.00     100.00     411653
-+-------------------
-+micro avg                                              100.00     100.00     100.00     411653
-+macro avg                                              100.00     100.00     100.00     411653
-+weighted avg                                           100.00     100.00     100.00     411653
-+
-+-------------------
-+           0
-+   411653.00
-+-------------------
-+
-+[2021-02-23 08:44:12,439][root][INFO] - saving to /home/nxingyu/project/Punctuation_with_Domain_discriminator/opendice33acc42021-02-22_09-49-04//test.txt
-+[2021-02-23 08:44:12,539][wandb.sdk.internal.internal][INFO] - Internal process exited
-diff --git a/experiment/outputs/2021-02-23/08-20-55/testing.log b/experiment/outputs/2021-02-23/08-20-55/testing.log
-index 717645a..7100fd1 100644
---- a/experiment/outputs/2021-02-23/08-20-55/testing.log
-+++ b/experiment/outputs/2021-02-23/08-20-55/testing.log
-@@ -1 +1,74 @@
- [2021-02-23 08:21:08,018][root][INFO] - shuffling train set
-+[2021-02-23 09:05:21,673][root][INFO] - Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          94.88      97.99      96.41   33617452
-+! (label_id: 1)                                         33.89       9.66      15.04     578585
-+# (label_id: 2)                                         99.49      99.10      99.30    6976446
-+, (label_id: 3)                                         52.51      39.66      45.19    2858145
-+- (label_id: 4)                                         56.89      22.57      32.32     255633
-+. (label_id: 5)                                         62.04      77.10      68.76    5425019
-+: (label_id: 6)                                         77.05      41.40      53.86      15576
-+? (label_id: 7)                                         70.01      36.10      47.64    1415356
-+… (label_id: 8)                                         57.21       6.15      11.10     482702
-+-------------------
-+micro avg                                               88.78      88.78      88.78   51624912
-+macro avg                                               67.11      47.75      52.18   51624912
-+weighted avg                                            87.80      88.78      87.68   51624912
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 32940746.00     42247.00     56263.00    637305.00    117974.00    572846.00      3579.00    174660.00    172542.00
-+    10770.00     55899.00        88.00     35948.00      1672.00     46823.00       184.00      8367.00      5210.00
-+    27771.00       545.00   6913637.00      1128.00      1968.00      2819.00        16.00       480.00       560.00
-+   163910.00    113876.00       544.00   1133679.00     17942.00    526536.00       840.00    121929.00     79630.00
-+    19931.00      1771.00       104.00      4132.00     57687.00     14847.00        40.00       600.00      2282.00
-+   403834.00    347864.00      5066.00    988029.00     38393.00   4182951.00      4372.00    597272.00    174593.00
-+      608.00         0.00         0.00       505.00       360.00       288.00      6449.00        32.00       128.00
-+    48028.00     16247.00       712.00     54579.00      4683.00     76459.00        80.00    510999.00     18088.00
-+     1745.00       136.00        32.00      2840.00     14954.00      1450.00        16.00      1017.00     29669.00
-+-------------------
-+
-+[2021-02-23 09:05:21,682][root][INFO] - Chunked Punctuation report: 
-+label                                                precision    recall       f1           support   
-+ (label_id: 0)                                          95.08      98.11      96.57   16876740
-+! (label_id: 1)                                         33.70      10.09      15.54     290645
-+# (label_id: 2)                                         99.61      99.52      99.57    3541392
-+, (label_id: 3)                                         52.66      40.24      45.62    1447727
-+- (label_id: 4)                                         57.66      22.91      32.79     130953
-+. (label_id: 5)                                         62.89      77.75      69.53    2759312
-+: (label_id: 6)                                         78.52      42.08      54.79       7645
-+? (label_id: 7)                                         70.98      37.06      48.70     716850
-+… (label_id: 8)                                         58.27       6.35      11.46     243286
-+-------------------
-+micro avg                                               89.00      89.00      89.00   26014552
-+macro avg                                               67.71      48.24      52.73   26014552
-+weighted avg                                            88.03      89.00      87.92   26014552
-+
-+-------------------
-+                       !           #           ,           -           .           :           ?           …
-+ 16557577.00     19231.00     15829.00    319520.00     60251.00    272070.00      1746.00     82502.00     86301.00
-+     5837.00     29340.00        16.00     18850.00       800.00     24913.00       120.00      4276.00      2921.00
-+    11597.00        88.00   3524547.00       280.00       800.00       737.00         8.00        88.00        96.00
-+    83677.00     57621.00       136.00    582598.00      9566.00    269820.00       440.00     61935.00     40462.00
-+    10150.00       904.00        56.00      2011.00     29998.00      7605.00        16.00       240.00      1049.00
-+   183939.00    175228.00       744.00    495087.00     19564.00   2145232.00      2058.00    301633.00     87509.00
-+      176.00         0.00         0.00       296.00       128.00       168.00      3217.00        16.00        96.00
-+    22954.00      8169.00        64.00     27597.00      2353.00     38063.00        32.00    265680.00      9397.00
-+      833.00        64.00         0.00      1488.00      7493.00       704.00         8.00       480.00     15455.00
-+-------------------
-+
-+[2021-02-23 09:05:21,687][root][INFO] - Domain report: 
-+label                                                precision    recall       f1           support   
-+0 (label_id: 0)                                        100.00     100.00     100.00     411653
-+-------------------
-+micro avg                                              100.00     100.00     100.00     411653
-+macro avg                                              100.00     100.00     100.00     411653
-+weighted avg                                           100.00     100.00     100.00     411653
-+
-+-------------------
-+           0
-+   411653.00
-+-------------------
-+
-+[2021-02-23 09:05:21,688][root][INFO] - saving to /home/nxingyu/project/Punctuation_with_Domain_discriminator/opencrfacc42021-02-22_09-48-50//test.txt
-+[2021-02-23 09:05:21,785][wandb.sdk.internal.internal][INFO] - Internal process exited
-diff --git a/experiment/testing.py b/experiment/testing.py
-index 3e967b0..77f95ad 100644
---- a/experiment/testing.py
-+++ b/experiment/testing.py
-@@ -1,3 +1,8 @@
-+
-+
-+
-+
-+
- #%%
- import hydra
- import numpy as np
-@@ -20,7 +25,7 @@ import atexit
- from copy import deepcopy
- import snoop
- snoop.install()
--exp='opencrfacc42021-02-22_09-48-50'
-+exp='2021-02-23_09-59-35'
- @hydra.main(config_path=f"../Punctuation_with_Domain_discriminator/{exp}/",config_name="hparams.yaml")
- def main(cfg : DictConfig) -> None:
-     torch.set_printoptions(sci_mode=False)
-@@ -41,7 +46,7 @@ def main(cfg : DictConfig) -> None:
-                     max_seq_length=model.dm.max_seq_length,
-                     punct_label_ids=model.dm.punct_label_ids,
-                     label_map=model.dm.label_map,
--                    labelled=['/home/nxingyu/data/open_subtitles_processed'],
-+                    labelled=['/home/nxingyu/data/ted_talks_processed'],
-                     unlabelled=[],
-                     tokenizer=model.dm.tokenizer,
-                     randomize=model.dm.val_shuffle,
-@@ -49,7 +54,7 @@ def main(cfg : DictConfig) -> None:
-                     tmp_path=model.dm.tmp_path,
-                     attach_label_to_end=model.dm.attach_label_to_end,
-                     no_space_label=model.dm.no_space_label,
--                    pad_start=0,
-+                    pad_start=model.dm.pad_start,
-                     )
-     model.hparams.log_dir=f"/home/nxingyu/project/Punctuation_with_Domain_discriminator/{exp}/"
-     trainer = pl.Trainer(**cfg.trainer)
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/hparams.yaml b/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/hparams.yaml
deleted file mode 100644
index 0537201..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/hparams.yaml
+++ /dev/null
@@ -1,127 +0,0 @@
-seed: 42
-trainer:
-  gpus: 1
-  num_nodes: 1
-  max_epochs: 8
-  max_steps: null
-  accumulate_grad_batches: 4
-  gradient_clip_val: 0
-  amp_level: O1
-  precision: 16
-  accelerator: ddp
-  checkpoint_callback: false
-  logger: false
-  log_every_n_steps: 1
-  val_check_interval: 1.0
-  resume_from_checkpoint: null
-exp_manager:
-  exp_dir: /home/nxingyu/project/
-  name: Punctuation_with_Domain_discriminator
-  create_tensorboard_logger: true
-  create_checkpoint_callback: true
-base_path: /home/nxingyu/data
-tmp_path: /home/nxingyu/data/tmp
-log_dir: /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23
-model:
-  nemo_path: null
-  transformer_path: google/electra-base-discriminator
-  unfrozen: 0
-  maximum_unfrozen: 2
-  unfreeze_step: 1
-  punct_label_ids:
-  - ''
-  - ','
-  - .
-  - '?'
-  - '-'
-  - '!'
-  - ':'
-  - …
-  label_map:
-    —: ','
-    ;: .
-  no_space_label: '#'
-  test_chunk_percent: 0.5
-  pad_start_and_end: 0
-  punct_class_weights: false
-  dataset:
-    data_dir: /home/nxingyu/data
-    labelled:
-    - /home/nxingyu/data/open_subtitles_processed
-    unlabelled: null
-    max_seq_length: 128
-    pad_label: ''
-    ignore_extra_tokens: false
-    ignore_start_end: false
-    use_cache: false
-    num_workers: 8
-    pin_memory: false
-    drop_last: true
-    num_labels: 9
-    num_domains: 2
-    test_unlabelled: true
-    attach_label_to_end: null
-    pad_start: 64
-    train_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 16
-      manual_len: 20000
-    validation_ds:
-      shuffle: true
-      num_samples: -1
-      batch_size: 16
-  tokenizer:
-    tokenizer_name: google/electra-base-discriminator
-    vocab_file: null
-    tokenizer_model: null
-    special_tokens: null
-  language_model:
-    pretrained_model_name: google/electra-base-discriminator
-    lm_checkpoint: null
-    config_file: null
-    config: null
-  punct_head:
-    punct_num_fc_layers: 3
-    fc_dropout: 0.1
-    activation: gelu
-    log_softmax: false
-    use_transformer_init: true
-    loss: dice
-    bilstm: false
-  domain_head:
-    domain_num_fc_layers: 3
-    fc_dropout: 0.1
-    activation: relu
-    log_softmax: false
-    use_transformer_init: true
-    loss: cel
-    gamma: 0.01
-    pooling: mean_max
-    idx_conditioned_on: 0
-  dice_loss:
-    epsilon: 0.01
-    alpha: 2
-    macro_average: true
-  focal_loss:
-    gamma: 3
-  frozen_lr:
-  - 0.02
-  - 0.001
-  - 0.0004
-  - 0.0001
-  - 1.0e-05
-  - 1.0e-06
-  - 1.0e-07
-  optim:
-    name: adamw
-    lr: 0.01
-    weight_decay: 0.0
-    sched:
-      name: CosineAnnealing
-      warmup_steps: null
-      warmup_ratio: 0.1
-      min_lr: 1.0e-08
-      last_epoch: -1
-      monitor: val_loss
-      reduce_on_plateau: false
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/lightning_logs.txt b/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/lightning_logs.txt
deleted file mode 100644
index 2efbbe8..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/lightning_logs.txt
+++ /dev/null
@@ -1,23 +0,0 @@
-Global seed set to 42
-GPU available: True, used: True
-TPU available: None, using: 0 TPU cores
-LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]
-Using native 16bit precision.
-Global seed set to 42
-initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
-
-  | Name                       | Type                 | Params
---------------------------------------------------------------------
-0 | transformer                | ElectraModel         | 108 M 
-1 | punct_classifier           | TokenClassifier      | 1.2 M 
-2 | domain_classifier          | SequenceClassifier   | 4.7 M 
-3 | punctuation_loss           | FocalDiceLoss        | 0     
-4 | domain_loss                | CrossEntropyLoss     | 0     
-5 | agg_loss                   | AggregatorLoss       | 0     
-6 | punct_class_report         | ClassificationReport | 0     
-7 | chunked_punct_class_report | ClassificationReport | 0     
-8 | domain_class_report        | ClassificationReport | 0     
---------------------------------------------------------------------
-5.9 M     Trainable params
-108 M     Non-trainable params
-114 M     Total params
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/nemo_error_log.txt b/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/nemo_error_log.txt
deleted file mode 100644
index 06bde3b..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/nemo_error_log.txt
+++ /dev/null
@@ -1,19 +0,0 @@
-[NeMo W 2021-02-23 14:44:23 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
-[NeMo W 2021-02-23 14:44:57 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:44:57 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:45:02 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:45:02 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:45:02 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:45:03 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
-      warnings.warn(*args, **kwargs)
-    
diff --git a/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/nemo_log_globalrank-0_localrank-0.txt b/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/nemo_log_globalrank-0_localrank-0.txt
deleted file mode 100644
index 4f2b355..0000000
--- a/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23/nemo_log_globalrank-0_localrank-0.txt
+++ /dev/null
@@ -1,21 +0,0 @@
-[NeMo I 2021-02-23 14:44:23 exp_manager:183] Experiments will be logged at /home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_14-44-23
-[NeMo I 2021-02-23 14:44:23 exp_manager:519] TensorboardLogger has been set up
-[NeMo W 2021-02-23 14:44:23 exp_manager:562] trainer had a weights_save_path of cwd(). This was ignored.
-[NeMo W 2021-02-23 14:44:57 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:44:57 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:45:02 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:45:02 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:45:02 nemo_logging:349] /home/nxingyu/project/experiment/models/punctuation_domain_model.py:68: SyntaxWarning: assertion is always true, perhaps remove parentheses?
-      assert(len(self._cfg.model.dataset.labelled)>0,'Please include at least 1 labelled dataset')
-    
-[NeMo W 2021-02-23 14:45:03 nemo_logging:349] /home/nxingyu/miniconda3/envs/NLP/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-processing data loading (e.g. batch size > 1), this can lead to unintended side effects since the samples will be duplicated.
-      warnings.warn(*args, **kwargs)
-    
diff --git a/README.md b/README.md
index 54a7ce0..9c5c823 100644
--- a/README.md
+++ b/README.md
@@ -88,12 +88,14 @@ The process of converting continuous text is as follows:
 ``` console
 bash ~/project/get-data.sh
 
-bash ~/project/experiment/data/disfl2csv.sh /home/nxingyu/data/LDC99T42/treebank_3/dysfl/dff/swbd /home/nxingyu/data/switchboard_processed.csv
-bash ~/project/bin/processandsplit.sh ./switchboard_processed.csv 8 1 1
 
+bash ~/project/experiment/data/disfl2csv.sh /home/nxingyu/data/LDC99T42/treebank_3/dysfl/dff/swbd /home/nxingyu/data/switchboard_processed.csv
 bash ~/project/experiment/data/utt2csv.sh /home/nxingyu/data/utt /home/nxingyu/data/switchboardutt_processed.csv
+python ~/project/processcsv.py -i ~/data/switchboardutt_processed.csv -o ~/data/switchboardutt_processed.csv -c 2000
+python ~/project/processcsv.py -i ~/data/switchboard_processed.csv -o ~/data/switchboard_processed.csv -c 2000
+bash ~/project/bin/processandsplit.sh ./switchboard_processed.csv 8 1 1
 bash ~/project/bin/processandsplit.sh ./switchboardutt_processed.csv 8 1 1
-sed -i 1i"id,transcript" switchboard_*
+sed -i 1i"id,transcript" switchboard*
 
 python ~/project/processcsv.py -i ~/data/ted_talks_en.csv -o ~/data/ted_talks_processed.csv -c 2000
 bash ~/project/bin/processandsplit.sh ./ted_talks_processed.csv 8 1 1
diff --git a/experiment/config.yaml b/experiment/config.yaml
index ffcdd79..fd1cd16 100644
--- a/experiment/config.yaml
+++ b/experiment/config.yaml
@@ -78,13 +78,13 @@ model:
         data_dir: /home/nxingyu/data # /root/data # 
         labelled:
             # - ${base_path}/ted2010 #
-            # - ${base_path}/ted_talks_processed #
-            - ${base_path}/open_subtitles_processed #  
+            - ${base_path}/ted_talks_processed #
+            # - ${base_path}/open_subtitles_processed #  
             # - ${base_path}/switchboardutt_processed #
         unlabelled:
             # - ${base_path}/ted_talks_processed #
             # - ${base_path}/open_subtitles_processed #  
-            # - ${base_path}/switchboardutt_processed
+            - ${base_path}/switchboardutt_processed
         # parameters for dataset preprocessing
         max_seq_length: 128
         pad_label: ''
diff --git a/experiment/data/processdff.py b/experiment/data/processdff.py
index 7e76f7f..b497c2d 100644
--- a/experiment/data/processdff.py
+++ b/experiment/data/processdff.py
@@ -163,4 +163,6 @@ if __name__ == "__main__":
             script+=re.sub('\n',' ',line)
     with open (args.output, 'a') as f:
         writer=csv.writer(f)
-        writer.writerow((args.filename,preprocess(script)))
+        script=preprocess(script).strip()
+        if bool(script):
+            writer.writerow((args.filename,script))
diff --git a/experiment/data/processutt.py b/experiment/data/processutt.py
index d809a43..18e868c 100644
--- a/experiment/data/processutt.py
+++ b/experiment/data/processutt.py
@@ -164,4 +164,6 @@ if __name__ == "__main__":
             script+=re.sub('\n',' ',line)
     with open (args.output, 'a') as f:
         writer=csv.writer(f)
-        writer.writerow((args.filename,preprocess(script)))
+        script=preprocess(script).strip()
+        if bool(script):
+            writer.writerow((args.filename,script))
diff --git a/experiment/info.log b/experiment/info.log
index ad287a0..e69de29 100644
Binary files a/experiment/info.log and b/experiment/info.log differ
