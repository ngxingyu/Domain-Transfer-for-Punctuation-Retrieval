commit hash: e06c976eca0f0f1ece5dd302964c113374b09762
diff --git a/experiment/config.yaml b/experiment/config.yaml
index 2aa798f..29bcd19 100644
--- a/experiment/config.yaml
+++ b/experiment/config.yaml
@@ -1,38 +1,38 @@
 seed: 42
 trainer:
-    # gpus: 1 # the number of gpus, 0 for CPU
-    # num_nodes: 1
-    # max_epochs: 15
-    # max_steps: null # precedence over max_epochs
-    # accumulate_grad_batches: 4 # accumulates grads every k batches
-    # gradient_clip_val: 0
-    # amp_level: O1 # O1/O2 for mixed precision
-    # precision: 16 # Should be set to 16 for O1 and O2, default is 16 as PT ignores it when am_level is O0
-    # accelerator: ddp
-    # checkpoint_callback: false  # Provided by exp_manager
-    # logger: false #false  # Provided by exp_manager
-    # log_every_n_steps: 1  # Interval of logging.
-    # val_check_interval: 1.0  # Set to 0.25 to check 4 times per epoch, or an int for number of iterations
-    # resume_from_checkpoint: null
-
-    gpus: 0 # the number of gpus, 0 for CPU
+    gpus: 1 # the number of gpus, 0 for CPU
     num_nodes: 1
-    max_epochs: 8
+    max_epochs: 6
     max_steps: null # precedence over max_epochs
     accumulate_grad_batches: 4 # accumulates grads every k batches
     gradient_clip_val: 0
-    amp_level: O0 # O1/O2 for mixed precision
-    precision: 32 # Should be set to 16 for O1 and O2, default is 16 as PT ignores it when am_level is O0
-    # accelerator: ddp
+    amp_level: O1 # O1/O2 for mixed precision
+    precision: 16 # Should be set to 16 for O1 and O2, default is 16 as PT ignores it when am_level is O0
+    accelerator: ddp
     checkpoint_callback: false  # Provided by exp_manager
     logger: false #false  # Provided by exp_manager
     log_every_n_steps: 1  # Interval of logging.
     val_check_interval: 1.0  # Set to 0.25 to check 4 times per epoch, or an int for number of iterations
-    reload_dataloaders_every_epoch: true
     resume_from_checkpoint: null
 
+    # gpus: 0 # the number of gpus, 0 for CPU
+    # num_nodes: 1
+    # max_epochs: 8
+    # max_steps: null # precedence over max_epochs
+    # accumulate_grad_batches: 4 # accumulates grads every k batches
+    # gradient_clip_val: 0
+    # amp_level: O0 # O1/O2 for mixed precision
+    # precision: 32 # Should be set to 16 for O1 and O2, default is 16 as PT ignores it when am_level is O0
+    # # accelerator: ddp
+    # checkpoint_callback: false  # Provided by exp_manager
+    # logger: false #false  # Provided by exp_manager
+    # log_every_n_steps: 1  # Interval of logging.
+    # val_check_interval: 1.0  # Set to 0.25 to check 4 times per epoch, or an int for number of iterations
+    # reload_dataloaders_every_epoch: true
+    # resume_from_checkpoint: null
+
 exp_manager:
-    exp_dir: /home/nxingyu2/project/ # /root/project # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
+    exp_dir: /home/nxingyu2/project # /root/project # exp_dir for your experiment, if None, defaults to "./nemo_experiments"
     name: Punctuation_with_Domain_discriminator  # The name of your model
     create_tensorboard_logger: true  # Whether you want exp_manger to create a tb logger
     create_checkpoint_callback: true 
@@ -63,8 +63,8 @@ model:
     dataset:
         data_dir: /home/nxingyu2/data # /root/data # 
         labelled:
-            - ${base_path}/ted_talks_processed #
-            # - ${base_path}/open_subtitles_processed #  
+            # - ${base_path}/ted_talks_processed #
+            - ${base_path}/open_subtitles_processed #  
         unlabelled:
             # - ${base_path}/ted_talks_processed #
             # - ${base_path}/open_subtitles_processed #  
diff --git a/experiment/info.log b/experiment/info.log
index 85bc297..dc33065 100644
--- a/experiment/info.log
+++ b/experiment/info.log
@@ -1,192 +1,4 @@
-[INFO] - GPU available: True, used: False
+[INFO] - GPU available: True, used: True
 [INFO] - TPU available: None, using: 0 TPU cores
-[INFO] - shuffling train set
-[INFO] - Global seed set to 42
-[INFO] - initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
-[INFO] - Optimizer config = AdamW (
-Parameter Group 0
-    amsgrad: False
-    betas: (0.9, 0.999)
-    eps: 1e-08
-    lr: 0.01
-    weight_decay: 0.0
-)
-[INFO] - Scheduler "<core.optim.lr_scheduler.CosineAnnealing object at 0x7f13e0b714f0>" 
-will be used during training (effective maximum steps = 1600) - 
-Parameters : 
-(warmup_steps: null
-warmup_ratio: 0.1
-min_lr: 1.0e-10
-last_epoch: -1
-max_steps: 1600
-)
-[INFO] - 
-  | Name                | Type                 | Params
--------------------------------------------------------------
-0 | transformer         | ElectraModel         | 13.5 M
-1 | punct_classifier    | TokenClassifier      | 2.6 K 
-2 | domain_classifier   | SequenceClassifier   | 513   
-3 | punctuation_loss    | FocalDiceLoss        | 0     
-4 | domain_loss         | CrossEntropyLoss     | 0     
-5 | agg_loss            | AggregatorLoss       | 0     
-6 | punct_class_report  | ClassificationReport | 0     
-7 | domain_class_report | ClassificationReport | 0     
--------------------------------------------------------------
-299 K     Trainable params
-13.2 M    Non-trainable params
-13.5 M    Total params
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          91.10      19.21      31.73       3196
-! (label_id: 1)                                          0.00       0.00       0.00          0
-, (label_id: 2)                                          5.61      37.37       9.76        198
-- (label_id: 3)                                          0.79       9.09       1.46         22
-. (label_id: 4)                                          0.00       0.00       0.00        212
-: (label_id: 5)                                          0.00       0.00       0.00          4
-; (label_id: 6)                                          0.00       0.00       0.00          4
-? (label_id: 7)                                          0.96      62.50       1.88         16
-— (label_id: 8)                                          0.00       0.00       0.00         20
-… (label_id: 9)                                          0.00       0.00       0.00          0
--------------------
-micro avg                                               19.06      19.06      19.06       3672
-macro avg                                               12.31      16.02       5.60       3672
-weighted avg                                            79.60      19.06      28.16       3672
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                        100.00     100.00     100.00         34
--------------------
-micro avg                                              100.00     100.00     100.00         34
-macro avg                                              100.00     100.00     100.00         34
-weighted avg                                           100.00     100.00     100.00         34
-
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          97.76      93.83      95.75     303856
-! (label_id: 1)                                          0.00       0.00       0.00        155
-, (label_id: 2)                                         38.85      59.39      46.98      23143
-- (label_id: 3)                                         72.00      53.11      61.13       1830
-. (label_id: 4)                                         58.36      60.43      59.38      20164
-: (label_id: 5)                                          0.00       0.00       0.00        439
-; (label_id: 6)                                          0.00       0.00       0.00        176
-? (label_id: 7)                                         24.31      36.42      29.15       1590
-— (label_id: 8)                                          6.84       6.23       6.52       1509
-… (label_id: 9)                                          0.00       0.00       0.00        111
--------------------
-micro avg                                               88.58      88.58      88.58     352973
-macro avg                                               29.81      30.94      29.89     352973
-weighted avg                                            90.55      88.58      89.38     352973
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                        100.00     100.00     100.00       3181
--------------------
-micro avg                                              100.00     100.00     100.00       3181
-macro avg                                              100.00     100.00     100.00       3181
-weighted avg                                           100.00     100.00     100.00       3181
-
-[INFO] - Epoch 0, global step 199: val_loss reached 0.27337 (best 0.27337), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-10_14-21-43/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.27-epoch=0.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          97.63      94.98      96.29     303856
-! (label_id: 1)                                          0.00       0.00       0.00        155
-, (label_id: 2)                                         43.70      57.68      49.73      23143
-- (label_id: 3)                                         75.76      51.58      61.38       1830
-. (label_id: 4)                                         58.49      63.93      61.09      20164
-: (label_id: 5)                                          0.00       0.00       0.00        439
-; (label_id: 6)                                          0.00       0.00       0.00        176
-? (label_id: 7)                                         35.78      37.42      36.58       1590
-— (label_id: 8)                                          5.88       7.22       6.48       1509
-… (label_id: 9)                                          0.00       0.00       0.00        111
--------------------
-micro avg                                               89.67      89.67      89.67     352973
-macro avg                                               31.72      31.28      31.15     352973
-weighted avg                                            90.83      89.67      90.15     352973
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                        100.00     100.00     100.00       3181
--------------------
-micro avg                                              100.00     100.00     100.00       3181
-macro avg                                              100.00     100.00     100.00       3181
-weighted avg                                           100.00     100.00     100.00       3181
-
-[INFO] - Epoch 1, global step 399: val_loss reached 0.26732 (best 0.26732), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-10_14-21-43/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.27-epoch=1.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          97.23      95.39      96.30     303856
-! (label_id: 1)                                          0.00       0.00       0.00        155
-, (label_id: 2)                                         47.20      48.78      47.98      23143
-- (label_id: 3)                                         69.68      55.25      61.63       1830
-. (label_id: 4)                                         55.03      67.55      60.65      20164
-: (label_id: 5)                                          0.00       0.00       0.00        439
-; (label_id: 6)                                          0.00       0.00       0.00        176
-? (label_id: 7)                                         28.81      45.91      35.40       1590
-— (label_id: 8)                                          8.17      11.93       9.70       1509
-… (label_id: 9)                                          0.00       0.00       0.00        111
--------------------
-micro avg                                               89.72      89.72      89.72     352973
-macro avg                                               30.61      32.48      31.17     352973
-weighted avg                                            90.47      89.72      90.03     352973
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                        100.00     100.00     100.00       3181
--------------------
-micro avg                                              100.00     100.00     100.00       3181
-macro avg                                              100.00     100.00     100.00       3181
-weighted avg                                           100.00     100.00     100.00       3181
-
-[INFO] - Epoch 2, global step 599: val_loss reached 0.26594 (best 0.26594), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-10_14-21-43/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.27-epoch=2.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          97.60      95.36      96.46     303856
-! (label_id: 1)                                          0.00       0.00       0.00        155
-, (label_id: 2)                                         45.38      58.10      50.96      23143
-- (label_id: 3)                                         70.17      59.40      64.34       1830
-. (label_id: 4)                                         60.79      63.42      62.08      20164
-: (label_id: 5)                                          0.00       0.00       0.00        439
-; (label_id: 6)                                          0.00       0.00       0.00        176
-? (label_id: 7)                                         30.77      51.57      38.54       1590
-— (label_id: 8)                                         10.69       8.48       9.46       1509
-… (label_id: 9)                                          0.00       0.00       0.00        111
--------------------
-micro avg                                               90.10      90.10      90.10     352973
-macro avg                                               31.54      33.63      32.18     352973
-weighted avg                                            91.01      90.10      90.48     352973
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                        100.00     100.00     100.00       3181
--------------------
-micro avg                                              100.00     100.00     100.00       3181
-macro avg                                              100.00     100.00     100.00       3181
-weighted avg                                           100.00     100.00     100.00       3181
-
-[INFO] - Epoch 3, global step 799: val_loss reached 0.25942 (best 0.25942), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-10_14-21-43/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.26-epoch=3.ckpt" as top 3
-[INFO] - Punctuation report: 
-label                                                precision    recall       f1           support   
- (label_id: 0)                                          97.63      95.55      96.58     303856
-! (label_id: 1)                                          0.00       0.00       0.00        155
-, (label_id: 2)                                         46.84      57.30      51.54      23143
-- (label_id: 3)                                         75.90      57.49      65.42       1830
-. (label_id: 4)                                         59.34      67.15      63.00      20164
-: (label_id: 5)                                          0.00       0.00       0.00        439
-; (label_id: 6)                                          0.00       0.00       0.00        176
-? (label_id: 7)                                         33.55      48.62      39.70       1590
-— (label_id: 8)                                         12.65       6.36       8.47       1509
-… (label_id: 9)                                          0.00       0.00       0.00        111
--------------------
-micro avg                                               90.39      90.39      90.39     352973
-macro avg                                               32.59      33.25      32.47     352973
-weighted avg                                            91.10      90.39      90.67     352973
-
-[INFO] - Domain report: 
-label                                                precision    recall       f1           support   
-0 (label_id: 0)                                        100.00     100.00     100.00       3181
--------------------
-micro avg                                              100.00     100.00     100.00       3181
-macro avg                                              100.00     100.00     100.00       3181
-weighted avg                                           100.00     100.00     100.00       3181
-
-[INFO] - Epoch 4, global step 999: val_loss reached 0.26189 (best 0.25942), saving model to "/home/nxingyu2/project/Punctuation_with_Domain_discriminator/2021-02-10_14-21-43/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.26-epoch=4.ckpt" as top 3
+[INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
+[INFO] - Using native 16bit precision.
diff --git a/experiment/models/punctuation_domain_model.py b/experiment/models/punctuation_domain_model.py
index 20e9816..f99acec 100644
--- a/experiment/models/punctuation_domain_model.py
+++ b/experiment/models/punctuation_domain_model.py
@@ -171,7 +171,7 @@ class PunctuationDomainModel(pl.LightningModule, Serialization, FileIO):
 
         self.log('lr', lr, prog_bar=True)
         self.log('train_loss', loss)
-        self.log('gamma', self.grad_reverse.scale)
+        self.log('gamma', self.grad_reverse.scale,logger=True)
 
         return {'loss': loss, 'lr': lr}
 
