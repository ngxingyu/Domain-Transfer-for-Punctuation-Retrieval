Global seed set to 42
GPU available: True, used: True
TPU available: None, using: 0 TPU cores
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
Using native 16bit precision.
Global seed set to 42
initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1

  | Name                       | Type                 | Params
--------------------------------------------------------------------
0 | transformer                | ElectraModel         | 108 M 
1 | punct_classifier           | TokenClassifier      | 1.2 M 
2 | domain_classifier          | SequenceClassifier   | 4.7 M 
3 | punctuation_loss           | FocalDiceLoss        | 0     
4 | domain_loss                | CrossEntropyLoss     | 0     
5 | agg_loss                   | AggregatorLoss       | 0     
6 | punct_class_report         | ClassificationReport | 0     
7 | chunked_punct_class_report | ClassificationReport | 0     
8 | domain_class_report        | ClassificationReport | 0     
--------------------------------------------------------------------
5.9 M     Trainable params
108 M     Non-trainable params
114 M     Total params
Epoch 0, global step 49: val_loss reached 0.32279 (best 0.32279), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-03-56/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.32-epoch=0.ckpt" as top 3
Epoch 1, global step 99: val_loss reached 0.32283 (best 0.32279), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-03-56/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.32-epoch=1.ckpt" as top 3
Epoch 2, global step 149: val_loss reached 0.36743 (best 0.32279), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-03-56/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.37-epoch=2.ckpt" as top 3
Epoch 3, global step 199: val_loss reached 0.31189 (best 0.31189), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-03-56/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.31-epoch=3.ckpt" as top 3
Epoch 4, global step 249: val_loss reached 0.30030 (best 0.30030), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-03-56/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=4.ckpt" as top 3
Epoch 5, step 299: val_loss was not in top 3
Epoch 6, global step 349: val_loss reached 0.29981 (best 0.29981), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-03-56/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=6.ckpt" as top 3
Epoch 7, global step 399: val_loss reached 0.29778 (best 0.29778), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-03-56/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=7.ckpt" as top 3
Saving latest checkpoint...
Global seed set to 42

  | Name                       | Type                 | Params
--------------------------------------------------------------------
0 | transformer                | ElectraModel         | 108 M 
1 | punct_classifier           | TokenClassifier      | 1.2 M 
2 | domain_classifier          | SequenceClassifier   | 4.7 M 
3 | punctuation_loss           | FocalDiceLoss        | 0     
4 | domain_loss                | CrossEntropyLoss     | 0     
5 | agg_loss                   | AggregatorLoss       | 0     
6 | punct_class_report         | ClassificationReport | 0     
7 | chunked_punct_class_report | ClassificationReport | 0     
8 | domain_class_report        | ClassificationReport | 0     
--------------------------------------------------------------------
13.0 M    Trainable params
101 M     Non-trainable params
114 M     Total params
Epoch 0, global step 449: val_loss reached 0.29779 (best 0.29778), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-03-56/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=0.ckpt" as top 3
Epoch 1, global step 499: val_loss reached 0.29778 (best 0.29778), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-03-56/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=1.ckpt" as top 3
Epoch 2, global step 549: val_loss reached 0.29777 (best 0.29777), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-03-56/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=2.ckpt" as top 3
Epoch 3, global step 599: val_loss reached 0.29767 (best 0.29767), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-03-56/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=3.ckpt" as top 3
Epoch 4, global step 649: val_loss reached 0.29766 (best 0.29766), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-03-56/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=4.ckpt" as top 3
Epoch 5, global step 699: val_loss reached 0.29767 (best 0.29766), saving model to "/home/nxingyu/project/Punctuation_with_Domain_discriminator/2021-02-23_10-03-56/checkpoints/Punctuation_with_Domain_discriminator---val_loss=0.30-epoch=5.ckpt" as top 3
Epoch 6, step 749: val_loss was not in top 3
Epoch 7, step 799: val_loss was not in top 3
Global seed set to 42

  | Name                       | Type                 | Params
--------------------------------------------------------------------
0 | transformer                | ElectraModel         | 108 M 
1 | punct_classifier           | TokenClassifier      | 1.2 M 
2 | domain_classifier          | SequenceClassifier   | 4.7 M 
3 | punctuation_loss           | FocalDiceLoss        | 0     
4 | domain_loss                | CrossEntropyLoss     | 0     
5 | agg_loss                   | AggregatorLoss       | 0     
6 | punct_class_report         | ClassificationReport | 0     
7 | chunked_punct_class_report | ClassificationReport | 0     
8 | domain_class_report        | ClassificationReport | 0     
--------------------------------------------------------------------
20.1 M    Trainable params
94.7 M    Non-trainable params
114 M     Total params
